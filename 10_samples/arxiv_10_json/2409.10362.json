{
    "S4.T1.2": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T1.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.2.3.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.3.1.1.1\" style=\"font-size:90%;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.3.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.3.1.2.1\" style=\"font-size:90%;\">Ref</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.3.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.3.1.3.1\" style=\"font-size:90%;\">Data</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.3.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.3.1.4.1\" style=\"font-size:90%;\">Epoch</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.3.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.3.1.5.1\" style=\"font-size:90%;\">Token</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.3.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.3.1.6.1\" style=\"font-size:90%;\">ViT-S</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.4.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.2.4.2.1\"><span class=\"ltx_text\" id=\"S4.T1.2.4.2.1.1\" style=\"font-size:90%;\">Scratch</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.2.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.4.2.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Touvron et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.4.2.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib57\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2021</span></a><span class=\"ltx_text\" id=\"S4.T1.2.4.2.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.2.3\"><span class=\"ltx_text\" id=\"S4.T1.2.4.2.3.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.2.4\"><span class=\"ltx_text\" id=\"S4.T1.2.4.2.4.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.2.5\"><span class=\"ltx_text\" id=\"S4.T1.2.4.2.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.4.2.6\"><span class=\"ltx_text\" id=\"S4.T1.2.4.2.6.1\" style=\"font-size:90%;\">79.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.5.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.2.5.3.1\"><span class=\"ltx_text\" id=\"S4.T1.2.5.3.1.1\" style=\"font-size:90%;\">MAE</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.5.3.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.5.3.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">He et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.5.3.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib29\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022a</span></a><span class=\"ltx_text\" id=\"S4.T1.2.5.3.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.5.3.3\"><span class=\"ltx_text\" id=\"S4.T1.2.5.3.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.5.3.4\"><span class=\"ltx_text\" id=\"S4.T1.2.5.3.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.5.3.5\"><span class=\"ltx_text\" id=\"S4.T1.2.5.3.5.1\" style=\"font-size:90%;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.5.3.6\"><span class=\"ltx_text\" id=\"S4.T1.2.5.3.6.1\" style=\"font-size:90%;\">80.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.6.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.6.4.1\"><span class=\"ltx_text\" id=\"S4.T1.2.6.4.1.1\" style=\"font-size:90%;\">SimMIM</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.6.4.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.6.4.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.6.4.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib63\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T1.2.6.4.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.6.4.3\"><span class=\"ltx_text\" id=\"S4.T1.2.6.4.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.6.4.4\"><span class=\"ltx_text\" id=\"S4.T1.2.6.4.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.6.4.5\"><span class=\"ltx_text\" id=\"S4.T1.2.6.4.5.1\" style=\"font-size:90%;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.6.4.6\"><span class=\"ltx_text\" id=\"S4.T1.2.6.4.6.1\" style=\"font-size:90%;\">80.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.7.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.7.5.1\"><span class=\"ltx_text\" id=\"S4.T1.2.7.5.1.1\" style=\"font-size:90%;\">iBOT</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.7.5.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.7.5.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Zhou et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.7.5.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib72\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T1.2.7.5.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.7.5.3\"><span class=\"ltx_text\" id=\"S4.T1.2.7.5.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.7.5.4\"><span class=\"ltx_text\" id=\"S4.T1.2.7.5.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.7.5.5\"><span class=\"ltx_text\" id=\"S4.T1.2.7.5.5.1\" style=\"font-size:90%;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.7.5.6\"><span class=\"ltx_text\" id=\"S4.T1.2.7.5.6.1\" style=\"font-size:90%;\">81.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.8.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.8.6.1\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.8.6.1.1\" style=\"font-size:90%;\">BEiT</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.8.6.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.8.6.2.1\" style=\"font-size:90%;\"><cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_text\" style=\"font-size:90%;\">Bao et&#160;al.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib3\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a>)</cite></span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.8.6.3\"><span class=\"ltx_text\" id=\"S4.T1.2.8.6.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.8.6.4\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.8.6.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.8.6.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.8.6.5.1\" style=\"font-size:90%;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.8.6.6\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.8.6.6.1\" style=\"font-size:90%;\">81.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.9.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.9.7.1\"><span class=\"ltx_text\" id=\"S4.T1.2.9.7.1.1\" style=\"font-size:90%;\">+ DALL-E</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.10.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.10.8.1\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.1.1\" style=\"font-size:90%;\">AttMask</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.10.8.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Kakogeorgiou et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.10.8.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib32\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T1.2.10.8.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.10.8.3\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.10.8.4\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.10.8.5\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.5.1\" style=\"font-size:90%;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.10.8.6\"><span class=\"ltx_text\" id=\"S4.T1.2.10.8.6.1\" style=\"font-size:90%;\">81.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.11.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.11.9.1\"><span class=\"ltx_text\" id=\"S4.T1.2.11.9.1.1\" style=\"font-size:90%;\">MoCo V3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.11.9.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.11.9.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Ci et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.11.9.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib16\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T1.2.11.9.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.11.9.3\"><span class=\"ltx_text\" id=\"S4.T1.2.11.9.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.11.9.4\"><span class=\"ltx_text\" id=\"S4.T1.2.11.9.4.1\" style=\"font-size:90%;\">600</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.11.9.5\"><span class=\"ltx_text\" id=\"S4.T1.2.11.9.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.11.9.6\"><span class=\"ltx_text\" id=\"S4.T1.2.11.9.6.1\" style=\"font-size:90%;\">81.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.12.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.12.10.1\"><span class=\"ltx_text\" id=\"S4.T1.2.12.10.1.1\" style=\"font-size:90%;\">DINO</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.12.10.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.12.10.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Caron et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.12.10.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib7\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2021</span></a><span class=\"ltx_text\" id=\"S4.T1.2.12.10.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.12.10.3\"><span class=\"ltx_text\" id=\"S4.T1.2.12.10.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.12.10.4\"><span class=\"ltx_text\" id=\"S4.T1.2.12.10.4.1\" style=\"font-size:90%;\">1600</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.12.10.5\"><span class=\"ltx_text\" id=\"S4.T1.2.12.10.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.12.10.6\"><span class=\"ltx_text\" id=\"S4.T1.2.12.10.6.1\" style=\"font-size:90%;\">81.5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.13.11\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.13.11.1\"><span class=\"ltx_text\" id=\"S4.T1.2.13.11.1.1\" style=\"font-size:90%;\">MFM</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.13.11.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.2.13.11.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.2.13.11.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib62\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2023</span></a><span class=\"ltx_text\" id=\"S4.T1.2.13.11.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.13.11.3\"><span class=\"ltx_text\" id=\"S4.T1.2.13.11.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.13.11.4\"><span class=\"ltx_text\" id=\"S4.T1.2.13.11.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.13.11.5\"><span class=\"ltx_text\" id=\"S4.T1.2.13.11.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.13.11.6\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T1.2.13.11.6.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T1.2.13.11.6.2\" style=\"font-size:90%;\">81.6</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.1\">\n<span class=\"ltx_text\" id=\"S4.T1.1.1.1.1\" style=\"font-size:90%;\">MFM</span><sup class=\"ltx_sup\" id=\"S4.T1.1.1.1.2\"><span class=\"ltx_text\" id=\"S4.T1.1.1.1.2.1\" style=\"font-size:90%;\">&#8727;</span></sup>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T1.1.1.2.1.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T1.1.1.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib62\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2023</span></a><span class=\"ltx_text\" id=\"S4.T1.1.1.2.3.3\" style=\"font-size:90%;\">)</span></cite></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.3\"><span class=\"ltx_text\" id=\"S4.T1.1.1.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.4\"><span class=\"ltx_text\" id=\"S4.T1.1.1.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.5\"><span class=\"ltx_text\" id=\"S4.T1.1.1.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.6\"><span class=\"ltx_text\" id=\"S4.T1.1.1.6.1\" style=\"font-size:90%;\">81.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.14.12\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.14.12.1\"><span class=\"ltx_text\" id=\"S4.T1.2.14.12.1.1\" style=\"font-size:90%;\">MFM</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.14.12.2\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.14.12.2.1\" style=\"font-size:90%;\"><cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib62\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2023</span></a>)</cite></span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.14.12.3\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.14.12.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.14.12.4\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.14.12.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.14.12.5\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.14.12.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.2.14.12.6\" rowspan=\"2\"><span class=\"ltx_text\" id=\"S4.T1.2.14.12.6.1\" style=\"font-size:90%;\">81.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T1.2.2.1\">\n<span class=\"ltx_text\" id=\"S4.T1.2.2.1.1\" style=\"font-size:90%;\">+ R/Com</span><sup class=\"ltx_sup\" id=\"S4.T1.2.2.1.2\"><span class=\"ltx_text\" id=\"S4.T1.2.2.1.2.1\" style=\"font-size:90%;\">&#8727;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.15.13\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T1.2.15.13.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.15.13.1.1\" style=\"font-size:90%;\">FOLK</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.15.13.2\"><span class=\"ltx_text\" id=\"S4.T1.2.15.13.2.1\" style=\"font-size:90%;\">Ours</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.15.13.3\"><span class=\"ltx_text\" id=\"S4.T1.2.15.13.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.15.13.4\"><span class=\"ltx_text\" id=\"S4.T1.2.15.13.4.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.15.13.5\"><span class=\"ltx_text\" id=\"S4.T1.2.15.13.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.2.15.13.6\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T1.2.15.13.6.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T1.2.15.13.6.2\" style=\"font-size:90%;\">81.6</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.2.16.14\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T1.2.16.14.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.16.14.1.1\" style=\"font-size:90%;\">FOLK</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.16.14.2\"><span class=\"ltx_text\" id=\"S4.T1.2.16.14.2.1\" style=\"font-size:90%;\">Ours</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.16.14.3\"><span class=\"ltx_text\" id=\"S4.T1.2.16.14.3.1\" style=\"font-size:90%;\">ImageNet-1K</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.16.14.4\"><span class=\"ltx_text\" id=\"S4.T1.2.16.14.4.1\" style=\"font-size:90%;\">800</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.16.14.5\"><span class=\"ltx_text\" id=\"S4.T1.2.16.14.5.1\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T1.2.16.14.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.2.16.14.6.1\" style=\"font-size:90%;\">82.1</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 1:  Top-1 results of fine-tuning self-supervised approaches utilizing ViT-S/16 as an encoder for ImageNet-1K. All recorded data were resized to images of size  224 × 224 224 224 224\\times 224 224 × 224 . Data means the pre-training dataset, and token means methods that need a masked token.  ∗ Our reproduced results with MFM official code through a pre-training phase of  300 300 300 300  epochs followed by  200 200 200 200  epochs of full fine-tuning. Also, MFM + R/Com means using the MFM approach with our proposed filters, instead of its original low/high-pass filters.",
        "footnotes": [
            "Touvron et al. [2021] \nHugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Hervé Jégou.\n \n Training data-efficient image transformers & distillation through attention.\n \n In  International conference on machine learning , pages 10347–10357. PMLR, 2021.\n \n",
            "He et al. [2022a] \nKaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick.\n \n Masked autoencoders are scalable vision learners.\n \n In  Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 16000–16009, 2022a.\n \n",
            "Xie et al. [2022] \nZhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, and Han Hu.\n \n Simmim: A simple framework for masked image modeling.\n \n In  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 9653–9663, 2022.\n \n",
            "Zhou et al. [2022] \nJinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.\n \n ibot: Image bert pre-training with online tokenizer.\n \n International Conference on Learning Representations (ICLR) , 2022.\n \n",
            "Bao et al. [2022] \nHangbo Bao, Li Dong, Songhao Piao, and Furu Wei.\n \n Beit: Bert pre-training of image transformers.\n \n In  International Conference on Learning Representations , 2022.\n \n",
            "Kakogeorgiou et al. [2022] \nIoannis Kakogeorgiou, Spyros Gidaris, Bill Psomas, Yannis Avrithis, Andrei Bursuc, Konstantinos Karantzalos, and Nikos Komodakis.\n \n What to hide from your students: Attention-guided masked image modeling.\n \n In  European Conference on Computer Vision , pages 300–318. Springer, 2022.\n \n",
            "Ci et al. [2022] \nYuanzheng Ci, Chen Lin, Lei Bai, and Wanli Ouyang.\n \n Fast-moco: Boost momentum-based contrastive learning with combinatorial patches.\n \n In  European Conference on Computer Vision , pages 290–306. Springer, 2022.\n \n",
            "Caron et al. [2021] \nMathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.\n \n Emerging properties in self-supervised vision transformers.\n \n In  Proceedings of the IEEE/CVF international conference on computer vision , pages 9650–9660, 2021.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n"
        ],
        "references": [
            "In Table 1, notably, the traditional training from scratch method achieves a baseline accuracy of 79.9%percent79.979.9\\%79.9 %, which sets the stage for evaluating the added value of SSL strategies. Models employing masked token (i.e. image patch) strategies, such as MAE, SimMIM, BEiT, and AttMask, show a notable improvement over the baseline, with accuracies ranging from 80.6%percent80.680.6\\%80.6 % to 81.3%percent81.381.3\\%81.3 %. This highlights the potential benefits of using masked tokens in training to boost model performance. However, these methods only work with image token-based models, such as ViTs."
        ]
    },
    "S4.T2.6": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S4.T2.6\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.6.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.1.1\" style=\"font-size:90%;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.2.1\" style=\"font-size:90%;\">Base LR = 2e-4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.3.1\" style=\"font-size:90%;\">Base LR = 2e-4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.4.1\" style=\"font-size:90%;\">Base LR = 2e-3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.1.1.5\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.1.1.5.1\" style=\"font-size:90%;\">AVG</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.2.2.1.1\" style=\"font-size:90%;\">Warm Up = 0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.2.2.2.1\" style=\"font-size:90%;\">Warm Up = 100</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.2.2.3.1\" style=\"font-size:90%;\">Warm Up = 5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.3.3.1\"><span class=\"ltx_text\" id=\"S4.T2.6.3.3.1.1\" style=\"font-size:90%;\">iBOT</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.3.3.2\"><span class=\"ltx_text\" id=\"S4.T2.6.3.3.2.1\" style=\"font-size:90%;\">64.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.3.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.3.3.3.1\" style=\"font-size:90%;\">71.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T2.6.3.3.4\"><span class=\"ltx_text\" id=\"S4.T2.6.3.3.4.1\" style=\"font-size:90%;\">2.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.6.3.3.5\"><span class=\"ltx_text\" id=\"S4.T2.6.3.3.5.1\" style=\"font-size:90%;\">45.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.4.4.1\"><span class=\"ltx_text\" id=\"S4.T2.6.4.4.1.1\" style=\"font-size:90%;\">AttMask</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.4.4.2\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T2.6.4.4.2.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T2.6.4.4.2.2\" style=\"font-size:90%;\">69.8</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.4.4.3\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T2.6.4.4.3.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T2.6.4.4.3.2\" style=\"font-size:90%;\">71.0</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.4.4.4\"><span class=\"ltx_text\" id=\"S4.T2.6.4.4.4.1\" style=\"font-size:90%;\">31.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.4.4.5\"><span class=\"ltx_text\" id=\"S4.T2.6.4.4.5.1\" style=\"font-size:90%;\">57.4</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.5.5.1\"><span class=\"ltx_text\" id=\"S4.T2.6.5.5.1.1\" style=\"font-size:90%;\">MFM</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.5.5.2\"><span class=\"ltx_text\" id=\"S4.T2.6.5.5.2.1\" style=\"font-size:90%;\">57.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.5.5.3\"><span class=\"ltx_text\" id=\"S4.T2.6.5.5.3.1\" style=\"font-size:90%;\">58.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.5.5.4\"><span class=\"ltx_text\" id=\"S4.T2.6.5.5.4.1\" style=\"font-size:90%;\">41.9</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.5.5.5\"><span class=\"ltx_text\" id=\"S4.T2.6.5.5.5.1\" style=\"font-size:90%;\">52.7</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.1\"><span class=\"ltx_text\" id=\"S4.T2.6.6.6.1.1\" style=\"font-size:90%;\">MFM + Com/RCom</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.2\"><span class=\"ltx_text\" id=\"S4.T2.6.6.6.2.1\" style=\"font-size:90%;\">66.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.3\"><span class=\"ltx_text\" id=\"S4.T2.6.6.6.3.1\" style=\"font-size:90%;\">63.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T2.6.6.6.4\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T2.6.6.6.4.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T2.6.6.6.4.2\" style=\"font-size:90%;\">59.9</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.6.6.6.5\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T2.6.6.6.5.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T2.6.6.6.5.2\" style=\"font-size:90%;\">63.4</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.6.7.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T2.6.7.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.1.1\" style=\"font-size:90%;\">FOLK</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T2.6.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.2.1\" style=\"font-size:90%;\">71.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T2.6.7.7.3\"><span class=\"ltx_text\" id=\"S4.T2.6.7.7.3.1\" style=\"font-size:90%;\">68.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"S4.T2.6.7.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.4.1\" style=\"font-size:90%;\">62.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T2.6.7.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.6.7.7.5.1\" style=\"font-size:90%;\">67.2</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 2:  Results of few-shot learning that fine-tunes the pre-trained ViT-S with different approaches for  200 200 200 200  epoch with  10 % percent 10 10\\% 10 %  of labeled data from ImageNet-1k. Base LR means the peak value of the learning rate, and Warm Up refers to the initial epochs during which the learning rate increases from 0 to the predefined Base LR. After reaching the Base LR, the learning rate then decreases according to a cosine function, from the Base LR back down to 0. AVG: average.",
        "footnotes": [],
        "references": [
            "Table 2 demonstrates the potential of our approach to effectively leverage small datasets, making it especially relevant for applications where data is scarce. The MFM model does not perform well with limited data in downstream tasks assumably because, during the pretext task, MFM does not see the original image without augmentation. And this limitation has been addressed in our proposed FOLK method, owing to the self-distillation design. FOLK is more robust in different training settings compared to other methods."
        ]
    },
    "S4.T3.5": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.5\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T3.5.6.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T3.5.6.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.6.1.1.1\" style=\"font-size:90%;\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.5.6.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.6.1.2.1\" style=\"font-size:90%;\">mIoU</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" id=\"S4.T3.1.1.1\">\n<span class=\"ltx_text\" id=\"S4.T3.1.1.1.1\" style=\"font-size:90%;\">Supervised Learning</span><sup class=\"ltx_sup\" id=\"S4.T3.1.1.1.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.2.1\" style=\"font-size:90%;\">&#8729;</span></sup><span class=\"ltx_text\" id=\"S4.T3.1.1.1.3\" style=\"font-size:90%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T3.1.1.1.4.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Zhou et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T3.1.1.1.5.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib72\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T3.1.1.1.6.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T3.1.1.2\"><span class=\"ltx_text\" id=\"S4.T3.1.1.2.1\" style=\"font-size:90%;\">44.5</span></th>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.7.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\" id=\"S4.T3.5.7.2.1\">\n<span class=\"ltx_text\" id=\"S4.T3.5.7.2.1.1\" style=\"font-size:90%;\">iBOT </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T3.5.7.2.1.2.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Zhou et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T3.5.7.2.1.3.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib72\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T3.5.7.2.1.4.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" id=\"S4.T3.5.7.2.2\">\n<span class=\"ltx_ERROR undefined\" id=\"S4.T3.5.7.2.2.1\">\\ul</span><span class=\"ltx_text\" id=\"S4.T3.5.7.2.2.2\" style=\"font-size:90%;\">45.4</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.2.2.1\">\n<span class=\"ltx_text\" id=\"S4.T3.2.2.1.1\" style=\"font-size:90%;\">iBOT</span><math alttext=\"+\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.2.2.1.m1.1\"><semantics id=\"S4.T3.2.2.1.m1.1a\"><mo id=\"S4.T3.2.2.1.m1.1.1\" mathsize=\"90%\" xref=\"S4.T3.2.2.1.m1.1.1.cmml\">+</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.1.m1.1b\"><plus id=\"S4.T3.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.1.m1.1c\">+</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T3.2.2.1.m1.1d\">+</annotation></semantics></math><span class=\"ltx_text\" id=\"S4.T3.2.2.1.2\" style=\"font-size:90%;\">AttMask </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T3.2.2.1.3.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Kakogeorgiou et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T3.2.2.1.4.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib32\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2022</span></a><span class=\"ltx_text\" id=\"S4.T3.2.2.1.5.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.2.2.2\"><span class=\"ltx_text\" id=\"S4.T3.2.2.2.1\" style=\"font-size:90%;\">45.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.3.3.1\">\n<span class=\"ltx_text\" id=\"S4.T3.3.3.1.1\" style=\"font-size:90%;\">MFM</span><sup class=\"ltx_sup\" id=\"S4.T3.3.3.1.2\"><span class=\"ltx_text\" id=\"S4.T3.3.3.1.2.1\" style=\"font-size:90%;\">&#8727;</span></sup><span class=\"ltx_text\" id=\"S4.T3.3.3.1.3\" style=\"font-size:90%;\"> </span><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"S4.T3.3.3.1.4.1\" style=\"font-size:90%;\">(</span><span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span><span class=\"ltx_text\" id=\"S4.T3.3.3.1.5.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib62\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2023</span></a><span class=\"ltx_text\" id=\"S4.T3.3.3.1.6.3\" style=\"font-size:90%;\">)</span></cite>\n</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.3.3.2\"><span class=\"ltx_text\" id=\"S4.T3.3.3.2.1\" style=\"font-size:90%;\">44.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.4.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" id=\"S4.T3.4.4.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.4.4.1.1\" style=\"font-size:90%;\">FOLK<sup class=\"ltx_sup\" id=\"S4.T3.4.4.1.1.1\"><span class=\"ltx_text ltx_font_medium ltx_font_italic\" id=\"S4.T3.4.4.1.1.1.1\">&#8224;</span></sup></span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T3.4.4.2\"><span class=\"ltx_text\" id=\"S4.T3.4.4.2.1\" style=\"font-size:90%;\">45.3</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" id=\"S4.T3.5.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.5.1.1\" style=\"font-size:90%;\">FOLK<sup class=\"ltx_sup\" id=\"S4.T3.5.5.1.1.1\"><span class=\"ltx_text ltx_font_medium ltx_font_italic\" id=\"S4.T3.5.5.1.1.1.1\">&#8225;</span></sup></span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"S4.T3.5.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.5.5.2.1\" style=\"font-size:90%;\">45.5</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 3:  The full fine-tuning ViT-S/16 model for semantic segmentation task with ADE20K dataset.  ∙  Supervised Learning result taken from iBOT paper.  ∗  We produced MFM results with their official code. FOLK was pre-trained with  †  300 and  ‡  800 epochs.",
        "footnotes": [
            "Zhou et al. [2022] \nJinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.\n \n ibot: Image bert pre-training with online tokenizer.\n \n International Conference on Learning Representations (ICLR) , 2022.\n \n",
            "Zhou et al. [2022] \nJinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.\n \n ibot: Image bert pre-training with online tokenizer.\n \n International Conference on Learning Representations (ICLR) , 2022.\n \n",
            "Kakogeorgiou et al. [2022] \nIoannis Kakogeorgiou, Spyros Gidaris, Bill Psomas, Yannis Avrithis, Andrei Bursuc, Konstantinos Karantzalos, and Nikos Komodakis.\n \n What to hide from your students: Attention-guided masked image modeling.\n \n In  European Conference on Computer Vision , pages 300–318. Springer, 2022.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n"
        ],
        "references": [
            "Results of this fine-tuning effort for the semantic segmentation task on the ADE20K dataset are shown in Table 3. It presents a comparative analysis of different methodologies: Supervised Learning, iBOT, iBOT with Attention Mask (AttMask), MFM, and our FOLK model at different pre-training epochs (300300300300 and 800800800800 epochs). Notably, the FOLK model with 800800800800 epochs of pre-training achieves the highest mIoU at 45.545.545.545.5, slightly surpassing the iBOT’s 45.445.445.445.4 mIoU. This indicates a successful adaptation of the FOLK methodology, showing not only an improvement over the MFM results but also demonstrating that extended pre-training can lead to marginal yet significant performance gains. Furthermore, even at 300300300300 pre-training epochs, FOLK performs comparably to other advanced methods, highlighting its efficacy in leveraging the dataset and architecture for semantic segmentation tasks."
        ]
    },
    "S4.T4.6": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.6\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.6.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.6.6.7\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.6.6.7.1\" style=\"font-size:90%;\">Param</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.1\"><math alttext=\"\\alpha=4\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.1.1.1.m1.1\"><semantics id=\"S4.T4.1.1.1.m1.1a\"><mrow id=\"S4.T4.1.1.1.m1.1.1\" xref=\"S4.T4.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T4.1.1.1.m1.1.1.2\" mathsize=\"90%\" xref=\"S4.T4.1.1.1.m1.1.1.2.cmml\">&#945;</mi><mo id=\"S4.T4.1.1.1.m1.1.1.1\" mathsize=\"90%\" xref=\"S4.T4.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T4.1.1.1.m1.1.1.3\" mathsize=\"90%\" xref=\"S4.T4.1.1.1.m1.1.1.3.cmml\">4</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.m1.1b\"><apply id=\"S4.T4.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\"><eq id=\"S4.T4.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.1\"/><ci id=\"S4.T4.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.2\">&#120572;</ci><cn id=\"S4.T4.1.1.1.m1.1.1.3.cmml\" type=\"integer\" xref=\"S4.T4.1.1.1.m1.1.1.3\">4</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.m1.1c\">\\alpha=4</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.1.1.1.m1.1d\">italic_&#945; = 4</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.2.2.2\"><math alttext=\"\\alpha=3\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.2.2.2.m1.1\"><semantics id=\"S4.T4.2.2.2.m1.1a\"><mrow id=\"S4.T4.2.2.2.m1.1.1\" xref=\"S4.T4.2.2.2.m1.1.1.cmml\"><mi id=\"S4.T4.2.2.2.m1.1.1.2\" mathsize=\"90%\" xref=\"S4.T4.2.2.2.m1.1.1.2.cmml\">&#945;</mi><mo id=\"S4.T4.2.2.2.m1.1.1.1\" mathsize=\"90%\" xref=\"S4.T4.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T4.2.2.2.m1.1.1.3\" mathsize=\"90%\" xref=\"S4.T4.2.2.2.m1.1.1.3.cmml\">3</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.m1.1b\"><apply id=\"S4.T4.2.2.2.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1\"><eq id=\"S4.T4.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.1\"/><ci id=\"S4.T4.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T4.2.2.2.m1.1.1.2\">&#120572;</ci><cn id=\"S4.T4.2.2.2.m1.1.1.3.cmml\" type=\"integer\" xref=\"S4.T4.2.2.2.m1.1.1.3\">3</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.m1.1c\">\\alpha=3</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.2.2.2.m1.1d\">italic_&#945; = 3</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.3.3.3\"><math alttext=\"\\alpha=2\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.3.3.3.m1.1\"><semantics id=\"S4.T4.3.3.3.m1.1a\"><mrow id=\"S4.T4.3.3.3.m1.1.1\" xref=\"S4.T4.3.3.3.m1.1.1.cmml\"><mi id=\"S4.T4.3.3.3.m1.1.1.2\" mathsize=\"90%\" xref=\"S4.T4.3.3.3.m1.1.1.2.cmml\">&#945;</mi><mo id=\"S4.T4.3.3.3.m1.1.1.1\" mathsize=\"90%\" xref=\"S4.T4.3.3.3.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T4.3.3.3.m1.1.1.3\" mathsize=\"90%\" xref=\"S4.T4.3.3.3.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.3.3.3.m1.1b\"><apply id=\"S4.T4.3.3.3.m1.1.1.cmml\" xref=\"S4.T4.3.3.3.m1.1.1\"><eq id=\"S4.T4.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T4.3.3.3.m1.1.1.1\"/><ci id=\"S4.T4.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T4.3.3.3.m1.1.1.2\">&#120572;</ci><cn id=\"S4.T4.3.3.3.m1.1.1.3.cmml\" type=\"integer\" xref=\"S4.T4.3.3.3.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.3.3.3.m1.1c\">\\alpha=2</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.3.3.3.m1.1d\">italic_&#945; = 2</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.4.4.4\"><math alttext=\"\\alpha=1\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.4.4.4.m1.1\"><semantics id=\"S4.T4.4.4.4.m1.1a\"><mrow id=\"S4.T4.4.4.4.m1.1.1\" xref=\"S4.T4.4.4.4.m1.1.1.cmml\"><mi id=\"S4.T4.4.4.4.m1.1.1.2\" mathsize=\"90%\" xref=\"S4.T4.4.4.4.m1.1.1.2.cmml\">&#945;</mi><mo id=\"S4.T4.4.4.4.m1.1.1.1\" mathsize=\"90%\" xref=\"S4.T4.4.4.4.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T4.4.4.4.m1.1.1.3\" mathsize=\"90%\" xref=\"S4.T4.4.4.4.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.4.4.4.m1.1b\"><apply id=\"S4.T4.4.4.4.m1.1.1.cmml\" xref=\"S4.T4.4.4.4.m1.1.1\"><eq id=\"S4.T4.4.4.4.m1.1.1.1.cmml\" xref=\"S4.T4.4.4.4.m1.1.1.1\"/><ci id=\"S4.T4.4.4.4.m1.1.1.2.cmml\" xref=\"S4.T4.4.4.4.m1.1.1.2\">&#120572;</ci><cn id=\"S4.T4.4.4.4.m1.1.1.3.cmml\" type=\"integer\" xref=\"S4.T4.4.4.4.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.4.4.4.m1.1c\">\\alpha=1</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.4.4.4.m1.1d\">italic_&#945; = 1</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S4.T4.5.5.5\"><math alttext=\"\\alpha=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.5.5.5.m1.1\"><semantics id=\"S4.T4.5.5.5.m1.1a\"><mrow id=\"S4.T4.5.5.5.m1.1.1\" xref=\"S4.T4.5.5.5.m1.1.1.cmml\"><mi id=\"S4.T4.5.5.5.m1.1.1.2\" mathsize=\"90%\" xref=\"S4.T4.5.5.5.m1.1.1.2.cmml\">&#945;</mi><mo id=\"S4.T4.5.5.5.m1.1.1.1\" mathsize=\"90%\" xref=\"S4.T4.5.5.5.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T4.5.5.5.m1.1.1.3\" mathsize=\"90%\" xref=\"S4.T4.5.5.5.m1.1.1.3.cmml\">0.1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.5.5.5.m1.1b\"><apply id=\"S4.T4.5.5.5.m1.1.1.cmml\" xref=\"S4.T4.5.5.5.m1.1.1\"><eq id=\"S4.T4.5.5.5.m1.1.1.1.cmml\" xref=\"S4.T4.5.5.5.m1.1.1.1\"/><ci id=\"S4.T4.5.5.5.m1.1.1.2.cmml\" xref=\"S4.T4.5.5.5.m1.1.1.2\">&#120572;</ci><cn id=\"S4.T4.5.5.5.m1.1.1.3.cmml\" type=\"float\" xref=\"S4.T4.5.5.5.m1.1.1.3\">0.1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.5.5.5.m1.1c\">\\alpha=0.1</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.5.5.5.m1.1d\">italic_&#945; = 0.1</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.6.6.6\"><math alttext=\"\\alpha=0.05\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.6.6.6.m1.1\"><semantics id=\"S4.T4.6.6.6.m1.1a\"><mrow id=\"S4.T4.6.6.6.m1.1.1\" xref=\"S4.T4.6.6.6.m1.1.1.cmml\"><mi id=\"S4.T4.6.6.6.m1.1.1.2\" mathsize=\"90%\" xref=\"S4.T4.6.6.6.m1.1.1.2.cmml\">&#945;</mi><mo id=\"S4.T4.6.6.6.m1.1.1.1\" mathsize=\"90%\" xref=\"S4.T4.6.6.6.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T4.6.6.6.m1.1.1.3\" mathsize=\"90%\" xref=\"S4.T4.6.6.6.m1.1.1.3.cmml\">0.05</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.6.6.6.m1.1b\"><apply id=\"S4.T4.6.6.6.m1.1.1.cmml\" xref=\"S4.T4.6.6.6.m1.1.1\"><eq id=\"S4.T4.6.6.6.m1.1.1.1.cmml\" xref=\"S4.T4.6.6.6.m1.1.1.1\"/><ci id=\"S4.T4.6.6.6.m1.1.1.2.cmml\" xref=\"S4.T4.6.6.6.m1.1.1.2\">&#120572;</ci><cn id=\"S4.T4.6.6.6.m1.1.1.3.cmml\" type=\"float\" xref=\"S4.T4.6.6.6.m1.1.1.3\">0.05</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.6.6.6.m1.1c\">\\alpha=0.05</annotation><annotation encoding=\"application/x-llamapun\" id=\"S4.T4.6.6.6.m1.1d\">italic_&#945; = 0.05</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.6.7.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.6.7.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.6.7.1.1.1\" style=\"font-size:90%;\">Acc</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.6.7.1.2\"><span class=\"ltx_text\" id=\"S4.T4.6.7.1.2.1\" style=\"font-size:90%;\">80.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.6.7.1.3\"><span class=\"ltx_text\" id=\"S4.T4.6.7.1.3.1\" style=\"font-size:90%;\">80.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.6.7.1.4\"><span class=\"ltx_text\" id=\"S4.T4.6.7.1.4.1\" style=\"font-size:90%;\">81.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.6.7.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.6.7.1.5.1\" style=\"font-size:90%;\">81.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T4.6.7.1.6\">\n<span class=\"ltx_text\" id=\"S4.T4.6.7.1.6.1\" style=\"font-size:90%;\"/><span class=\"ltx_ERROR undefined\" id=\"S4.T4.6.7.1.6.2\">\\ul</span><span class=\"ltx_text\" id=\"S4.T4.6.7.1.6.3\" style=\"font-size:90%;\">81.4</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T4.6.7.1.7\">\n<span class=\"ltx_text\" id=\"S4.T4.6.7.1.7.1\" style=\"font-size:90%;\"/><span class=\"ltx_ERROR undefined\" id=\"S4.T4.6.7.1.7.2\">\\ul</span><span class=\"ltx_text\" id=\"S4.T4.6.7.1.7.3\" style=\"font-size:90%;\">81.4</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 4:  Effect of  α 𝛼 \\alpha italic_α  values in  ℒ tot subscript ℒ tot \\mathcal{L}_{\\text{tot}} caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT  on top 1 accuracy for a ViT-S/16 model using FOLK methodology.",
        "footnotes": [],
        "references": [
            "We explore the optimal weight values for ℒtotsubscriptℒtot\\mathcal{L}_{\\text{tot}}caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT, introduced in Eq. 6. Table 4 provides an insight into how variations in the parameter α𝛼\\alphaitalic_α influence the Top 1 Accuracy of a ViT-S/16 model employing the FOLK methodology. As α𝛼\\alphaitalic_α is adjusted from 4444 down to 0.050.050.050.05, a clear trend is observed where the model’s accuracy improves notably when α𝛼\\alphaitalic_α is reduced from 4444 to 1111, peaking at an accuracy of 81.6%percent81.681.6\\%81.6 % at α=1𝛼1\\alpha=1italic_α = 1. This suggests that a lower α𝛼\\alphaitalic_α enhances the model’s performance, potentially indicating an optimal configuration of the loss function ℒtotsubscriptℒtot\\mathcal{L}_{\\text{tot}}caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT at this point."
        ]
    },
    "A2.T5.2": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T5.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T5.2.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T5.2.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.1.1.1.1\" style=\"font-size:90%;\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T5.2.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.1.1.2.1\" style=\"font-size:90%;\">Ref</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T5.2.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.1.1.3.1\" style=\"font-size:90%;\">Epoch</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T5.2.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.1.1.4.1\" style=\"font-size:90%;\">Top-1 Acc</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T5.2.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T5.2.2.1.1\"><span class=\"ltx_text\" id=\"A2.T5.2.2.1.1.1\" style=\"font-size:90%;\">SimSiam</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.1.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.2.1.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Chen and He</span><span class=\"ltx_text\" id=\"A2.T5.2.2.1.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib13\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2021</span></a><span class=\"ltx_text\" id=\"A2.T5.2.2.1.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.1.3\"><span class=\"ltx_text\" id=\"A2.T5.2.2.1.3.1\" style=\"font-size:90%;\">400</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T5.2.2.1.4\"><span class=\"ltx_text\" id=\"A2.T5.2.2.1.4.1\" style=\"font-size:90%;\">79.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.2.3.2.1\"><span class=\"ltx_text\" id=\"A2.T5.2.3.2.1.1\" style=\"font-size:90%;\">MoCo v2</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.3.2.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.3.2.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Chen et&#160;al.</span><span class=\"ltx_text\" id=\"A2.T5.2.3.2.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib14\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2020d</span></a><span class=\"ltx_text\" id=\"A2.T5.2.3.2.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.3.2.3\"><span class=\"ltx_text\" id=\"A2.T5.2.3.2.3.1\" style=\"font-size:90%;\">400</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.3.2.4\"><span class=\"ltx_text\" id=\"A2.T5.2.3.2.4.1\" style=\"font-size:90%;\">79.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.2.4.3.1\"><span class=\"ltx_text\" id=\"A2.T5.2.4.3.1.1\" style=\"font-size:90%;\">SimCLR</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.4.3.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.4.3.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Chen et&#160;al.</span><span class=\"ltx_text\" id=\"A2.T5.2.4.3.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib11\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2020b</span></a><span class=\"ltx_text\" id=\"A2.T5.2.4.3.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.4.3.3\"><span class=\"ltx_text\" id=\"A2.T5.2.4.3.3.1\" style=\"font-size:90%;\">800</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.4.3.4\"><span class=\"ltx_text\" id=\"A2.T5.2.4.3.4.1\" style=\"font-size:90%;\">79.9</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.5.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.2.5.4.1\"><span class=\"ltx_text\" id=\"A2.T5.2.5.4.1.1\" style=\"font-size:90%;\">BYOL</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.5.4.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.5.4.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Grill et&#160;al.</span><span class=\"ltx_text\" id=\"A2.T5.2.5.4.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib26\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2020</span></a><span class=\"ltx_text\" id=\"A2.T5.2.5.4.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.5.4.3\"><span class=\"ltx_text\" id=\"A2.T5.2.5.4.3.1\" style=\"font-size:90%;\">400</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.5.4.4\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T5.2.5.4.4.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T5.2.5.4.4.2\" style=\"font-size:90%;\">80.0</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.6.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.2.6.5.1\"><span class=\"ltx_text\" id=\"A2.T5.2.6.5.1.1\" style=\"font-size:90%;\">SwAV</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.6.5.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.6.5.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Caron et&#160;al.</span><span class=\"ltx_text\" id=\"A2.T5.2.6.5.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib6\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2020</span></a><span class=\"ltx_text\" id=\"A2.T5.2.6.5.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.6.5.3\"><span class=\"ltx_text\" id=\"A2.T5.2.6.5.3.1\" style=\"font-size:90%;\">600</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.6.5.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.6.5.4.1\" style=\"font-size:90%;\">80.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.7.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.2.7.6.1\"><span class=\"ltx_text\" id=\"A2.T5.2.7.6.1.1\" style=\"font-size:90%;\">MFM</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.7.6.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.7.6.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span><span class=\"ltx_text\" id=\"A2.T5.2.7.6.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib62\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2023</span></a><span class=\"ltx_text\" id=\"A2.T5.2.7.6.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.7.6.3\"><span class=\"ltx_text\" id=\"A2.T5.2.7.6.3.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.7.6.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.7.6.4.1\" style=\"font-size:90%;\">80.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.8.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T5.2.8.7.1\"><span class=\"ltx_text\" id=\"A2.T5.2.8.7.1.1\" style=\"font-size:90%;\">MFM + Com/RCom</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.8.7.2\"><cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text\" id=\"A2.T5.2.8.7.2.1.1\" style=\"font-size:90%;\">[</span><span class=\"ltx_text\" style=\"font-size:90%;\">Xie et&#160;al.</span><span class=\"ltx_text\" id=\"A2.T5.2.8.7.2.2.2.1.1\" style=\"font-size:90%;\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2409.10362v1#bib.bib62\" title=\"\"><span class=\"ltx_text\" style=\"font-size:90%;\">2023</span></a><span class=\"ltx_text\" id=\"A2.T5.2.8.7.2.3.3\" style=\"font-size:90%;\">]</span></cite></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.8.7.3\"><span class=\"ltx_text\" id=\"A2.T5.2.8.7.3.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T5.2.8.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.8.7.4.1\" style=\"font-size:90%;\">80.1</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T5.2.9.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T5.2.9.8.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.9.8.1.1\" style=\"font-size:90%;\">FOLK</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.2.9.8.2\"><span class=\"ltx_text\" id=\"A2.T5.2.9.8.2.1\" style=\"font-size:90%;\">Ours</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.2.9.8.3\"><span class=\"ltx_text\" id=\"A2.T5.2.9.8.3.1\" style=\"font-size:90%;\">300</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T5.2.9.8.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T5.2.9.8.4.1\" style=\"font-size:90%;\">80.1</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 5:  The top-1 full fine-tuning accuracy on ImageNet-1K for self-supervised models that utilize ResNet-50 as the encoder. This information compares our methods against others, with the results of these comparative methods being sourced from  [ Xie et al. ,  2023 ]  and  [ Fang et al. ,  2023 ] . The highest model performance is highlighted in bold, with the second highest being underscored.",
        "footnotes": [
            "Chen and He [2021] \nXinlei Chen and Kaiming He.\n \n Exploring simple siamese representation learning.\n \n In  Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 15750–15758, 2021.\n \n",
            "Chen et al. [2020d] \nXinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.\n \n Improved baselines with momentum contrastive learning.\n \n arXiv preprint arXiv:2003.04297 , 2020d.\n \n",
            "Chen et al. [2020b] \nTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.\n \n A simple framework for contrastive learning of visual representations.\n \n In  International conference on machine learning , pages 1597–1607. PMLR, 2020b.\n \n",
            "Grill et al. [2020] \nJean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al.\n \n Bootstrap your own latent-a new approach to self-supervised learning.\n \n Advances in neural information processing systems , 33:21271–21284, 2020.\n \n",
            "Caron et al. [2020] \nMathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin.\n \n Unsupervised learning of visual features by contrasting cluster assignments.\n \n Advances in neural information processing systems , 33:9912–9924, 2020.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n",
            "Xie et al. [2023] \nJiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.\n \n Masked frequency modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n",
            "Fang et al. [2023] \nYuxin Fang, Li Dong, Hangbo Bao, Xinggang Wang, and Furu Wei.\n \n Corrupted image modeling for self-supervised visual pre-training.\n \n In  The Eleventh International Conference on Learning Representations , 2023.\n \n"
        ],
        "references": [
            "Table 5 presents the ResNet-50 [He et al., 2016] (a CNN-based model) performance under the FOLK framework. The same FOLK pre-training strategies that have been applied to ViTs were seamlessly adopted here for CNNs. The only necessary modification to adopt CNNs is to alter the inputs to the heads: replacing patch tokens from ViTs with reshaped feature maps from CNNs, and replacing the [C⁢L⁢S]delimited-[]𝐶𝐿𝑆[CLS][ italic_C italic_L italic_S ] token from ViTs with the average-pooled (and reshaped) feature map from CNNs. Our approach has demonstrated equal or superior performance to other methods with fewer epochs."
        ]
    },
    "A2.T6.6": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A2.T6.6\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T6.6.1.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.1.1.1\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.1.1.1.1\" style=\"font-size:90%;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.1.1.2.1\" style=\"font-size:90%;\">Base LR = 2e-4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.1.1.3.1\" style=\"font-size:90%;\">Base LR = 2e-4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.1.1.4.1\" style=\"font-size:90%;\">Base LR = 2e-3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.6.1.1.5\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.1.1.5.1\" style=\"font-size:90%;\">AVG</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.6.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.2.2.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.2.2.1.1\" style=\"font-size:90%;\">Warm Up = 0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.2.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.2.2.2.1\" style=\"font-size:90%;\">Warm Up = 100</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.2.2.3.1\" style=\"font-size:90%;\">Warm Up = 5</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.6.3.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.3.3.1\"><span class=\"ltx_text\" id=\"A2.T6.6.3.3.1.1\" style=\"font-size:90%;\">iBOT</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.3.3.2\"><span class=\"ltx_text\" id=\"A2.T6.6.3.3.2.1\" style=\"font-size:90%;\">33.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.3.3.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T6.6.3.3.3.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T6.6.3.3.3.2\" style=\"font-size:90%;\">59.0</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T6.6.3.3.4\"><span class=\"ltx_text\" id=\"A2.T6.6.3.3.4.1\" style=\"font-size:90%;\">1.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T6.6.3.3.5\"><span class=\"ltx_text\" id=\"A2.T6.6.3.3.5.1\" style=\"font-size:90%;\">31.2</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.6.4.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.4.4.1\"><span class=\"ltx_text\" id=\"A2.T6.6.4.4.1.1\" style=\"font-size:90%;\">AttMask</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.4.4.2\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T6.6.4.4.2.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T6.6.4.4.2.2\" style=\"font-size:90%;\">50.4</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.4.4.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.4.4.3.1\" style=\"font-size:90%;\">59.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.4.4.4\"><span class=\"ltx_text\" id=\"A2.T6.6.4.4.4.1\" style=\"font-size:90%;\">3.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.6.4.4.5\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T6.6.4.4.5.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T6.6.4.4.5.2\" style=\"font-size:90%;\">37.6</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.6.5.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.5.5.1\"><span class=\"ltx_text\" id=\"A2.T6.6.5.5.1.1\" style=\"font-size:90%;\">MFM</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.5.5.2\"><span class=\"ltx_text\" id=\"A2.T6.6.5.5.2.1\" style=\"font-size:90%;\">26.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.5.5.3\"><span class=\"ltx_text\" id=\"A2.T6.6.5.5.3.1\" style=\"font-size:90%;\">31.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.5.5.4\"><span class=\"ltx_text\" id=\"A2.T6.6.5.5.4.1\" style=\"font-size:90%;\">6.3</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.6.5.5.5\"><span class=\"ltx_text\" id=\"A2.T6.6.5.5.5.1\" style=\"font-size:90%;\">21.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.6.6.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.6.6.1\"><span class=\"ltx_text\" id=\"A2.T6.6.6.6.1.1\" style=\"font-size:90%;\">MFM + Com/RCom</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.6.6.2\"><span class=\"ltx_text\" id=\"A2.T6.6.6.6.2.1\" style=\"font-size:90%;\">42.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.6.6.3\"><span class=\"ltx_text\" id=\"A2.T6.6.6.6.3.1\" style=\"font-size:90%;\">44.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"A2.T6.6.6.6.4\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T6.6.6.6.4.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T6.6.6.6.4.2\" style=\"font-size:90%;\">10.7</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T6.6.6.6.5\"><span class=\"ltx_text\" id=\"A2.T6.6.6.6.5.1\" style=\"font-size:90%;\">32.6</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T6.6.7.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A2.T6.6.7.7.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.7.7.1.1\" style=\"font-size:90%;\">FOLK</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A2.T6.6.7.7.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.7.7.2.1\" style=\"font-size:90%;\">51.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A2.T6.6.7.7.3\"><span class=\"ltx_text\" id=\"A2.T6.6.7.7.3.1\" style=\"font-size:90%;\">56.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" id=\"A2.T6.6.7.7.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.7.7.4.1\" style=\"font-size:90%;\">20.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T6.6.7.7.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T6.6.7.7.5.1\" style=\"font-size:90%;\">42.8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 6:  Results of few-shot learning by fine-tuning pre-trained models for  1000 1000 1000 1000  epochs on  1 % percent 1 1\\% 1 %  of labeled ImageNet-1k. All models were sourced directly from their respective original repositories.",
        "footnotes": [],
        "references": [
            "In addition to the primary few-shot learning results discussed in Section 4.2.2, Table 6 presents an extensive evaluation of few-shot learning performance. Various pre-trained models were fine-tuned using only 1%percent11\\%1 % of the ImageNet-1K dataset over 1000100010001000 epochs. This setup facilitates a detailed comparison of each model’s ability to adapt to new data with minimal examples, highlighting a crucial aspect of model robustness and versatility. Furthermore, the evaluation considers three different settings for the base learning rate (LR) and warm-up periods, which are crucial hyperparameters in training deep learning models, especially under few-shot scenarios. The different configurations aim to assess each model’s robustness across varying learning rate adaptation conditions.",
            "The performance data presented in Table 6 underscores the robustness of the FOLK method across various learning rates and warm-up settings, evidenced by its superior average performance of 42.8%percent42.842.8\\%42.8 %. This consistency indicates FOLK’s inherent stability and adaptability in few-shot learning scenarios, distinguishing it from other models. Unlike iBOT and MFM, which exhibit fluctuating accuracies with changes in learning rates and warm-up periods, FOLK maintains a high level of performance. This suggests that FOLK is less sensitive to hyperparameter adjustments, thus requiring less fine-tuning to achieve good results. This characteristic is particularly significant in practical applications where extensive parameter tuning is inapplicable. By effectively integrating dual inputs—filtered and original images—FOLK enhances feature extraction and generalization capabilities, resulting in more reliable performance across various settings. This robustness, combined with a reduced dependency on precise parameter tuning, positions FOLK as an attractive option for tasks demanding high accuracy with minimal labeled data and limited pre-processing."
        ]
    },
    "A2.T7.2": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"A2.T7.2\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T7.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T7.2.2.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.2.2.3.1\" style=\"font-size:90%;\">Filters</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T7.2.2.4\"><span class=\"ltx_text\" id=\"A2.T7.2.2.4.1\" style=\"font-size:90%;\">Gabor</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T7.2.2.5\"><span class=\"ltx_text\" id=\"A2.T7.2.2.5.1\" style=\"font-size:90%;\">Token Mask</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"A2.T7.2.2.6\"><span class=\"ltx_text\" id=\"A2.T7.2.2.6.1\" style=\"font-size:90%;\">Circle Mask</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T7.2.2.2\">\n<math alttext=\"Com\" class=\"ltx_Math\" display=\"inline\" id=\"A2.T7.1.1.1.m1.1\"><semantics id=\"A2.T7.1.1.1.m1.1a\"><mrow id=\"A2.T7.1.1.1.m1.1.1\" xref=\"A2.T7.1.1.1.m1.1.1.cmml\"><mi id=\"A2.T7.1.1.1.m1.1.1.2\" mathsize=\"90%\" xref=\"A2.T7.1.1.1.m1.1.1.2.cmml\">C</mi><mo id=\"A2.T7.1.1.1.m1.1.1.1\" xref=\"A2.T7.1.1.1.m1.1.1.1.cmml\">&#8290;</mo><mi id=\"A2.T7.1.1.1.m1.1.1.3\" mathsize=\"90%\" xref=\"A2.T7.1.1.1.m1.1.1.3.cmml\">o</mi><mo id=\"A2.T7.1.1.1.m1.1.1.1a\" xref=\"A2.T7.1.1.1.m1.1.1.1.cmml\">&#8290;</mo><mi id=\"A2.T7.1.1.1.m1.1.1.4\" mathsize=\"90%\" xref=\"A2.T7.1.1.1.m1.1.1.4.cmml\">m</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A2.T7.1.1.1.m1.1b\"><apply id=\"A2.T7.1.1.1.m1.1.1.cmml\" xref=\"A2.T7.1.1.1.m1.1.1\"><times id=\"A2.T7.1.1.1.m1.1.1.1.cmml\" xref=\"A2.T7.1.1.1.m1.1.1.1\"/><ci id=\"A2.T7.1.1.1.m1.1.1.2.cmml\" xref=\"A2.T7.1.1.1.m1.1.1.2\">&#119862;</ci><ci id=\"A2.T7.1.1.1.m1.1.1.3.cmml\" xref=\"A2.T7.1.1.1.m1.1.1.3\">&#119900;</ci><ci id=\"A2.T7.1.1.1.m1.1.1.4.cmml\" xref=\"A2.T7.1.1.1.m1.1.1.4\">&#119898;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T7.1.1.1.m1.1c\">Com</annotation><annotation encoding=\"application/x-llamapun\" id=\"A2.T7.1.1.1.m1.1d\">italic_C italic_o italic_m</annotation></semantics></math><span class=\"ltx_text\" id=\"A2.T7.2.2.2.1\" style=\"font-size:90%;\">/</span><math alttext=\"RCom\" class=\"ltx_Math\" display=\"inline\" id=\"A2.T7.2.2.2.m2.1\"><semantics id=\"A2.T7.2.2.2.m2.1a\"><mrow id=\"A2.T7.2.2.2.m2.1.1\" xref=\"A2.T7.2.2.2.m2.1.1.cmml\"><mi id=\"A2.T7.2.2.2.m2.1.1.2\" mathsize=\"90%\" xref=\"A2.T7.2.2.2.m2.1.1.2.cmml\">R</mi><mo id=\"A2.T7.2.2.2.m2.1.1.1\" xref=\"A2.T7.2.2.2.m2.1.1.1.cmml\">&#8290;</mo><mi id=\"A2.T7.2.2.2.m2.1.1.3\" mathsize=\"90%\" xref=\"A2.T7.2.2.2.m2.1.1.3.cmml\">C</mi><mo id=\"A2.T7.2.2.2.m2.1.1.1a\" xref=\"A2.T7.2.2.2.m2.1.1.1.cmml\">&#8290;</mo><mi id=\"A2.T7.2.2.2.m2.1.1.4\" mathsize=\"90%\" xref=\"A2.T7.2.2.2.m2.1.1.4.cmml\">o</mi><mo id=\"A2.T7.2.2.2.m2.1.1.1b\" xref=\"A2.T7.2.2.2.m2.1.1.1.cmml\">&#8290;</mo><mi id=\"A2.T7.2.2.2.m2.1.1.5\" mathsize=\"90%\" xref=\"A2.T7.2.2.2.m2.1.1.5.cmml\">m</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A2.T7.2.2.2.m2.1b\"><apply id=\"A2.T7.2.2.2.m2.1.1.cmml\" xref=\"A2.T7.2.2.2.m2.1.1\"><times id=\"A2.T7.2.2.2.m2.1.1.1.cmml\" xref=\"A2.T7.2.2.2.m2.1.1.1\"/><ci id=\"A2.T7.2.2.2.m2.1.1.2.cmml\" xref=\"A2.T7.2.2.2.m2.1.1.2\">&#119877;</ci><ci id=\"A2.T7.2.2.2.m2.1.1.3.cmml\" xref=\"A2.T7.2.2.2.m2.1.1.3\">&#119862;</ci><ci id=\"A2.T7.2.2.2.m2.1.1.4.cmml\" xref=\"A2.T7.2.2.2.m2.1.1.4\">&#119900;</ci><ci id=\"A2.T7.2.2.2.m2.1.1.5.cmml\" xref=\"A2.T7.2.2.2.m2.1.1.5\">&#119898;</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T7.2.2.2.m2.1c\">RCom</annotation><annotation encoding=\"application/x-llamapun\" id=\"A2.T7.2.2.2.m2.1d\">italic_R italic_C italic_o italic_m</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T7.2.3.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"A2.T7.2.3.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.2.3.1.1.1\" style=\"font-size:90%;\">Acc</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"A2.T7.2.3.1.2\"><span class=\"ltx_text\" id=\"A2.T7.2.3.1.2.1\" style=\"font-size:90%;\">80.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"A2.T7.2.3.1.3\"><span class=\"ltx_text\" id=\"A2.T7.2.3.1.3.1\" style=\"font-size:90%;\">80.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"A2.T7.2.3.1.4\"><span class=\"ltx_text\" id=\"A2.T7.2.3.1.4.1\" style=\"font-size:90%;\">80.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"A2.T7.2.3.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T7.2.3.1.5.1\" style=\"font-size:90%;\">81.6</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 7:  Image classification results of utilizing different filters for masking in the FOLK framework.",
        "footnotes": [],
        "references": [
            "Table 7 illustrates the impact of various filtering techniques used for masking within the FOLK framework on model accuracy. The methods compared include Gabor filters, Token Mask, and Circle Mask filters. A clear pattern emerges from the data, with the C⁢o⁢m𝐶𝑜𝑚Comitalic_C italic_o italic_m/R⁢C⁢o⁢m𝑅𝐶𝑜𝑚RComitalic_R italic_C italic_o italic_m filters significantly outperforming the other techniques, achieving the highest accuracy at 81.6%percent81.681.6\\%81.6 %. This indicates a superior efficacy of C⁢o⁢m𝐶𝑜𝑚Comitalic_C italic_o italic_m/R⁢C⁢o⁢m𝑅𝐶𝑜𝑚RComitalic_R italic_C italic_o italic_m filters in capturing and utilizing relevant image features for model training. The other filters—Gabor, Token, and Circle—also show competitive accuracies, but they are notably less effective than C⁢o⁢m𝐶𝑜𝑚Comitalic_C italic_o italic_m/R⁢C⁢o⁢m𝑅𝐶𝑜𝑚RComitalic_R italic_C italic_o italic_m, with accuracies hovering around the 80%percent8080\\%80 % mark. This suggests that the design and application of the C⁢o⁢m𝐶𝑜𝑚Comitalic_C italic_o italic_m/R⁢C⁢o⁢m𝑅𝐶𝑜𝑚RComitalic_R italic_C italic_o italic_m filters are better aligned with image intrinsic information, enhancing the model’s ability to generalize from the training effectively."
        ]
    },
    "A2.T8.2": {
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"A2.T8.2\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"A2.T8.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T8.1.1.2\"><span class=\"ltx_text\" id=\"A2.T8.1.1.2.1\" style=\"font-size:90%;\">Methods</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T8.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T8.1.1.3.1\" style=\"font-size:90%;\">FOLK</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T8.1.1.4\"><span class=\"ltx_text\" id=\"A2.T8.1.1.4.1\" style=\"font-size:90%;\">MFM</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T8.1.1.5\"><span class=\"ltx_text\" id=\"A2.T8.1.1.5.1\" style=\"font-size:90%;\">iBOT</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"A2.T8.1.1.1\">\n<span class=\"ltx_text\" id=\"A2.T8.1.1.1.1\" style=\"font-size:90%;\">AttMask</span><sup class=\"ltx_sup\" id=\"A2.T8.1.1.1.2\"><span class=\"ltx_text\" id=\"A2.T8.1.1.1.2.1\" style=\"font-size:90%;\">&#8727;</span></sup>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"A2.T8.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"A2.T8.2.2.2\"><span class=\"ltx_text\" id=\"A2.T8.2.2.2.1\" style=\"font-size:90%;\">MemGPU (GB)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.2.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T8.2.2.3.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T8.2.2.3.2\" style=\"font-size:90%;\">19.82</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.2.4\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T8.2.2.4.1\" style=\"font-size:90%;\">10.11</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.2.5\"><span class=\"ltx_text\" id=\"A2.T8.2.2.5.1\" style=\"font-size:90%;\">21.99</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"A2.T8.2.2.1\">\n<span class=\"ltx_text\" id=\"A2.T8.2.2.1.1\" style=\"font-size:90%;\">39.38</span><sup class=\"ltx_sup\" id=\"A2.T8.2.2.1.2\"><span class=\"ltx_text\" id=\"A2.T8.2.2.1.2.1\" style=\"font-size:90%;\">&#8727;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.3.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"A2.T8.2.3.1.1\"><span class=\"ltx_text\" id=\"A2.T8.2.3.1.1.1\" style=\"font-size:90%;\">Few-Shot Accuracy (%)</span></th>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.3.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T8.2.3.1.2.1\" style=\"font-size:90%;\">67.2</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.3.1.3\"><span class=\"ltx_text\" id=\"A2.T8.2.3.1.3.1\" style=\"font-size:90%;\">52.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.3.1.4\"><span class=\"ltx_text\" id=\"A2.T8.2.3.1.4.1\" style=\"font-size:90%;\">45.7</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"A2.T8.2.3.1.5\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T8.2.3.1.5.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T8.2.3.1.5.2\" style=\"font-size:90%;\">57.4</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"A2.T8.2.4.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"A2.T8.2.4.2.1\"><span class=\"ltx_text\" id=\"A2.T8.2.4.2.1.1\" style=\"font-size:90%;\">Classification Accuracy (%)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T8.2.4.2.2\"><span class=\"ltx_text ltx_font_bold\" id=\"A2.T8.2.4.2.2.1\" style=\"font-size:90%;\">81.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T8.2.4.2.3\">\n<span class=\"ltx_ERROR undefined\" id=\"A2.T8.2.4.2.3.1\">\\ul</span><span class=\"ltx_text\" id=\"A2.T8.2.4.2.3.2\" style=\"font-size:90%;\">81.4</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T8.2.4.2.4\"><span class=\"ltx_text\" id=\"A2.T8.2.4.2.4.1\" style=\"font-size:90%;\">81.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" id=\"A2.T8.2.4.2.5\"><span class=\"ltx_text\" id=\"A2.T8.2.4.2.5.1\" style=\"font-size:90%;\">81.3</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "caption": "Table 8:  Comparison of GPU memory usage and model accuracy between FOLK and other methods. All methods are based on a ViT-S backbone. MemGPU is GPU memory with a batch size of 128. Few-Shot Accuracy is averaged from Table  2 . Classification Accuracy comes from Table  1  in the main manuscript.  ∗ We could not run AttMask’s official code with batch 128 with A100 80G and received a memory error. Hence, we ran it with batch 64.",
        "footnotes": [],
        "references": [
            "To assess the effectiveness of our enhanced model, we provide memory usage on the GPU, and overall accuracy. The results of these evaluations are summarized in Table 8.",
            "Table 8 summarizes the performance metrics of various self-supervised learning methods, highlighting the impact of integrating dual inputs—original and filtered images—on model efficacy, particularly within the FOLK framework. Memory usage is a crucial consideration, as only GPUs with high capacity can run the model. This is noteworthy when compared to iBOT and AttMask which consume more memory222AttMask cannot run with a batch size of 128 on an A100 80GB GPU, so we run it with a batch size of 64., while our model requires less than 20GB of memory for the same batch size. The increased memory usage in models like FOLK and iBOT correlates with the advanced processing capabilities necessary for handling dual inputs. However, the evident gains in learning accuracy justify the resource allocation, making it a worthwhile trade-off for applications where high precision and robust feature recognition are critical, such as few-shot learning scenarios. FOLK achieves the highest few-shot learning accuracy at 67.2%percent67.267.2\\%67.2 % and tops classification accuracy at 81.6%percent81.681.6\\%81.6 %. This performance indicates that the model’s ability to effectively utilize both filtered and original images significantly enhances its learning capabilities, particularly in tasks requiring robust feature recognition."
        ]
    }
}