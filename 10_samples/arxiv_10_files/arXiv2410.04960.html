<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>On Efficient Variants of Segment Anything Model: A Survey</title>
<!--Generated on Mon Oct  7 11:16:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.04960v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S1" title="In On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2" title="In On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Preliminaries</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1" title="In 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Segment Anything Model</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1.SSS1" title="In 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1.SSS2" title="In 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1.SSS3" title="In 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.3 </span>Application</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1.SSS4" title="In 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.4 </span>Limitation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS2" title="In 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Efficient Backbone</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS2.SSS1" title="In 2.2 Efficient Backbone ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Efficient Vision Transformer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS2.SSS2" title="In 2.2 Efficient Backbone ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Transformer-alternative Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3" title="In 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Model Compression</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3.SSS1" title="In 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Knowledge Distillation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3.SSS2" title="In 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Quantization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3.SSS3" title="In 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.3 </span>Pruning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3.SSS4" title="In 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.4 </span>Low-Rank Factorization</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3" title="In On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Efficient Variants of SAM</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1" title="In 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Accelerating SegAny Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS1" title="In 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Training from Scratch</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS2" title="In 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Knowledge Distillation based Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS3" title="In 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Quantization based Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS4" title="In 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.4 </span>Pruning based Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS5" title="In 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.5 </span>Code Refactorization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS2" title="In 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Accelerating SegEvery Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS3" title="In 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Future Research Directions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4" title="In On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS1" title="In 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Datasets and Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS2" title="In 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Efficiency Comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS3" title="In 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Accuracy Comparison</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S5" title="In On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">On Efficient Variants of Segment Anything Model: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaorui Sun<sup class="ltx_sup" id="id9.9.id1">1</sup>           Jun Liu<sup class="ltx_sup" id="id10.10.id2">2</sup>           Heng Tao Shen<sup class="ltx_sup" id="id11.11.id3"><span class="ltx_text ltx_font_italic" id="id11.11.id3.1">1,3</span></sup>           Xiaofeng Zhu<sup class="ltx_sup" id="id12.12.id4"><span class="ltx_text ltx_font_italic" id="id12.12.id4.1">1</span></sup>           Ping Hu<sup class="ltx_sup" id="id13.13.id5"><span class="ltx_text ltx_font_italic" id="id13.13.id5.1">1</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id6">1</sup>School of Computer Science and Engineering, UESTC
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id7">2</sup>School of Computing and Communications, Lancaster University
<br class="ltx_break"/><sup class="ltx_sup" id="id16.16.id8">3</sup>School of Computer Science and Technology, Tongji University
<br class="ltx_break"/>
</span><span class="ltx_author_notes">email:chinahuping@gmail.com</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id17.id1">The Segment Anything Model (SAM) is a foundational model for image segmentation tasks, known for its strong generalization across diverse applications. However, its impressive performance comes with significant computational and resource demands, making it challenging to deploy in resource-limited environments such as mobile devices. To address this, a variety of SAM variants have been proposed to enhance efficiency without sacrificing accuracy. This survey provides the first comprehensive review of these efficient SAM variants. We begin by exploring the motivations driving this research. We then present core techniques used in SAM and model acceleration. This is followed by an in-depth analysis of various acceleration strategies, categorized by approach. Finally, we offer a unified and extensive evaluation of these methods, assessing their efficiency and accuracy on representative benchmarks, and providing a clear comparison of their overall performance.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The emergence of foundation models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite> has led to a thorough revolution in the field of artificial intelligence (AI). Foundation models are large-scale neural networks pre-trained on massive data, which have powerful representing ability and strong generalization to perform on various tasks. In the field of natural language processing (NLP), the recently popular research trend is about the large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib160" title=""><span class="ltx_text" style="font-size:90%;">160</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib116" title=""><span class="ltx_text" style="font-size:90%;">116</span></a>]</cite>, which has been witnessed great development with prominent works like OpenAI’s GPT series <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">9</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>, Google’s PaLM series <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> and Meta’s LLaMA series <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib111" title=""><span class="ltx_text" style="font-size:90%;">111</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib112" title=""><span class="ltx_text" style="font-size:90%;">112</span></a>]</cite>. Meanwhile, the success of Vision Transformer (ViT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite> which firstly introduces the Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib115" title=""><span class="ltx_text" style="font-size:90%;">115</span></a>]</cite> architecture into the field of computer vision (CV), has brought up a new era for vision foundation models (VFMs). Vision-Language foundation models like CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib89" title=""><span class="ltx_text" style="font-size:90%;">89</span></a>]</cite>, LLaVA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib67" title=""><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite>, and Video-ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib79" title=""><span class="ltx_text" style="font-size:90%;">79</span></a>]</cite> etc., which aim at aligning the vision and language modalities, have demonstrated promising performance on plenty of downstream vision tasks<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib58" title=""><span class="ltx_text" style="font-size:90%;">58</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">34</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib167" title=""><span class="ltx_text" style="font-size:90%;">167</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib110" title=""><span class="ltx_text" style="font-size:90%;">110</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recently, a novel foundation model for general image segmentation, the Segment Anything Model (SAM), was proposed by Meta <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite>. Being fully trained on their proposed SA-1B dataset, which consists of more than one billion masks and eleven million images, with the task of achieving valid segmentation given any prompt (e.g. points, boxes, masks and text), SAM is able to well generalize to a wide range of downstream tasks (e.g. edge detection, object proposal and instance segmentation) with proper prompts. Shortly after its emergence, SAM has garnered significant attention from the research community and results in a surge of related works exploring SAM’s generalization ability in various scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib78" title=""><span class="ltx_text" style="font-size:90%;">78</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, including different image segmentation tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib95" title=""><span class="ltx_text" style="font-size:90%;">95</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib57" title=""><span class="ltx_text" style="font-size:90%;">57</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib130" title=""><span class="ltx_text" style="font-size:90%;">130</span></a>]</cite>, video analysis tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib154" title=""><span class="ltx_text" style="font-size:90%;">154</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib137" title=""><span class="ltx_text" style="font-size:90%;">137</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib76" title=""><span class="ltx_text" style="font-size:90%;">76</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite> and 3D vision tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib100" title=""><span class="ltx_text" style="font-size:90%;">100</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">28</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib134" title=""><span class="ltx_text" style="font-size:90%;">134</span></a>]</cite>.
With the huge success of SAM, the upgraded Segment Anything Model 2 (SAM 2) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite> is further proposed, aiming for efficient segmentation in both images and videos. SAM 2 introduces the streaming memory mechanism to extend SAM’s ability to videos. It is trained on both the SA-1B dataset and SA-V dataset which is their newly collected video segmentation dataset. As a result, SAM 2 naturally holds the powerful generalization and surpasses SAM when handling segmentation tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib99" title=""><span class="ltx_text" style="font-size:90%;">99</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib135" title=""><span class="ltx_text" style="font-size:90%;">135</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib140" title=""><span class="ltx_text" style="font-size:90%;">140</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib113" title=""><span class="ltx_text" style="font-size:90%;">113</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib70" title=""><span class="ltx_text" style="font-size:90%;">70</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Despite its success in a wide range of applications, the original Segment Anything Model (SAM), particularly SAM-H, faces significant limitations due to its slow runtime and high computational cost. These challenges become even more pronounced when SAM is deployed in resource-constrained or real-time environments, such as edge devices and mobile applications. As the demand for deploying machine learning models in practical, resource-constrained scenarios continues to grow, SAM’s current design proves inefficient for widespread use. This has led to a pressing need for more lightweight and efficient variants that can maintain the model’s powerful segmentation capabilities while addressing these constraints. The challenge of optimizing SAM for efficiency is further amplified by the increasing emphasis on real-time applications, mobile platforms and embedded systems, where computational resources are limited. As the community strives to overcome these obstacles <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib114" title=""><span class="ltx_text" style="font-size:90%;">114</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib118" title=""><span class="ltx_text" style="font-size:90%;">118</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib77" title=""><span class="ltx_text" style="font-size:90%;">77</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, a comprehensive understanding of the latest advancements in making SAM more efficient is crucial. Consequently, it is both timely and necessary to conduct a detailed survey of the ongoing efforts aimed at improving SAM’s efficiency and extending its applicability across diverse environments.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">With the growing research related to SAM, several surveys have been presented to provide an overview from different perspectives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib150" title=""><span class="ltx_text" style="font-size:90%;">150</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib149" title=""><span class="ltx_text" style="font-size:90%;">149</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib152" title=""><span class="ltx_text" style="font-size:90%;">152</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib157" title=""><span class="ltx_text" style="font-size:90%;">157</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib151" title=""><span class="ltx_text" style="font-size:90%;">151</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib155" title=""><span class="ltx_text" style="font-size:90%;">155</span></a>]</cite>. However, these existing surveys primarily focus on SAM’s downstream applications and exhibit several limitations: 1) None of them address the emerging field of improving SAM’s efficiency, which is gaining significant attention and is crucial for practical deployment in real-world applications. 2) With the exception of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib151" title=""><span class="ltx_text" style="font-size:90%;">151</span></a>]</cite>, these surveys lack a structured taxonomy that would allow for clearer organization and reference. 3) Most prior surveys focus on collecting and describing SAM-based methods but lack a systematic evaluation or comparison of these approaches. To address these gaps, we conduct this survey, not only to comprehensively review the development of efficient Segment Anything Models but also to fairly evaluate and compare them. The main contributions of this work can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p5">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We provide a systematic review of the efficient SAM variants designed to accelerate segmentation tasks. We introduce a well-structured taxonomy for the methods, categorizing them based on the acceleration strategies they employ. To the best of our knowledge, this is the first survey focused specifically on this area.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We offer comprehensive evaluations and comparisons of the efficiency and accuracy of these variants, aiming to assist researchers in selecting models that best meet their performance and application needs.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We propose several potential directions for future research, offering insights that may inspire readers to contribute to the continued advancement of this field.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The rest of this survey is organized as follows. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2" title="2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>, we begin by introducing the background of the original SAM, followed by a review of efficient backbones for visual representation and model compression techniques that can be applied to enhance SAM’s efficiency. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3" title="3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>, we categorize the existing methodologies based on their objectives and techniques, providing a detailed review of each category. We also discuss several potential research directions for further accelerating SAM. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4" title="4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>, we conduct a fair evaluation of these models in terms of efficiency, accuracy, and the resulting trade-offs. Finally, in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S5" title="5 Conclusion ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>, we provide a brief summary of this survey.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminaries</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we will first introduce the details and applications of the Segment Anything Model in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1" title="2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.1</span></a>. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS2" title="2.2 Efficient Backbone ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.2</span></a>, we review efficient backbones that could potentially replace SAM’s image encoder, and in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3" title="2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.3</span></a>, we examine model compression techniques that could be applied to SAM. For a more comprehensive understanding of efficient backbones and model compression methods, we recommend referring to surveys <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib86" title=""><span class="ltx_text" style="font-size:90%;">86</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib132" title=""><span class="ltx_text" style="font-size:90%;">132</span></a>]</cite>.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Segment Anything Model</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Segment Anything Model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> is a powerful foundation model in the image segmentation field, which can unify most image segmentation tasks by a fundamental segmentation task, i.e. the promptable segmentation task, with prompt engineering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib68" title=""><span class="ltx_text" style="font-size:90%;">68</span></a>]</cite>. Another significant contribution of this project is the SA-1B dataset, which has over 1B masks from 11M licensed and privacy-preserving images. Trained with such abundant and high-quality data, SAM is expected to have strong robustness and generalization. The huge potential of SAM has quickly sparked researcher’s interest in both exploring its ability in a wide range of real-world applications and improving its architecture to segment more efficiently or accurately.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Recently, Segment Anything Model 2 (SAM 2) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite> is proposed as a successor with a focus on efficient promptable visual segmentation (PVS) for both images and videos. To enable SAM 2 to segment anything in videos, researchers introduce the streaming memory mechanism into SAM’s original architecture. SAM 2 is trained from scratch by two stages: 1) Pre-training on SA-1B dataset with the promptable segmentation task for images; 2) Training on mixed data with the promptable segmentation task for images and videos. Similar to SAM, researchers build up a data engine to generate a large-scale dataset for video segmentation, named the SA-V dataset. With both manually annotated and automatically generated masklets (object segmentation in videos), SA-V finally collects 642.6K masklets across 50.9K videos. In this survey, we consider SAM 2 as an efficient SAM variant and include it in the evaluation and comparison.</p>
</div>
<figure class="ltx_figure" id="S2.F1">
<figure class="ltx_figure ltx_align_center" id="S2.F1.sf2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="164" id="S2.F1.sf2.g1" src="x1.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.sf2.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S2.F1.sf2.3.2" style="font-size:90%;">Segment Anything Model</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="209" id="S2.F1.sf2.g2" src="x2.png" width="830"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.sf2.4.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S2.F1.sf2.5.2" style="font-size:90%;">Segment Anything Model 2</span></figcaption>
</figure>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">The architectures of (a) SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> and (b) the recent proposed SAM 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite>.</span></figcaption>
</figure>
<section class="ltx_subsubsection" id="S2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Model</h4>
<div class="ltx_para" id="S2.SS1.SSS1.p1">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">SAM consists of three components: an image encoder, a prompt decoder and a mask decoder, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.F1" title="Figure 1 ‣ 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> (a). The image encoder is a MAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> pre-trained Vision Transformer(ViT) with minimal modification. It takes the preprocessed images as input and outputs an image embedding for each image. The prompt decoder is to embed prompts: points, boxes, masks and text. The two embeddings are then fed into the light-weight mask decoder, which is built upon two modified Transformer decoder blocks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib115" title=""><span class="ltx_text" style="font-size:90%;">115</span></a>]</cite> and a few prediction heads, to generate valid masks.
Based on SAM’s architecture, SAM 2 additionally introduces a streaming memory mechanism. Specifically, a memory encoder, a memory bank and a memory attention module. The structure of SAM 2 is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.F1" title="Figure 1 ‣ 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> (b). With the memory mechanism, SAM 2 can handling videos frame by frame. The memory encoder is to generate memory of the prediction of the current frame and send it to the memory bank. The memory bank stores memories of recent prediction, feature maps of prompted frames and high-level semantic information of the target objects (i.e. object pointers). The memory attention mechanism is to make the image embedding from image encoder fully interact with the information from memory bank, resulting in the refined embedding. Apart from the memory mechanism, SAM 2 also adopts the MAE pre-trained Hiera <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib96" title=""><span class="ltx_text" style="font-size:90%;">96</span></a>]</cite> as image encoder which is more efficient than ViT-H, with expectation for faster speed.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Task</h4>
<div class="ltx_para" id="S2.SS1.SSS2.p1">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">The promptable segmentation task is proposed as the fundamental task of SAM, whose goal is to return a valid mask with any given prompt (e.g. a point, a box, a mask, and text). This task is not only the objective during SAM’s training, but also the base that enables SAM to solve various downstream tasks. Another important task is the all-mask generation which segments all objects in a picture. It is achieved by prompting SAM with a grid of points and then predicting masks based on these dense prompts. It is also a key procedure in the last stage of the data engine, which aims at enhancing the diversity of masks in SA-1B. As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.F2" title="Figure 2 ‣ 2.1.2 Task ‣ 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>, the promptable segmentation task is called <span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p1.1.1">Segment Anything (SegAny)</span>, and the all-masks generation task is termed as <span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p1.1.2">Segment Everything (SegEvery)</span>. These two tasks have summarized SAM’s segmentation ability and have led to two research directions for enhancing SAM’s efficiency. In this survey, We follow the two definitions, exploring SAM-based efficient variants’ performance in both SegAny and SegEvery task.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="731" id="S2.F2.g1" src="x3.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S2.F2.3.2" style="font-size:90%;">Illustration of the Segment Anything task (SegAny) and the Segment Everything task (SegEvery).</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>Application</h4>
<div class="ltx_para" id="S2.SS1.SSS3.p1">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1">As SAM and its successor SAM 2 have demonstrated strong generalization in plenty of zero-shot downstream tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite>, the community is diving into exploring their application in more scenarios.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p2">
<p class="ltx_p" id="S2.SS1.SSS3.p2.1">One of the major applications of SAM is medical image segmentation. According to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib157" title=""><span class="ltx_text" style="font-size:90%;">157</span></a>]</cite>, works in this area can be classified into two types. Some aim at testing SAM’s segmentation performance in CT images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib95" title=""><span class="ltx_text" style="font-size:90%;">95</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite>, MRI images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib82" title=""><span class="ltx_text" style="font-size:90%;">82</span></a>]</cite>, pathological images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>, and so on. Others focus on improving the adaptation of SAM to these tasks by fine-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib78" title=""><span class="ltx_text" style="font-size:90%;">78</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib64" title=""><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite>, auto-prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">48</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib98" title=""><span class="ltx_text" style="font-size:90%;">98</span></a>]</cite> or framework modification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib156" title=""><span class="ltx_text" style="font-size:90%;">156</span></a>]</cite>. Furthermore, works like <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib57" title=""><span class="ltx_text" style="font-size:90%;">57</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite> attempt to improve medical SAM methods’ efficiency.
SAM is also applied to object detection across a diverse range of real-world scenes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib149" title=""><span class="ltx_text" style="font-size:90%;">149</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>, including crack detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> and crater detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite> in civil infrastructure defect assessment, crop disease and pest detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">63</span></a>]</cite> in agriculture, anomaly detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite> and remote sensing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib85" title=""><span class="ltx_text" style="font-size:90%;">85</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib119" title=""><span class="ltx_text" style="font-size:90%;">119</span></a>]</cite>.
Moreover, Segment Anything has been adapted to Edit Everything <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib130" title=""><span class="ltx_text" style="font-size:90%;">130</span></a>]</cite>, Inpaint Anything <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib141" title=""><span class="ltx_text" style="font-size:90%;">141</span></a>]</cite> and Caption Anything <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib121" title=""><span class="ltx_text" style="font-size:90%;">121</span></a>]</cite> to handle image editing tasks.</p>
</div>
<div class="ltx_para" id="S2.SS1.SSS3.p3">
<p class="ltx_p" id="S2.SS1.SSS3.p3.1">Apart from image segmentation tasks, SAM has been widely applied to various video tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib151" title=""><span class="ltx_text" style="font-size:90%;">151</span></a>]</cite>. A large portion of the works concentrate on two basic tasks: video object segmentation (VOS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib154" title=""><span class="ltx_text" style="font-size:90%;">154</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib158" title=""><span class="ltx_text" style="font-size:90%;">158</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> and video object tracking (VOT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib137" title=""><span class="ltx_text" style="font-size:90%;">137</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">20</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib92" title=""><span class="ltx_text" style="font-size:90%;">92</span></a>]</cite>. Researchers also explore SAM’s application in tasks related to generation, for example, video super-resolution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib76" title=""><span class="ltx_text" style="font-size:90%;">76</span></a>]</cite> and video dataset annotation generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>. Besides these, SAM is further utilized as an intermediate tool in video editing tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib163" title=""><span class="ltx_text" style="font-size:90%;">163</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib126" title=""><span class="ltx_text" style="font-size:90%;">126</span></a>]</cite>.
Beyond 2D tasks, SAM is also extended to 3D vision filed. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib100" title=""><span class="ltx_text" style="font-size:90%;">100</span></a>]</cite> applies SAM to 3D reconstruction and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite> applies it to 3D point cloud segmentation. The recent work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib134" title=""><span class="ltx_text" style="font-size:90%;">134</span></a>]</cite> aims at achieving real-time segmentation for any 3D thing in an online setting.
For the recent proposed SAM 2, there are already some studies exploring its application in both image and video tasks. A popular trend is to apply SAM 2 to medical images and video tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib155" title=""><span class="ltx_text" style="font-size:90%;">155</span></a>]</cite>. Works like <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib99" title=""><span class="ltx_text" style="font-size:90%;">99</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">27</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib135" title=""><span class="ltx_text" style="font-size:90%;">135</span></a>]</cite> evaluate SAM 2’s performance in medical images in both 2D and 3D modalities, while some others <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib140" title=""><span class="ltx_text" style="font-size:90%;">140</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib75" title=""><span class="ltx_text" style="font-size:90%;">75</span></a>]</cite> test it on surgical video segmentation tasks. Researchers are also seeking for strategies to adapt SAM 2 to medical tasks better <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib136" title=""><span class="ltx_text" style="font-size:90%;">136</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib166" title=""><span class="ltx_text" style="font-size:90%;">166</span></a>]</cite>. Besides these, SAM 2 has been applied to some specific image segmentation tasks like digital pathology semantic segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib153" title=""><span class="ltx_text" style="font-size:90%;">153</span></a>]</cite>, mesh part segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib109" title=""><span class="ltx_text" style="font-size:90%;">109</span></a>]</cite> and solar panels segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib91" title=""><span class="ltx_text" style="font-size:90%;">91</span></a>]</cite>. Moreover, several works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib113" title=""><span class="ltx_text" style="font-size:90%;">113</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib70" title=""><span class="ltx_text" style="font-size:90%;">70</span></a>]</cite> have utilized SAM 2 on the challenging Large-scale Video Object Segmentation (LSVOS) task and achieved good results.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4 </span>Limitation</h4>
<div class="ltx_para" id="S2.SS1.SSS4.p1">
<p class="ltx_p" id="S2.SS1.SSS4.p1.1">Although SAM has demonstrated promising performance across various tasks, it still faces two key challenges in practical applications: 1) it often struggles to predict complete masks for fine structures, leading to imprecise boundaries; and 2) it is not real-time and remains resource-intensive, particularly when using heavy image encoders like ViT-H. To address these issues, works such as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib54" title=""><span class="ltx_text" style="font-size:90%;">54</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite> aim to improve mask quality by utilizing high-resolution images, while others <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib131" title=""><span class="ltx_text" style="font-size:90%;">131</span></a>]</cite> focus on creating more efficient architectures to reduce SAM’s time and resource consumption. Previous surveys <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib78" title=""><span class="ltx_text" style="font-size:90%;">78</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib158" title=""><span class="ltx_text" style="font-size:90%;">158</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib100" title=""><span class="ltx_text" style="font-size:90%;">100</span></a>]</cite> have explored recent advances in enhancing SAM for higher-quality results. In this survey, we focus specifically on efforts to improve SAM’s efficiency.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Efficient Backbone</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">SAM’s inefficiency primarily stems from its heavy-weight image encoder. The sizes of SAM’s image encoder are detailed in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.T1" title="Table 1 ‣ 2.2 Efficient Backbone ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a>, with further estimates of SAM’s total parameters provided in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS1" title="4.1 Datasets and Metrics ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4.1</span></a>. As shown, in SAM-H, the ViT-H image encoder contains approximately 632M parameters, while the total model size is 641M, meaning the image encoder accounts for most of the model’s parameters. Even in the smallest variant, SAM-B, the image encoder still represents over 90<math alttext="\%" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mo id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\%</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">%</annotation></semantics></math> of the total parameters. Therefore, a straightforward yet effective method to accelerate SAM is to replace the large image encoder with more efficient backbones. These efficient backbones can include pure convolutional neural networks (CNNs) such as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib94" title=""><span class="ltx_text" style="font-size:90%;">94</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">43</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib117" title=""><span class="ltx_text" style="font-size:90%;">117</span></a>]</cite>, efficient vision Transformer architectures like <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib127" title=""><span class="ltx_text" style="font-size:90%;">127</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib61" title=""><span class="ltx_text" style="font-size:90%;">61</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>, and recent Transformer-alternative models like <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib87" title=""><span class="ltx_text" style="font-size:90%;">87</span></a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T1.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.2.1.1.1">Parameters</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.2.1.1.2">SAM-H</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.2.1.1.3">SAM-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.2.1.1.4">SAM-B</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.2.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.1.1">Image Encoder</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.1.2">632M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.1.3">307M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.2.2.1.4">86M</td>
</tr>
<tr class="ltx_tr" id="S2.T1.2.3.2">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T1.2.3.2.1">Prompt Encoder</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" colspan="3" id="S2.T1.2.3.2.2">0.006M</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S2.T1.4.2" style="font-size:90%;">Parameters of SAM’s encoders.</span></figcaption>
</figure>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Efficient Vision Transformer</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">Efforts to improve the efficiency of Vision Transformers can generally be categorized into two approaches: 1) Designing more efficient architectures; 2) Refactoring the attention mechanism.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS1.p2">
<p class="ltx_p" id="S2.SS2.SSS1.p2.1">To reduce computational cost from a structural perspective, MobileViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib80" title=""><span class="ltx_text" style="font-size:90%;">80</span></a>]</cite>, a pioneering hybrid architecture, creatively integrates CNN blocks (MobileNetV2 blocks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib97" title=""><span class="ltx_text" style="font-size:90%;">97</span></a>]</cite>) with Transformer blocks into a single model. Subsequent works such as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib127" title=""><span class="ltx_text" style="font-size:90%;">127</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">62</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> basically follow this idea to build up efficient ViTs with hybrid structures, which have been widely used to substitute SAM’s heavy image encoder. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite>, TinyViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib127" title=""><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite> serves as the efficient backbone, while in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib162" title=""><span class="ltx_text" style="font-size:90%;">162</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite>, EfficientFormerV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> and EfficientViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> supplant SAM’s original image encoder, respectively.
Another influential ViT design, MetaFormer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib142" title=""><span class="ltx_text" style="font-size:90%;">142</span></a>]</cite>, which abstracts the attention mechanism into a broader concept called the token mixer, can deliver performance on par with Transformers using various token mixers. The simplest variant, PoolFormer, which uses pooling operations as the token mixer without introducing additional learnable parameters, has been leveraged as the base architecture to develop the light-weight image encoder for Lite-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS1.p3">
<p class="ltx_p" id="S2.SS2.SSS1.p3.1">Researchers have also made significant progress in optimizing the attention mechanism. It has been observed that the softmax operation within the attention mechanism contributes significantly to the overall computational cost. In EfficientViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>, a novel ReLU linear attention is proposed to achieve global receptive field with higher efficiency. This efficient backbone is further adopted in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite> to accelerate SAM.
Improvements to the attention mechanism have also been made at the hardware level. FlashAttention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> significantly reduces computation costs through techniques such as tiling, kernel fusion, and recomputation. And it is utilized in SAM acceleration works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib101" title=""><span class="ltx_text" style="font-size:90%;">101</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib104" title=""><span class="ltx_text" style="font-size:90%;">104</span></a>]</cite> to reduce memory need and enhance computation efficiency.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Transformer-alternative Models</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">While Transformers currently dominate both the language and vision fields, several newly proposed models have shown the potential to surpass them in terms of efficiency and performance.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p2">
<p class="ltx_p" id="S2.SS2.SSS2.p2.3">The Receptance Weighted Key Value (RWKV) model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib87" title=""><span class="ltx_text" style="font-size:90%;">87</span></a>]</cite>, which combines the strengths of both recurrent neural networks (RNNs) and Transformers, achieves linear time complexity as sequence length increases. RWKV is well-suited for handling long sequence processing challenges. To facilitate global information interaction, RWKV replaces the traditional attention mechanism, which has quadratic complexity, with the more efficient WKV Operator and output gating mechanism. These are formulated as follows,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx1">
<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle wkv_{t}" class="ltx_Math" display="inline" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mi id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">w</mi><mo id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml">k</mi><mo id="S2.E1.m1.1.1.1a" xref="S2.E1.m1.1.1.1.cmml">⁢</mo><msub id="S2.E1.m1.1.1.4" xref="S2.E1.m1.1.1.4.cmml"><mi id="S2.E1.m1.1.1.4.2" xref="S2.E1.m1.1.1.4.2.cmml">v</mi><mi id="S2.E1.m1.1.1.4.3" xref="S2.E1.m1.1.1.4.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><times id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"></times><ci id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2">𝑤</ci><ci id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3">𝑘</ci><apply id="S2.E1.m1.1.1.4.cmml" xref="S2.E1.m1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.4">subscript</csymbol><ci id="S2.E1.m1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.4.2">𝑣</ci><ci id="S2.E1.m1.1.1.4.3.cmml" xref="S2.E1.m1.1.1.4.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle wkv_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">italic_w italic_k italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{\sum_{i=1}^{t-1}e^{-(t-1-i)w+k_{i}}\odot v_{i}+e^{u+k_{t}}%
\odot v_{t}}{\sum_{i=1}^{t-1}e^{-(t-1-i)w+k_{i}}+e^{u+k_{t}}}" class="ltx_Math" display="inline" id="S2.E1.m2.2"><semantics id="S2.E1.m2.2a"><mrow id="S2.E1.m2.2.3" xref="S2.E1.m2.2.3.cmml"><mi id="S2.E1.m2.2.3.2" xref="S2.E1.m2.2.3.2.cmml"></mi><mo id="S2.E1.m2.2.3.1" xref="S2.E1.m2.2.3.1.cmml">=</mo><mstyle displaystyle="true" id="S2.E1.m2.2.2" xref="S2.E1.m2.2.2.cmml"><mfrac id="S2.E1.m2.2.2a" xref="S2.E1.m2.2.2.cmml"><mrow id="S2.E1.m2.1.1.1" xref="S2.E1.m2.1.1.1.cmml"><mrow id="S2.E1.m2.1.1.1.3" xref="S2.E1.m2.1.1.1.3.cmml"><msubsup id="S2.E1.m2.1.1.1.3.1" xref="S2.E1.m2.1.1.1.3.1.cmml"><mo id="S2.E1.m2.1.1.1.3.1.2.2" xref="S2.E1.m2.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m2.1.1.1.3.1.2.3" xref="S2.E1.m2.1.1.1.3.1.2.3.cmml"><mi id="S2.E1.m2.1.1.1.3.1.2.3.2" xref="S2.E1.m2.1.1.1.3.1.2.3.2.cmml">i</mi><mo id="S2.E1.m2.1.1.1.3.1.2.3.1" xref="S2.E1.m2.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m2.1.1.1.3.1.2.3.3" xref="S2.E1.m2.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S2.E1.m2.1.1.1.3.1.3" xref="S2.E1.m2.1.1.1.3.1.3.cmml"><mi id="S2.E1.m2.1.1.1.3.1.3.2" xref="S2.E1.m2.1.1.1.3.1.3.2.cmml">t</mi><mo id="S2.E1.m2.1.1.1.3.1.3.1" xref="S2.E1.m2.1.1.1.3.1.3.1.cmml">−</mo><mn id="S2.E1.m2.1.1.1.3.1.3.3" xref="S2.E1.m2.1.1.1.3.1.3.3.cmml">1</mn></mrow></msubsup><mrow id="S2.E1.m2.1.1.1.3.2" xref="S2.E1.m2.1.1.1.3.2.cmml"><msup id="S2.E1.m2.1.1.1.3.2.2" xref="S2.E1.m2.1.1.1.3.2.2.cmml"><mi id="S2.E1.m2.1.1.1.3.2.2.2" xref="S2.E1.m2.1.1.1.3.2.2.2.cmml">e</mi><mrow id="S2.E1.m2.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.cmml"><mrow id="S2.E1.m2.1.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.cmml"><mo id="S2.E1.m2.1.1.1.1.1.1a" xref="S2.E1.m2.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m2.1.1.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m2.1.1.1.1.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E1.m2.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mo id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.3.cmml">1</mn><mo id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.1a" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.4" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.4.cmml">i</mi></mrow><mo id="S2.E1.m2.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E1.m2.1.1.1.1.1.1.1.2" xref="S2.E1.m2.1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.E1.m2.1.1.1.1.1.1.1.3" xref="S2.E1.m2.1.1.1.1.1.1.1.3.cmml">w</mi></mrow></mrow><mo id="S2.E1.m2.1.1.1.1.1.2" xref="S2.E1.m2.1.1.1.1.1.2.cmml">+</mo><msub id="S2.E1.m2.1.1.1.1.1.3" xref="S2.E1.m2.1.1.1.1.1.3.cmml"><mi id="S2.E1.m2.1.1.1.1.1.3.2" xref="S2.E1.m2.1.1.1.1.1.3.2.cmml">k</mi><mi id="S2.E1.m2.1.1.1.1.1.3.3" xref="S2.E1.m2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow></msup><mo id="S2.E1.m2.1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m2.1.1.1.3.2.1.cmml">⊙</mo><msub id="S2.E1.m2.1.1.1.3.2.3" xref="S2.E1.m2.1.1.1.3.2.3.cmml"><mi id="S2.E1.m2.1.1.1.3.2.3.2" xref="S2.E1.m2.1.1.1.3.2.3.2.cmml">v</mi><mi id="S2.E1.m2.1.1.1.3.2.3.3" xref="S2.E1.m2.1.1.1.3.2.3.3.cmml">i</mi></msub></mrow></mrow><mo id="S2.E1.m2.1.1.1.2" xref="S2.E1.m2.1.1.1.2.cmml">+</mo><mrow id="S2.E1.m2.1.1.1.4" xref="S2.E1.m2.1.1.1.4.cmml"><msup id="S2.E1.m2.1.1.1.4.2" xref="S2.E1.m2.1.1.1.4.2.cmml"><mi id="S2.E1.m2.1.1.1.4.2.2" xref="S2.E1.m2.1.1.1.4.2.2.cmml">e</mi><mrow id="S2.E1.m2.1.1.1.4.2.3" xref="S2.E1.m2.1.1.1.4.2.3.cmml"><mi id="S2.E1.m2.1.1.1.4.2.3.2" xref="S2.E1.m2.1.1.1.4.2.3.2.cmml">u</mi><mo id="S2.E1.m2.1.1.1.4.2.3.1" xref="S2.E1.m2.1.1.1.4.2.3.1.cmml">+</mo><msub id="S2.E1.m2.1.1.1.4.2.3.3" xref="S2.E1.m2.1.1.1.4.2.3.3.cmml"><mi id="S2.E1.m2.1.1.1.4.2.3.3.2" xref="S2.E1.m2.1.1.1.4.2.3.3.2.cmml">k</mi><mi id="S2.E1.m2.1.1.1.4.2.3.3.3" xref="S2.E1.m2.1.1.1.4.2.3.3.3.cmml">t</mi></msub></mrow></msup><mo id="S2.E1.m2.1.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m2.1.1.1.4.1.cmml">⊙</mo><msub id="S2.E1.m2.1.1.1.4.3" xref="S2.E1.m2.1.1.1.4.3.cmml"><mi id="S2.E1.m2.1.1.1.4.3.2" xref="S2.E1.m2.1.1.1.4.3.2.cmml">v</mi><mi id="S2.E1.m2.1.1.1.4.3.3" xref="S2.E1.m2.1.1.1.4.3.3.cmml">t</mi></msub></mrow></mrow><mrow id="S2.E1.m2.2.2.2" xref="S2.E1.m2.2.2.2.cmml"><mrow id="S2.E1.m2.2.2.2.3" xref="S2.E1.m2.2.2.2.3.cmml"><msubsup id="S2.E1.m2.2.2.2.3.1" xref="S2.E1.m2.2.2.2.3.1.cmml"><mo id="S2.E1.m2.2.2.2.3.1.2.2" xref="S2.E1.m2.2.2.2.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m2.2.2.2.3.1.2.3" xref="S2.E1.m2.2.2.2.3.1.2.3.cmml"><mi id="S2.E1.m2.2.2.2.3.1.2.3.2" xref="S2.E1.m2.2.2.2.3.1.2.3.2.cmml">i</mi><mo id="S2.E1.m2.2.2.2.3.1.2.3.1" xref="S2.E1.m2.2.2.2.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m2.2.2.2.3.1.2.3.3" xref="S2.E1.m2.2.2.2.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S2.E1.m2.2.2.2.3.1.3" xref="S2.E1.m2.2.2.2.3.1.3.cmml"><mi id="S2.E1.m2.2.2.2.3.1.3.2" xref="S2.E1.m2.2.2.2.3.1.3.2.cmml">t</mi><mo id="S2.E1.m2.2.2.2.3.1.3.1" xref="S2.E1.m2.2.2.2.3.1.3.1.cmml">−</mo><mn id="S2.E1.m2.2.2.2.3.1.3.3" xref="S2.E1.m2.2.2.2.3.1.3.3.cmml">1</mn></mrow></msubsup><msup id="S2.E1.m2.2.2.2.3.2" xref="S2.E1.m2.2.2.2.3.2.cmml"><mi id="S2.E1.m2.2.2.2.3.2.2" xref="S2.E1.m2.2.2.2.3.2.2.cmml">e</mi><mrow id="S2.E1.m2.2.2.2.1.1" xref="S2.E1.m2.2.2.2.1.1.cmml"><mrow id="S2.E1.m2.2.2.2.1.1.1" xref="S2.E1.m2.2.2.2.1.1.1.cmml"><mo id="S2.E1.m2.2.2.2.1.1.1a" xref="S2.E1.m2.2.2.2.1.1.1.cmml">−</mo><mrow id="S2.E1.m2.2.2.2.1.1.1.1" xref="S2.E1.m2.2.2.2.1.1.1.1.cmml"><mrow id="S2.E1.m2.2.2.2.1.1.1.1.1.1" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.cmml"><mo id="S2.E1.m2.2.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.2" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.2.cmml">t</mi><mo id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.1" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.3" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.3.cmml">1</mn><mo id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.1a" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.4" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.4.cmml">i</mi></mrow><mo id="S2.E1.m2.2.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E1.m2.2.2.2.1.1.1.1.2" xref="S2.E1.m2.2.2.2.1.1.1.1.2.cmml">⁢</mo><mi id="S2.E1.m2.2.2.2.1.1.1.1.3" xref="S2.E1.m2.2.2.2.1.1.1.1.3.cmml">w</mi></mrow></mrow><mo id="S2.E1.m2.2.2.2.1.1.2" xref="S2.E1.m2.2.2.2.1.1.2.cmml">+</mo><msub id="S2.E1.m2.2.2.2.1.1.3" xref="S2.E1.m2.2.2.2.1.1.3.cmml"><mi id="S2.E1.m2.2.2.2.1.1.3.2" xref="S2.E1.m2.2.2.2.1.1.3.2.cmml">k</mi><mi id="S2.E1.m2.2.2.2.1.1.3.3" xref="S2.E1.m2.2.2.2.1.1.3.3.cmml">i</mi></msub></mrow></msup></mrow><mo id="S2.E1.m2.2.2.2.2" xref="S2.E1.m2.2.2.2.2.cmml">+</mo><msup id="S2.E1.m2.2.2.2.4" xref="S2.E1.m2.2.2.2.4.cmml"><mi id="S2.E1.m2.2.2.2.4.2" xref="S2.E1.m2.2.2.2.4.2.cmml">e</mi><mrow id="S2.E1.m2.2.2.2.4.3" xref="S2.E1.m2.2.2.2.4.3.cmml"><mi id="S2.E1.m2.2.2.2.4.3.2" xref="S2.E1.m2.2.2.2.4.3.2.cmml">u</mi><mo id="S2.E1.m2.2.2.2.4.3.1" xref="S2.E1.m2.2.2.2.4.3.1.cmml">+</mo><msub id="S2.E1.m2.2.2.2.4.3.3" xref="S2.E1.m2.2.2.2.4.3.3.cmml"><mi id="S2.E1.m2.2.2.2.4.3.3.2" xref="S2.E1.m2.2.2.2.4.3.3.2.cmml">k</mi><mi id="S2.E1.m2.2.2.2.4.3.3.3" xref="S2.E1.m2.2.2.2.4.3.3.3.cmml">t</mi></msub></mrow></msup></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m2.2b"><apply id="S2.E1.m2.2.3.cmml" xref="S2.E1.m2.2.3"><eq id="S2.E1.m2.2.3.1.cmml" xref="S2.E1.m2.2.3.1"></eq><csymbol cd="latexml" id="S2.E1.m2.2.3.2.cmml" xref="S2.E1.m2.2.3.2">absent</csymbol><apply id="S2.E1.m2.2.2.cmml" xref="S2.E1.m2.2.2"><divide id="S2.E1.m2.2.2.3.cmml" xref="S2.E1.m2.2.2"></divide><apply id="S2.E1.m2.1.1.1.cmml" xref="S2.E1.m2.1.1.1"><plus id="S2.E1.m2.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.2"></plus><apply id="S2.E1.m2.1.1.1.3.cmml" xref="S2.E1.m2.1.1.1.3"><apply id="S2.E1.m2.1.1.1.3.1.cmml" xref="S2.E1.m2.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.3.1.1.cmml" xref="S2.E1.m2.1.1.1.3.1">superscript</csymbol><apply id="S2.E1.m2.1.1.1.3.1.2.cmml" xref="S2.E1.m2.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.3.1.2.1.cmml" xref="S2.E1.m2.1.1.1.3.1">subscript</csymbol><sum id="S2.E1.m2.1.1.1.3.1.2.2.cmml" xref="S2.E1.m2.1.1.1.3.1.2.2"></sum><apply id="S2.E1.m2.1.1.1.3.1.2.3.cmml" xref="S2.E1.m2.1.1.1.3.1.2.3"><eq id="S2.E1.m2.1.1.1.3.1.2.3.1.cmml" xref="S2.E1.m2.1.1.1.3.1.2.3.1"></eq><ci id="S2.E1.m2.1.1.1.3.1.2.3.2.cmml" xref="S2.E1.m2.1.1.1.3.1.2.3.2">𝑖</ci><cn id="S2.E1.m2.1.1.1.3.1.2.3.3.cmml" type="integer" xref="S2.E1.m2.1.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m2.1.1.1.3.1.3.cmml" xref="S2.E1.m2.1.1.1.3.1.3"><minus id="S2.E1.m2.1.1.1.3.1.3.1.cmml" xref="S2.E1.m2.1.1.1.3.1.3.1"></minus><ci id="S2.E1.m2.1.1.1.3.1.3.2.cmml" xref="S2.E1.m2.1.1.1.3.1.3.2">𝑡</ci><cn id="S2.E1.m2.1.1.1.3.1.3.3.cmml" type="integer" xref="S2.E1.m2.1.1.1.3.1.3.3">1</cn></apply></apply><apply id="S2.E1.m2.1.1.1.3.2.cmml" xref="S2.E1.m2.1.1.1.3.2"><csymbol cd="latexml" id="S2.E1.m2.1.1.1.3.2.1.cmml" xref="S2.E1.m2.1.1.1.3.2.1">direct-product</csymbol><apply id="S2.E1.m2.1.1.1.3.2.2.cmml" xref="S2.E1.m2.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.3.2.2.1.cmml" xref="S2.E1.m2.1.1.1.3.2.2">superscript</csymbol><ci id="S2.E1.m2.1.1.1.3.2.2.2.cmml" xref="S2.E1.m2.1.1.1.3.2.2.2">𝑒</ci><apply id="S2.E1.m2.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1"><plus id="S2.E1.m2.1.1.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.1.1.2"></plus><apply id="S2.E1.m2.1.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1.1"><minus id="S2.E1.m2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.1.1.1"></minus><apply id="S2.E1.m2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1"><times id="S2.E1.m2.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1.2"></times><apply id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1"><minus id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.1"></minus><ci id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.2">𝑡</ci><cn id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.3">1</cn><ci id="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1.1.1.1.4">𝑖</ci></apply><ci id="S2.E1.m2.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m2.1.1.1.1.1.1.1.3">𝑤</ci></apply></apply><apply id="S2.E1.m2.1.1.1.1.1.3.cmml" xref="S2.E1.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.1.1.3.1.cmml" xref="S2.E1.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m2.1.1.1.1.1.3.2.cmml" xref="S2.E1.m2.1.1.1.1.1.3.2">𝑘</ci><ci id="S2.E1.m2.1.1.1.1.1.3.3.cmml" xref="S2.E1.m2.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><apply id="S2.E1.m2.1.1.1.3.2.3.cmml" xref="S2.E1.m2.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.3.2.3.1.cmml" xref="S2.E1.m2.1.1.1.3.2.3">subscript</csymbol><ci id="S2.E1.m2.1.1.1.3.2.3.2.cmml" xref="S2.E1.m2.1.1.1.3.2.3.2">𝑣</ci><ci id="S2.E1.m2.1.1.1.3.2.3.3.cmml" xref="S2.E1.m2.1.1.1.3.2.3.3">𝑖</ci></apply></apply></apply><apply id="S2.E1.m2.1.1.1.4.cmml" xref="S2.E1.m2.1.1.1.4"><csymbol cd="latexml" id="S2.E1.m2.1.1.1.4.1.cmml" xref="S2.E1.m2.1.1.1.4.1">direct-product</csymbol><apply id="S2.E1.m2.1.1.1.4.2.cmml" xref="S2.E1.m2.1.1.1.4.2"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.4.2.1.cmml" xref="S2.E1.m2.1.1.1.4.2">superscript</csymbol><ci id="S2.E1.m2.1.1.1.4.2.2.cmml" xref="S2.E1.m2.1.1.1.4.2.2">𝑒</ci><apply id="S2.E1.m2.1.1.1.4.2.3.cmml" xref="S2.E1.m2.1.1.1.4.2.3"><plus id="S2.E1.m2.1.1.1.4.2.3.1.cmml" xref="S2.E1.m2.1.1.1.4.2.3.1"></plus><ci id="S2.E1.m2.1.1.1.4.2.3.2.cmml" xref="S2.E1.m2.1.1.1.4.2.3.2">𝑢</ci><apply id="S2.E1.m2.1.1.1.4.2.3.3.cmml" xref="S2.E1.m2.1.1.1.4.2.3.3"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.4.2.3.3.1.cmml" xref="S2.E1.m2.1.1.1.4.2.3.3">subscript</csymbol><ci id="S2.E1.m2.1.1.1.4.2.3.3.2.cmml" xref="S2.E1.m2.1.1.1.4.2.3.3.2">𝑘</ci><ci id="S2.E1.m2.1.1.1.4.2.3.3.3.cmml" xref="S2.E1.m2.1.1.1.4.2.3.3.3">𝑡</ci></apply></apply></apply><apply id="S2.E1.m2.1.1.1.4.3.cmml" xref="S2.E1.m2.1.1.1.4.3"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.4.3.1.cmml" xref="S2.E1.m2.1.1.1.4.3">subscript</csymbol><ci id="S2.E1.m2.1.1.1.4.3.2.cmml" xref="S2.E1.m2.1.1.1.4.3.2">𝑣</ci><ci id="S2.E1.m2.1.1.1.4.3.3.cmml" xref="S2.E1.m2.1.1.1.4.3.3">𝑡</ci></apply></apply></apply><apply id="S2.E1.m2.2.2.2.cmml" xref="S2.E1.m2.2.2.2"><plus id="S2.E1.m2.2.2.2.2.cmml" xref="S2.E1.m2.2.2.2.2"></plus><apply id="S2.E1.m2.2.2.2.3.cmml" xref="S2.E1.m2.2.2.2.3"><apply id="S2.E1.m2.2.2.2.3.1.cmml" xref="S2.E1.m2.2.2.2.3.1"><csymbol cd="ambiguous" id="S2.E1.m2.2.2.2.3.1.1.cmml" xref="S2.E1.m2.2.2.2.3.1">superscript</csymbol><apply id="S2.E1.m2.2.2.2.3.1.2.cmml" xref="S2.E1.m2.2.2.2.3.1"><csymbol cd="ambiguous" id="S2.E1.m2.2.2.2.3.1.2.1.cmml" xref="S2.E1.m2.2.2.2.3.1">subscript</csymbol><sum id="S2.E1.m2.2.2.2.3.1.2.2.cmml" xref="S2.E1.m2.2.2.2.3.1.2.2"></sum><apply id="S2.E1.m2.2.2.2.3.1.2.3.cmml" xref="S2.E1.m2.2.2.2.3.1.2.3"><eq id="S2.E1.m2.2.2.2.3.1.2.3.1.cmml" xref="S2.E1.m2.2.2.2.3.1.2.3.1"></eq><ci id="S2.E1.m2.2.2.2.3.1.2.3.2.cmml" xref="S2.E1.m2.2.2.2.3.1.2.3.2">𝑖</ci><cn id="S2.E1.m2.2.2.2.3.1.2.3.3.cmml" type="integer" xref="S2.E1.m2.2.2.2.3.1.2.3.3">1</cn></apply></apply><apply id="S2.E1.m2.2.2.2.3.1.3.cmml" xref="S2.E1.m2.2.2.2.3.1.3"><minus id="S2.E1.m2.2.2.2.3.1.3.1.cmml" xref="S2.E1.m2.2.2.2.3.1.3.1"></minus><ci id="S2.E1.m2.2.2.2.3.1.3.2.cmml" xref="S2.E1.m2.2.2.2.3.1.3.2">𝑡</ci><cn id="S2.E1.m2.2.2.2.3.1.3.3.cmml" type="integer" xref="S2.E1.m2.2.2.2.3.1.3.3">1</cn></apply></apply><apply id="S2.E1.m2.2.2.2.3.2.cmml" xref="S2.E1.m2.2.2.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m2.2.2.2.3.2.1.cmml" xref="S2.E1.m2.2.2.2.3.2">superscript</csymbol><ci id="S2.E1.m2.2.2.2.3.2.2.cmml" xref="S2.E1.m2.2.2.2.3.2.2">𝑒</ci><apply id="S2.E1.m2.2.2.2.1.1.cmml" xref="S2.E1.m2.2.2.2.1.1"><plus id="S2.E1.m2.2.2.2.1.1.2.cmml" xref="S2.E1.m2.2.2.2.1.1.2"></plus><apply id="S2.E1.m2.2.2.2.1.1.1.cmml" xref="S2.E1.m2.2.2.2.1.1.1"><minus id="S2.E1.m2.2.2.2.1.1.1.2.cmml" xref="S2.E1.m2.2.2.2.1.1.1"></minus><apply id="S2.E1.m2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1"><times id="S2.E1.m2.2.2.2.1.1.1.1.2.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1.2"></times><apply id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1"><minus id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.1"></minus><ci id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.2">𝑡</ci><cn id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.3">1</cn><ci id="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1.1.1.1.4">𝑖</ci></apply><ci id="S2.E1.m2.2.2.2.1.1.1.1.3.cmml" xref="S2.E1.m2.2.2.2.1.1.1.1.3">𝑤</ci></apply></apply><apply id="S2.E1.m2.2.2.2.1.1.3.cmml" xref="S2.E1.m2.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m2.2.2.2.1.1.3.1.cmml" xref="S2.E1.m2.2.2.2.1.1.3">subscript</csymbol><ci id="S2.E1.m2.2.2.2.1.1.3.2.cmml" xref="S2.E1.m2.2.2.2.1.1.3.2">𝑘</ci><ci id="S2.E1.m2.2.2.2.1.1.3.3.cmml" xref="S2.E1.m2.2.2.2.1.1.3.3">𝑖</ci></apply></apply></apply></apply><apply id="S2.E1.m2.2.2.2.4.cmml" xref="S2.E1.m2.2.2.2.4"><csymbol cd="ambiguous" id="S2.E1.m2.2.2.2.4.1.cmml" xref="S2.E1.m2.2.2.2.4">superscript</csymbol><ci id="S2.E1.m2.2.2.2.4.2.cmml" xref="S2.E1.m2.2.2.2.4.2">𝑒</ci><apply id="S2.E1.m2.2.2.2.4.3.cmml" xref="S2.E1.m2.2.2.2.4.3"><plus id="S2.E1.m2.2.2.2.4.3.1.cmml" xref="S2.E1.m2.2.2.2.4.3.1"></plus><ci id="S2.E1.m2.2.2.2.4.3.2.cmml" xref="S2.E1.m2.2.2.2.4.3.2">𝑢</ci><apply id="S2.E1.m2.2.2.2.4.3.3.cmml" xref="S2.E1.m2.2.2.2.4.3.3"><csymbol cd="ambiguous" id="S2.E1.m2.2.2.2.4.3.3.1.cmml" xref="S2.E1.m2.2.2.2.4.3.3">subscript</csymbol><ci id="S2.E1.m2.2.2.2.4.3.3.2.cmml" xref="S2.E1.m2.2.2.2.4.3.3.2">𝑘</ci><ci id="S2.E1.m2.2.2.2.4.3.3.3.cmml" xref="S2.E1.m2.2.2.2.4.3.3.3">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m2.2c">\displaystyle=\frac{\sum_{i=1}^{t-1}e^{-(t-1-i)w+k_{i}}\odot v_{i}+e^{u+k_{t}}%
\odot v_{t}}{\sum_{i=1}^{t-1}e^{-(t-1-i)w+k_{i}}+e^{u+k_{t}}}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m2.2d">= divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - ( italic_t - 1 - italic_i ) italic_w + italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ⊙ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_e start_POSTSUPERSCRIPT italic_u + italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ⊙ italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_e start_POSTSUPERSCRIPT - ( italic_t - 1 - italic_i ) italic_w + italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT + italic_e start_POSTSUPERSCRIPT italic_u + italic_k start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx2">
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle o_{t}" class="ltx_Math" display="inline" id="S2.E2.m1.1"><semantics id="S2.E2.m1.1a"><msub id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mi id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml">o</mi><mi id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2">𝑜</ci><ci id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\displaystyle o_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.1d">italic_o start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=W_{o}\cdot(\sigma(r_{t})\odot wkv_{t})" class="ltx_Math" display="inline" id="S2.E2.m2.1"><semantics id="S2.E2.m2.1a"><mrow id="S2.E2.m2.1.1" xref="S2.E2.m2.1.1.cmml"><mi id="S2.E2.m2.1.1.3" xref="S2.E2.m2.1.1.3.cmml"></mi><mo id="S2.E2.m2.1.1.2" xref="S2.E2.m2.1.1.2.cmml">=</mo><mrow id="S2.E2.m2.1.1.1" xref="S2.E2.m2.1.1.1.cmml"><msub id="S2.E2.m2.1.1.1.3" xref="S2.E2.m2.1.1.1.3.cmml"><mi id="S2.E2.m2.1.1.1.3.2" xref="S2.E2.m2.1.1.1.3.2.cmml">W</mi><mi id="S2.E2.m2.1.1.1.3.3" xref="S2.E2.m2.1.1.1.3.3.cmml">o</mi></msub><mo id="S2.E2.m2.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S2.E2.m2.1.1.1.2.cmml">⋅</mo><mrow id="S2.E2.m2.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.cmml"><mo id="S2.E2.m2.1.1.1.1.1.2" stretchy="false" xref="S2.E2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m2.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m2.1.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m2.1.1.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m2.1.1.1.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.1.1.3.cmml">σ</mi><mo id="S2.E2.m2.1.1.1.1.1.1.1.1.2" xref="S2.E2.m2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">r</mi><mi id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m2.1.1.1.1.1.1.1.2" rspace="0.222em" xref="S2.E2.m2.1.1.1.1.1.1.1.2.cmml">⊙</mo><mi id="S2.E2.m2.1.1.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.1.3.cmml">w</mi></mrow><mo id="S2.E2.m2.1.1.1.1.1.1.2" xref="S2.E2.m2.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S2.E2.m2.1.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.3.cmml">k</mi><mo id="S2.E2.m2.1.1.1.1.1.1.2a" xref="S2.E2.m2.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S2.E2.m2.1.1.1.1.1.1.4" xref="S2.E2.m2.1.1.1.1.1.1.4.cmml"><mi id="S2.E2.m2.1.1.1.1.1.1.4.2" xref="S2.E2.m2.1.1.1.1.1.1.4.2.cmml">v</mi><mi id="S2.E2.m2.1.1.1.1.1.1.4.3" xref="S2.E2.m2.1.1.1.1.1.1.4.3.cmml">t</mi></msub></mrow><mo id="S2.E2.m2.1.1.1.1.1.3" stretchy="false" xref="S2.E2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m2.1b"><apply id="S2.E2.m2.1.1.cmml" xref="S2.E2.m2.1.1"><eq id="S2.E2.m2.1.1.2.cmml" xref="S2.E2.m2.1.1.2"></eq><csymbol cd="latexml" id="S2.E2.m2.1.1.3.cmml" xref="S2.E2.m2.1.1.3">absent</csymbol><apply id="S2.E2.m2.1.1.1.cmml" xref="S2.E2.m2.1.1.1"><ci id="S2.E2.m2.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.2">⋅</ci><apply id="S2.E2.m2.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m2.1.1.1.3.1.cmml" xref="S2.E2.m2.1.1.1.3">subscript</csymbol><ci id="S2.E2.m2.1.1.1.3.2.cmml" xref="S2.E2.m2.1.1.1.3.2">𝑊</ci><ci id="S2.E2.m2.1.1.1.3.3.cmml" xref="S2.E2.m2.1.1.1.3.3">𝑜</ci></apply><apply id="S2.E2.m2.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1"><times id="S2.E2.m2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.2"></times><apply id="S2.E2.m2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m2.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.2">direct-product</csymbol><apply id="S2.E2.m2.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1"><times id="S2.E2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1.3">𝜎</ci><apply id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.2">𝑟</ci><ci id="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply><ci id="S2.E2.m2.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.1.3">𝑤</ci></apply><ci id="S2.E2.m2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.3">𝑘</ci><apply id="S2.E2.m2.1.1.1.1.1.1.4.cmml" xref="S2.E2.m2.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m2.1.1.1.1.1.1.4.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E2.m2.1.1.1.1.1.1.4.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.4.2">𝑣</ci><ci id="S2.E2.m2.1.1.1.1.1.1.4.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.4.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m2.1c">\displaystyle=W_{o}\cdot(\sigma(r_{t})\odot wkv_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m2.1d">= italic_W start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ⋅ ( italic_σ ( italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ⊙ italic_w italic_k italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.SSS2.p2.2">where <math alttext="r,k,v" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p2.1.m1.3"><semantics id="S2.SS2.SSS2.p2.1.m1.3a"><mrow id="S2.SS2.SSS2.p2.1.m1.3.4.2" xref="S2.SS2.SSS2.p2.1.m1.3.4.1.cmml"><mi id="S2.SS2.SSS2.p2.1.m1.1.1" xref="S2.SS2.SSS2.p2.1.m1.1.1.cmml">r</mi><mo id="S2.SS2.SSS2.p2.1.m1.3.4.2.1" xref="S2.SS2.SSS2.p2.1.m1.3.4.1.cmml">,</mo><mi id="S2.SS2.SSS2.p2.1.m1.2.2" xref="S2.SS2.SSS2.p2.1.m1.2.2.cmml">k</mi><mo id="S2.SS2.SSS2.p2.1.m1.3.4.2.2" xref="S2.SS2.SSS2.p2.1.m1.3.4.1.cmml">,</mo><mi id="S2.SS2.SSS2.p2.1.m1.3.3" xref="S2.SS2.SSS2.p2.1.m1.3.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.1.m1.3b"><list id="S2.SS2.SSS2.p2.1.m1.3.4.1.cmml" xref="S2.SS2.SSS2.p2.1.m1.3.4.2"><ci id="S2.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1">𝑟</ci><ci id="S2.SS2.SSS2.p2.1.m1.2.2.cmml" xref="S2.SS2.SSS2.p2.1.m1.2.2">𝑘</ci><ci id="S2.SS2.SSS2.p2.1.m1.3.3.cmml" xref="S2.SS2.SSS2.p2.1.m1.3.3">𝑣</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.1.m1.3c">r,k,v</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p2.1.m1.3d">italic_r , italic_k , italic_v</annotation></semantics></math> represents the shifted tokens of receptance, key and value respectively and <math alttext="W" class="ltx_Math" display="inline" id="S2.SS2.SSS2.p2.2.m2.1"><semantics id="S2.SS2.SSS2.p2.2.m2.1a"><mi id="S2.SS2.SSS2.p2.2.m2.1.1" xref="S2.SS2.SSS2.p2.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.2.m2.1b"><ci id="S2.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.2.m2.1c">W</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS2.p2.2.m2.1d">italic_W</annotation></semantics></math> refers to weight.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p3">
<p class="ltx_p" id="S2.SS2.SSS2.p3.1">RWKV has also been extended to the vision tasks. The Vision-RWKV (VRWKV) model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> demonstrates performance comparable to Vision Transformers (ViT) but with greater efficiency. To adapt RWKV from 1D sequences to 2D images, Q-shift tokens is introduced to fuse neighborhood information in four directions. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib145" title=""><span class="ltx_text" style="font-size:90%;">145</span></a>]</cite>, a RWKV-based variant of SAM has achieved outstanding performance in efficiency, by adopting the efficient backbone mixed of MobileNetV2 blocks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib97" title=""><span class="ltx_text" style="font-size:90%;">97</span></a>]</cite> and VRWKV blocks.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Model Compression</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Model compression encompasses a range of techniques aimed at reducing the size and computational complexity of models, making it essential for deploying large models in real-world applications where computational resources are limited. The four primary methods for model compression and acceleration are knowledge distillation, quantization, pruning, and low-rank factorization.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Knowledge Distillation</h4>
<div class="ltx_para" id="S2.SS3.SSS1.p1">
<p class="ltx_p" id="S2.SS3.SSS1.p1.1">Knowledge distillation (KD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib45" title=""><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> was first introduced as a solution for deploying large, complex neural networks in resource-constrained environments. The core concept is to transfer the knowledge and representation capability from a larger, well-trained model (the teacher model) to a smaller, more efficient model (the student model).</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS1.p2">
<p class="ltx_p" id="S2.SS3.SSS1.p2.1">When applying KD to accelerate SAM, the goal is to distill the knowledge from the original, larger SAM and impart it to more efficient SAM-like models. Given SAM’s encoder-decoder architecture, KD can generally be categorized into two approaches: distilling the entire SAM model or distilling the image encoder alone. Most works, such as <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib84" title=""><span class="ltx_text" style="font-size:90%;">84</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib117" title=""><span class="ltx_text" style="font-size:90%;">117</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite>, focus on distilling only the efficient backbone, while retaining the original SAM’s prompt encoder and mask decoder. However, other approaches, like <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib162" title=""><span class="ltx_text" style="font-size:90%;">162</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>]</cite>, aim to distill the entire model by supervising the outputs of both the encoder and decoder.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Quantization</h4>
<div class="ltx_para" id="S2.SS3.SSS2.p1">
<p class="ltx_p" id="S2.SS3.SSS2.p1.2">Quantization is the process to convert model’s high precision weights/activation values <math alttext="X" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.1.m1.1"><semantics id="S2.SS3.SSS2.p1.1.m1.1a"><mi id="S2.SS3.SSS2.p1.1.m1.1.1" xref="S2.SS3.SSS2.p1.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.1.m1.1b"><ci id="S2.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.1.m1.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.1.m1.1c">X</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.1.m1.1d">italic_X</annotation></semantics></math> (e.g. 32-bit floating point) to low precision formats <math alttext="X_{q}" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.2.m2.1"><semantics id="S2.SS3.SSS2.p1.2.m2.1a"><msub id="S2.SS3.SSS2.p1.2.m2.1.1" xref="S2.SS3.SSS2.p1.2.m2.1.1.cmml"><mi id="S2.SS3.SSS2.p1.2.m2.1.1.2" xref="S2.SS3.SSS2.p1.2.m2.1.1.2.cmml">X</mi><mi id="S2.SS3.SSS2.p1.2.m2.1.1.3" xref="S2.SS3.SSS2.p1.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.2.m2.1b"><apply id="S2.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1.2">𝑋</ci><ci id="S2.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S2.SS3.SSS2.p1.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.2.m2.1c">X_{q}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> (e.g. 16-bit floating point, 8-bit integer). One of the widely used quantization function, uniform symmetric quantization, is formulated as follows,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx3">
<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle X_{q}=Clamp(round(\frac{X}{s}),-2^{b}-1,2^{b-1}-1)" class="ltx_Math" display="inline" id="S2.E3.m1.4"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><msub id="S2.E3.m1.4.4.5" xref="S2.E3.m1.4.4.5.cmml"><mi id="S2.E3.m1.4.4.5.2" xref="S2.E3.m1.4.4.5.2.cmml">X</mi><mi id="S2.E3.m1.4.4.5.3" xref="S2.E3.m1.4.4.5.3.cmml">q</mi></msub><mo id="S2.E3.m1.4.4.4" xref="S2.E3.m1.4.4.4.cmml">=</mo><mrow id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml"><mi id="S2.E3.m1.4.4.3.5" xref="S2.E3.m1.4.4.3.5.cmml">C</mi><mo id="S2.E3.m1.4.4.3.4" xref="S2.E3.m1.4.4.3.4.cmml">⁢</mo><mi id="S2.E3.m1.4.4.3.6" xref="S2.E3.m1.4.4.3.6.cmml">l</mi><mo id="S2.E3.m1.4.4.3.4a" xref="S2.E3.m1.4.4.3.4.cmml">⁢</mo><mi id="S2.E3.m1.4.4.3.7" xref="S2.E3.m1.4.4.3.7.cmml">a</mi><mo id="S2.E3.m1.4.4.3.4b" xref="S2.E3.m1.4.4.3.4.cmml">⁢</mo><mi id="S2.E3.m1.4.4.3.8" xref="S2.E3.m1.4.4.3.8.cmml">m</mi><mo id="S2.E3.m1.4.4.3.4c" xref="S2.E3.m1.4.4.3.4.cmml">⁢</mo><mi id="S2.E3.m1.4.4.3.9" xref="S2.E3.m1.4.4.3.9.cmml">p</mi><mo id="S2.E3.m1.4.4.3.4d" xref="S2.E3.m1.4.4.3.4.cmml">⁢</mo><mrow id="S2.E3.m1.4.4.3.3.3" xref="S2.E3.m1.4.4.3.3.4.cmml"><mo id="S2.E3.m1.4.4.3.3.3.4" stretchy="false" xref="S2.E3.m1.4.4.3.3.4.cmml">(</mo><mrow id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.2.cmml">r</mi><mo id="S2.E3.m1.2.2.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="S2.E3.m1.2.2.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.3.cmml">o</mi><mo id="S2.E3.m1.2.2.1.1.1.1.1a" xref="S2.E3.m1.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="S2.E3.m1.2.2.1.1.1.1.4" xref="S2.E3.m1.2.2.1.1.1.1.4.cmml">u</mi><mo id="S2.E3.m1.2.2.1.1.1.1.1b" xref="S2.E3.m1.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="S2.E3.m1.2.2.1.1.1.1.5" xref="S2.E3.m1.2.2.1.1.1.1.5.cmml">n</mi><mo id="S2.E3.m1.2.2.1.1.1.1.1c" xref="S2.E3.m1.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="S2.E3.m1.2.2.1.1.1.1.6" xref="S2.E3.m1.2.2.1.1.1.1.6.cmml">d</mi><mo id="S2.E3.m1.2.2.1.1.1.1.1d" xref="S2.E3.m1.2.2.1.1.1.1.1.cmml">⁢</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.7.2" xref="S2.E3.m1.1.1.cmml"><mo id="S2.E3.m1.2.2.1.1.1.1.7.2.1" stretchy="false" xref="S2.E3.m1.1.1.cmml">(</mo><mstyle displaystyle="true" id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml"><mfrac id="S2.E3.m1.1.1a" xref="S2.E3.m1.1.1.cmml"><mi id="S2.E3.m1.1.1.2" xref="S2.E3.m1.1.1.2.cmml">X</mi><mi id="S2.E3.m1.1.1.3" xref="S2.E3.m1.1.1.3.cmml">s</mi></mfrac></mstyle><mo id="S2.E3.m1.2.2.1.1.1.1.7.2.2" stretchy="false" xref="S2.E3.m1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.3.3.3.5" xref="S2.E3.m1.4.4.3.3.4.cmml">,</mo><mrow id="S2.E3.m1.3.3.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.cmml"><mrow id="S2.E3.m1.3.3.2.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.2.cmml"><mo id="S2.E3.m1.3.3.2.2.2.2.2a" xref="S2.E3.m1.3.3.2.2.2.2.2.cmml">−</mo><msup id="S2.E3.m1.3.3.2.2.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.2.2.cmml"><mn id="S2.E3.m1.3.3.2.2.2.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.2.2.2.cmml">2</mn><mi id="S2.E3.m1.3.3.2.2.2.2.2.2.3" xref="S2.E3.m1.3.3.2.2.2.2.2.2.3.cmml">b</mi></msup></mrow><mo id="S2.E3.m1.3.3.2.2.2.2.1" xref="S2.E3.m1.3.3.2.2.2.2.1.cmml">−</mo><mn id="S2.E3.m1.3.3.2.2.2.2.3" xref="S2.E3.m1.3.3.2.2.2.2.3.cmml">1</mn></mrow><mo id="S2.E3.m1.4.4.3.3.3.6" xref="S2.E3.m1.4.4.3.3.4.cmml">,</mo><mrow id="S2.E3.m1.4.4.3.3.3.3" xref="S2.E3.m1.4.4.3.3.3.3.cmml"><msup id="S2.E3.m1.4.4.3.3.3.3.2" xref="S2.E3.m1.4.4.3.3.3.3.2.cmml"><mn id="S2.E3.m1.4.4.3.3.3.3.2.2" xref="S2.E3.m1.4.4.3.3.3.3.2.2.cmml">2</mn><mrow id="S2.E3.m1.4.4.3.3.3.3.2.3" xref="S2.E3.m1.4.4.3.3.3.3.2.3.cmml"><mi id="S2.E3.m1.4.4.3.3.3.3.2.3.2" xref="S2.E3.m1.4.4.3.3.3.3.2.3.2.cmml">b</mi><mo id="S2.E3.m1.4.4.3.3.3.3.2.3.1" xref="S2.E3.m1.4.4.3.3.3.3.2.3.1.cmml">−</mo><mn id="S2.E3.m1.4.4.3.3.3.3.2.3.3" xref="S2.E3.m1.4.4.3.3.3.3.2.3.3.cmml">1</mn></mrow></msup><mo id="S2.E3.m1.4.4.3.3.3.3.1" xref="S2.E3.m1.4.4.3.3.3.3.1.cmml">−</mo><mn id="S2.E3.m1.4.4.3.3.3.3.3" xref="S2.E3.m1.4.4.3.3.3.3.3.cmml">1</mn></mrow><mo id="S2.E3.m1.4.4.3.3.3.7" stretchy="false" xref="S2.E3.m1.4.4.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><eq id="S2.E3.m1.4.4.4.cmml" xref="S2.E3.m1.4.4.4"></eq><apply id="S2.E3.m1.4.4.5.cmml" xref="S2.E3.m1.4.4.5"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.5.1.cmml" xref="S2.E3.m1.4.4.5">subscript</csymbol><ci id="S2.E3.m1.4.4.5.2.cmml" xref="S2.E3.m1.4.4.5.2">𝑋</ci><ci id="S2.E3.m1.4.4.5.3.cmml" xref="S2.E3.m1.4.4.5.3">𝑞</ci></apply><apply id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"><times id="S2.E3.m1.4.4.3.4.cmml" xref="S2.E3.m1.4.4.3.4"></times><ci id="S2.E3.m1.4.4.3.5.cmml" xref="S2.E3.m1.4.4.3.5">𝐶</ci><ci id="S2.E3.m1.4.4.3.6.cmml" xref="S2.E3.m1.4.4.3.6">𝑙</ci><ci id="S2.E3.m1.4.4.3.7.cmml" xref="S2.E3.m1.4.4.3.7">𝑎</ci><ci id="S2.E3.m1.4.4.3.8.cmml" xref="S2.E3.m1.4.4.3.8">𝑚</ci><ci id="S2.E3.m1.4.4.3.9.cmml" xref="S2.E3.m1.4.4.3.9">𝑝</ci><vector id="S2.E3.m1.4.4.3.3.4.cmml" xref="S2.E3.m1.4.4.3.3.3"><apply id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1"><times id="S2.E3.m1.2.2.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1"></times><ci id="S2.E3.m1.2.2.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2">𝑟</ci><ci id="S2.E3.m1.2.2.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3">𝑜</ci><ci id="S2.E3.m1.2.2.1.1.1.1.4.cmml" xref="S2.E3.m1.2.2.1.1.1.1.4">𝑢</ci><ci id="S2.E3.m1.2.2.1.1.1.1.5.cmml" xref="S2.E3.m1.2.2.1.1.1.1.5">𝑛</ci><ci id="S2.E3.m1.2.2.1.1.1.1.6.cmml" xref="S2.E3.m1.2.2.1.1.1.1.6">𝑑</ci><apply id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.7.2"><divide id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.7.2"></divide><ci id="S2.E3.m1.1.1.2.cmml" xref="S2.E3.m1.1.1.2">𝑋</ci><ci id="S2.E3.m1.1.1.3.cmml" xref="S2.E3.m1.1.1.3">𝑠</ci></apply></apply><apply id="S2.E3.m1.3.3.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2"><minus id="S2.E3.m1.3.3.2.2.2.2.1.cmml" xref="S2.E3.m1.3.3.2.2.2.2.1"></minus><apply id="S2.E3.m1.3.3.2.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2"><minus id="S2.E3.m1.3.3.2.2.2.2.2.1.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2"></minus><apply id="S2.E3.m1.3.3.2.2.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.2.2.2.2.2.1.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2.2">superscript</csymbol><cn id="S2.E3.m1.3.3.2.2.2.2.2.2.2.cmml" type="integer" xref="S2.E3.m1.3.3.2.2.2.2.2.2.2">2</cn><ci id="S2.E3.m1.3.3.2.2.2.2.2.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2.2.3">𝑏</ci></apply></apply><cn id="S2.E3.m1.3.3.2.2.2.2.3.cmml" type="integer" xref="S2.E3.m1.3.3.2.2.2.2.3">1</cn></apply><apply id="S2.E3.m1.4.4.3.3.3.3.cmml" xref="S2.E3.m1.4.4.3.3.3.3"><minus id="S2.E3.m1.4.4.3.3.3.3.1.cmml" xref="S2.E3.m1.4.4.3.3.3.3.1"></minus><apply id="S2.E3.m1.4.4.3.3.3.3.2.cmml" xref="S2.E3.m1.4.4.3.3.3.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.3.3.3.2.1.cmml" xref="S2.E3.m1.4.4.3.3.3.3.2">superscript</csymbol><cn id="S2.E3.m1.4.4.3.3.3.3.2.2.cmml" type="integer" xref="S2.E3.m1.4.4.3.3.3.3.2.2">2</cn><apply id="S2.E3.m1.4.4.3.3.3.3.2.3.cmml" xref="S2.E3.m1.4.4.3.3.3.3.2.3"><minus id="S2.E3.m1.4.4.3.3.3.3.2.3.1.cmml" xref="S2.E3.m1.4.4.3.3.3.3.2.3.1"></minus><ci id="S2.E3.m1.4.4.3.3.3.3.2.3.2.cmml" xref="S2.E3.m1.4.4.3.3.3.3.2.3.2">𝑏</ci><cn id="S2.E3.m1.4.4.3.3.3.3.2.3.3.cmml" type="integer" xref="S2.E3.m1.4.4.3.3.3.3.2.3.3">1</cn></apply></apply><cn id="S2.E3.m1.4.4.3.3.3.3.3.cmml" type="integer" xref="S2.E3.m1.4.4.3.3.3.3.3">1</cn></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\displaystyle X_{q}=Clamp(round(\frac{X}{s}),-2^{b}-1,2^{b-1}-1)</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.4d">italic_X start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = italic_C italic_l italic_a italic_m italic_p ( italic_r italic_o italic_u italic_n italic_d ( divide start_ARG italic_X end_ARG start_ARG italic_s end_ARG ) , - 2 start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT - 1 , 2 start_POSTSUPERSCRIPT italic_b - 1 end_POSTSUPERSCRIPT - 1 )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx4">
<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle X\approx\hat{X}=X_{q}*s" class="ltx_Math" display="inline" id="S2.E4.m1.1"><semantics id="S2.E4.m1.1a"><mrow id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1.cmml"><mi id="S2.E4.m1.1.1.2" xref="S2.E4.m1.1.1.2.cmml">X</mi><mo id="S2.E4.m1.1.1.3" xref="S2.E4.m1.1.1.3.cmml">≈</mo><mover accent="true" id="S2.E4.m1.1.1.4" xref="S2.E4.m1.1.1.4.cmml"><mi id="S2.E4.m1.1.1.4.2" xref="S2.E4.m1.1.1.4.2.cmml">X</mi><mo id="S2.E4.m1.1.1.4.1" xref="S2.E4.m1.1.1.4.1.cmml">^</mo></mover><mo id="S2.E4.m1.1.1.5" xref="S2.E4.m1.1.1.5.cmml">=</mo><mrow id="S2.E4.m1.1.1.6" xref="S2.E4.m1.1.1.6.cmml"><msub id="S2.E4.m1.1.1.6.2" xref="S2.E4.m1.1.1.6.2.cmml"><mi id="S2.E4.m1.1.1.6.2.2" xref="S2.E4.m1.1.1.6.2.2.cmml">X</mi><mi id="S2.E4.m1.1.1.6.2.3" xref="S2.E4.m1.1.1.6.2.3.cmml">q</mi></msub><mo id="S2.E4.m1.1.1.6.1" lspace="0.222em" rspace="0.222em" xref="S2.E4.m1.1.1.6.1.cmml">∗</mo><mi id="S2.E4.m1.1.1.6.3" xref="S2.E4.m1.1.1.6.3.cmml">s</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.1b"><apply id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1"><and id="S2.E4.m1.1.1a.cmml" xref="S2.E4.m1.1.1"></and><apply id="S2.E4.m1.1.1b.cmml" xref="S2.E4.m1.1.1"><approx id="S2.E4.m1.1.1.3.cmml" xref="S2.E4.m1.1.1.3"></approx><ci id="S2.E4.m1.1.1.2.cmml" xref="S2.E4.m1.1.1.2">𝑋</ci><apply id="S2.E4.m1.1.1.4.cmml" xref="S2.E4.m1.1.1.4"><ci id="S2.E4.m1.1.1.4.1.cmml" xref="S2.E4.m1.1.1.4.1">^</ci><ci id="S2.E4.m1.1.1.4.2.cmml" xref="S2.E4.m1.1.1.4.2">𝑋</ci></apply></apply><apply id="S2.E4.m1.1.1c.cmml" xref="S2.E4.m1.1.1"><eq id="S2.E4.m1.1.1.5.cmml" xref="S2.E4.m1.1.1.5"></eq><share href="https://arxiv.org/html/2410.04960v1#S2.E4.m1.1.1.4.cmml" id="S2.E4.m1.1.1d.cmml" xref="S2.E4.m1.1.1"></share><apply id="S2.E4.m1.1.1.6.cmml" xref="S2.E4.m1.1.1.6"><times id="S2.E4.m1.1.1.6.1.cmml" xref="S2.E4.m1.1.1.6.1"></times><apply id="S2.E4.m1.1.1.6.2.cmml" xref="S2.E4.m1.1.1.6.2"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.6.2.1.cmml" xref="S2.E4.m1.1.1.6.2">subscript</csymbol><ci id="S2.E4.m1.1.1.6.2.2.cmml" xref="S2.E4.m1.1.1.6.2.2">𝑋</ci><ci id="S2.E4.m1.1.1.6.2.3.cmml" xref="S2.E4.m1.1.1.6.2.3">𝑞</ci></apply><ci id="S2.E4.m1.1.1.6.3.cmml" xref="S2.E4.m1.1.1.6.3">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.1c">\displaystyle X\approx\hat{X}=X_{q}*s</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.1d">italic_X ≈ over^ start_ARG italic_X end_ARG = italic_X start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ∗ italic_s</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.SSS2.p1.7">where <math alttext="b,s" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.3.m1.2"><semantics id="S2.SS3.SSS2.p1.3.m1.2a"><mrow id="S2.SS3.SSS2.p1.3.m1.2.3.2" xref="S2.SS3.SSS2.p1.3.m1.2.3.1.cmml"><mi id="S2.SS3.SSS2.p1.3.m1.1.1" xref="S2.SS3.SSS2.p1.3.m1.1.1.cmml">b</mi><mo id="S2.SS3.SSS2.p1.3.m1.2.3.2.1" xref="S2.SS3.SSS2.p1.3.m1.2.3.1.cmml">,</mo><mi id="S2.SS3.SSS2.p1.3.m1.2.2" xref="S2.SS3.SSS2.p1.3.m1.2.2.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.3.m1.2b"><list id="S2.SS3.SSS2.p1.3.m1.2.3.1.cmml" xref="S2.SS3.SSS2.p1.3.m1.2.3.2"><ci id="S2.SS3.SSS2.p1.3.m1.1.1.cmml" xref="S2.SS3.SSS2.p1.3.m1.1.1">𝑏</ci><ci id="S2.SS3.SSS2.p1.3.m1.2.2.cmml" xref="S2.SS3.SSS2.p1.3.m1.2.2">𝑠</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.3.m1.2c">b,s</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.3.m1.2d">italic_b , italic_s</annotation></semantics></math> refers to the bit number in low precision and the scaling factor respectively, <math alttext="Clamp(x,a1,a2)" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.4.m2.3"><semantics id="S2.SS3.SSS2.p1.4.m2.3a"><mrow id="S2.SS3.SSS2.p1.4.m2.3.3" xref="S2.SS3.SSS2.p1.4.m2.3.3.cmml"><mi id="S2.SS3.SSS2.p1.4.m2.3.3.4" xref="S2.SS3.SSS2.p1.4.m2.3.3.4.cmml">C</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.3" xref="S2.SS3.SSS2.p1.4.m2.3.3.3.cmml">⁢</mo><mi id="S2.SS3.SSS2.p1.4.m2.3.3.5" xref="S2.SS3.SSS2.p1.4.m2.3.3.5.cmml">l</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.3a" xref="S2.SS3.SSS2.p1.4.m2.3.3.3.cmml">⁢</mo><mi id="S2.SS3.SSS2.p1.4.m2.3.3.6" xref="S2.SS3.SSS2.p1.4.m2.3.3.6.cmml">a</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.3b" xref="S2.SS3.SSS2.p1.4.m2.3.3.3.cmml">⁢</mo><mi id="S2.SS3.SSS2.p1.4.m2.3.3.7" xref="S2.SS3.SSS2.p1.4.m2.3.3.7.cmml">m</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.3c" xref="S2.SS3.SSS2.p1.4.m2.3.3.3.cmml">⁢</mo><mi id="S2.SS3.SSS2.p1.4.m2.3.3.8" xref="S2.SS3.SSS2.p1.4.m2.3.3.8.cmml">p</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.3d" xref="S2.SS3.SSS2.p1.4.m2.3.3.3.cmml">⁢</mo><mrow id="S2.SS3.SSS2.p1.4.m2.3.3.2.2" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.3.cmml"><mo id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.3" stretchy="false" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.3.cmml">(</mo><mi id="S2.SS3.SSS2.p1.4.m2.1.1" xref="S2.SS3.SSS2.p1.4.m2.1.1.cmml">x</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.4" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.3.cmml">,</mo><mrow id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.cmml"><mi id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.2" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.2.cmml">a</mi><mo id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.1" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.1.cmml">⁢</mo><mn id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.3" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.3.cmml">1</mn></mrow><mo id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.5" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.3.cmml">,</mo><mrow id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.cmml"><mi id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.2" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.2.cmml">a</mi><mo id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.1" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.1.cmml">⁢</mo><mn id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.3" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.3.cmml">2</mn></mrow><mo id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.6" stretchy="false" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.4.m2.3b"><apply id="S2.SS3.SSS2.p1.4.m2.3.3.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3"><times id="S2.SS3.SSS2.p1.4.m2.3.3.3.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.3"></times><ci id="S2.SS3.SSS2.p1.4.m2.3.3.4.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.4">𝐶</ci><ci id="S2.SS3.SSS2.p1.4.m2.3.3.5.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.5">𝑙</ci><ci id="S2.SS3.SSS2.p1.4.m2.3.3.6.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.6">𝑎</ci><ci id="S2.SS3.SSS2.p1.4.m2.3.3.7.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.7">𝑚</ci><ci id="S2.SS3.SSS2.p1.4.m2.3.3.8.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.8">𝑝</ci><vector id="S2.SS3.SSS2.p1.4.m2.3.3.2.3.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2"><ci id="S2.SS3.SSS2.p1.4.m2.1.1.cmml" xref="S2.SS3.SSS2.p1.4.m2.1.1">𝑥</ci><apply id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.cmml" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1"><times id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.1.cmml" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.1"></times><ci id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.2.cmml" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.2">𝑎</ci><cn id="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS3.SSS2.p1.4.m2.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2"><times id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.1.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.1"></times><ci id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.2.cmml" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.2">𝑎</ci><cn id="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS3.SSS2.p1.4.m2.3.3.2.2.2.3">2</cn></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.4.m2.3c">Clamp(x,a1,a2)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.4.m2.3d">italic_C italic_l italic_a italic_m italic_p ( italic_x , italic_a 1 , italic_a 2 )</annotation></semantics></math> clips integer <math alttext="x" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.5.m3.1"><semantics id="S2.SS3.SSS2.p1.5.m3.1a"><mi id="S2.SS3.SSS2.p1.5.m3.1.1" xref="S2.SS3.SSS2.p1.5.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.5.m3.1b"><ci id="S2.SS3.SSS2.p1.5.m3.1.1.cmml" xref="S2.SS3.SSS2.p1.5.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.5.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.5.m3.1d">italic_x</annotation></semantics></math> to <math alttext="a1/a2" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.6.m4.1"><semantics id="S2.SS3.SSS2.p1.6.m4.1a"><mrow id="S2.SS3.SSS2.p1.6.m4.1.1" xref="S2.SS3.SSS2.p1.6.m4.1.1.cmml"><mrow id="S2.SS3.SSS2.p1.6.m4.1.1.2" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.cmml"><mrow id="S2.SS3.SSS2.p1.6.m4.1.1.2.2" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.cmml"><mi id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.2" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.2.cmml">a</mi><mo id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.1" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.1.cmml">⁢</mo><mn id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.3" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.3.cmml">1</mn></mrow><mo id="S2.SS3.SSS2.p1.6.m4.1.1.2.1" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.1.cmml">/</mo><mi id="S2.SS3.SSS2.p1.6.m4.1.1.2.3" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.3.cmml">a</mi></mrow><mo id="S2.SS3.SSS2.p1.6.m4.1.1.1" xref="S2.SS3.SSS2.p1.6.m4.1.1.1.cmml">⁢</mo><mn id="S2.SS3.SSS2.p1.6.m4.1.1.3" xref="S2.SS3.SSS2.p1.6.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.6.m4.1b"><apply id="S2.SS3.SSS2.p1.6.m4.1.1.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1"><times id="S2.SS3.SSS2.p1.6.m4.1.1.1.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.1"></times><apply id="S2.SS3.SSS2.p1.6.m4.1.1.2.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.2"><divide id="S2.SS3.SSS2.p1.6.m4.1.1.2.1.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.1"></divide><apply id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2"><times id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.1.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.1"></times><ci id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.2.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.2">𝑎</ci><cn id="S2.SS3.SSS2.p1.6.m4.1.1.2.2.3.cmml" type="integer" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.2.3">1</cn></apply><ci id="S2.SS3.SSS2.p1.6.m4.1.1.2.3.cmml" xref="S2.SS3.SSS2.p1.6.m4.1.1.2.3">𝑎</ci></apply><cn id="S2.SS3.SSS2.p1.6.m4.1.1.3.cmml" type="integer" xref="S2.SS3.SSS2.p1.6.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.6.m4.1c">a1/a2</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.6.m4.1d">italic_a 1 / italic_a 2</annotation></semantics></math> when <math alttext="x\leq a1/x\geq a2" class="ltx_Math" display="inline" id="S2.SS3.SSS2.p1.7.m5.1"><semantics id="S2.SS3.SSS2.p1.7.m5.1a"><mrow id="S2.SS3.SSS2.p1.7.m5.1.1" xref="S2.SS3.SSS2.p1.7.m5.1.1.cmml"><mi id="S2.SS3.SSS2.p1.7.m5.1.1.2" xref="S2.SS3.SSS2.p1.7.m5.1.1.2.cmml">x</mi><mo id="S2.SS3.SSS2.p1.7.m5.1.1.3" xref="S2.SS3.SSS2.p1.7.m5.1.1.3.cmml">≤</mo><mrow id="S2.SS3.SSS2.p1.7.m5.1.1.4" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.cmml"><mrow id="S2.SS3.SSS2.p1.7.m5.1.1.4.2" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.cmml"><mi id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.2" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.2.cmml">a</mi><mo id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.1" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.1.cmml">⁢</mo><mn id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.3" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.3.cmml">1</mn></mrow><mo id="S2.SS3.SSS2.p1.7.m5.1.1.4.1" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.1.cmml">/</mo><mi id="S2.SS3.SSS2.p1.7.m5.1.1.4.3" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.3.cmml">x</mi></mrow><mo id="S2.SS3.SSS2.p1.7.m5.1.1.5" xref="S2.SS3.SSS2.p1.7.m5.1.1.5.cmml">≥</mo><mrow id="S2.SS3.SSS2.p1.7.m5.1.1.6" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.cmml"><mi id="S2.SS3.SSS2.p1.7.m5.1.1.6.2" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.2.cmml">a</mi><mo id="S2.SS3.SSS2.p1.7.m5.1.1.6.1" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.1.cmml">⁢</mo><mn id="S2.SS3.SSS2.p1.7.m5.1.1.6.3" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.3.cmml">2</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS2.p1.7.m5.1b"><apply id="S2.SS3.SSS2.p1.7.m5.1.1.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1"><and id="S2.SS3.SSS2.p1.7.m5.1.1a.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1"></and><apply id="S2.SS3.SSS2.p1.7.m5.1.1b.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1"><leq id="S2.SS3.SSS2.p1.7.m5.1.1.3.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.3"></leq><ci id="S2.SS3.SSS2.p1.7.m5.1.1.2.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.2">𝑥</ci><apply id="S2.SS3.SSS2.p1.7.m5.1.1.4.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.4"><divide id="S2.SS3.SSS2.p1.7.m5.1.1.4.1.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.1"></divide><apply id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2"><times id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.1.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.1"></times><ci id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.2.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.2">𝑎</ci><cn id="S2.SS3.SSS2.p1.7.m5.1.1.4.2.3.cmml" type="integer" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.2.3">1</cn></apply><ci id="S2.SS3.SSS2.p1.7.m5.1.1.4.3.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.4.3">𝑥</ci></apply></apply><apply id="S2.SS3.SSS2.p1.7.m5.1.1c.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1"><geq id="S2.SS3.SSS2.p1.7.m5.1.1.5.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.5"></geq><share href="https://arxiv.org/html/2410.04960v1#S2.SS3.SSS2.p1.7.m5.1.1.4.cmml" id="S2.SS3.SSS2.p1.7.m5.1.1d.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1"></share><apply id="S2.SS3.SSS2.p1.7.m5.1.1.6.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.6"><times id="S2.SS3.SSS2.p1.7.m5.1.1.6.1.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.1"></times><ci id="S2.SS3.SSS2.p1.7.m5.1.1.6.2.cmml" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.2">𝑎</ci><cn id="S2.SS3.SSS2.p1.7.m5.1.1.6.3.cmml" type="integer" xref="S2.SS3.SSS2.p1.7.m5.1.1.6.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS2.p1.7.m5.1c">x\leq a1/x\geq a2</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS2.p1.7.m5.1d">italic_x ≤ italic_a 1 / italic_x ≥ italic_a 2</annotation></semantics></math>.
There are two primary types of quantization for neural networks: Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT). PTQ applies quantization to fully trained models using a small calibration dataset to mitigate accuracy loss, while QAT adapts models to low precision during training, requiring the full training dataset. As a result, QAT is generally more costly and inefficient compared to PTQ.
Numerous PTQ methods have been developed for CNNs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib83" title=""><span class="ltx_text" style="font-size:90%;">83</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib122" title=""><span class="ltx_text" style="font-size:90%;">122</span></a>]</cite> and Transformer-based architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">32</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib139" title=""><span class="ltx_text" style="font-size:90%;">139</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">72</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib146" title=""><span class="ltx_text" style="font-size:90%;">146</span></a>]</cite>. In the context of accelerating SAM, works like <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib77" title=""><span class="ltx_text" style="font-size:90%;">77</span></a>]</cite> utilize PTQ techniques to compress SAM with targeted strategies for improved efficiency.</p>
</div>
<figure class="ltx_figure" id="S2.F3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.F3.2" style="width:496.9pt;height:227.5pt;vertical-align:-221.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.0pt,0.5pt) scale(0.858414451576492,0.858414451576492) ;"><span class="ltx_ERROR undefined" id="S2.F3.2.1">{forest}</span>
<p class="ltx_p" id="S2.F3.2.2">forked edges,
for tree=
grow=east,
reversed=true,
anchor=base west,
parent anchor=east,
child anchor=west,
base=center,
font=<span class="ltx_text" id="S2.F3.2.2.1" style="font-size:120%;">,
rectangle,
draw=hidden-draw,
rounded corners,
align=left,
text centered,
minimum width=4em,
edge+=darkgray, line width=1pt,
s sep=3pt,
inner xsep=2pt,
inner ysep=3pt,
line width=0.8pt,
ver/.style=rotate=90, child anchor=north, parent anchor=south, anchor=center,
</span>,
where level=1text width=16em,font=,,
where level=2text width=18em,font=,,
where level=3text width=18em,font=,,
where level=4text width=18em,font=,,
where level=5text width=12em,font=,,
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.2">Efficient SAM variants</span>, ver
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.3">Accelerating SegAny</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1" title="3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a>), fill=green!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.4">Training from Scratch</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS1" title="3.1.1 Training from Scratch ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.1</span></a>), fill=blue!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.5">SAM-different architectures</span>, fill=yellow!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.6">FastSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.7">SqueezeSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib114" title=""><span class="ltx_text" style="font-size:90%;">114</span></a>]</cite></span>, fill=gray!10]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.8">SAM-like architectures</span>, fill=yellow!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.9">EfficientSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib131" title=""><span class="ltx_text" style="font-size:90%;">131</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.10">RAP-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib133" title=""><span class="ltx_text" style="font-size:90%;">133</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.11">SAM 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite></span>, fill=gray!10]
]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.12">Knowledge Distillation</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS2" title="3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.2</span></a>), fill=blue!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.13">With Light-weight ViT Encoders</span>, fill=yellow!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.14">MobileSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.15">ESAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib162" title=""><span class="ltx_text" style="font-size:90%;">162</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.16">TinySAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite></span>, fill=gray!10]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.17">With Pure CNN Encoders</span>, fill=yellow!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.18">NanoSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib84" title=""><span class="ltx_text" style="font-size:90%;">84</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.19">RepViT-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib118" title=""><span class="ltx_text" style="font-size:90%;">118</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.20">EdgeSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>]</cite></span>, fill=gray!10]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.21">With Attention-modified Encoders</span>, fill=yellow!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.22">EfficientViT-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.23">FastSAM3D <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib101" title=""><span class="ltx_text" style="font-size:90%;">101</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.24">SAM-Lightening <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib104" title=""><span class="ltx_text" style="font-size:90%;">104</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.25">RWKV-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib87" title=""><span class="ltx_text" style="font-size:90%;">87</span></a>]</cite></span>, fill=gray!10]
]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.26">Quantization</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS3" title="3.1.3 Quantization based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.3</span></a>), fill=blue!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.27">TinySAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.28">PTQ4SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib77" title=""><span class="ltx_text" style="font-size:90%;">77</span></a>]</cite></span>, fill=gray!10]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.29">Pruning</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS4" title="3.1.4 Pruning based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.4</span></a>), fill=blue!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.30">SlimSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite></span>, fill=gray!10]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.31">Code Refactorization</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS5" title="3.1.5 Code Refactorization ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.5</span></a>), fill=blue!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.32">SAMFast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib88" title=""><span class="ltx_text" style="font-size:90%;">88</span></a>]</cite></span>, fill=gray!10]
]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.33">Accelerating SegEvery</span> (§<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS2" title="3.2 Accelerating SegEvery Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.2</span></a>), fill=green!10
[,coordinate,
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.34">FastSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>]</cite></span>, fill=gray!10, tier=number]
]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.35">Efficient sampling strategy</span>, fill=blue!10
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.36">MobileSAMV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib148" title=""><span class="ltx_text" style="font-size:90%;">148</span></a>]</cite></span>, fill=gray!10, tier=number]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.37">TinySAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite></span>, fill=gray!10]
[<span class="ltx_text ltx_font_bold" id="S2.F3.2.2.38">LiteSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite></span>, fill=gray!10]
]
]
]</p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F3.3.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S2.F3.4.2" style="font-size:90%;">Taxonomy of Efficient Variants of Segment Anything Model (SAM).</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3 </span>Pruning</h4>
<div class="ltx_para" id="S2.SS3.SSS3.p1">
<p class="ltx_p" id="S2.SS3.SSS3.p1.1">Model pruning reduces a model’s size and complexity by eliminating redundant weights or connections, while aiming to maintain accuracy as much as possible. Pruning methods are typically categorized into two types: structured pruning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib123" title=""><span class="ltx_text" style="font-size:90%;">123</span></a>]</cite> and unstructured pruning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib56" title=""><span class="ltx_text" style="font-size:90%;">56</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS3.p2">
<p class="ltx_p" id="S2.SS3.SSS3.p2.1">Structured pruning removes parameters in groups based on specific criteria, targeting substructures such as channels, layers, or blocks in a systematic manner. In contrast, unstructured pruning focuses on individual weights, often resulting in a sparse and fragmented network. However, unstructured pruning may not lead to effective acceleration on general hardware due to the irregularity of the remaining network structure. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, structured pruning is applied to lighten SAM, significantly reducing the model’s size while preserving most of SAM’s capabilities by removing large amounts of redundant weights.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.4 </span>Low-Rank Factorization</h4>
<div class="ltx_para" id="S2.SS3.SSS4.p1">
<p class="ltx_p" id="S2.SS3.SSS4.p1.1">Low-rank factorization is the technique that decomposes the high dimension matrix into the product of low dimension matrices, aiming at reducing parameters of models for less space occupation and higher computational efficiency. A commonly used method of low-rank factorization is the singular value decomposition (SVD). It factorizes the complex matrix <math alttext="A\in\mathbb{R}^{m\times n}" class="ltx_Math" display="inline" id="S2.SS3.SSS4.p1.1.m1.1"><semantics id="S2.SS3.SSS4.p1.1.m1.1a"><mrow id="S2.SS3.SSS4.p1.1.m1.1.1" xref="S2.SS3.SSS4.p1.1.m1.1.1.cmml"><mi id="S2.SS3.SSS4.p1.1.m1.1.1.2" xref="S2.SS3.SSS4.p1.1.m1.1.1.2.cmml">A</mi><mo id="S2.SS3.SSS4.p1.1.m1.1.1.1" xref="S2.SS3.SSS4.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S2.SS3.SSS4.p1.1.m1.1.1.3" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.cmml"><mi id="S2.SS3.SSS4.p1.1.m1.1.1.3.2" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS4.p1.1.m1.1.1.3.3" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.cmml"><mi id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.2" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.2.cmml">m</mi><mo id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.3" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS4.p1.1.m1.1b"><apply id="S2.SS3.SSS4.p1.1.m1.1.1.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1"><in id="S2.SS3.SSS4.p1.1.m1.1.1.1.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.1"></in><ci id="S2.SS3.SSS4.p1.1.m1.1.1.2.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.2">𝐴</ci><apply id="S2.SS3.SSS4.p1.1.m1.1.1.3.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.SSS4.p1.1.m1.1.1.3.1.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS3.SSS4.p1.1.m1.1.1.3.2.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3"><times id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.1.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.1"></times><ci id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.2.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.2">𝑚</ci><ci id="S2.SS3.SSS4.p1.1.m1.1.1.3.3.3.cmml" xref="S2.SS3.SSS4.p1.1.m1.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS4.p1.1.m1.1c">A\in\mathbb{R}^{m\times n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS4.p1.1.m1.1d">italic_A ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_n end_POSTSUPERSCRIPT</annotation></semantics></math> into three matrices and the calculation can be further rewritten as follows:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx5">
<tbody id="S2.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle A=U\Sigma V^{T}=\sum_{i=1}^{r}\sigma_{i}u_{i}v_{i}^{T}" class="ltx_Math" display="inline" id="S2.E5.m1.1"><semantics id="S2.E5.m1.1a"><mrow id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml"><mi id="S2.E5.m1.1.1.2" xref="S2.E5.m1.1.1.2.cmml">A</mi><mo id="S2.E5.m1.1.1.3" xref="S2.E5.m1.1.1.3.cmml">=</mo><mrow id="S2.E5.m1.1.1.4" xref="S2.E5.m1.1.1.4.cmml"><mi id="S2.E5.m1.1.1.4.2" xref="S2.E5.m1.1.1.4.2.cmml">U</mi><mo id="S2.E5.m1.1.1.4.1" xref="S2.E5.m1.1.1.4.1.cmml">⁢</mo><mi id="S2.E5.m1.1.1.4.3" mathvariant="normal" xref="S2.E5.m1.1.1.4.3.cmml">Σ</mi><mo id="S2.E5.m1.1.1.4.1a" xref="S2.E5.m1.1.1.4.1.cmml">⁢</mo><msup id="S2.E5.m1.1.1.4.4" xref="S2.E5.m1.1.1.4.4.cmml"><mi id="S2.E5.m1.1.1.4.4.2" xref="S2.E5.m1.1.1.4.4.2.cmml">V</mi><mi id="S2.E5.m1.1.1.4.4.3" xref="S2.E5.m1.1.1.4.4.3.cmml">T</mi></msup></mrow><mo id="S2.E5.m1.1.1.5" xref="S2.E5.m1.1.1.5.cmml">=</mo><mrow id="S2.E5.m1.1.1.6" xref="S2.E5.m1.1.1.6.cmml"><mstyle displaystyle="true" id="S2.E5.m1.1.1.6.1" xref="S2.E5.m1.1.1.6.1.cmml"><munderover id="S2.E5.m1.1.1.6.1a" xref="S2.E5.m1.1.1.6.1.cmml"><mo id="S2.E5.m1.1.1.6.1.2.2" movablelimits="false" xref="S2.E5.m1.1.1.6.1.2.2.cmml">∑</mo><mrow id="S2.E5.m1.1.1.6.1.2.3" xref="S2.E5.m1.1.1.6.1.2.3.cmml"><mi id="S2.E5.m1.1.1.6.1.2.3.2" xref="S2.E5.m1.1.1.6.1.2.3.2.cmml">i</mi><mo id="S2.E5.m1.1.1.6.1.2.3.1" xref="S2.E5.m1.1.1.6.1.2.3.1.cmml">=</mo><mn id="S2.E5.m1.1.1.6.1.2.3.3" xref="S2.E5.m1.1.1.6.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E5.m1.1.1.6.1.3" xref="S2.E5.m1.1.1.6.1.3.cmml">r</mi></munderover></mstyle><mrow id="S2.E5.m1.1.1.6.2" xref="S2.E5.m1.1.1.6.2.cmml"><msub id="S2.E5.m1.1.1.6.2.2" xref="S2.E5.m1.1.1.6.2.2.cmml"><mi id="S2.E5.m1.1.1.6.2.2.2" xref="S2.E5.m1.1.1.6.2.2.2.cmml">σ</mi><mi id="S2.E5.m1.1.1.6.2.2.3" xref="S2.E5.m1.1.1.6.2.2.3.cmml">i</mi></msub><mo id="S2.E5.m1.1.1.6.2.1" xref="S2.E5.m1.1.1.6.2.1.cmml">⁢</mo><msub id="S2.E5.m1.1.1.6.2.3" xref="S2.E5.m1.1.1.6.2.3.cmml"><mi id="S2.E5.m1.1.1.6.2.3.2" xref="S2.E5.m1.1.1.6.2.3.2.cmml">u</mi><mi id="S2.E5.m1.1.1.6.2.3.3" xref="S2.E5.m1.1.1.6.2.3.3.cmml">i</mi></msub><mo id="S2.E5.m1.1.1.6.2.1a" xref="S2.E5.m1.1.1.6.2.1.cmml">⁢</mo><msubsup id="S2.E5.m1.1.1.6.2.4" xref="S2.E5.m1.1.1.6.2.4.cmml"><mi id="S2.E5.m1.1.1.6.2.4.2.2" xref="S2.E5.m1.1.1.6.2.4.2.2.cmml">v</mi><mi id="S2.E5.m1.1.1.6.2.4.2.3" xref="S2.E5.m1.1.1.6.2.4.2.3.cmml">i</mi><mi id="S2.E5.m1.1.1.6.2.4.3" xref="S2.E5.m1.1.1.6.2.4.3.cmml">T</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.1b"><apply id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1"><and id="S2.E5.m1.1.1a.cmml" xref="S2.E5.m1.1.1"></and><apply id="S2.E5.m1.1.1b.cmml" xref="S2.E5.m1.1.1"><eq id="S2.E5.m1.1.1.3.cmml" xref="S2.E5.m1.1.1.3"></eq><ci id="S2.E5.m1.1.1.2.cmml" xref="S2.E5.m1.1.1.2">𝐴</ci><apply id="S2.E5.m1.1.1.4.cmml" xref="S2.E5.m1.1.1.4"><times id="S2.E5.m1.1.1.4.1.cmml" xref="S2.E5.m1.1.1.4.1"></times><ci id="S2.E5.m1.1.1.4.2.cmml" xref="S2.E5.m1.1.1.4.2">𝑈</ci><ci id="S2.E5.m1.1.1.4.3.cmml" xref="S2.E5.m1.1.1.4.3">Σ</ci><apply id="S2.E5.m1.1.1.4.4.cmml" xref="S2.E5.m1.1.1.4.4"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.4.4.1.cmml" xref="S2.E5.m1.1.1.4.4">superscript</csymbol><ci id="S2.E5.m1.1.1.4.4.2.cmml" xref="S2.E5.m1.1.1.4.4.2">𝑉</ci><ci id="S2.E5.m1.1.1.4.4.3.cmml" xref="S2.E5.m1.1.1.4.4.3">𝑇</ci></apply></apply></apply><apply id="S2.E5.m1.1.1c.cmml" xref="S2.E5.m1.1.1"><eq id="S2.E5.m1.1.1.5.cmml" xref="S2.E5.m1.1.1.5"></eq><share href="https://arxiv.org/html/2410.04960v1#S2.E5.m1.1.1.4.cmml" id="S2.E5.m1.1.1d.cmml" xref="S2.E5.m1.1.1"></share><apply id="S2.E5.m1.1.1.6.cmml" xref="S2.E5.m1.1.1.6"><apply id="S2.E5.m1.1.1.6.1.cmml" xref="S2.E5.m1.1.1.6.1"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.6.1.1.cmml" xref="S2.E5.m1.1.1.6.1">superscript</csymbol><apply id="S2.E5.m1.1.1.6.1.2.cmml" xref="S2.E5.m1.1.1.6.1"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.6.1.2.1.cmml" xref="S2.E5.m1.1.1.6.1">subscript</csymbol><sum id="S2.E5.m1.1.1.6.1.2.2.cmml" xref="S2.E5.m1.1.1.6.1.2.2"></sum><apply id="S2.E5.m1.1.1.6.1.2.3.cmml" xref="S2.E5.m1.1.1.6.1.2.3"><eq id="S2.E5.m1.1.1.6.1.2.3.1.cmml" xref="S2.E5.m1.1.1.6.1.2.3.1"></eq><ci id="S2.E5.m1.1.1.6.1.2.3.2.cmml" xref="S2.E5.m1.1.1.6.1.2.3.2">𝑖</ci><cn id="S2.E5.m1.1.1.6.1.2.3.3.cmml" type="integer" xref="S2.E5.m1.1.1.6.1.2.3.3">1</cn></apply></apply><ci id="S2.E5.m1.1.1.6.1.3.cmml" xref="S2.E5.m1.1.1.6.1.3">𝑟</ci></apply><apply id="S2.E5.m1.1.1.6.2.cmml" xref="S2.E5.m1.1.1.6.2"><times id="S2.E5.m1.1.1.6.2.1.cmml" xref="S2.E5.m1.1.1.6.2.1"></times><apply id="S2.E5.m1.1.1.6.2.2.cmml" xref="S2.E5.m1.1.1.6.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.6.2.2.1.cmml" xref="S2.E5.m1.1.1.6.2.2">subscript</csymbol><ci id="S2.E5.m1.1.1.6.2.2.2.cmml" xref="S2.E5.m1.1.1.6.2.2.2">𝜎</ci><ci id="S2.E5.m1.1.1.6.2.2.3.cmml" xref="S2.E5.m1.1.1.6.2.2.3">𝑖</ci></apply><apply id="S2.E5.m1.1.1.6.2.3.cmml" xref="S2.E5.m1.1.1.6.2.3"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.6.2.3.1.cmml" xref="S2.E5.m1.1.1.6.2.3">subscript</csymbol><ci id="S2.E5.m1.1.1.6.2.3.2.cmml" xref="S2.E5.m1.1.1.6.2.3.2">𝑢</ci><ci id="S2.E5.m1.1.1.6.2.3.3.cmml" xref="S2.E5.m1.1.1.6.2.3.3">𝑖</ci></apply><apply id="S2.E5.m1.1.1.6.2.4.cmml" xref="S2.E5.m1.1.1.6.2.4"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.6.2.4.1.cmml" xref="S2.E5.m1.1.1.6.2.4">superscript</csymbol><apply id="S2.E5.m1.1.1.6.2.4.2.cmml" xref="S2.E5.m1.1.1.6.2.4"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.6.2.4.2.1.cmml" xref="S2.E5.m1.1.1.6.2.4">subscript</csymbol><ci id="S2.E5.m1.1.1.6.2.4.2.2.cmml" xref="S2.E5.m1.1.1.6.2.4.2.2">𝑣</ci><ci id="S2.E5.m1.1.1.6.2.4.2.3.cmml" xref="S2.E5.m1.1.1.6.2.4.2.3">𝑖</ci></apply><ci id="S2.E5.m1.1.1.6.2.4.3.cmml" xref="S2.E5.m1.1.1.6.2.4.3">𝑇</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.1c">\displaystyle A=U\Sigma V^{T}=\sum_{i=1}^{r}\sigma_{i}u_{i}v_{i}^{T}</annotation><annotation encoding="application/x-llamapun" id="S2.E5.m1.1d">italic_A = italic_U roman_Σ italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_σ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.SSS4.p1.6">where <math alttext="U\in\mathbb{R}^{m\times m},\ V\in\mathbb{R}^{n\times n}" class="ltx_Math" display="inline" id="S2.SS3.SSS4.p1.2.m1.2"><semantics id="S2.SS3.SSS4.p1.2.m1.2a"><mrow id="S2.SS3.SSS4.p1.2.m1.2.2.2" xref="S2.SS3.SSS4.p1.2.m1.2.2.3.cmml"><mrow id="S2.SS3.SSS4.p1.2.m1.1.1.1.1" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.cmml"><mi id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.2" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.2.cmml">U</mi><mo id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.1" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.1.cmml">∈</mo><msup id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.cmml"><mi id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.2" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.cmml"><mi id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.2" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.2.cmml">m</mi><mo id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.3" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.3.cmml">m</mi></mrow></msup></mrow><mo id="S2.SS3.SSS4.p1.2.m1.2.2.2.3" rspace="0.667em" xref="S2.SS3.SSS4.p1.2.m1.2.2.3a.cmml">,</mo><mrow id="S2.SS3.SSS4.p1.2.m1.2.2.2.2" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.cmml"><mi id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.2" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.2.cmml">V</mi><mo id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.1" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.1.cmml">∈</mo><msup id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.cmml"><mi id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.2" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.cmml"><mi id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.2" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.2.cmml">n</mi><mo id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.1.cmml">×</mo><mi id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.3" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.3.cmml">n</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS4.p1.2.m1.2b"><apply id="S2.SS3.SSS4.p1.2.m1.2.2.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.SSS4.p1.2.m1.2.2.3a.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1"><in id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.1"></in><ci id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.2">𝑈</ci><apply id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3">superscript</csymbol><ci id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.2">ℝ</ci><apply id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3"><times id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.1"></times><ci id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.2">𝑚</ci><ci id="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.1.1.1.1.3.3.3">𝑚</ci></apply></apply></apply><apply id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2"><in id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.1"></in><ci id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.2">𝑉</ci><apply id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3">superscript</csymbol><ci id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.2">ℝ</ci><apply id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3"><times id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.1.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.1"></times><ci id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.2.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.2">𝑛</ci><ci id="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.3.cmml" xref="S2.SS3.SSS4.p1.2.m1.2.2.2.2.3.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS4.p1.2.m1.2c">U\in\mathbb{R}^{m\times m},\ V\in\mathbb{R}^{n\times n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS4.p1.2.m1.2d">italic_U ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_m end_POSTSUPERSCRIPT , italic_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT</annotation></semantics></math> are orthogonal matrices and <math alttext="\Sigma\in\mathbb{R}^{m\times n}" class="ltx_Math" display="inline" id="S2.SS3.SSS4.p1.3.m2.1"><semantics id="S2.SS3.SSS4.p1.3.m2.1a"><mrow id="S2.SS3.SSS4.p1.3.m2.1.1" xref="S2.SS3.SSS4.p1.3.m2.1.1.cmml"><mi id="S2.SS3.SSS4.p1.3.m2.1.1.2" mathvariant="normal" xref="S2.SS3.SSS4.p1.3.m2.1.1.2.cmml">Σ</mi><mo id="S2.SS3.SSS4.p1.3.m2.1.1.1" xref="S2.SS3.SSS4.p1.3.m2.1.1.1.cmml">∈</mo><msup id="S2.SS3.SSS4.p1.3.m2.1.1.3" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.cmml"><mi id="S2.SS3.SSS4.p1.3.m2.1.1.3.2" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.SSS4.p1.3.m2.1.1.3.3" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.cmml"><mi id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.2" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.2.cmml">m</mi><mo id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.3" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.3.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS4.p1.3.m2.1b"><apply id="S2.SS3.SSS4.p1.3.m2.1.1.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1"><in id="S2.SS3.SSS4.p1.3.m2.1.1.1.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.1"></in><ci id="S2.SS3.SSS4.p1.3.m2.1.1.2.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.2">Σ</ci><apply id="S2.SS3.SSS4.p1.3.m2.1.1.3.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.SSS4.p1.3.m2.1.1.3.1.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3">superscript</csymbol><ci id="S2.SS3.SSS4.p1.3.m2.1.1.3.2.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.2">ℝ</ci><apply id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3"><times id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.1.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.1"></times><ci id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.2.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.2">𝑚</ci><ci id="S2.SS3.SSS4.p1.3.m2.1.1.3.3.3.cmml" xref="S2.SS3.SSS4.p1.3.m2.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS4.p1.3.m2.1c">\Sigma\in\mathbb{R}^{m\times n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS4.p1.3.m2.1d">roman_Σ ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_n end_POSTSUPERSCRIPT</annotation></semantics></math> is a diagonal matrix with the none-zero singular values of <math alttext="A" class="ltx_Math" display="inline" id="S2.SS3.SSS4.p1.4.m3.1"><semantics id="S2.SS3.SSS4.p1.4.m3.1a"><mi id="S2.SS3.SSS4.p1.4.m3.1.1" xref="S2.SS3.SSS4.p1.4.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS4.p1.4.m3.1b"><ci id="S2.SS3.SSS4.p1.4.m3.1.1.cmml" xref="S2.SS3.SSS4.p1.4.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS4.p1.4.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS4.p1.4.m3.1d">italic_A</annotation></semantics></math>, while <math alttext="r\leq\min\{m,n\}" class="ltx_Math" display="inline" id="S2.SS3.SSS4.p1.5.m4.3"><semantics id="S2.SS3.SSS4.p1.5.m4.3a"><mrow id="S2.SS3.SSS4.p1.5.m4.3.4" xref="S2.SS3.SSS4.p1.5.m4.3.4.cmml"><mi id="S2.SS3.SSS4.p1.5.m4.3.4.2" xref="S2.SS3.SSS4.p1.5.m4.3.4.2.cmml">r</mi><mo id="S2.SS3.SSS4.p1.5.m4.3.4.1" xref="S2.SS3.SSS4.p1.5.m4.3.4.1.cmml">≤</mo><mrow id="S2.SS3.SSS4.p1.5.m4.3.4.3.2" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml"><mi id="S2.SS3.SSS4.p1.5.m4.1.1" xref="S2.SS3.SSS4.p1.5.m4.1.1.cmml">min</mi><mo id="S2.SS3.SSS4.p1.5.m4.3.4.3.2a" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml">⁡</mo><mrow id="S2.SS3.SSS4.p1.5.m4.3.4.3.2.1" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml"><mo id="S2.SS3.SSS4.p1.5.m4.3.4.3.2.1.1" stretchy="false" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml">{</mo><mi id="S2.SS3.SSS4.p1.5.m4.2.2" xref="S2.SS3.SSS4.p1.5.m4.2.2.cmml">m</mi><mo id="S2.SS3.SSS4.p1.5.m4.3.4.3.2.1.2" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml">,</mo><mi id="S2.SS3.SSS4.p1.5.m4.3.3" xref="S2.SS3.SSS4.p1.5.m4.3.3.cmml">n</mi><mo id="S2.SS3.SSS4.p1.5.m4.3.4.3.2.1.3" stretchy="false" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS4.p1.5.m4.3b"><apply id="S2.SS3.SSS4.p1.5.m4.3.4.cmml" xref="S2.SS3.SSS4.p1.5.m4.3.4"><leq id="S2.SS3.SSS4.p1.5.m4.3.4.1.cmml" xref="S2.SS3.SSS4.p1.5.m4.3.4.1"></leq><ci id="S2.SS3.SSS4.p1.5.m4.3.4.2.cmml" xref="S2.SS3.SSS4.p1.5.m4.3.4.2">𝑟</ci><apply id="S2.SS3.SSS4.p1.5.m4.3.4.3.1.cmml" xref="S2.SS3.SSS4.p1.5.m4.3.4.3.2"><min id="S2.SS3.SSS4.p1.5.m4.1.1.cmml" xref="S2.SS3.SSS4.p1.5.m4.1.1"></min><ci id="S2.SS3.SSS4.p1.5.m4.2.2.cmml" xref="S2.SS3.SSS4.p1.5.m4.2.2">𝑚</ci><ci id="S2.SS3.SSS4.p1.5.m4.3.3.cmml" xref="S2.SS3.SSS4.p1.5.m4.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS4.p1.5.m4.3c">r\leq\min\{m,n\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS4.p1.5.m4.3d">italic_r ≤ roman_min { italic_m , italic_n }</annotation></semantics></math> refers to the rank of <math alttext="A" class="ltx_Math" display="inline" id="S2.SS3.SSS4.p1.6.m5.1"><semantics id="S2.SS3.SSS4.p1.6.m5.1a"><mi id="S2.SS3.SSS4.p1.6.m5.1.1" xref="S2.SS3.SSS4.p1.6.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS4.p1.6.m5.1b"><ci id="S2.SS3.SSS4.p1.6.m5.1.1.cmml" xref="S2.SS3.SSS4.p1.6.m5.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS4.p1.6.m5.1c">A</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.SSS4.p1.6.m5.1d">italic_A</annotation></semantics></math>.
The low-rank factorization has been widely applied in deep neural networks, such as CNNs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib108" title=""><span class="ltx_text" style="font-size:90%;">108</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib144" title=""><span class="ltx_text" style="font-size:90%;">144</span></a>]</cite>, LSTMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib37" title=""><span class="ltx_text" style="font-size:90%;">37</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib124" title=""><span class="ltx_text" style="font-size:90%;">124</span></a>]</cite>, and Transformer-based models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib107" title=""><span class="ltx_text" style="font-size:90%;">107</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">31</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite>. However, to date, no studies have applied this technique to compress and accelerate SAM, presenting a potential future research direction.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Efficient Variants of SAM</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section reviews the efforts to develop lightweight, efficient SAM-like models that have emerged since SAM gained prominence. These works aim to reduce the model’s high computational cost and enable efficient performance, while preserving SAM’s robust segmentation capabilities and generalization strength. As outlined in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS1.SSS2" title="2.1.2 Task ‣ 2.1 Segment Anything Model ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.1.2</span></a>, SAM addresses two primary tasks including Segment Anything (SegAny) and Segment Everything (SegEvery). Accordingly, we discuss the research aimed at improving each task separately: Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1" title="3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a> focuses on accelerating the SegAny task, and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS2" title="3.2 Accelerating SegEvery Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.2</span></a> covers efforts to accelerate the SegEvery task. Notably, some methods are applicable to both tasks, and we discuss these contributions individually.
Additionally, we categorize all models into different classes based on the techniques they employ, and the taxonomy of methodologies is presented in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.F3" title="Figure 3 ‣ 2.3.2 Quantization ‣ 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>. Finally, in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS3" title="3.3 Future Research Directions ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.3</span></a>, we outline four potential directions for future research in this area.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Accelerating SegAny Tasks</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">As analyzed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS2" title="2.2 Efficient Backbone ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.2</span></a>, the primary bottleneck of the SegAny task lies in SAM’s heavy architecture. One straightforward solution is to replace the encoder with a more efficient backbone. Alternatively, adopting a different architecture that retains the same segmentation capabilities as SAM is another approach. Works following these strategies either involve training lightweight models entirely from scratch (discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS1" title="3.1.1 Training from Scratch ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.1</span></a>) or training models using knowledge distillation with suitable supervision (covered in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS2" title="3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.2</span></a>). Additionally, some research explores methods such as quantization, pruning, or localized optimizations to compress SAM directly, without replacing the encoder or constructing a new architecture. These efforts will be reviewed in Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS3" title="3.1.3 Quantization based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS4" title="3.1.4 Pruning based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.4</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1.SSS5" title="3.1.5 Code Refactorization ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1.5</span></a>, respectively.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Training from Scratch</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">This subsection focuses on works that train SAM variants entirely from scratch. Based on their architecture, these models can be categorized into two types: SAM-different architectures and SAM-like architectures. We will explore each type in detail, following this classification.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">FastSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>]</cite> is one of the first SAM variants that does not rely on SAM’s original Encoder-Decoder architecture. To achieve faster segmentation, it divides the SegAny task into two sub-tasks: all-instance segmentation and prompt-guided selection. Since instance segmentation has been effectively addressed by many CNN-based methods, FastSAM offers improved efficiency compared to the Transformer-based SAM. For instance segmentation, FastSAM employs the YOLOv8-Seg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite> model, using the YOLACT method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite> for enhanced performance. FastSAM can reliably predict objects of interest using points, boxes, or text as prompts.
In addition to accelerating the SegAny task, FastSAM also excels in the SegEvery task, as this can be efficiently achieved alongside all-instance segmentation. However, as an early efficient variant of SAM, FastSAM still has some limitations, such as producing low-quality masks for smaller objects and generating masks with less smooth boundaries. Despite these shortcomings, FastSAM marks significant progress by introducing a CNN-based architecture into this domain. The architecture of FastSAM is illustrated in Fig <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F4" title="Figure 4 ‣ 3.1.1 Training from Scratch ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="596" id="S3.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S3.F4.3.2" style="font-size:90%;">The architecture of FastSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>]</cite>. It takes two stages to achieve segmenting anything: all-instance segmentation (the upper part) and prompt-guided selection (the lower part). It is worth noting that FastSAM have introduced CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib89" title=""><span class="ltx_text" style="font-size:90%;">89</span></a>]</cite> to support text prompt.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1">Building on the successful application of CNNs in FastSAM, Varadarajan et al. introduced SqueezeSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib114" title=""><span class="ltx_text" style="font-size:90%;">114</span></a>]</cite>, which further replaces SAM’s Transformer-based architecture with a U-Net structure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib94" title=""><span class="ltx_text" style="font-size:90%;">94</span></a>]</cite>. U-Net is composed of an encoder for feature extraction and a decoder for information recovery. SqueezeSAM retains the general U-Net architecture but incorporates two Transformer layers at the lowest scale of the U-Net to strike a balance between speed and accuracy.
Additionally, SqueezeSAM features several micro-level optimizations, such as capping the output channels at 256, using BatchNorm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> instead of LayerNorm <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> for efficiency, and introducing skip connections <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite> between the encoder and decoder.
A unique challenge for SqueezeSAM lies in handling prompts. Unlike SAM, where prompt tokens are utilized at the decoding stage, SqueezeSAM adopts an early fusion strategy, adding encoded prompts as additional input channels before feeding them into the encoder. The model is trained from scratch using the SA-1B dataset, with data augmentation techniques addressing low-quality data issues.
SqueezeSAM is primarily designed for deployment in photography applications, where efficient interactive segmentation is needed. As depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F5" title="Figure 5 ‣ 3.1.1 Training from Scratch ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>, its workflow involves generating an initial mask of the salient object, followed by fine-grained segmentation refined by user clicks.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="412" id="S3.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S3.F5.3.2" style="font-size:90%;">The architecture of SqueezeSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib114" title=""><span class="ltx_text" style="font-size:90%;">114</span></a>]</cite>. It replaces the Transformer-based encoder-decoder structure with U-Net backbone<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib94" title=""><span class="ltx_text" style="font-size:90%;">94</span></a>]</cite>. Clicks from users and masks of salience objects are fed into SqueezeSAM with the input image to achieve interactive segmentation.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p4">
<p class="ltx_p" id="S3.SS1.SSS1.p4.1">Instead of introducing an entirely new network, EfficientSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib131" title=""><span class="ltx_text" style="font-size:90%;">131</span></a>]</cite> retains SAM’s original architecture but replaces the image encoder. They use ViT-tiny or ViT-small as a lightweight encoder and re-train them from scratch, leveraging the SAM-based Masked Image (SAMI) pretraining strategy. SAMI is adapted from the Masked AutoEncoder (MAE) framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite>, which was initially used to pretrain SAM’s original image encoder.
SAMI follows an Encoder-Decoder pipeline: the encoder generates latent feature representations from unmasked patches, while the decoder reconstructs the missing embeddings of masked patches. This process is supervised by reconstruction loss, comparing the embeddings produced by SAM’s ViT-H encoder with those generated by the SAMI pipeline. After pretraining, the lightweight encoder is extracted from the SAMI pipeline and integrated with the rest of SAM’s components, forming EfficientSAM. The final step involves fine-tuning the entire model on the SA-1B dataset for further alignment and refinement.
SAMI is a general pretraining approach that can be applied to train any backbone for SAM variants. The overall structure of SAMI and EfficientSAM is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F6" title="Figure 6 ‣ 3.1.1 Training from Scratch ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="382" id="S3.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S3.F6.3.2" style="font-size:90%;">The framework of SAMI and efficientSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib131" title=""><span class="ltx_text" style="font-size:90%;">131</span></a>]</cite>. The target of SAMI is to pretrain a light-weight encoder which holds representation ability close to SAM’s image encoder. And the encoder is further extracted to build up the EfficientSAM.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p5">
<p class="ltx_p" id="S3.SS1.SSS1.p5.1">Xu et al. propose the RAP-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib133" title=""><span class="ltx_text" style="font-size:90%;">133</span></a>]</cite>, a model designed to achieve real-time, all-purpose segmentation, including panoptic segmentation (PS), video instance segmentation (VIS), and interactive segmentation (equivalent to the SegAny task). RAP-SAM retains SAM’s basic Encoder-Decoder architecture but incorporates more efficient components to enhance performance.
For the encoder, RAP-SAM combines Feature Pyramid Networks (FPN) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib66" title=""><span class="ltx_text" style="font-size:90%;">66</span></a>]</cite> with deformable convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite> to extract features from both images and videos, while using a prompt encoder to embed visual prompts. In the decoder, RAP-SAM employs a three-stage pipeline utilizing novel pooling-based dynamic convolutions to refine the mask tokens. The tokens generated in each stage, along with the feature maps from the encoder, serve as inputs. These inputs are first processed by dynamic convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>, followed by refinement using Multi-Head Self Attention (MHSA) and a Feed Forward Network (FFN).
After the decoder, two additional prompt adapters are introduced to enhance interaction between the visual prompts and segmentation tokens. The final masks are generated by computing the inner product between the updated tokens and updated prompts. The architecture of RAP-SAM is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F7" title="Figure 7 ‣ 3.1.1 Training from Scratch ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="294" id="S3.F7.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="S3.F7.3.2" style="font-size:90%;">The architecture of RAP-SAM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib133" title=""><span class="ltx_text" style="font-size:90%;">133</span></a>]</cite>. The encoder embeds images and videos to feature maps and encodes visual prompts as queries (tokens). The multi-stage decoder is to refine queries by interacting with feature maps. In the end, the feature maps and refined queries are fed into adapters to generate masks and classes.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p6">
<p class="ltx_p" id="S3.SS1.SSS1.p6.1">Recently, Ravi et al. introduced the Segment Anything Model 2 (SAM 2) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite>, an extension of the original SAM. The objective of SAM 2 is to deliver high-quality, real-time promptable segmentation across both images and videos. In image segmentation tasks, SAM 2 is reported to achieve higher accuracy and a 6× improvement in efficiency compared to the original SAM. This significant advancement is largely attributed to its efficient image encoder, Hiera <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib96" title=""><span class="ltx_text" style="font-size:90%;">96</span></a>]</cite>, a hierarchical ViT that has been simplified from MViTv2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib60" title=""><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite> by removing redundant components and utilizing the MAE framework for training. Hiera is a streamlined, purely transformer-based architecture that runs faster and delivers better accuracy than traditional ViTs in both image and video tasks.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Knowledge Distillation based Methods</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">From the taxonomy shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.F3" title="Figure 3 ‣ 2.3.2 Quantization ‣ 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>, we observe that many methods utilize knowledge distillation, as this approach typically requires less time and fewer resources compared to full model training. In this section, we review SAM variants that adopt efficient backbones for the image encoder while employing knowledge distillation for training. We categorize these models into three groups based on their encoder types: models with (i) lightweight ViT encoders, (ii) pure CNN encoders, and (iii) attention-modified encoders. We will introduce each category in turn.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p2.1.1">(i) Lightweight ViT Encoders</span></p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.1">Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>]</cite> made the first attempt to replace SAM’s heavy ViT encoder with the more efficient TinyViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib127" title=""><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite>, resulting in the integrated model named MobileSAM . As highlighted in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite>, training SAM from scratch requires multiple days and 128 GPUs. MobileSAM attributes this complexity to the challenge of optimizing both the encoder and decoder simultaneously. To address this, they propose an encoder-only distillation strategy as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F8" title="Figure 8 ‣ 3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">8</span></a>, which aims to transfer the visual representation capabilities of ViT-H to TinyViT. The loss function used is a simple Mean Square Error (MSE) between the output image embeddings of the two encoders. Further fine-tuning of the prompt encoder or mask decoder is optional and can lead to improved accuracy.</p>
</div>
<figure class="ltx_figure" id="S3.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="S3.F8.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="S3.F8.3.2" style="font-size:90%;">The framework of the encoder-only distillation for MobileSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>]</cite>. The small ViT-based image encoder, TinyViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib127" title=""><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite>, is distilled from SAM’s ViT-H and the prompt-guided mask decoder is inherited from SAM directly.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS2.p4">
<p class="ltx_p" id="S3.SS1.SSS2.p4.1">Similar to MobileSAM, the later proposed ESAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib162" title=""><span class="ltx_text" style="font-size:90%;">162</span></a>]</cite> utilizes EfficientFormerV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> as its backbone, aiming for improved performance in CPU environments, particularly resource-constrained medical devices. Given that expert models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib125" title=""><span class="ltx_text" style="font-size:90%;">125</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib120" title=""><span class="ltx_text" style="font-size:90%;">120</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite> often outperform SAM in medical applications, ESAM incorporates a novel Knowledge Distillation (KD) strategy called Holistic Knowledge Distillation (HKD) to transfer knowledge from an expert model to ESAM.
HKD involves two components: distillation on feature maps and distillation on output masks. For the feature map distillation, three different methods with varying focuses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">13</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib102" title=""><span class="ltx_text" style="font-size:90%;">102</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib138" title=""><span class="ltx_text" style="font-size:90%;">138</span></a>]</cite> are combined to guide the learning process. For the output mask distillation, ESAM uses the Mean Square Error (MSE) loss between the teacher’s and student’s masks, supplemented by a Binary Cross-Entropy (BCE) loss between the teacher’s masks and the ground truth masks. To further align the feature maps between the expert model and ESAM, a Teacher Guided Module (TGM) is introduced as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F9" title="Figure 9 ‣ 3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="620" id="S3.F9.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F9.2.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="S3.F9.3.2" style="font-size:90%;">The framework of distilling ESAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib162" title=""><span class="ltx_text" style="font-size:90%;">162</span></a>]</cite> from expert model. ESAM adopts the EfficientFormerV2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> as image encoder and a Teacher Guided Module (TGM) is applied to align the feature maps for holistic konwledge distillation (HKD).</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS2.p5">
<p class="ltx_p" id="S3.SS1.SSS2.p5.1">Shu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite> conducted an analysis of MobileSAM, identifying that encoder-only distillation can lead to significant performance degradation. To address this issue, they propose the Hard Mining Full-Stage Knowledge Distillation strategy for more effective distillation, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F10" title="Figure 10 ‣ 3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">10</span></a>. With a structure identical to MobileSAM, they developed a new SAM variant called TinySAM by training with this improved KD strategy.
Specifically, the strategy supervises not only the image embeddings but also the output tokens and output masks, all using L1 Loss. To further enhance the distillation process, they introduced the Hard Mask Weighting strategy, which assigns larger weights to masks that are harder to predict, thereby improving learning efficiency. The factor <math alttext="H" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p5.1.m1.1"><semantics id="S3.SS1.SSS2.p5.1.m1.1a"><mi id="S3.SS1.SSS2.p5.1.m1.1.1" xref="S3.SS1.SSS2.p5.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.1.m1.1b"><ci id="S3.SS1.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p5.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.1.m1.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p5.1.m1.1d">italic_H</annotation></semantics></math> is calculated as follows,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx6">
<tbody id="S3.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle H=sigmoid(\frac{IoU(M^{T},M^{GT})}{IoU(M^{S},M^{GT})+\epsilon}" class="ltx_math_unparsed" display="inline" id="S3.E6.m1.4"><semantics id="S3.E6.m1.4a"><mrow id="S3.E6.m1.4b"><mi id="S3.E6.m1.4.5">H</mi><mo id="S3.E6.m1.4.6">=</mo><mi id="S3.E6.m1.4.7">s</mi><mi id="S3.E6.m1.4.8">i</mi><mi id="S3.E6.m1.4.9">g</mi><mi id="S3.E6.m1.4.10">m</mi><mi id="S3.E6.m1.4.11">o</mi><mi id="S3.E6.m1.4.12">i</mi><mi id="S3.E6.m1.4.13">d</mi><mrow id="S3.E6.m1.4.14"><mo id="S3.E6.m1.4.14.1" stretchy="false">(</mo><mstyle displaystyle="true" id="S3.E6.m1.4.4"><mfrac id="S3.E6.m1.4.4a"><mrow id="S3.E6.m1.2.2.2"><mi id="S3.E6.m1.2.2.2.4">I</mi><mo id="S3.E6.m1.2.2.2.3">⁢</mo><mi id="S3.E6.m1.2.2.2.5">o</mi><mo id="S3.E6.m1.2.2.2.3a">⁢</mo><mi id="S3.E6.m1.2.2.2.6">U</mi><mo id="S3.E6.m1.2.2.2.3b">⁢</mo><mrow id="S3.E6.m1.2.2.2.2.2"><mo id="S3.E6.m1.2.2.2.2.2.3" stretchy="false">(</mo><msup id="S3.E6.m1.1.1.1.1.1.1"><mi id="S3.E6.m1.1.1.1.1.1.1.2">M</mi><mi id="S3.E6.m1.1.1.1.1.1.1.3">T</mi></msup><mo id="S3.E6.m1.2.2.2.2.2.4">,</mo><msup id="S3.E6.m1.2.2.2.2.2.2"><mi id="S3.E6.m1.2.2.2.2.2.2.2">M</mi><mrow id="S3.E6.m1.2.2.2.2.2.2.3"><mi id="S3.E6.m1.2.2.2.2.2.2.3.2">G</mi><mo id="S3.E6.m1.2.2.2.2.2.2.3.1">⁢</mo><mi id="S3.E6.m1.2.2.2.2.2.2.3.3">T</mi></mrow></msup><mo id="S3.E6.m1.2.2.2.2.2.5" stretchy="false">)</mo></mrow></mrow><mrow id="S3.E6.m1.4.4.4"><mrow id="S3.E6.m1.4.4.4.2"><mi id="S3.E6.m1.4.4.4.2.4">I</mi><mo id="S3.E6.m1.4.4.4.2.3">⁢</mo><mi id="S3.E6.m1.4.4.4.2.5">o</mi><mo id="S3.E6.m1.4.4.4.2.3a">⁢</mo><mi id="S3.E6.m1.4.4.4.2.6">U</mi><mo id="S3.E6.m1.4.4.4.2.3b">⁢</mo><mrow id="S3.E6.m1.4.4.4.2.2.2"><mo id="S3.E6.m1.4.4.4.2.2.2.3" stretchy="false">(</mo><msup id="S3.E6.m1.3.3.3.1.1.1.1"><mi id="S3.E6.m1.3.3.3.1.1.1.1.2">M</mi><mi id="S3.E6.m1.3.3.3.1.1.1.1.3">S</mi></msup><mo id="S3.E6.m1.4.4.4.2.2.2.4">,</mo><msup id="S3.E6.m1.4.4.4.2.2.2.2"><mi id="S3.E6.m1.4.4.4.2.2.2.2.2">M</mi><mrow id="S3.E6.m1.4.4.4.2.2.2.2.3"><mi id="S3.E6.m1.4.4.4.2.2.2.2.3.2">G</mi><mo id="S3.E6.m1.4.4.4.2.2.2.2.3.1">⁢</mo><mi id="S3.E6.m1.4.4.4.2.2.2.2.3.3">T</mi></mrow></msup><mo id="S3.E6.m1.4.4.4.2.2.2.5" stretchy="false">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.4.3">+</mo><mi id="S3.E6.m1.4.4.4.4">ϵ</mi></mrow></mfrac></mstyle></mrow></mrow><annotation encoding="application/x-tex" id="S3.E6.m1.4c">\displaystyle H=sigmoid(\frac{IoU(M^{T},M^{GT})}{IoU(M^{S},M^{GT})+\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.4d">italic_H = italic_s italic_i italic_g italic_m italic_o italic_i italic_d ( divide start_ARG italic_I italic_o italic_U ( italic_M start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , italic_M start_POSTSUPERSCRIPT italic_G italic_T end_POSTSUPERSCRIPT ) end_ARG start_ARG italic_I italic_o italic_U ( italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , italic_M start_POSTSUPERSCRIPT italic_G italic_T end_POSTSUPERSCRIPT ) + italic_ϵ end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS2.p5.2">where <math alttext="M^{T},M^{S},M^{GT}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p5.2.m1.3"><semantics id="S3.SS1.SSS2.p5.2.m1.3a"><mrow id="S3.SS1.SSS2.p5.2.m1.3.3.3" xref="S3.SS1.SSS2.p5.2.m1.3.3.4.cmml"><msup id="S3.SS1.SSS2.p5.2.m1.1.1.1.1" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p5.2.m1.1.1.1.1.2" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1.2.cmml">M</mi><mi id="S3.SS1.SSS2.p5.2.m1.1.1.1.1.3" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1.3.cmml">T</mi></msup><mo id="S3.SS1.SSS2.p5.2.m1.3.3.3.4" xref="S3.SS1.SSS2.p5.2.m1.3.3.4.cmml">,</mo><msup id="S3.SS1.SSS2.p5.2.m1.2.2.2.2" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2.cmml"><mi id="S3.SS1.SSS2.p5.2.m1.2.2.2.2.2" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2.2.cmml">M</mi><mi id="S3.SS1.SSS2.p5.2.m1.2.2.2.2.3" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2.3.cmml">S</mi></msup><mo id="S3.SS1.SSS2.p5.2.m1.3.3.3.5" xref="S3.SS1.SSS2.p5.2.m1.3.3.4.cmml">,</mo><msup id="S3.SS1.SSS2.p5.2.m1.3.3.3.3" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.cmml"><mi id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.2" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.2.cmml">M</mi><mrow id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.cmml"><mi id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.2" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.2.cmml">G</mi><mo id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.1" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.3" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.3.cmml">T</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.2.m1.3b"><list id="S3.SS1.SSS2.p5.2.m1.3.3.4.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3"><apply id="S3.SS1.SSS2.p5.2.m1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.2.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p5.2.m1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1.2">𝑀</ci><ci id="S3.SS1.SSS2.p5.2.m1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p5.2.m1.1.1.1.1.3">𝑇</ci></apply><apply id="S3.SS1.SSS2.p5.2.m1.2.2.2.2.cmml" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.2.m1.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2">superscript</csymbol><ci id="S3.SS1.SSS2.p5.2.m1.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2.2">𝑀</ci><ci id="S3.SS1.SSS2.p5.2.m1.2.2.2.2.3.cmml" xref="S3.SS1.SSS2.p5.2.m1.2.2.2.2.3">𝑆</ci></apply><apply id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.1.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3">superscript</csymbol><ci id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.2.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.2">𝑀</ci><apply id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3"><times id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.1.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.1"></times><ci id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.2.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.2">𝐺</ci><ci id="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.3.cmml" xref="S3.SS1.SSS2.p5.2.m1.3.3.3.3.3.3">𝑇</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.2.m1.3c">M^{T},M^{S},M^{GT}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p5.2.m1.3d">italic_M start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , italic_M start_POSTSUPERSCRIPT italic_G italic_T end_POSTSUPERSCRIPT</annotation></semantics></math> refers to the predicted masks of the teacher,
the student and the ground truth mask respectively. An extra strategy named Hard Prompt Sampling is adopted to sample prompts from areas with prediction failure to make the model focus more on image’s hard regions.</p>
</div>
<figure class="ltx_figure" id="S3.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="370" id="S3.F10.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F10.2.1.1" style="font-size:90%;">Figure 10</span>: </span><span class="ltx_text" id="S3.F10.3.2" style="font-size:90%;">The framework of the hard mining full-stage knowledge distillation for TinySAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite>. It contains two novel strategies to improve the quality of distillation: the Hard Mask Weighting and the Hard Prompt Sampling.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p6">
<p class="ltx_p" id="S3.SS1.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p6.1.1">(ii) CNN-based Encoders</span></p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p7">
<p class="ltx_p" id="S3.SS1.SSS2.p7.1">Researchers from NVIDIA introduced a new SAM variant, NanoSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib84" title=""><span class="ltx_text" style="font-size:90%;">84</span></a>]</cite>, based on MobileSAM. It is designed to achieve real-time performance on NVIDIA Jetson Orin platforms using NVIDIA TensorRT. NanoSAM replaces the ViT-based encoder with a pure convolutional network, specifically ResNet18 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite>, while retaining the other components from MobileSAM. NanoSAM is distilled from MobileSAM, and both models are retrained with TensorRT for optimized performance.
The image encoder of MobileSAM is optimized with FP32 precision, whereas NanoSAM’s image encoder is built using FP16 precision for faster execution. Inference latency results on Jetson Orin Nano and Jetson AGX Orin demonstrate that NanoSAM is 5x faster than MobileSAM, with minimal accuracy loss.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p8">
<p class="ltx_p" id="S3.SS1.SSS2.p8.1">Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib117" title=""><span class="ltx_text" style="font-size:90%;">117</span></a>]</cite> developed an efficient SAM variant, RepViT-SAM, using their newly proposed CNN-based backbone, RepViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib118" title=""><span class="ltx_text" style="font-size:90%;">118</span></a>]</cite>, as the image encoder. The core idea behind RepViT is to integrate the effective design principles of efficient Vision Transformers (ViTs) into lightweight CNNs. These design principles are applied at three levels: block-level, macro-level, and micro-level.
At the block level, RepViT separates the token mixer and channel mixer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib143" title=""><span class="ltx_text" style="font-size:90%;">143</span></a>]</cite>, reduces the expansion ratio <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>, and increases the width of blocks. For the macro design, it incorporates early convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib129" title=""><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite> as the input stem, deepens the down-sampling layers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib73" title=""><span class="ltx_text" style="font-size:90%;">73</span></a>]</cite>, employs a simpler classifier, and adjusts the block ratios across stages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib90" title=""><span class="ltx_text" style="font-size:90%;">90</span></a>]</cite>. At the micro level, only 3x3 convolutions are used, and Squeeze-and-Excitation layers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite> are applied only in odd-numbered blocks.
RepViT-SAM is trained using knowledge distillation, following the same pipeline as in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>]</cite>, achieving a 10x increase in inference speed compared to MobileSAM.</p>
</div>
<figure class="ltx_figure" id="S3.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="260" id="S3.F11.g1" src="extracted/5905254/figs/methods/edgesam.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F11.2.1.1" style="font-size:90%;">Figure 11</span>: </span><span class="ltx_text" id="S3.F11.3.2" style="font-size:90%;">The framework of distilling EdgeSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>]</cite>. It consists of the encoder-only distillation and the prompt-in-the-loop distillation.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS2.p9">
<p class="ltx_p" id="S3.SS1.SSS2.p9.1">Concurrent with the development of RepViT-SAM, Zhou et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>]</cite> observe that MobileSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>]</cite> still struggles to achieve real-time performance when deployed on edge devices, such as mobile phones. To address this, they introduced EdgeSAM, which replaces the Transformer-based encoder with the more lightweight and efficient, pure CNN-based RepViT, aiming for better performance on resource-constrained devices.
Similar to the approach in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib162" title=""><span class="ltx_text" style="font-size:90%;">162</span></a>]</cite>, Zhou et al. argue that encoder-only distillation is inadequate, as it is task-agnostic and does not fully capture the model’s task-specific needs. To overcome this, they propose the Prompt-in-the-Loop Distillation method, which adds additional supervision to the output masks. The ”Prompt-in-the-Loop” refers to a dynamic sampling strategy that iteratively samples new prompts from the non-overlapping zones of the teacher’s and student’s predicted masks. After several iterations, the accumulated loss is backpropagated to update both the encoder and decoder.
To further enhance the output quality, EdgeSAM offers an optional module that embeds granularity priors from specific datasets. The overall framework for distilling EdgeSAM is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F11" title="Figure 11 ‣ 3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p10">
<p class="ltx_p" id="S3.SS1.SSS2.p10.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p10.1.1">(iii) Attention-modified Encoders</span></p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p11">
<p class="ltx_p" id="S3.SS1.SSS2.p11.5">Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite> introduced EfficientViT-SAM, which utilizes EfficientViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> as the image encoder. The primary advantage of EfficientViT is its use of the ReLU linear attention mechanism, which facilitates global information interaction while enhancing hardware efficiency. By eliminating the hardware-unfriendly softmax operations and replacing them with ReLU, the attention calculation is reformulated as follows,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx7">
<tbody id="S3.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle O_{i}=\frac{ReLU(Q_{i})(\sum_{j=1}^{N}ReLU(K_{j})^{T}V_{j})}{%
ReLU(Q_{i})(\sum_{j=1}^{N}ReLU(K_{j})^{T})}" class="ltx_Math" display="inline" id="S3.E7.m1.4"><semantics id="S3.E7.m1.4a"><mrow id="S3.E7.m1.4.5" xref="S3.E7.m1.4.5.cmml"><msub id="S3.E7.m1.4.5.2" xref="S3.E7.m1.4.5.2.cmml"><mi id="S3.E7.m1.4.5.2.2" xref="S3.E7.m1.4.5.2.2.cmml">O</mi><mi id="S3.E7.m1.4.5.2.3" xref="S3.E7.m1.4.5.2.3.cmml">i</mi></msub><mo id="S3.E7.m1.4.5.1" xref="S3.E7.m1.4.5.1.cmml">=</mo><mstyle displaystyle="true" id="S3.E7.m1.4.4" xref="S3.E7.m1.4.4.cmml"><mfrac id="S3.E7.m1.4.4a" xref="S3.E7.m1.4.4.cmml"><mrow id="S3.E7.m1.2.2.2" xref="S3.E7.m1.2.2.2.cmml"><mi id="S3.E7.m1.2.2.2.4" xref="S3.E7.m1.2.2.2.4.cmml">R</mi><mo id="S3.E7.m1.2.2.2.3" xref="S3.E7.m1.2.2.2.3.cmml">⁢</mo><mi id="S3.E7.m1.2.2.2.5" xref="S3.E7.m1.2.2.2.5.cmml">e</mi><mo id="S3.E7.m1.2.2.2.3a" xref="S3.E7.m1.2.2.2.3.cmml">⁢</mo><mi id="S3.E7.m1.2.2.2.6" xref="S3.E7.m1.2.2.2.6.cmml">L</mi><mo id="S3.E7.m1.2.2.2.3b" xref="S3.E7.m1.2.2.2.3.cmml">⁢</mo><mi id="S3.E7.m1.2.2.2.7" xref="S3.E7.m1.2.2.2.7.cmml">U</mi><mo id="S3.E7.m1.2.2.2.3c" xref="S3.E7.m1.2.2.2.3.cmml">⁢</mo><mrow id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E7.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml">Q</mi><mi id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E7.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E7.m1.2.2.2.3d" xref="S3.E7.m1.2.2.2.3.cmml">⁢</mo><mrow id="S3.E7.m1.2.2.2.2.1" xref="S3.E7.m1.2.2.2.2.1.1.cmml"><mo id="S3.E7.m1.2.2.2.2.1.2" stretchy="false" xref="S3.E7.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S3.E7.m1.2.2.2.2.1.1" xref="S3.E7.m1.2.2.2.2.1.1.cmml"><msubsup id="S3.E7.m1.2.2.2.2.1.1.2" xref="S3.E7.m1.2.2.2.2.1.1.2.cmml"><mo id="S3.E7.m1.2.2.2.2.1.1.2.2.2" lspace="0em" xref="S3.E7.m1.2.2.2.2.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E7.m1.2.2.2.2.1.1.2.2.3" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.cmml"><mi id="S3.E7.m1.2.2.2.2.1.1.2.2.3.2" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.2.cmml">j</mi><mo id="S3.E7.m1.2.2.2.2.1.1.2.2.3.1" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E7.m1.2.2.2.2.1.1.2.2.3.3" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E7.m1.2.2.2.2.1.1.2.3" xref="S3.E7.m1.2.2.2.2.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.E7.m1.2.2.2.2.1.1.1" xref="S3.E7.m1.2.2.2.2.1.1.1.cmml"><mi id="S3.E7.m1.2.2.2.2.1.1.1.3" xref="S3.E7.m1.2.2.2.2.1.1.1.3.cmml">R</mi><mo id="S3.E7.m1.2.2.2.2.1.1.1.2" xref="S3.E7.m1.2.2.2.2.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.2.2.2.2.1.1.1.4" xref="S3.E7.m1.2.2.2.2.1.1.1.4.cmml">e</mi><mo id="S3.E7.m1.2.2.2.2.1.1.1.2a" xref="S3.E7.m1.2.2.2.2.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.2.2.2.2.1.1.1.5" xref="S3.E7.m1.2.2.2.2.1.1.1.5.cmml">L</mi><mo id="S3.E7.m1.2.2.2.2.1.1.1.2b" xref="S3.E7.m1.2.2.2.2.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.2.2.2.2.1.1.1.6" xref="S3.E7.m1.2.2.2.2.1.1.1.6.cmml">U</mi><mo id="S3.E7.m1.2.2.2.2.1.1.1.2c" xref="S3.E7.m1.2.2.2.2.1.1.1.2.cmml">⁢</mo><msup id="S3.E7.m1.2.2.2.2.1.1.1.1" xref="S3.E7.m1.2.2.2.2.1.1.1.1.cmml"><mrow id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml">K</mi><mi id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E7.m1.2.2.2.2.1.1.1.1.3" xref="S3.E7.m1.2.2.2.2.1.1.1.1.3.cmml">T</mi></msup><mo id="S3.E7.m1.2.2.2.2.1.1.1.2d" xref="S3.E7.m1.2.2.2.2.1.1.1.2.cmml">⁢</mo><msub id="S3.E7.m1.2.2.2.2.1.1.1.7" xref="S3.E7.m1.2.2.2.2.1.1.1.7.cmml"><mi id="S3.E7.m1.2.2.2.2.1.1.1.7.2" xref="S3.E7.m1.2.2.2.2.1.1.1.7.2.cmml">V</mi><mi id="S3.E7.m1.2.2.2.2.1.1.1.7.3" xref="S3.E7.m1.2.2.2.2.1.1.1.7.3.cmml">j</mi></msub></mrow></mrow><mo id="S3.E7.m1.2.2.2.2.1.3" stretchy="false" xref="S3.E7.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E7.m1.4.4.4" xref="S3.E7.m1.4.4.4.cmml"><mi id="S3.E7.m1.4.4.4.4" xref="S3.E7.m1.4.4.4.4.cmml">R</mi><mo id="S3.E7.m1.4.4.4.3" xref="S3.E7.m1.4.4.4.3.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.5" xref="S3.E7.m1.4.4.4.5.cmml">e</mi><mo id="S3.E7.m1.4.4.4.3a" xref="S3.E7.m1.4.4.4.3.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.6" xref="S3.E7.m1.4.4.4.6.cmml">L</mi><mo id="S3.E7.m1.4.4.4.3b" xref="S3.E7.m1.4.4.4.3.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.7" xref="S3.E7.m1.4.4.4.7.cmml">U</mi><mo id="S3.E7.m1.4.4.4.3c" xref="S3.E7.m1.4.4.4.3.cmml">⁢</mo><mrow id="S3.E7.m1.3.3.3.1.1" xref="S3.E7.m1.3.3.3.1.1.1.cmml"><mo id="S3.E7.m1.3.3.3.1.1.2" stretchy="false" xref="S3.E7.m1.3.3.3.1.1.1.cmml">(</mo><msub id="S3.E7.m1.3.3.3.1.1.1" xref="S3.E7.m1.3.3.3.1.1.1.cmml"><mi id="S3.E7.m1.3.3.3.1.1.1.2" xref="S3.E7.m1.3.3.3.1.1.1.2.cmml">Q</mi><mi id="S3.E7.m1.3.3.3.1.1.1.3" xref="S3.E7.m1.3.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.E7.m1.3.3.3.1.1.3" stretchy="false" xref="S3.E7.m1.3.3.3.1.1.1.cmml">)</mo></mrow><mo id="S3.E7.m1.4.4.4.3d" xref="S3.E7.m1.4.4.4.3.cmml">⁢</mo><mrow id="S3.E7.m1.4.4.4.2.1" xref="S3.E7.m1.4.4.4.2.1.1.cmml"><mo id="S3.E7.m1.4.4.4.2.1.2" stretchy="false" xref="S3.E7.m1.4.4.4.2.1.1.cmml">(</mo><mrow id="S3.E7.m1.4.4.4.2.1.1" xref="S3.E7.m1.4.4.4.2.1.1.cmml"><msubsup id="S3.E7.m1.4.4.4.2.1.1.2" xref="S3.E7.m1.4.4.4.2.1.1.2.cmml"><mo id="S3.E7.m1.4.4.4.2.1.1.2.2.2" lspace="0em" xref="S3.E7.m1.4.4.4.2.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E7.m1.4.4.4.2.1.1.2.2.3" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.cmml"><mi id="S3.E7.m1.4.4.4.2.1.1.2.2.3.2" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.2.cmml">j</mi><mo id="S3.E7.m1.4.4.4.2.1.1.2.2.3.1" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E7.m1.4.4.4.2.1.1.2.2.3.3" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E7.m1.4.4.4.2.1.1.2.3" xref="S3.E7.m1.4.4.4.2.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.E7.m1.4.4.4.2.1.1.1" xref="S3.E7.m1.4.4.4.2.1.1.1.cmml"><mi id="S3.E7.m1.4.4.4.2.1.1.1.3" xref="S3.E7.m1.4.4.4.2.1.1.1.3.cmml">R</mi><mo id="S3.E7.m1.4.4.4.2.1.1.1.2" xref="S3.E7.m1.4.4.4.2.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.2.1.1.1.4" xref="S3.E7.m1.4.4.4.2.1.1.1.4.cmml">e</mi><mo id="S3.E7.m1.4.4.4.2.1.1.1.2a" xref="S3.E7.m1.4.4.4.2.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.2.1.1.1.5" xref="S3.E7.m1.4.4.4.2.1.1.1.5.cmml">L</mi><mo id="S3.E7.m1.4.4.4.2.1.1.1.2b" xref="S3.E7.m1.4.4.4.2.1.1.1.2.cmml">⁢</mo><mi id="S3.E7.m1.4.4.4.2.1.1.1.6" xref="S3.E7.m1.4.4.4.2.1.1.1.6.cmml">U</mi><mo id="S3.E7.m1.4.4.4.2.1.1.1.2c" xref="S3.E7.m1.4.4.4.2.1.1.1.2.cmml">⁢</mo><msup id="S3.E7.m1.4.4.4.2.1.1.1.1" xref="S3.E7.m1.4.4.4.2.1.1.1.1.cmml"><mrow id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.2" stretchy="false" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.2" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.2.cmml">K</mi><mi id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.3" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.3" stretchy="false" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E7.m1.4.4.4.2.1.1.1.1.3" xref="S3.E7.m1.4.4.4.2.1.1.1.1.3.cmml">T</mi></msup></mrow></mrow><mo id="S3.E7.m1.4.4.4.2.1.3" stretchy="false" xref="S3.E7.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.4b"><apply id="S3.E7.m1.4.5.cmml" xref="S3.E7.m1.4.5"><eq id="S3.E7.m1.4.5.1.cmml" xref="S3.E7.m1.4.5.1"></eq><apply id="S3.E7.m1.4.5.2.cmml" xref="S3.E7.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.5.2.1.cmml" xref="S3.E7.m1.4.5.2">subscript</csymbol><ci id="S3.E7.m1.4.5.2.2.cmml" xref="S3.E7.m1.4.5.2.2">𝑂</ci><ci id="S3.E7.m1.4.5.2.3.cmml" xref="S3.E7.m1.4.5.2.3">𝑖</ci></apply><apply id="S3.E7.m1.4.4.cmml" xref="S3.E7.m1.4.4"><divide id="S3.E7.m1.4.4.5.cmml" xref="S3.E7.m1.4.4"></divide><apply id="S3.E7.m1.2.2.2.cmml" xref="S3.E7.m1.2.2.2"><times id="S3.E7.m1.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.3"></times><ci id="S3.E7.m1.2.2.2.4.cmml" xref="S3.E7.m1.2.2.2.4">𝑅</ci><ci id="S3.E7.m1.2.2.2.5.cmml" xref="S3.E7.m1.2.2.2.5">𝑒</ci><ci id="S3.E7.m1.2.2.2.6.cmml" xref="S3.E7.m1.2.2.2.6">𝐿</ci><ci id="S3.E7.m1.2.2.2.7.cmml" xref="S3.E7.m1.2.2.2.7">𝑈</ci><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">𝑄</ci><ci id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E7.m1.2.2.2.2.1.1.cmml" xref="S3.E7.m1.2.2.2.2.1"><apply id="S3.E7.m1.2.2.2.2.1.1.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.1.1.2.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2">superscript</csymbol><apply id="S3.E7.m1.2.2.2.2.1.1.2.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.1.1.2.2.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2">subscript</csymbol><sum id="S3.E7.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2.2.2"></sum><apply id="S3.E7.m1.2.2.2.2.1.1.2.2.3.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3"><eq id="S3.E7.m1.2.2.2.2.1.1.2.2.3.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.1"></eq><ci id="S3.E7.m1.2.2.2.2.1.1.2.2.3.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.2">𝑗</ci><cn id="S3.E7.m1.2.2.2.2.1.1.2.2.3.3.cmml" type="integer" xref="S3.E7.m1.2.2.2.2.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E7.m1.2.2.2.2.1.1.2.3.cmml" xref="S3.E7.m1.2.2.2.2.1.1.2.3">𝑁</ci></apply><apply id="S3.E7.m1.2.2.2.2.1.1.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1"><times id="S3.E7.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.2"></times><ci id="S3.E7.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.3">𝑅</ci><ci id="S3.E7.m1.2.2.2.2.1.1.1.4.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.4">𝑒</ci><ci id="S3.E7.m1.2.2.2.2.1.1.1.5.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.5">𝐿</ci><ci id="S3.E7.m1.2.2.2.2.1.1.1.6.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.6">𝑈</ci><apply id="S3.E7.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1">superscript</csymbol><apply id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.2">𝐾</ci><ci id="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1.1.1.1.3">𝑗</ci></apply><ci id="S3.E7.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.1.3">𝑇</ci></apply><apply id="S3.E7.m1.2.2.2.2.1.1.1.7.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.7"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.1.1.1.7.1.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.7">subscript</csymbol><ci id="S3.E7.m1.2.2.2.2.1.1.1.7.2.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.7.2">𝑉</ci><ci id="S3.E7.m1.2.2.2.2.1.1.1.7.3.cmml" xref="S3.E7.m1.2.2.2.2.1.1.1.7.3">𝑗</ci></apply></apply></apply></apply><apply id="S3.E7.m1.4.4.4.cmml" xref="S3.E7.m1.4.4.4"><times id="S3.E7.m1.4.4.4.3.cmml" xref="S3.E7.m1.4.4.4.3"></times><ci id="S3.E7.m1.4.4.4.4.cmml" xref="S3.E7.m1.4.4.4.4">𝑅</ci><ci id="S3.E7.m1.4.4.4.5.cmml" xref="S3.E7.m1.4.4.4.5">𝑒</ci><ci id="S3.E7.m1.4.4.4.6.cmml" xref="S3.E7.m1.4.4.4.6">𝐿</ci><ci id="S3.E7.m1.4.4.4.7.cmml" xref="S3.E7.m1.4.4.4.7">𝑈</ci><apply id="S3.E7.m1.3.3.3.1.1.1.cmml" xref="S3.E7.m1.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.1.1.1.1.cmml" xref="S3.E7.m1.3.3.3.1.1">subscript</csymbol><ci id="S3.E7.m1.3.3.3.1.1.1.2.cmml" xref="S3.E7.m1.3.3.3.1.1.1.2">𝑄</ci><ci id="S3.E7.m1.3.3.3.1.1.1.3.cmml" xref="S3.E7.m1.3.3.3.1.1.1.3">𝑖</ci></apply><apply id="S3.E7.m1.4.4.4.2.1.1.cmml" xref="S3.E7.m1.4.4.4.2.1"><apply id="S3.E7.m1.4.4.4.2.1.1.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.2.1.1.2.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2">superscript</csymbol><apply id="S3.E7.m1.4.4.4.2.1.1.2.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.2.1.1.2.2.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2">subscript</csymbol><sum id="S3.E7.m1.4.4.4.2.1.1.2.2.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2.2.2"></sum><apply id="S3.E7.m1.4.4.4.2.1.1.2.2.3.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3"><eq id="S3.E7.m1.4.4.4.2.1.1.2.2.3.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.1"></eq><ci id="S3.E7.m1.4.4.4.2.1.1.2.2.3.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.2">𝑗</ci><cn id="S3.E7.m1.4.4.4.2.1.1.2.2.3.3.cmml" type="integer" xref="S3.E7.m1.4.4.4.2.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E7.m1.4.4.4.2.1.1.2.3.cmml" xref="S3.E7.m1.4.4.4.2.1.1.2.3">𝑁</ci></apply><apply id="S3.E7.m1.4.4.4.2.1.1.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1"><times id="S3.E7.m1.4.4.4.2.1.1.1.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.2"></times><ci id="S3.E7.m1.4.4.4.2.1.1.1.3.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.3">𝑅</ci><ci id="S3.E7.m1.4.4.4.2.1.1.1.4.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.4">𝑒</ci><ci id="S3.E7.m1.4.4.4.2.1.1.1.5.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.5">𝐿</ci><ci id="S3.E7.m1.4.4.4.2.1.1.1.6.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.6">𝑈</ci><apply id="S3.E7.m1.4.4.4.2.1.1.1.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.2.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1">superscript</csymbol><apply id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.2">𝐾</ci><ci id="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1.1.1.1.3">𝑗</ci></apply><ci id="S3.E7.m1.4.4.4.2.1.1.1.1.3.cmml" xref="S3.E7.m1.4.4.4.2.1.1.1.1.3">𝑇</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.4c">\displaystyle O_{i}=\frac{ReLU(Q_{i})(\sum_{j=1}^{N}ReLU(K_{j})^{T}V_{j})}{%
ReLU(Q_{i})(\sum_{j=1}^{N}ReLU(K_{j})^{T})}</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.4d">italic_O start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG italic_R italic_e italic_L italic_U ( italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ( ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_R italic_e italic_L italic_U ( italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) end_ARG start_ARG italic_R italic_e italic_L italic_U ( italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ( ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_R italic_e italic_L italic_U ( italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS2.p11.4">once the sub-expressions <math alttext="(\sum_{j=1}^{N}ReLU(K_{j})^{T}V_{j})" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p11.1.m1.1"><semantics id="S3.SS1.SSS2.p11.1.m1.1a"><mrow id="S3.SS1.SSS2.p11.1.m1.1.1.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.cmml"><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS2.p11.1.m1.1.1.1.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.cmml"><msubsup id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.cmml"><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.2" lspace="0em" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.2" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.2.cmml">j</mi><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.3.cmml">R</mi><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.4" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.4.cmml">e</mi><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2a" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.5" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.5.cmml">L</mi><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2b" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.6" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.6.cmml">U</mi><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2c" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2.cmml">⁢</mo><msup id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">K</mi><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.3.cmml">T</mi></msup><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2d" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.cmml"><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.2" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.2.cmml">V</mi><mi id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.3" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.3.cmml">j</mi></msub></mrow></mrow><mo id="S3.SS1.SSS2.p11.1.m1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p11.1.m1.1b"><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1"><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.2"></sum><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3"><eq id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.2">𝑗</ci><cn id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1"><times id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.2"></times><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.3">𝑅</ci><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.4.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.4">𝑒</ci><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.5.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.5">𝐿</ci><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.6.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.6">𝑈</ci><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.2">𝐾</ci><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.1.3">𝑇</ci></apply><apply id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.1.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7">subscript</csymbol><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.2.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.2">𝑉</ci><ci id="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.3.cmml" xref="S3.SS1.SSS2.p11.1.m1.1.1.1.1.1.7.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p11.1.m1.1c">(\sum_{j=1}^{N}ReLU(K_{j})^{T}V_{j})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p11.1.m1.1d">( ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_R italic_e italic_L italic_U ( italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="(\sum_{j=1}^{N}ReLU(K_{j})^{T})" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p11.2.m2.1"><semantics id="S3.SS1.SSS2.p11.2.m2.1a"><mrow id="S3.SS1.SSS2.p11.2.m2.1.1.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.cmml"><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.2" stretchy="false" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS2.p11.2.m2.1.1.1.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.cmml"><msubsup id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.cmml"><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.2" lspace="0em" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.cmml"><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.2" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.2.cmml">j</mi><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.3" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.3" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.3" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.3.cmml">R</mi><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.4" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.4.cmml">e</mi><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2a" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.5" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.5.cmml">L</mi><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2b" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.6" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.6.cmml">U</mi><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2c" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2.cmml">⁢</mo><msup id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.cmml"><mrow id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.2.cmml">K</mi><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.3.cmml">T</mi></msup></mrow></mrow><mo id="S3.SS1.SSS2.p11.2.m2.1.1.1.3" stretchy="false" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p11.2.m2.1b"><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1"><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2">superscript</csymbol><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2">subscript</csymbol><sum id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.2"></sum><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3"><eq id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.1"></eq><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.2">𝑗</ci><cn id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.3.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.2.3">𝑁</ci></apply><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1"><times id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.2"></times><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.3">𝑅</ci><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.4.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.4">𝑒</ci><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.5.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.5">𝐿</ci><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.6.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.6">𝑈</ci><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.2">𝐾</ci><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply><ci id="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p11.2.m2.1.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p11.2.m2.1c">(\sum_{j=1}^{N}ReLU(K_{j})^{T})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p11.2.m2.1d">( ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_R italic_e italic_L italic_U ( italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT )</annotation></semantics></math> are computed, they can be reused for each query <math alttext="Q_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p11.3.m3.1"><semantics id="S3.SS1.SSS2.p11.3.m3.1a"><msub id="S3.SS1.SSS2.p11.3.m3.1.1" xref="S3.SS1.SSS2.p11.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p11.3.m3.1.1.2" xref="S3.SS1.SSS2.p11.3.m3.1.1.2.cmml">Q</mi><mi id="S3.SS1.SSS2.p11.3.m3.1.1.3" xref="S3.SS1.SSS2.p11.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p11.3.m3.1b"><apply id="S3.SS1.SSS2.p11.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p11.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p11.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p11.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p11.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p11.3.m3.1.1.2">𝑄</ci><ci id="S3.SS1.SSS2.p11.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p11.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p11.3.m3.1c">Q_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p11.3.m3.1d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Therefore, the complexity is decreased to <math alttext="\mathcal{O}(N)" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p11.4.m4.1"><semantics id="S3.SS1.SSS2.p11.4.m4.1a"><mrow id="S3.SS1.SSS2.p11.4.m4.1.2" xref="S3.SS1.SSS2.p11.4.m4.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p11.4.m4.1.2.2" xref="S3.SS1.SSS2.p11.4.m4.1.2.2.cmml">𝒪</mi><mo id="S3.SS1.SSS2.p11.4.m4.1.2.1" xref="S3.SS1.SSS2.p11.4.m4.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.SSS2.p11.4.m4.1.2.3.2" xref="S3.SS1.SSS2.p11.4.m4.1.2.cmml"><mo id="S3.SS1.SSS2.p11.4.m4.1.2.3.2.1" stretchy="false" xref="S3.SS1.SSS2.p11.4.m4.1.2.cmml">(</mo><mi id="S3.SS1.SSS2.p11.4.m4.1.1" xref="S3.SS1.SSS2.p11.4.m4.1.1.cmml">N</mi><mo id="S3.SS1.SSS2.p11.4.m4.1.2.3.2.2" stretchy="false" xref="S3.SS1.SSS2.p11.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p11.4.m4.1b"><apply id="S3.SS1.SSS2.p11.4.m4.1.2.cmml" xref="S3.SS1.SSS2.p11.4.m4.1.2"><times id="S3.SS1.SSS2.p11.4.m4.1.2.1.cmml" xref="S3.SS1.SSS2.p11.4.m4.1.2.1"></times><ci id="S3.SS1.SSS2.p11.4.m4.1.2.2.cmml" xref="S3.SS1.SSS2.p11.4.m4.1.2.2">𝒪</ci><ci id="S3.SS1.SSS2.p11.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p11.4.m4.1.1">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p11.4.m4.1c">\mathcal{O}(N)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p11.4.m4.1d">caligraphic_O ( italic_N )</annotation></semantics></math>. The training of EfficientViT-SAM is divided into two steps. The first step is distilling from ViT-H to EfficientViT and the second step is train the entire model end-to-end on the SA-1B dataset. This approach achieves nearly no accuracy loss as well as huge improvement in efficiency.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p12">
<p class="ltx_p" id="S3.SS1.SSS2.p12.1">Shen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib101" title=""><span class="ltx_text" style="font-size:90%;">101</span></a>]</cite> introduced FastSAM3D, an efficient segment-anything model specifically designed for 3D volumetric medical images. The key contribution of this work is the development of the 3D Sparse Flash Attention mechanism. This novel attention approach combines the advantages of the 3D Dilated Attention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>, which extends the receptive field, with FlashAttention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> to accelerate computations. FastSAM3D utilizes a modified ViT-Tiny as the image encoder, distilled from the ViT-Base encoder, ensuring efficiency without compromising performance. The authors implemented a layer-wise progressive distillation strategy to iteratively align feature maps between the two encoders.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p13">
<p class="ltx_p" id="S3.SS1.SSS2.p13.1">Building on the approach of FastSAM3D, Song et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib104" title=""><span class="ltx_text" style="font-size:90%;">104</span></a>]</cite> introduced a 2D variant called SAM-Lightening. Like its 3D counterpart, SAM-Lightening combines Sparse/Dilated Attention and FlashAttention as a replacement for the standard attention mechanism, while retaining the same image encoder. The key difference lies in the Knowledge Distillation (KD) strategy, referred to as Dynamic Layer-Wise Distillation (DLD). In DLD, a series of time-varying weights <math alttext="\in[0,1]" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p13.1.m1.2"><semantics id="S3.SS1.SSS2.p13.1.m1.2a"><mrow id="S3.SS1.SSS2.p13.1.m1.2.3" xref="S3.SS1.SSS2.p13.1.m1.2.3.cmml"><mi id="S3.SS1.SSS2.p13.1.m1.2.3.2" xref="S3.SS1.SSS2.p13.1.m1.2.3.2.cmml"></mi><mo id="S3.SS1.SSS2.p13.1.m1.2.3.1" xref="S3.SS1.SSS2.p13.1.m1.2.3.1.cmml">∈</mo><mrow id="S3.SS1.SSS2.p13.1.m1.2.3.3.2" xref="S3.SS1.SSS2.p13.1.m1.2.3.3.1.cmml"><mo id="S3.SS1.SSS2.p13.1.m1.2.3.3.2.1" stretchy="false" xref="S3.SS1.SSS2.p13.1.m1.2.3.3.1.cmml">[</mo><mn id="S3.SS1.SSS2.p13.1.m1.1.1" xref="S3.SS1.SSS2.p13.1.m1.1.1.cmml">0</mn><mo id="S3.SS1.SSS2.p13.1.m1.2.3.3.2.2" xref="S3.SS1.SSS2.p13.1.m1.2.3.3.1.cmml">,</mo><mn id="S3.SS1.SSS2.p13.1.m1.2.2" xref="S3.SS1.SSS2.p13.1.m1.2.2.cmml">1</mn><mo id="S3.SS1.SSS2.p13.1.m1.2.3.3.2.3" stretchy="false" xref="S3.SS1.SSS2.p13.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p13.1.m1.2b"><apply id="S3.SS1.SSS2.p13.1.m1.2.3.cmml" xref="S3.SS1.SSS2.p13.1.m1.2.3"><in id="S3.SS1.SSS2.p13.1.m1.2.3.1.cmml" xref="S3.SS1.SSS2.p13.1.m1.2.3.1"></in><csymbol cd="latexml" id="S3.SS1.SSS2.p13.1.m1.2.3.2.cmml" xref="S3.SS1.SSS2.p13.1.m1.2.3.2">absent</csymbol><interval closure="closed" id="S3.SS1.SSS2.p13.1.m1.2.3.3.1.cmml" xref="S3.SS1.SSS2.p13.1.m1.2.3.3.2"><cn id="S3.SS1.SSS2.p13.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS2.p13.1.m1.1.1">0</cn><cn id="S3.SS1.SSS2.p13.1.m1.2.2.cmml" type="integer" xref="S3.SS1.SSS2.p13.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p13.1.m1.2c">\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p13.1.m1.2d">∈ [ 0 , 1 ]</annotation></semantics></math> are applied to determine which layers need to be updated and how much each layer contributes to the update process. As training progresses, the entire architecture is gradually optimized. SAM-Lightening reportedly achieves a 30× acceleration compared to SAM-H. The overall distillation framework is similar to FastSAM3D, with the main change being the substitution of the distillation strategy for dynamic layer-wise distillation.</p>
</div>
<figure class="ltx_figure" id="S3.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S3.F12.g1" src="x11.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F12.2.1.1" style="font-size:90%;">Figure 12</span>: </span><span class="ltx_text" id="S3.F12.3.2" style="font-size:90%;">The overview of RWKV-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib145" title=""><span class="ltx_text" style="font-size:90%;">145</span></a>]</cite> (left) and its image encoder (right). The image encoder is made up of three stages, where the first two stages use Mobile Convolution Blocks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib97" title=""><span class="ltx_text" style="font-size:90%;">97</span></a>]</cite> and the last stage uses Vision RWKV blocks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS2.p14">
<p class="ltx_p" id="S3.SS1.SSS2.p14.1">A recent work by Yuan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib145" title=""><span class="ltx_text" style="font-size:90%;">145</span></a>]</cite>, RWKV-SAM, represents a significant advancement in accelerating SAM by introducing the popular linear attention model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">39</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib87" title=""><span class="ltx_text" style="font-size:90%;">87</span></a>]</cite> as an efficient backbone. In their study, they compare RWKV-based and Mamba-based architectures and select the RWKV-based approach to construct a lightweight version of SAM. The backbone is a hybrid design, with the first two stages consisting of Mobile Convolution Blocks from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib97" title=""><span class="ltx_text" style="font-size:90%;">97</span></a>]</cite>, and the final stage built using Vision RWKV blocks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>. More details on RWKV can be found in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS2.SSS2" title="2.2.2 Transformer-alternative Models ‣ 2.2 Efficient Backbone ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.2.2</span></a>.
Additionally, a refinement module is incorporated into the SAM-like architecture to enhance mask quality by fusing features from different levels generated at each stage. The overall architecture of RWKV-SAM is depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F12" title="Figure 12 ‣ 3.1.2 Knowledge Distillation based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">12</span></a>. The model is trained using a ”distillation-finetune” strategy, where knowledge from SAM-H is first distilled into the backbone, followed by fine-tuning of the entire model. RWKV-SAM demonstrates significant improvements in efficiency, while maintaining comparable segmentation performance to SAM.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Quantization based Methods</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.6">As detailed in previous section, TinySAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite> leverages the Hard Mining Full-Stage Distillation to improve the effectiveness of transferring knowledge. To further contract the scale of TinySAM, Shu et al. adopt a post-training quantization to the encoder of TinySAM and the quantified version is named as Q-TinySAM. They take the quantization basically following the instructions in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib146" title=""><span class="ltx_text" style="font-size:90%;">146</span></a>]</cite>. For the matrix multiplication in ViT, <math alttext="O=AB" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.1.m1.1"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><mrow id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS3.p1.1.m1.1.1.2" xref="S3.SS1.SSS3.p1.1.m1.1.1.2.cmml">O</mi><mo id="S3.SS1.SSS3.p1.1.m1.1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS1.SSS3.p1.1.m1.1.1.3" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS3.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.2.cmml">A</mi><mo id="S3.SS1.SSS3.p1.1.m1.1.1.3.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS3.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.3.cmml">B</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><apply id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1"><eq id="S3.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.1"></eq><ci id="S3.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.2">𝑂</ci><apply id="S3.SS1.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.3"><times id="S3.SS1.SSS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.SSS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.2">𝐴</ci><ci id="S3.SS1.SSS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">O=AB</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.1.m1.1d">italic_O = italic_A italic_B</annotation></semantics></math> would be quantified to <math alttext="\hat{O}=\hat{A}\hat{B}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.2.m2.1"><semantics id="S3.SS1.SSS3.p1.2.m2.1a"><mrow id="S3.SS1.SSS3.p1.2.m2.1.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.SS1.SSS3.p1.2.m2.1.1.2" xref="S3.SS1.SSS3.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS3.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS3.p1.2.m2.1.1.2.2.cmml">O</mi><mo id="S3.SS1.SSS3.p1.2.m2.1.1.2.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS1.SSS3.p1.2.m2.1.1.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS1.SSS3.p1.2.m2.1.1.3" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.cmml"><mover accent="true" id="S3.SS1.SSS3.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.2.cmml"><mi id="S3.SS1.SSS3.p1.2.m2.1.1.3.2.2" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.2.2.cmml">A</mi><mo id="S3.SS1.SSS3.p1.2.m2.1.1.3.2.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.2.1.cmml">^</mo></mover><mo id="S3.SS1.SSS3.p1.2.m2.1.1.3.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mover accent="true" id="S3.SS1.SSS3.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.SSS3.p1.2.m2.1.1.3.3.2" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.3.2.cmml">B</mi><mo id="S3.SS1.SSS3.p1.2.m2.1.1.3.3.1" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.3.1.cmml">^</mo></mover></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.2.m2.1b"><apply id="S3.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1"><eq id="S3.SS1.SSS3.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.1"></eq><apply id="S3.SS1.SSS3.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.2"><ci id="S3.SS1.SSS3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.2.1">^</ci><ci id="S3.SS1.SSS3.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.2.2">𝑂</ci></apply><apply id="S3.SS1.SSS3.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3"><times id="S3.SS1.SSS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.1"></times><apply id="S3.SS1.SSS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.2"><ci id="S3.SS1.SSS3.p1.2.m2.1.1.3.2.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.2.1">^</ci><ci id="S3.SS1.SSS3.p1.2.m2.1.1.3.2.2.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.2.2">𝐴</ci></apply><apply id="S3.SS1.SSS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.3"><ci id="S3.SS1.SSS3.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.3.1">^</ci><ci id="S3.SS1.SSS3.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.SSS3.p1.2.m2.1.1.3.3.2">𝐵</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.2.m2.1c">\hat{O}=\hat{A}\hat{B}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.2.m2.1d">over^ start_ARG italic_O end_ARG = over^ start_ARG italic_A end_ARG over^ start_ARG italic_B end_ARG</annotation></semantics></math>, with scaling factors <math alttext="s_{A},s_{B}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.3.m3.2"><semantics id="S3.SS1.SSS3.p1.3.m3.2a"><mrow id="S3.SS1.SSS3.p1.3.m3.2.2.2" xref="S3.SS1.SSS3.p1.3.m3.2.2.3.cmml"><msub id="S3.SS1.SSS3.p1.3.m3.1.1.1.1" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS1.SSS3.p1.3.m3.1.1.1.1.2" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1.2.cmml">s</mi><mi id="S3.SS1.SSS3.p1.3.m3.1.1.1.1.3" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1.3.cmml">A</mi></msub><mo id="S3.SS1.SSS3.p1.3.m3.2.2.2.3" xref="S3.SS1.SSS3.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS1.SSS3.p1.3.m3.2.2.2.2" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS1.SSS3.p1.3.m3.2.2.2.2.2" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2.2.cmml">s</mi><mi id="S3.SS1.SSS3.p1.3.m3.2.2.2.2.3" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2.3.cmml">B</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.3.m3.2b"><list id="S3.SS1.SSS3.p1.3.m3.2.2.3.cmml" xref="S3.SS1.SSS3.p1.3.m3.2.2.2"><apply id="S3.SS1.SSS3.p1.3.m3.1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS3.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1.2">𝑠</ci><ci id="S3.SS1.SSS3.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.SSS3.p1.3.m3.1.1.1.1.3">𝐴</ci></apply><apply id="S3.SS1.SSS3.p1.3.m3.2.2.2.2.cmml" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS3.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2.2">𝑠</ci><ci id="S3.SS1.SSS3.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.SSS3.p1.3.m3.2.2.2.2.3">𝐵</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.3.m3.2c">s_{A},s_{B}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.3.m3.2d">italic_s start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT</annotation></semantics></math>. The researchers takes a alternative and iterative search strategy for the best <math alttext="s_{A},s_{B}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.4.m4.2"><semantics id="S3.SS1.SSS3.p1.4.m4.2a"><mrow id="S3.SS1.SSS3.p1.4.m4.2.2.2" xref="S3.SS1.SSS3.p1.4.m4.2.2.3.cmml"><msub id="S3.SS1.SSS3.p1.4.m4.1.1.1.1" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1.cmml"><mi id="S3.SS1.SSS3.p1.4.m4.1.1.1.1.2" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1.2.cmml">s</mi><mi id="S3.SS1.SSS3.p1.4.m4.1.1.1.1.3" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1.3.cmml">A</mi></msub><mo id="S3.SS1.SSS3.p1.4.m4.2.2.2.3" xref="S3.SS1.SSS3.p1.4.m4.2.2.3.cmml">,</mo><msub id="S3.SS1.SSS3.p1.4.m4.2.2.2.2" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2.cmml"><mi id="S3.SS1.SSS3.p1.4.m4.2.2.2.2.2" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2.2.cmml">s</mi><mi id="S3.SS1.SSS3.p1.4.m4.2.2.2.2.3" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2.3.cmml">B</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.4.m4.2b"><list id="S3.SS1.SSS3.p1.4.m4.2.2.3.cmml" xref="S3.SS1.SSS3.p1.4.m4.2.2.2"><apply id="S3.SS1.SSS3.p1.4.m4.1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS3.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1.2">𝑠</ci><ci id="S3.SS1.SSS3.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS1.SSS3.p1.4.m4.1.1.1.1.3">𝐴</ci></apply><apply id="S3.SS1.SSS3.p1.4.m4.2.2.2.2.cmml" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.4.m4.2.2.2.2.1.cmml" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS3.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2.2">𝑠</ci><ci id="S3.SS1.SSS3.p1.4.m4.2.2.2.2.3.cmml" xref="S3.SS1.SSS3.p1.4.m4.2.2.2.2.3">𝐵</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.4.m4.2c">s_{A},s_{B}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.4.m4.2d">italic_s start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT</annotation></semantics></math> which can minimize the distance between <math alttext="O" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.5.m5.1"><semantics id="S3.SS1.SSS3.p1.5.m5.1a"><mi id="S3.SS1.SSS3.p1.5.m5.1.1" xref="S3.SS1.SSS3.p1.5.m5.1.1.cmml">O</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.5.m5.1b"><ci id="S3.SS1.SSS3.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS3.p1.5.m5.1.1">𝑂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.5.m5.1c">O</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.5.m5.1d">italic_O</annotation></semantics></math> and <math alttext="\hat{O}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.6.m6.1"><semantics id="S3.SS1.SSS3.p1.6.m6.1a"><mover accent="true" id="S3.SS1.SSS3.p1.6.m6.1.1" xref="S3.SS1.SSS3.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS3.p1.6.m6.1.1.2" xref="S3.SS1.SSS3.p1.6.m6.1.1.2.cmml">O</mi><mo id="S3.SS1.SSS3.p1.6.m6.1.1.1" xref="S3.SS1.SSS3.p1.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.6.m6.1b"><apply id="S3.SS1.SSS3.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS3.p1.6.m6.1.1"><ci id="S3.SS1.SSS3.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS3.p1.6.m6.1.1.1">^</ci><ci id="S3.SS1.SSS3.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS3.p1.6.m6.1.1.2">𝑂</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.6.m6.1c">\hat{O}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.6.m6.1d">over^ start_ARG italic_O end_ARG</annotation></semantics></math>. The hessian guided metric is used to measure the distance which is approximately calculated as follows:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx8">
<tbody id="S3.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\min_{\Delta}\mathbb{E}[M^{T}diag\big{(}(\frac{\partial L}{%
\partial O^{l}_{1}})^{2},\dots,(\frac{\partial L}{\partial O^{l}_{|O^{l}|}})^{%
2}\big{)}M]" class="ltx_Math" display="inline" id="S3.E8.m1.4"><semantics id="S3.E8.m1.4a"><mrow id="S3.E8.m1.4.4" xref="S3.E8.m1.4.4.cmml"><mrow id="S3.E8.m1.4.4.3" xref="S3.E8.m1.4.4.3.cmml"><munder id="S3.E8.m1.4.4.3.1" xref="S3.E8.m1.4.4.3.1.cmml"><mi id="S3.E8.m1.4.4.3.1.2" xref="S3.E8.m1.4.4.3.1.2.cmml">min</mi><mi id="S3.E8.m1.4.4.3.1.3" mathvariant="normal" xref="S3.E8.m1.4.4.3.1.3.cmml">Δ</mi></munder><mo id="S3.E8.m1.4.4.3a" lspace="0.167em" xref="S3.E8.m1.4.4.3.cmml">⁡</mo><mi id="S3.E8.m1.4.4.3.2" xref="S3.E8.m1.4.4.3.2.cmml">𝔼</mi></mrow><mo id="S3.E8.m1.4.4.2" xref="S3.E8.m1.4.4.2.cmml">⁢</mo><mrow id="S3.E8.m1.4.4.1.1" xref="S3.E8.m1.4.4.1.2.cmml"><mo id="S3.E8.m1.4.4.1.1.2" stretchy="false" xref="S3.E8.m1.4.4.1.2.1.cmml">[</mo><mrow id="S3.E8.m1.4.4.1.1.1" xref="S3.E8.m1.4.4.1.1.1.cmml"><msup id="S3.E8.m1.4.4.1.1.1.4" xref="S3.E8.m1.4.4.1.1.1.4.cmml"><mi id="S3.E8.m1.4.4.1.1.1.4.2" xref="S3.E8.m1.4.4.1.1.1.4.2.cmml">M</mi><mi id="S3.E8.m1.4.4.1.1.1.4.3" xref="S3.E8.m1.4.4.1.1.1.4.3.cmml">T</mi></msup><mo id="S3.E8.m1.4.4.1.1.1.3" xref="S3.E8.m1.4.4.1.1.1.3.cmml">⁢</mo><mi id="S3.E8.m1.4.4.1.1.1.5" xref="S3.E8.m1.4.4.1.1.1.5.cmml">d</mi><mo id="S3.E8.m1.4.4.1.1.1.3a" xref="S3.E8.m1.4.4.1.1.1.3.cmml">⁢</mo><mi id="S3.E8.m1.4.4.1.1.1.6" xref="S3.E8.m1.4.4.1.1.1.6.cmml">i</mi><mo id="S3.E8.m1.4.4.1.1.1.3b" xref="S3.E8.m1.4.4.1.1.1.3.cmml">⁢</mo><mi id="S3.E8.m1.4.4.1.1.1.7" xref="S3.E8.m1.4.4.1.1.1.7.cmml">a</mi><mo id="S3.E8.m1.4.4.1.1.1.3c" xref="S3.E8.m1.4.4.1.1.1.3.cmml">⁢</mo><mi id="S3.E8.m1.4.4.1.1.1.8" xref="S3.E8.m1.4.4.1.1.1.8.cmml">g</mi><mo id="S3.E8.m1.4.4.1.1.1.3d" xref="S3.E8.m1.4.4.1.1.1.3.cmml">⁢</mo><mrow id="S3.E8.m1.4.4.1.1.1.2.2" xref="S3.E8.m1.4.4.1.1.1.2.3.cmml"><mo id="S3.E8.m1.4.4.1.1.1.2.2.3" maxsize="120%" minsize="120%" xref="S3.E8.m1.4.4.1.1.1.2.3.cmml">(</mo><msup id="S3.E8.m1.4.4.1.1.1.1.1.1" xref="S3.E8.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S3.E8.m1.4.4.1.1.1.1.1.1.2.2" xref="S3.E8.m1.2.2.cmml"><mo id="S3.E8.m1.4.4.1.1.1.1.1.1.2.2.1" stretchy="false" xref="S3.E8.m1.2.2.cmml">(</mo><mstyle displaystyle="true" id="S3.E8.m1.2.2" xref="S3.E8.m1.2.2.cmml"><mfrac id="S3.E8.m1.2.2a" xref="S3.E8.m1.2.2.cmml"><mrow id="S3.E8.m1.2.2.2" xref="S3.E8.m1.2.2.2.cmml"><mo id="S3.E8.m1.2.2.2.1" rspace="0em" xref="S3.E8.m1.2.2.2.1.cmml">∂</mo><mi id="S3.E8.m1.2.2.2.2" xref="S3.E8.m1.2.2.2.2.cmml">L</mi></mrow><mrow id="S3.E8.m1.2.2.3" xref="S3.E8.m1.2.2.3.cmml"><mo id="S3.E8.m1.2.2.3.1" rspace="0em" xref="S3.E8.m1.2.2.3.1.cmml">∂</mo><msubsup id="S3.E8.m1.2.2.3.2" xref="S3.E8.m1.2.2.3.2.cmml"><mi id="S3.E8.m1.2.2.3.2.2.2" xref="S3.E8.m1.2.2.3.2.2.2.cmml">O</mi><mn id="S3.E8.m1.2.2.3.2.3" xref="S3.E8.m1.2.2.3.2.3.cmml">1</mn><mi id="S3.E8.m1.2.2.3.2.2.3" xref="S3.E8.m1.2.2.3.2.2.3.cmml">l</mi></msubsup></mrow></mfrac></mstyle><mo id="S3.E8.m1.4.4.1.1.1.1.1.1.2.2.2" stretchy="false" xref="S3.E8.m1.2.2.cmml">)</mo></mrow><mn id="S3.E8.m1.4.4.1.1.1.1.1.1.3" xref="S3.E8.m1.4.4.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.E8.m1.4.4.1.1.1.2.2.4" xref="S3.E8.m1.4.4.1.1.1.2.3.cmml">,</mo><mi id="S3.E8.m1.3.3" mathvariant="normal" xref="S3.E8.m1.3.3.cmml">…</mi><mo id="S3.E8.m1.4.4.1.1.1.2.2.5" xref="S3.E8.m1.4.4.1.1.1.2.3.cmml">,</mo><msup id="S3.E8.m1.4.4.1.1.1.2.2.2" xref="S3.E8.m1.4.4.1.1.1.2.2.2.cmml"><mrow id="S3.E8.m1.4.4.1.1.1.2.2.2.2.2" xref="S3.E8.m1.1.1.cmml"><mo id="S3.E8.m1.4.4.1.1.1.2.2.2.2.2.1" stretchy="false" xref="S3.E8.m1.1.1.cmml">(</mo><mstyle displaystyle="true" id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><mfrac id="S3.E8.m1.1.1a" xref="S3.E8.m1.1.1.cmml"><mrow id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml"><mo id="S3.E8.m1.1.1.3.1" rspace="0em" xref="S3.E8.m1.1.1.3.1.cmml">∂</mo><mi id="S3.E8.m1.1.1.3.2" xref="S3.E8.m1.1.1.3.2.cmml">L</mi></mrow><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml"><mo id="S3.E8.m1.1.1.1.2" rspace="0em" xref="S3.E8.m1.1.1.1.2.cmml">∂</mo><msubsup id="S3.E8.m1.1.1.1.3" xref="S3.E8.m1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.3.2.2" xref="S3.E8.m1.1.1.1.3.2.2.cmml">O</mi><mrow id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.2.cmml"><mo id="S3.E8.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.1.1.1.1.1.2.1.cmml">|</mo><msup id="S3.E8.m1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.2.cmml">O</mi><mi id="S3.E8.m1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.3.cmml">l</mi></msup><mo id="S3.E8.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E8.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mi id="S3.E8.m1.1.1.1.3.2.3" xref="S3.E8.m1.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow></mfrac></mstyle><mo id="S3.E8.m1.4.4.1.1.1.2.2.2.2.2.2" stretchy="false" xref="S3.E8.m1.1.1.cmml">)</mo></mrow><mn id="S3.E8.m1.4.4.1.1.1.2.2.2.3" xref="S3.E8.m1.4.4.1.1.1.2.2.2.3.cmml">2</mn></msup><mo id="S3.E8.m1.4.4.1.1.1.2.2.6" maxsize="120%" minsize="120%" xref="S3.E8.m1.4.4.1.1.1.2.3.cmml">)</mo></mrow><mo id="S3.E8.m1.4.4.1.1.1.3e" xref="S3.E8.m1.4.4.1.1.1.3.cmml">⁢</mo><mi id="S3.E8.m1.4.4.1.1.1.9" xref="S3.E8.m1.4.4.1.1.1.9.cmml">M</mi></mrow><mo id="S3.E8.m1.4.4.1.1.3" stretchy="false" xref="S3.E8.m1.4.4.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.4b"><apply id="S3.E8.m1.4.4.cmml" xref="S3.E8.m1.4.4"><times id="S3.E8.m1.4.4.2.cmml" xref="S3.E8.m1.4.4.2"></times><apply id="S3.E8.m1.4.4.3.cmml" xref="S3.E8.m1.4.4.3"><apply id="S3.E8.m1.4.4.3.1.cmml" xref="S3.E8.m1.4.4.3.1"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.3.1.1.cmml" xref="S3.E8.m1.4.4.3.1">subscript</csymbol><min id="S3.E8.m1.4.4.3.1.2.cmml" xref="S3.E8.m1.4.4.3.1.2"></min><ci id="S3.E8.m1.4.4.3.1.3.cmml" xref="S3.E8.m1.4.4.3.1.3">Δ</ci></apply><ci id="S3.E8.m1.4.4.3.2.cmml" xref="S3.E8.m1.4.4.3.2">𝔼</ci></apply><apply id="S3.E8.m1.4.4.1.2.cmml" xref="S3.E8.m1.4.4.1.1"><csymbol cd="latexml" id="S3.E8.m1.4.4.1.2.1.cmml" xref="S3.E8.m1.4.4.1.1.2">delimited-[]</csymbol><apply id="S3.E8.m1.4.4.1.1.1.cmml" xref="S3.E8.m1.4.4.1.1.1"><times id="S3.E8.m1.4.4.1.1.1.3.cmml" xref="S3.E8.m1.4.4.1.1.1.3"></times><apply id="S3.E8.m1.4.4.1.1.1.4.cmml" xref="S3.E8.m1.4.4.1.1.1.4"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.1.4.1.cmml" xref="S3.E8.m1.4.4.1.1.1.4">superscript</csymbol><ci id="S3.E8.m1.4.4.1.1.1.4.2.cmml" xref="S3.E8.m1.4.4.1.1.1.4.2">𝑀</ci><ci id="S3.E8.m1.4.4.1.1.1.4.3.cmml" xref="S3.E8.m1.4.4.1.1.1.4.3">𝑇</ci></apply><ci id="S3.E8.m1.4.4.1.1.1.5.cmml" xref="S3.E8.m1.4.4.1.1.1.5">𝑑</ci><ci id="S3.E8.m1.4.4.1.1.1.6.cmml" xref="S3.E8.m1.4.4.1.1.1.6">𝑖</ci><ci id="S3.E8.m1.4.4.1.1.1.7.cmml" xref="S3.E8.m1.4.4.1.1.1.7">𝑎</ci><ci id="S3.E8.m1.4.4.1.1.1.8.cmml" xref="S3.E8.m1.4.4.1.1.1.8">𝑔</ci><vector id="S3.E8.m1.4.4.1.1.1.2.3.cmml" xref="S3.E8.m1.4.4.1.1.1.2.2"><apply id="S3.E8.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E8.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.4.4.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E8.m1.2.2.cmml" xref="S3.E8.m1.4.4.1.1.1.1.1.1.2.2"><divide id="S3.E8.m1.2.2.1.cmml" xref="S3.E8.m1.4.4.1.1.1.1.1.1.2.2"></divide><apply id="S3.E8.m1.2.2.2.cmml" xref="S3.E8.m1.2.2.2"><partialdiff id="S3.E8.m1.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.1"></partialdiff><ci id="S3.E8.m1.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2">𝐿</ci></apply><apply id="S3.E8.m1.2.2.3.cmml" xref="S3.E8.m1.2.2.3"><partialdiff id="S3.E8.m1.2.2.3.1.cmml" xref="S3.E8.m1.2.2.3.1"></partialdiff><apply id="S3.E8.m1.2.2.3.2.cmml" xref="S3.E8.m1.2.2.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.3.2.1.cmml" xref="S3.E8.m1.2.2.3.2">subscript</csymbol><apply id="S3.E8.m1.2.2.3.2.2.cmml" xref="S3.E8.m1.2.2.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.3.2.2.1.cmml" xref="S3.E8.m1.2.2.3.2">superscript</csymbol><ci id="S3.E8.m1.2.2.3.2.2.2.cmml" xref="S3.E8.m1.2.2.3.2.2.2">𝑂</ci><ci id="S3.E8.m1.2.2.3.2.2.3.cmml" xref="S3.E8.m1.2.2.3.2.2.3">𝑙</ci></apply><cn id="S3.E8.m1.2.2.3.2.3.cmml" type="integer" xref="S3.E8.m1.2.2.3.2.3">1</cn></apply></apply></apply><cn id="S3.E8.m1.4.4.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E8.m1.4.4.1.1.1.1.1.1.3">2</cn></apply><ci id="S3.E8.m1.3.3.cmml" xref="S3.E8.m1.3.3">…</ci><apply id="S3.E8.m1.4.4.1.1.1.2.2.2.cmml" xref="S3.E8.m1.4.4.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.1.2.2.2.1.cmml" xref="S3.E8.m1.4.4.1.1.1.2.2.2">superscript</csymbol><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.4.4.1.1.1.2.2.2.2.2"><divide id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.4.4.1.1.1.2.2.2.2.2"></divide><apply id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3"><partialdiff id="S3.E8.m1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.3.1"></partialdiff><ci id="S3.E8.m1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.3.2">𝐿</ci></apply><apply id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><partialdiff id="S3.E8.m1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.2"></partialdiff><apply id="S3.E8.m1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.3">subscript</csymbol><apply id="S3.E8.m1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.3.2.1.cmml" xref="S3.E8.m1.1.1.1.3">superscript</csymbol><ci id="S3.E8.m1.1.1.1.3.2.2.cmml" xref="S3.E8.m1.1.1.1.3.2.2">𝑂</ci><ci id="S3.E8.m1.1.1.1.3.2.3.cmml" xref="S3.E8.m1.1.1.1.3.2.3">𝑙</ci></apply><apply id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><abs id="S3.E8.m1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2"></abs><apply id="S3.E8.m1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2">𝑂</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3">𝑙</ci></apply></apply></apply></apply></apply><cn id="S3.E8.m1.4.4.1.1.1.2.2.2.3.cmml" type="integer" xref="S3.E8.m1.4.4.1.1.1.2.2.2.3">2</cn></apply></vector><ci id="S3.E8.m1.4.4.1.1.1.9.cmml" xref="S3.E8.m1.4.4.1.1.1.9">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.4c">\displaystyle\min_{\Delta}\mathbb{E}[M^{T}diag\big{(}(\frac{\partial L}{%
\partial O^{l}_{1}})^{2},\dots,(\frac{\partial L}{\partial O^{l}_{|O^{l}|}})^{%
2}\big{)}M]</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.4d">roman_min start_POSTSUBSCRIPT roman_Δ end_POSTSUBSCRIPT blackboard_E [ italic_M start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_d italic_i italic_a italic_g ( ( divide start_ARG ∂ italic_L end_ARG start_ARG ∂ italic_O start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , ( divide start_ARG ∂ italic_L end_ARG start_ARG ∂ italic_O start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT | italic_O start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT | end_POSTSUBSCRIPT end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) italic_M ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS3.p1.7">where <math alttext="M=(\hat{O^{l}}-O^{l})" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.7.m1.1"><semantics id="S3.SS1.SSS3.p1.7.m1.1a"><mrow id="S3.SS1.SSS3.p1.7.m1.1.1" xref="S3.SS1.SSS3.p1.7.m1.1.1.cmml"><mi id="S3.SS1.SSS3.p1.7.m1.1.1.3" xref="S3.SS1.SSS3.p1.7.m1.1.1.3.cmml">M</mi><mo id="S3.SS1.SSS3.p1.7.m1.1.1.2" xref="S3.SS1.SSS3.p1.7.m1.1.1.2.cmml">=</mo><mrow id="S3.SS1.SSS3.p1.7.m1.1.1.1.1" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.cmml"><mo id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.cmml"><mover accent="true" id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.cmml"><msup id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.2" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.2.cmml">O</mi><mi id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.3" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.3.cmml">l</mi></msup><mo id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.1" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.1" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.1.cmml">−</mo><msup id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.2" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.2.cmml">O</mi><mi id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.3" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.3.cmml">l</mi></msup></mrow><mo id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.7.m1.1b"><apply id="S3.SS1.SSS3.p1.7.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1"><eq id="S3.SS1.SSS3.p1.7.m1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.2"></eq><ci id="S3.SS1.SSS3.p1.7.m1.1.1.3.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.3">𝑀</ci><apply id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1"><minus id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.1"></minus><apply id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2"><ci id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.1">^</ci><apply id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.2">𝑂</ci><ci id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.2.2.3">𝑙</ci></apply></apply><apply id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.2">𝑂</ci><ci id="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.SSS3.p1.7.m1.1.1.1.1.1.3.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.7.m1.1c">M=(\hat{O^{l}}-O^{l})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.7.m1.1d">italic_M = ( over^ start_ARG italic_O start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_ARG - italic_O start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math> and the Kullback-Leible (KL) divergence of masks and IoUs are used for task loss.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<p class="ltx_p" id="S3.SS1.SSS3.p2.2">Different from taking quantization in an encoder-only manner used for Q-TinySAM, Lv et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib77" title=""><span class="ltx_text" style="font-size:90%;">77</span></a>]</cite> propose a novel framework that can directly take post-training quantization on SAM, namely PTQ4SAM. They start the work by first discovering the two challenges after traditional PTQ: 1) the existence of bimodal distribution which has negative effects on quantization quality and 2) the obvious discrepancy in the distribution of different attention mechanisms. Therefore, researchers bring up two strategies to solve them respectively: the Bimodal Integration (BIG) and the Adaptive Granularity Quantization (AGQ). For the Bimodal Integration, a sign factor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.1.m1.1"><semantics id="S3.SS1.SSS3.p2.1.m1.1a"><mi id="S3.SS1.SSS3.p2.1.m1.1.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.1.m1.1b"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.1.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.1.m1.1d">italic_γ</annotation></semantics></math> is introduced to convert the bimodal distribution into a normal distribution. For the Adaptive Granularity Quantization, the key is to adopt an adaptive parameter <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.2.m2.1"><semantics id="S3.SS1.SSS3.p2.2.m2.1a"><mi id="S3.SS1.SSS3.p2.2.m2.1.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.2.m2.1b"><ci id="S3.SS1.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.2.m2.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.2.m2.1d">italic_τ</annotation></semantics></math> to adjust the base in the Log2 quantizer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib81" title=""><span class="ltx_text" style="font-size:90%;">81</span></a>]</cite>. With the use of the AGQ strategy, the discrepancy between post-softmax distributions of different attention is expected to narrow down effectively. The PTQ4SAM is a plug-and-play SAM variant that can be easily deployed to downstream tasks.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4 </span>Pruning based Methods</h4>
<figure class="ltx_figure" id="S3.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="276" id="S3.F13.g1" src="x12.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F13.2.1.1" style="font-size:90%;">Figure 13</span>: </span><span class="ltx_text" id="S3.F13.3.2" style="font-size:90%;">The overall pipeline of the alternate slimming strategy for SlimSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>. It takes two steps to contract the heavy image encoder of SAM into a light-weight one: 1) Embedding pruning and bottleneck aligning; 2) Bottleneck pruning and embedding aligning.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS4.p1">
<p class="ltx_p" id="S3.SS1.SSS4.p1.1">Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> were the first to develop an effective pruning strategy for reducing the size and complexity of SAM, resulting in the model known as SlimSAM. As discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S2.SS3.SSS3" title="2.3.3 Pruning ‣ 2.3 Model Compression ‣ 2 Preliminaries ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2.3.3</span></a>, pruning algorithms aim to remove redundant parameters either structurally or individually. When applied to SAM’s heavy encoder, the initial step involves estimating the importance of weights and activation values to determine which should be pruned. The core idea behind assessing importance is to evaluate the discrepancy in loss generated with and without the given parameter.
SlimSAM introduces the Disturbed Taylor Importance method, which uses the first-order Taylor expansion to approximate the importance of parameters and introduces Gaussian Noise <math alttext="\mathcal{N}" class="ltx_Math" display="inline" id="S3.SS1.SSS4.p1.1.m1.1"><semantics id="S3.SS1.SSS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS4.p1.1.m1.1.1" xref="S3.SS1.SSS4.p1.1.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.1.m1.1b"><ci id="S3.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS4.p1.1.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.1.m1.1c">\mathcal{N}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS4.p1.1.m1.1d">caligraphic_N</annotation></semantics></math> to prevent gradients from becoming zero. This process is formulated as follows,</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS4.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx9">
<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle I_{w_{i}}" class="ltx_Math" display="inline" id="S3.Ex1.m1.1"><semantics id="S3.Ex1.m1.1a"><msub id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.2" xref="S3.Ex1.m1.1.1.2.cmml">I</mi><msub id="S3.Ex1.m1.1.1.3" xref="S3.Ex1.m1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.3.2" xref="S3.Ex1.m1.1.1.3.2.cmml">w</mi><mi id="S3.Ex1.m1.1.1.3.3" xref="S3.Ex1.m1.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.cmml" xref="S3.Ex1.m1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.2">𝐼</ci><apply id="S3.Ex1.m1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.3.2">𝑤</ci><ci id="S3.Ex1.m1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">\displaystyle I_{w_{i}}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.1d">italic_I start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx\left|\mathcal{L}_{w_{i}}(x_{i},t_{i}+\mathcal{N})-%
\mathcal{L}_{w_{i}=0}(x_{i},t_{i}+\mathcal{N})\right|" class="ltx_Math" display="inline" id="S3.Ex1.m2.1"><semantics id="S3.Ex1.m2.1a"><mrow id="S3.Ex1.m2.1.1" xref="S3.Ex1.m2.1.1.cmml"><mi id="S3.Ex1.m2.1.1.3" xref="S3.Ex1.m2.1.1.3.cmml"></mi><mo id="S3.Ex1.m2.1.1.2" xref="S3.Ex1.m2.1.1.2.cmml">≈</mo><mrow id="S3.Ex1.m2.1.1.1.1" xref="S3.Ex1.m2.1.1.1.2.cmml"><mo id="S3.Ex1.m2.1.1.1.1.2" xref="S3.Ex1.m2.1.1.1.2.1.cmml">|</mo><mrow id="S3.Ex1.m2.1.1.1.1.1" xref="S3.Ex1.m2.1.1.1.1.1.cmml"><mrow id="S3.Ex1.m2.1.1.1.1.1.2" xref="S3.Ex1.m2.1.1.1.1.1.2.cmml"><msub id="S3.Ex1.m2.1.1.1.1.1.2.4" xref="S3.Ex1.m2.1.1.1.1.1.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m2.1.1.1.1.1.2.4.2" xref="S3.Ex1.m2.1.1.1.1.1.2.4.2.cmml">ℒ</mi><msub id="S3.Ex1.m2.1.1.1.1.1.2.4.3" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3.cmml"><mi id="S3.Ex1.m2.1.1.1.1.1.2.4.3.2" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3.2.cmml">w</mi><mi id="S3.Ex1.m2.1.1.1.1.1.2.4.3.3" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3.3.cmml">i</mi></msub></msub><mo id="S3.Ex1.m2.1.1.1.1.1.2.3" xref="S3.Ex1.m2.1.1.1.1.1.2.3.cmml">⁢</mo><mrow id="S3.Ex1.m2.1.1.1.1.1.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.2.2.3.cmml"><mo id="S3.Ex1.m2.1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.Ex1.m2.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.Ex1.m2.1.1.1.1.1.2.2.2.4" xref="S3.Ex1.m2.1.1.1.1.1.2.2.3.cmml">,</mo><mrow id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.cmml"><msub id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.2.cmml">t</mi><mi id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.3" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.1" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.1.cmml">+</mo><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.3" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.3.cmml">𝒩</mi></mrow><mo id="S3.Ex1.m2.1.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.Ex1.m2.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m2.1.1.1.1.1.5" xref="S3.Ex1.m2.1.1.1.1.1.5.cmml">−</mo><mrow id="S3.Ex1.m2.1.1.1.1.1.4" xref="S3.Ex1.m2.1.1.1.1.1.4.cmml"><msub id="S3.Ex1.m2.1.1.1.1.1.4.4" xref="S3.Ex1.m2.1.1.1.1.1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m2.1.1.1.1.1.4.4.2" xref="S3.Ex1.m2.1.1.1.1.1.4.4.2.cmml">ℒ</mi><mrow id="S3.Ex1.m2.1.1.1.1.1.4.4.3" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.cmml"><msub id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.cmml"><mi id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.2" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.2.cmml">w</mi><mi id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.3" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.3.cmml">i</mi></msub><mo id="S3.Ex1.m2.1.1.1.1.1.4.4.3.1" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.1.cmml">=</mo><mn id="S3.Ex1.m2.1.1.1.1.1.4.4.3.3" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.3.cmml">0</mn></mrow></msub><mo id="S3.Ex1.m2.1.1.1.1.1.4.3" xref="S3.Ex1.m2.1.1.1.1.1.4.3.cmml">⁢</mo><mrow id="S3.Ex1.m2.1.1.1.1.1.4.2.2" xref="S3.Ex1.m2.1.1.1.1.1.4.2.3.cmml"><mo id="S3.Ex1.m2.1.1.1.1.1.4.2.2.3" stretchy="false" xref="S3.Ex1.m2.1.1.1.1.1.4.2.3.cmml">(</mo><msub id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.cmml"><mi id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.2" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.2.cmml">x</mi><mi id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.3" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.Ex1.m2.1.1.1.1.1.4.2.2.4" xref="S3.Ex1.m2.1.1.1.1.1.4.2.3.cmml">,</mo><mrow id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.cmml"><msub id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.cmml"><mi id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.2" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.2.cmml">t</mi><mi id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.3" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.1" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.1.cmml">+</mo><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.3" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.3.cmml">𝒩</mi></mrow><mo id="S3.Ex1.m2.1.1.1.1.1.4.2.2.5" stretchy="false" xref="S3.Ex1.m2.1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.Ex1.m2.1.1.1.1.3" xref="S3.Ex1.m2.1.1.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m2.1b"><apply id="S3.Ex1.m2.1.1.cmml" xref="S3.Ex1.m2.1.1"><approx id="S3.Ex1.m2.1.1.2.cmml" xref="S3.Ex1.m2.1.1.2"></approx><csymbol cd="latexml" id="S3.Ex1.m2.1.1.3.cmml" xref="S3.Ex1.m2.1.1.3">absent</csymbol><apply id="S3.Ex1.m2.1.1.1.2.cmml" xref="S3.Ex1.m2.1.1.1.1"><abs id="S3.Ex1.m2.1.1.1.2.1.cmml" xref="S3.Ex1.m2.1.1.1.1.2"></abs><apply id="S3.Ex1.m2.1.1.1.1.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1"><minus id="S3.Ex1.m2.1.1.1.1.1.5.cmml" xref="S3.Ex1.m2.1.1.1.1.1.5"></minus><apply id="S3.Ex1.m2.1.1.1.1.1.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2"><times id="S3.Ex1.m2.1.1.1.1.1.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.3"></times><apply id="S3.Ex1.m2.1.1.1.1.1.2.4.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.2.4.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.2.4.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4.2">ℒ</ci><apply id="S3.Ex1.m2.1.1.1.1.1.2.4.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.2.4.3.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.2.4.3.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3.2">𝑤</ci><ci id="S3.Ex1.m2.1.1.1.1.1.2.4.3.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.4.3.3">𝑖</ci></apply></apply><interval closure="open" id="S3.Ex1.m2.1.1.1.1.1.2.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2"><apply id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2"><plus id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.1"></plus><apply id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.2">𝑡</ci><ci id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.2.3">𝑖</ci></apply><ci id="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.2.2.2.2.3">𝒩</ci></apply></interval></apply><apply id="S3.Ex1.m2.1.1.1.1.1.4.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4"><times id="S3.Ex1.m2.1.1.1.1.1.4.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.3"></times><apply id="S3.Ex1.m2.1.1.1.1.1.4.4.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.4.4.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.4.4.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.2">ℒ</ci><apply id="S3.Ex1.m2.1.1.1.1.1.4.4.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3"><eq id="S3.Ex1.m2.1.1.1.1.1.4.4.3.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.1"></eq><apply id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.2">𝑤</ci><ci id="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.2.3">𝑖</ci></apply><cn id="S3.Ex1.m2.1.1.1.1.1.4.4.3.3.cmml" type="integer" xref="S3.Ex1.m2.1.1.1.1.1.4.4.3.3">0</cn></apply></apply><interval closure="open" id="S3.Ex1.m2.1.1.1.1.1.4.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2"><apply id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.2">𝑥</ci><ci id="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.3.1.1.1.3">𝑖</ci></apply><apply id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2"><plus id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.1"></plus><apply id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.1.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.2.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.2">𝑡</ci><ci id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.2.3">𝑖</ci></apply><ci id="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.3.cmml" xref="S3.Ex1.m2.1.1.1.1.1.4.2.2.2.3">𝒩</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m2.1c">\displaystyle\approx\left|\mathcal{L}_{w_{i}}(x_{i},t_{i}+\mathcal{N})-%
\mathcal{L}_{w_{i}=0}(x_{i},t_{i}+\mathcal{N})\right|</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m2.1d">≈ | caligraphic_L start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + caligraphic_N ) - caligraphic_L start_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + caligraphic_N ) |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S3.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\approx\left|\frac{\partial\mathcal{L}(x_{i},t_{i}+\mathcal{N})}{%
\partial w_{i}}w_{i}\right|" class="ltx_Math" display="inline" id="S3.E9.m1.3"><semantics id="S3.E9.m1.3a"><mrow id="S3.E9.m1.3.3" xref="S3.E9.m1.3.3.cmml"><mi id="S3.E9.m1.3.3.3" xref="S3.E9.m1.3.3.3.cmml"></mi><mo id="S3.E9.m1.3.3.2" xref="S3.E9.m1.3.3.2.cmml">≈</mo><mrow id="S3.E9.m1.3.3.1.1" xref="S3.E9.m1.3.3.1.2.cmml"><mo id="S3.E9.m1.3.3.1.1.2" xref="S3.E9.m1.3.3.1.2.1.cmml">|</mo><mrow id="S3.E9.m1.3.3.1.1.1" xref="S3.E9.m1.3.3.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E9.m1.2.2" xref="S3.E9.m1.2.2.cmml"><mfrac id="S3.E9.m1.2.2a" xref="S3.E9.m1.2.2.cmml"><mrow id="S3.E9.m1.2.2.2" xref="S3.E9.m1.2.2.2.cmml"><mo id="S3.E9.m1.2.2.2.3" rspace="0em" xref="S3.E9.m1.2.2.2.3.cmml">∂</mo><mrow id="S3.E9.m1.2.2.2.2" xref="S3.E9.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.2.2.2.2.4" xref="S3.E9.m1.2.2.2.2.4.cmml">ℒ</mi><mo id="S3.E9.m1.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.3.cmml">⁢</mo><mrow id="S3.E9.m1.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.3.cmml"><mo id="S3.E9.m1.2.2.2.2.2.2.3" stretchy="false" xref="S3.E9.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E9.m1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E9.m1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E9.m1.2.2.2.2.2.2.4" xref="S3.E9.m1.2.2.2.2.2.3.cmml">,</mo><mrow id="S3.E9.m1.2.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.2.2.cmml"><msub id="S3.E9.m1.2.2.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E9.m1.2.2.2.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E9.m1.2.2.2.2.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.E9.m1.2.2.2.2.2.2.2.1" xref="S3.E9.m1.2.2.2.2.2.2.2.1.cmml">+</mo><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.2.2.2.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.2.2.2.3.cmml">𝒩</mi></mrow><mo id="S3.E9.m1.2.2.2.2.2.2.5" stretchy="false" xref="S3.E9.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E9.m1.2.2.4" xref="S3.E9.m1.2.2.4.cmml"><mo id="S3.E9.m1.2.2.4.1" rspace="0em" xref="S3.E9.m1.2.2.4.1.cmml">∂</mo><msub id="S3.E9.m1.2.2.4.2" xref="S3.E9.m1.2.2.4.2.cmml"><mi id="S3.E9.m1.2.2.4.2.2" xref="S3.E9.m1.2.2.4.2.2.cmml">w</mi><mi id="S3.E9.m1.2.2.4.2.3" xref="S3.E9.m1.2.2.4.2.3.cmml">i</mi></msub></mrow></mfrac></mstyle><mo id="S3.E9.m1.3.3.1.1.1.1" xref="S3.E9.m1.3.3.1.1.1.1.cmml">⁢</mo><msub id="S3.E9.m1.3.3.1.1.1.2" xref="S3.E9.m1.3.3.1.1.1.2.cmml"><mi id="S3.E9.m1.3.3.1.1.1.2.2" xref="S3.E9.m1.3.3.1.1.1.2.2.cmml">w</mi><mi id="S3.E9.m1.3.3.1.1.1.2.3" xref="S3.E9.m1.3.3.1.1.1.2.3.cmml">i</mi></msub></mrow><mo id="S3.E9.m1.3.3.1.1.3" xref="S3.E9.m1.3.3.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.3b"><apply id="S3.E9.m1.3.3.cmml" xref="S3.E9.m1.3.3"><approx id="S3.E9.m1.3.3.2.cmml" xref="S3.E9.m1.3.3.2"></approx><csymbol cd="latexml" id="S3.E9.m1.3.3.3.cmml" xref="S3.E9.m1.3.3.3">absent</csymbol><apply id="S3.E9.m1.3.3.1.2.cmml" xref="S3.E9.m1.3.3.1.1"><abs id="S3.E9.m1.3.3.1.2.1.cmml" xref="S3.E9.m1.3.3.1.1.2"></abs><apply id="S3.E9.m1.3.3.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1"><times id="S3.E9.m1.3.3.1.1.1.1.cmml" xref="S3.E9.m1.3.3.1.1.1.1"></times><apply id="S3.E9.m1.2.2.cmml" xref="S3.E9.m1.2.2"><divide id="S3.E9.m1.2.2.3.cmml" xref="S3.E9.m1.2.2"></divide><apply id="S3.E9.m1.2.2.2.cmml" xref="S3.E9.m1.2.2.2"><partialdiff id="S3.E9.m1.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.3"></partialdiff><apply id="S3.E9.m1.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2"><times id="S3.E9.m1.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.3"></times><ci id="S3.E9.m1.2.2.2.2.4.cmml" xref="S3.E9.m1.2.2.2.2.4">ℒ</ci><interval closure="open" id="S3.E9.m1.2.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.2.2"><apply id="S3.E9.m1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E9.m1.2.2.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2"><plus id="S3.E9.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2.1"></plus><apply id="S3.E9.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E9.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2.2.2">𝑡</ci><ci id="S3.E9.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply><ci id="S3.E9.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2.3">𝒩</ci></apply></interval></apply></apply><apply id="S3.E9.m1.2.2.4.cmml" xref="S3.E9.m1.2.2.4"><partialdiff id="S3.E9.m1.2.2.4.1.cmml" xref="S3.E9.m1.2.2.4.1"></partialdiff><apply id="S3.E9.m1.2.2.4.2.cmml" xref="S3.E9.m1.2.2.4.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.4.2.1.cmml" xref="S3.E9.m1.2.2.4.2">subscript</csymbol><ci id="S3.E9.m1.2.2.4.2.2.cmml" xref="S3.E9.m1.2.2.4.2.2">𝑤</ci><ci id="S3.E9.m1.2.2.4.2.3.cmml" xref="S3.E9.m1.2.2.4.2.3">𝑖</ci></apply></apply></apply><apply id="S3.E9.m1.3.3.1.1.1.2.cmml" xref="S3.E9.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.3.3.1.1.1.2.1.cmml" xref="S3.E9.m1.3.3.1.1.1.2">subscript</csymbol><ci id="S3.E9.m1.3.3.1.1.1.2.2.cmml" xref="S3.E9.m1.3.3.1.1.1.2.2">𝑤</ci><ci id="S3.E9.m1.3.3.1.1.1.2.3.cmml" xref="S3.E9.m1.3.3.1.1.1.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.3c">\displaystyle\approx\left|\frac{\partial\mathcal{L}(x_{i},t_{i}+\mathcal{N})}{%
\partial w_{i}}w_{i}\right|</annotation><annotation encoding="application/x-llamapun" id="S3.E9.m1.3d">≈ | divide start_ARG ∂ caligraphic_L ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + caligraphic_N ) end_ARG start_ARG ∂ italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS4.p2.1">Once the importance of parameters is estimated, a strategy called Alternate Slimming is employed to perform structural pruning and post-alignment. The ViT-based encoder is first divided into two substructures: the embedding layer and the bottleneck layer. The strategy alternates between pruning the embedding/bottleneck layers to reduce model size and aligning the bottleneck/embedding layers to maintain model quality, ensuring both efficiency and performance. The workflow for this process is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F13" title="Figure 13 ‣ 3.1.4 Pruning based Methods ‣ 3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.5 </span>Code Refactorization</h4>
<div class="ltx_para" id="S3.SS1.SSS5.p1">
<p class="ltx_p" id="S3.SS1.SSS5.p1.1">The Segment Anything Fast model (SAMfast), developed by the PyTorch team <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib88" title=""><span class="ltx_text" style="font-size:90%;">88</span></a>]</cite>, is a rewritten version of SAM that leverages pure, native PyTorch optimizations. SAMfast is reported to be 8x faster than the original implementation while maintaining nearly the same accuracy. This improvement is the result of a systematic process of identifying bottlenecks and applying targeted optimizations.
Initially, the team identified long function calls that caused synchronous blocking, leading them to rewrite the corresponding code. Another significant bottleneck was the time-consuming matrix multiplication, which was mitigated by using bfloat16 precision. Following these adjustments, the team utilized torch.compile to fuse smaller operations and adopted PyTorch’s scaled_dot_product_attention (SDPA) to accelerate attention computations on the GPU. Additionally, by integrating the new kernel built with Triton, memory usage on the GPU was further reduced.
When SAM uses the batch prediction method, input tensors of varying sizes are unified into NestedTensors, which significantly improve throughput. Despite these optimizations, matrix multiplications remained a key bottleneck. To address this, the team implemented int8 quantization and approximated matrix multiplication using semi-structured sparsity.
For more details on the step-by-step optimization process, it is recommended to go through the official blog for more details.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Accelerating SegEvery Tasks</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">As described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.SS1" title="3.1 Accelerating SegAny Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a>, the primary efficiency bottleneck for the SegAny task lies in the heavy image encoder. Any SAM variant with a more lightweight architecture will inherently be able to segment everything faster than the original SAM. However, as analyzed by Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib148" title=""><span class="ltx_text" style="font-size:90%;">148</span></a>]</cite>, the main challenge of the SegEvery task stems from the dense grid sampling strategy. This strategy first predicts numerous masks based on a point grid and then selects valid masks, which is computationally expensive. Consequently, designing a more efficient sampling strategy to reduce the number of predicted masks has become the core approach to accelerating the SegEvery task.
Another potential solution is to convert the SegEvery task into another well-established task, such as all-instance segmentation, as done in FastSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>]</cite>. In this part, we will review works that have specifically proposed optimized sampling strategies to accelerate the SegEvery task.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Building on the structure of SAM, Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib148" title=""><span class="ltx_text" style="font-size:90%;">148</span></a>]</cite> introduced an object-aware prompt sampling strategy to enhance the efficiency of the SegEvery task. This project, named MobileSAMv2, operates independently of their previous work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib147" title=""><span class="ltx_text" style="font-size:90%;">147</span></a>]</cite> focused on accelerating the SegAny task. In MobileSAMv2, the researchers employ the YOLOv8 model, trained on a small subset of SA-1B, for object discovery. This model generates a large number of bounding boxes corresponding to latent objects. Highly overlapping boxes are filtered using Non-Maximum Suppression (NMS), and the remaining boxes are used as box prompts.
By using these filtered boxes as prompts, MobileSAMv2 eliminates the need to filter predicted masks—a much more time-consuming process. With the maximum number of prompts set to 320, the new strategy is reported to be 16 times faster than the traditional 32*32 grid sampling strategy. Additionally, MobileSAMv2 can be integrated with MobileSAM to create a unified model that achieves high efficiency in both SegAny and SegEvery tasks.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Shu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite> observed that using a dense points grid (e.g., 32*32, 64*64) often generates a large number of redundant masks, which are later filtered out during post-processing, an operation that incurs significant time costs. In reality, only a few points within the grid are necessary to produce confident masks. To address this inefficiency, they proposed a hierarchical strategy for efficient sampling, which progressively selects optimal points for mask generation.
This strategy involves two rounds of prompt generation. In the first round, a sparse grid is used, incorporating only a fraction (approximately 1/4) of the default points along each side. Masks are generated based on these points, and after filtering, only high-confidence masks are retained as final predictions. In the second round, a denser grid is applied, following the default configuration. However, points located in regions already covered by confident masks are excluded, significantly reducing the number of points. The predicted results from both rounds are then fused to produce the final output.
The pipeline for this hierarchical strategy is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F14" title="Figure 14 ‣ 3.2 Accelerating SegEvery Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">14</span></a>. By employing this two-round approach, the sampling process becomes both more time-efficient and fine-grained, leading to a notable acceleration in the SegEvery task with minimal performance degradation.</p>
</div>
<figure class="ltx_figure" id="S3.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="342" id="S3.F14.g1" src="x13.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F14.2.1.1" style="font-size:90%;">Figure 14</span>: </span><span class="ltx_text" id="S3.F14.3.2" style="font-size:90%;">Comparison between the default sampling strategy (a-b) for SAM and the hierarchical sampling strategy (c-e) for TinySAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib103" title=""><span class="ltx_text" style="font-size:90%;">103</span></a>]</cite>. The hierarchical strategy contains two rounds of sampling: one round for sparse sampling (c) and the other round for dense sampling (d). The final prediction comes from the fusion of results in two rounds.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Different from all aforementioned works, Fu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite> propose an end-to-end training pipeline specifically designed for the SegEvery task, aiming to develop a SAM variant capable of segmenting everything more efficiently. Their model, named Lite-SAM, retains the overall architecture of the original SAM but replaces the heavy image encoder with a more lightweight solution. The architecture overview of Lite-SAM is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S3.F15" title="Figure 15 ‣ 3.2 Accelerating SegEvery Tasks ‣ 3 Efficient Variants of SAM ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">15</span></a>.
Lite-SAM employs a CNN-Transformer hybrid structure called Lite-ViT, which consists of four stages with 2, 2, 6, and 2 Lite-ViT blocks, respectively. The key innovation in Lite-ViT is the Multi-Scale Pooling Module (MSPM), which serves as an alternative to the traditional attention mechanism. Adapted from the PoolFormer block <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib142" title=""><span class="ltx_text" style="font-size:90%;">142</span></a>]</cite>, MSPM utilizes channel-wise LayerNorm and extends the pooling operation to multiple scales.
As discussed earlier, another major bottleneck in SAM lies in the time-consuming grid sampling strategy. To address this, Lite-SAM introduces an Automated Prompt Proposal Network (AutoPPN) to improve sampling efficiency. AutoPPN takes the feature maps generated by the encoder as input and directly predicts point and box prompts. To ensure high-quality prompts, Lite-SAM uses a more powerful MSPM-based network instead of CNNs, and incorporates distance transform to estimate the confidence of point prompts.
While Lite-SAM is primarily designed to accelerate the SegEvery task, it also demonstrates improved efficiency in the SegAny task due to its lightweight image encoder.</p>
</div>
<figure class="ltx_figure" id="S3.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="203" id="S3.F15.g1" src="x14.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F15.2.1.1" style="font-size:90%;">Figure 15</span>: </span><span class="ltx_text" id="S3.F15.3.2" style="font-size:90%;">The architecture of Lite-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>. It takes the Lite-ViT as an image encoder and proposes an automated prompt proposal network (AutoPPN) for efficient sampling, while the prompt encoder and the mask decoder are copied from the original SAM.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Future Research Directions</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Through this comprehensive review of efficient SAM variants, we have outlined the current advancements in accelerating SAM. However, there remain opportunities for further exploration and innovation. Below, we present several potential future research directions, offering preliminary insights with the hope of inspiring readers to contribute to the ongoing development in this field.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Exploring Advanced Architectures.</span>
While current SAM variants have demonstrated efficiency gains through the adoption of efficient architectures and model compression techniques, there is substantial potential for further improvement. The exploration of Transformer-alternative models, such as Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite>, RetNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib105" title=""><span class="ltx_text" style="font-size:90%;">105</span></a>]</cite>, KAN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib74" title=""><span class="ltx_text" style="font-size:90%;">74</span></a>]</cite>, and TTT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib106" title=""><span class="ltx_text" style="font-size:90%;">106</span></a>]</cite>, presents an exciting opportunity to design more lightweight and efficient structures. These models may offer advantages in computational efficiency without sacrificing segmentation accuracy. In addition to alternative models, refining the efficiency of the attention mechanism across both the image encoder and mask decoder remains critical. Methods such as linear attention, low-rank factorization, or hybrid architectures combining convolutional and attention-based designs should be further investigated. Addressing bottlenecks in both computation and memory usage will enhance SAM’s deployment across diverse hardware environments.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Exploiting Sparsity and Acceleration Techniques.</span>
The inherent sparsity observed in deep neural networks, where only a subset of parameters significantly contributes to model output, offers a promising avenue for improving SAM’s efficiency. Techniques like pruning, quantization, and structured sparsity could further reduce SAM’s computational demands. While initial efforts in sparsification, such as those in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, have shown success, future research could focus on understanding the distribution and dynamics of sparsity in SAM’s architecture. This includes investigating the optimal layers or components of SAM that can be pruned or sparsified without impacting performance. Additionally, techniques such as sparse attention mechanisms, dynamic pruning during inference, and low-precision training should be explored to balance accuracy and efficiency, especially for large-scale deployments. By combining these with advanced knowledge distillation techniques, more compact, efficient variants of SAM could be realized.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1">Hardware-Specific Optimizations.</span> Optimizing SAM for specific hardware platforms, including GPUs, TPUs, specialized AI accelerators (e.g., NVIDIA’s TensorRT or Google’s Edge TPU), and edge devices, can unlock significant gains in performance and efficiency. Hardware-aware model optimization techniques, such as operator fusion, quantization-aware training, and custom CUDA kernels, can maximize throughput and reduce latency when deploying SAM on modern hardware platforms. In the context of edge devices, which face extreme constraints in storage, computational power, and energy supply, these optimizations are crucial for real-time applications, such as segmentation on UAVs or IoT devices. Future research could explore hierarchical cloud-edge architectures to offload computationally expensive tasks to the cloud, while running lightweight models locally on edge devices. Additionally, leveraging specialized AI hardware like Field-Programmable Gate Arrays (FPGAs) or using techniques such as hardware-aware neural architecture search (NAS) and mixed-precision quantization could further optimize SAM for low-latency, resource-constrained environments, ensuring that the model operates effectively across diverse hardware platforms.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1">Efficient Segmentation for Video and Multi-Modality Data.</span>
Video and multi-modality tasks, which deal with complex, dynamic environments, are rapidly gaining relevance across numerous real-world applications. While some initial efforts, such as SAM 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib93" title=""><span class="ltx_text" style="font-size:90%;">93</span></a>]</cite> for video segmentation and MM-SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib128" title=""><span class="ltx_text" style="font-size:90%;">128</span></a>]</cite> for multi-modality tasks, have extended SAM’s applicability, efficiency remains a pressing issue. Video data contains temporal redundancy, while multimodal data often exhibits correlations between modalities. Leveraging these inherent redundancies through techniques like temporal aggregation and cross-modal feature sharing could significantly reduce computational costs. Future work could focus on optimizing SAM’s runtime complexity by utilizing spatiotemporal attention, efficient memory mechanisms for temporal data, and early-fusion techniques to reduce the number of modality-specific computations. Developing frameworks that adapt dynamically to different levels of redundancy across frames or modalities can further drive computational efficiency in real-world applications.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we systematically compare the efficiency and accuracy of the previously described SAM variants. With reference to the experiments conducted in these works, we choose the tasks that most of the works have carried out and evaluate them on their commonly used datasets with corresponding metrics. Our evaluations are conducted on a single <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">24GB RTX 3090 GPU</span> with a 14 vCPU <span class="ltx_text ltx_font_italic" id="S4.p1.1.2">Intel(R) Xeon(R) Gold 6330 Processor @ 2.00GHz</span>. More details are provided in the following subsections: Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS1" title="4.1 Datasets and Metrics ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4.1</span></a> introduces the datasets and metrics used for evaluation; Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS2" title="4.2 Efficiency Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4.2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS3" title="4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a> report the quantitative results of efficiency and accuracy, respectively.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and Metrics</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.5">We select COCO 2017 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib65" title=""><span class="ltx_text" style="font-size:90%;">65</span></a>]</cite> and LVIS v1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite> as the evaluation datasets. COCO is a large-scale dataset designed for object detection, segmentation, and captioning, containing 330K images and 1.5 million object instances across 80 object categories. LVIS is tailored for large vocabulary instance segmentation, featuring over 2 million high-quality segmentation masks across more than 1200 categories in 164K images. For our evaluation, we use the validation sets of both datasets, which include 36,781 instances in 5,000 images for COCO and 244,707 instances in 19,809 images for LVIS.
To evaluate efficiency, we first test several soft indicators like <math alttext="\#Params" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" mathvariant="normal" xref="S4.SS1.p1.1.m1.1.1.2.cmml">#</mi><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">P</mi><mo id="S4.SS1.p1.1.m1.1.1.1a" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.4" xref="S4.SS1.p1.1.m1.1.1.4.cmml">a</mi><mo id="S4.SS1.p1.1.m1.1.1.1b" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.5" xref="S4.SS1.p1.1.m1.1.1.5.cmml">r</mi><mo id="S4.SS1.p1.1.m1.1.1.1c" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.6" xref="S4.SS1.p1.1.m1.1.1.6.cmml">a</mi><mo id="S4.SS1.p1.1.m1.1.1.1d" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.7" xref="S4.SS1.p1.1.m1.1.1.7.cmml">m</mi><mo id="S4.SS1.p1.1.m1.1.1.1e" xref="S4.SS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.8" xref="S4.SS1.p1.1.m1.1.1.8.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">#</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">𝑃</ci><ci id="S4.SS1.p1.1.m1.1.1.4.cmml" xref="S4.SS1.p1.1.m1.1.1.4">𝑎</ci><ci id="S4.SS1.p1.1.m1.1.1.5.cmml" xref="S4.SS1.p1.1.m1.1.1.5">𝑟</ci><ci id="S4.SS1.p1.1.m1.1.1.6.cmml" xref="S4.SS1.p1.1.m1.1.1.6">𝑎</ci><ci id="S4.SS1.p1.1.m1.1.1.7.cmml" xref="S4.SS1.p1.1.m1.1.1.7">𝑚</ci><ci id="S4.SS1.p1.1.m1.1.1.8.cmml" xref="S4.SS1.p1.1.m1.1.1.8">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\#Params</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d"># italic_P italic_a italic_r italic_a italic_m italic_s</annotation></semantics></math>, <math alttext="FLOPs" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">F</mi><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">L</mi><mo id="S4.SS1.p1.2.m2.1.1.1a" xref="S4.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.4" xref="S4.SS1.p1.2.m2.1.1.4.cmml">O</mi><mo id="S4.SS1.p1.2.m2.1.1.1b" xref="S4.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.5" xref="S4.SS1.p1.2.m2.1.1.5.cmml">P</mi><mo id="S4.SS1.p1.2.m2.1.1.1c" xref="S4.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.6" xref="S4.SS1.p1.2.m2.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></times><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝐹</ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">𝐿</ci><ci id="S4.SS1.p1.2.m2.1.1.4.cmml" xref="S4.SS1.p1.2.m2.1.1.4">𝑂</ci><ci id="S4.SS1.p1.2.m2.1.1.5.cmml" xref="S4.SS1.p1.2.m2.1.1.5">𝑃</ci><ci id="S4.SS1.p1.2.m2.1.1.6.cmml" xref="S4.SS1.p1.2.m2.1.1.6">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">FLOPs</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_F italic_L italic_O italic_P italic_s</annotation></semantics></math>, <math alttext="MACs" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">M</mi><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">A</mi><mo id="S4.SS1.p1.3.m3.1.1.1a" xref="S4.SS1.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.4" xref="S4.SS1.p1.3.m3.1.1.4.cmml">C</mi><mo id="S4.SS1.p1.3.m3.1.1.1b" xref="S4.SS1.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.3.m3.1.1.5" xref="S4.SS1.p1.3.m3.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><times id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></times><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝑀</ci><ci id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">𝐴</ci><ci id="S4.SS1.p1.3.m3.1.1.4.cmml" xref="S4.SS1.p1.3.m3.1.1.4">𝐶</ci><ci id="S4.SS1.p1.3.m3.1.1.5.cmml" xref="S4.SS1.p1.3.m3.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">MACs</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_M italic_A italic_C italic_s</annotation></semantics></math>, and <math alttext="Memory\ Usage" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">M</mi><mo id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">e</mi><mo id="S4.SS1.p1.4.m4.1.1.1a" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.4" xref="S4.SS1.p1.4.m4.1.1.4.cmml">m</mi><mo id="S4.SS1.p1.4.m4.1.1.1b" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.5" xref="S4.SS1.p1.4.m4.1.1.5.cmml">o</mi><mo id="S4.SS1.p1.4.m4.1.1.1c" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.6" xref="S4.SS1.p1.4.m4.1.1.6.cmml">r</mi><mo id="S4.SS1.p1.4.m4.1.1.1d" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.7" xref="S4.SS1.p1.4.m4.1.1.7.cmml">y</mi><mo id="S4.SS1.p1.4.m4.1.1.1e" lspace="0.500em" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.8" xref="S4.SS1.p1.4.m4.1.1.8.cmml">U</mi><mo id="S4.SS1.p1.4.m4.1.1.1f" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.9" xref="S4.SS1.p1.4.m4.1.1.9.cmml">s</mi><mo id="S4.SS1.p1.4.m4.1.1.1g" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.10" xref="S4.SS1.p1.4.m4.1.1.10.cmml">a</mi><mo id="S4.SS1.p1.4.m4.1.1.1h" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.11" xref="S4.SS1.p1.4.m4.1.1.11.cmml">g</mi><mo id="S4.SS1.p1.4.m4.1.1.1i" xref="S4.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.4.m4.1.1.12" xref="S4.SS1.p1.4.m4.1.1.12.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><times id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"></times><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝑀</ci><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">𝑒</ci><ci id="S4.SS1.p1.4.m4.1.1.4.cmml" xref="S4.SS1.p1.4.m4.1.1.4">𝑚</ci><ci id="S4.SS1.p1.4.m4.1.1.5.cmml" xref="S4.SS1.p1.4.m4.1.1.5">𝑜</ci><ci id="S4.SS1.p1.4.m4.1.1.6.cmml" xref="S4.SS1.p1.4.m4.1.1.6">𝑟</ci><ci id="S4.SS1.p1.4.m4.1.1.7.cmml" xref="S4.SS1.p1.4.m4.1.1.7">𝑦</ci><ci id="S4.SS1.p1.4.m4.1.1.8.cmml" xref="S4.SS1.p1.4.m4.1.1.8">𝑈</ci><ci id="S4.SS1.p1.4.m4.1.1.9.cmml" xref="S4.SS1.p1.4.m4.1.1.9">𝑠</ci><ci id="S4.SS1.p1.4.m4.1.1.10.cmml" xref="S4.SS1.p1.4.m4.1.1.10">𝑎</ci><ci id="S4.SS1.p1.4.m4.1.1.11.cmml" xref="S4.SS1.p1.4.m4.1.1.11">𝑔</ci><ci id="S4.SS1.p1.4.m4.1.1.12.cmml" xref="S4.SS1.p1.4.m4.1.1.12">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">Memory\ Usage</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_M italic_e italic_m italic_o italic_r italic_y italic_U italic_s italic_a italic_g italic_e</annotation></semantics></math>. And we further calculate the Efficient Error Rate (<math alttext="EER" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">E</mi><mo id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">E</mi><mo id="S4.SS1.p1.5.m5.1.1.1a" xref="S4.SS1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.5.m5.1.1.4" xref="S4.SS1.p1.5.m5.1.1.4.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><times id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1"></times><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">𝐸</ci><ci id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3">𝐸</ci><ci id="S4.SS1.p1.5.m5.1.1.4.cmml" xref="S4.SS1.p1.5.m5.1.1.4">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">EER</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_E italic_E italic_R</annotation></semantics></math>) a more comprehensive evaluation, as outlined in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib86" title=""><span class="ltx_text" style="font-size:90%;">86</span></a>]</cite>. EER is defined as,</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx10">
<tbody id="S4.E10"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle EER=\frac{1}{N}\sum_{i=1}^{N}(\frac{M_{i}}{R_{i}})" class="ltx_Math" display="inline" id="S4.E10.m1.1"><semantics id="S4.E10.m1.1a"><mrow id="S4.E10.m1.1.2" xref="S4.E10.m1.1.2.cmml"><mrow id="S4.E10.m1.1.2.2" xref="S4.E10.m1.1.2.2.cmml"><mi id="S4.E10.m1.1.2.2.2" xref="S4.E10.m1.1.2.2.2.cmml">E</mi><mo id="S4.E10.m1.1.2.2.1" xref="S4.E10.m1.1.2.2.1.cmml">⁢</mo><mi id="S4.E10.m1.1.2.2.3" xref="S4.E10.m1.1.2.2.3.cmml">E</mi><mo id="S4.E10.m1.1.2.2.1a" xref="S4.E10.m1.1.2.2.1.cmml">⁢</mo><mi id="S4.E10.m1.1.2.2.4" xref="S4.E10.m1.1.2.2.4.cmml">R</mi></mrow><mo id="S4.E10.m1.1.2.1" xref="S4.E10.m1.1.2.1.cmml">=</mo><mrow id="S4.E10.m1.1.2.3" xref="S4.E10.m1.1.2.3.cmml"><mstyle displaystyle="true" id="S4.E10.m1.1.2.3.2" xref="S4.E10.m1.1.2.3.2.cmml"><mfrac id="S4.E10.m1.1.2.3.2a" xref="S4.E10.m1.1.2.3.2.cmml"><mn id="S4.E10.m1.1.2.3.2.2" xref="S4.E10.m1.1.2.3.2.2.cmml">1</mn><mi id="S4.E10.m1.1.2.3.2.3" xref="S4.E10.m1.1.2.3.2.3.cmml">N</mi></mfrac></mstyle><mo id="S4.E10.m1.1.2.3.1" xref="S4.E10.m1.1.2.3.1.cmml">⁢</mo><mrow id="S4.E10.m1.1.2.3.3" xref="S4.E10.m1.1.2.3.3.cmml"><mstyle displaystyle="true" id="S4.E10.m1.1.2.3.3.1" xref="S4.E10.m1.1.2.3.3.1.cmml"><munderover id="S4.E10.m1.1.2.3.3.1a" xref="S4.E10.m1.1.2.3.3.1.cmml"><mo id="S4.E10.m1.1.2.3.3.1.2.2" movablelimits="false" xref="S4.E10.m1.1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S4.E10.m1.1.2.3.3.1.2.3" xref="S4.E10.m1.1.2.3.3.1.2.3.cmml"><mi id="S4.E10.m1.1.2.3.3.1.2.3.2" xref="S4.E10.m1.1.2.3.3.1.2.3.2.cmml">i</mi><mo id="S4.E10.m1.1.2.3.3.1.2.3.1" xref="S4.E10.m1.1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S4.E10.m1.1.2.3.3.1.2.3.3" xref="S4.E10.m1.1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E10.m1.1.2.3.3.1.3" xref="S4.E10.m1.1.2.3.3.1.3.cmml">N</mi></munderover></mstyle><mrow id="S4.E10.m1.1.2.3.3.2.2" xref="S4.E10.m1.1.1.cmml"><mo id="S4.E10.m1.1.2.3.3.2.2.1" stretchy="false" xref="S4.E10.m1.1.1.cmml">(</mo><mstyle displaystyle="true" id="S4.E10.m1.1.1" xref="S4.E10.m1.1.1.cmml"><mfrac id="S4.E10.m1.1.1a" xref="S4.E10.m1.1.1.cmml"><msub id="S4.E10.m1.1.1.2" xref="S4.E10.m1.1.1.2.cmml"><mi id="S4.E10.m1.1.1.2.2" xref="S4.E10.m1.1.1.2.2.cmml">M</mi><mi id="S4.E10.m1.1.1.2.3" xref="S4.E10.m1.1.1.2.3.cmml">i</mi></msub><msub id="S4.E10.m1.1.1.3" xref="S4.E10.m1.1.1.3.cmml"><mi id="S4.E10.m1.1.1.3.2" xref="S4.E10.m1.1.1.3.2.cmml">R</mi><mi id="S4.E10.m1.1.1.3.3" xref="S4.E10.m1.1.1.3.3.cmml">i</mi></msub></mfrac></mstyle><mo id="S4.E10.m1.1.2.3.3.2.2.2" stretchy="false" xref="S4.E10.m1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E10.m1.1b"><apply id="S4.E10.m1.1.2.cmml" xref="S4.E10.m1.1.2"><eq id="S4.E10.m1.1.2.1.cmml" xref="S4.E10.m1.1.2.1"></eq><apply id="S4.E10.m1.1.2.2.cmml" xref="S4.E10.m1.1.2.2"><times id="S4.E10.m1.1.2.2.1.cmml" xref="S4.E10.m1.1.2.2.1"></times><ci id="S4.E10.m1.1.2.2.2.cmml" xref="S4.E10.m1.1.2.2.2">𝐸</ci><ci id="S4.E10.m1.1.2.2.3.cmml" xref="S4.E10.m1.1.2.2.3">𝐸</ci><ci id="S4.E10.m1.1.2.2.4.cmml" xref="S4.E10.m1.1.2.2.4">𝑅</ci></apply><apply id="S4.E10.m1.1.2.3.cmml" xref="S4.E10.m1.1.2.3"><times id="S4.E10.m1.1.2.3.1.cmml" xref="S4.E10.m1.1.2.3.1"></times><apply id="S4.E10.m1.1.2.3.2.cmml" xref="S4.E10.m1.1.2.3.2"><divide id="S4.E10.m1.1.2.3.2.1.cmml" xref="S4.E10.m1.1.2.3.2"></divide><cn id="S4.E10.m1.1.2.3.2.2.cmml" type="integer" xref="S4.E10.m1.1.2.3.2.2">1</cn><ci id="S4.E10.m1.1.2.3.2.3.cmml" xref="S4.E10.m1.1.2.3.2.3">𝑁</ci></apply><apply id="S4.E10.m1.1.2.3.3.cmml" xref="S4.E10.m1.1.2.3.3"><apply id="S4.E10.m1.1.2.3.3.1.cmml" xref="S4.E10.m1.1.2.3.3.1"><csymbol cd="ambiguous" id="S4.E10.m1.1.2.3.3.1.1.cmml" xref="S4.E10.m1.1.2.3.3.1">superscript</csymbol><apply id="S4.E10.m1.1.2.3.3.1.2.cmml" xref="S4.E10.m1.1.2.3.3.1"><csymbol cd="ambiguous" id="S4.E10.m1.1.2.3.3.1.2.1.cmml" xref="S4.E10.m1.1.2.3.3.1">subscript</csymbol><sum id="S4.E10.m1.1.2.3.3.1.2.2.cmml" xref="S4.E10.m1.1.2.3.3.1.2.2"></sum><apply id="S4.E10.m1.1.2.3.3.1.2.3.cmml" xref="S4.E10.m1.1.2.3.3.1.2.3"><eq id="S4.E10.m1.1.2.3.3.1.2.3.1.cmml" xref="S4.E10.m1.1.2.3.3.1.2.3.1"></eq><ci id="S4.E10.m1.1.2.3.3.1.2.3.2.cmml" xref="S4.E10.m1.1.2.3.3.1.2.3.2">𝑖</ci><cn id="S4.E10.m1.1.2.3.3.1.2.3.3.cmml" type="integer" xref="S4.E10.m1.1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S4.E10.m1.1.2.3.3.1.3.cmml" xref="S4.E10.m1.1.2.3.3.1.3">𝑁</ci></apply><apply id="S4.E10.m1.1.1.cmml" xref="S4.E10.m1.1.2.3.3.2.2"><divide id="S4.E10.m1.1.1.1.cmml" xref="S4.E10.m1.1.2.3.3.2.2"></divide><apply id="S4.E10.m1.1.1.2.cmml" xref="S4.E10.m1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.2.1.cmml" xref="S4.E10.m1.1.1.2">subscript</csymbol><ci id="S4.E10.m1.1.1.2.2.cmml" xref="S4.E10.m1.1.1.2.2">𝑀</ci><ci id="S4.E10.m1.1.1.2.3.cmml" xref="S4.E10.m1.1.1.2.3">𝑖</ci></apply><apply id="S4.E10.m1.1.1.3.cmml" xref="S4.E10.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.3.1.cmml" xref="S4.E10.m1.1.1.3">subscript</csymbol><ci id="S4.E10.m1.1.1.3.2.cmml" xref="S4.E10.m1.1.1.3.2">𝑅</ci><ci id="S4.E10.m1.1.1.3.3.cmml" xref="S4.E10.m1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E10.m1.1c">\displaystyle EER=\frac{1}{N}\sum_{i=1}^{N}(\frac{M_{i}}{R_{i}})</annotation><annotation encoding="application/x-llamapun" id="S4.E10.m1.1d">italic_E italic_E italic_R = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( divide start_ARG italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p1.10">where <math alttext="N" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m1.1"><semantics id="S4.SS1.p1.6.m1.1a"><mi id="S4.SS1.p1.6.m1.1.1" xref="S4.SS1.p1.6.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m1.1b"><ci id="S4.SS1.p1.6.m1.1.1.cmml" xref="S4.SS1.p1.6.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m1.1d">italic_N</annotation></semantics></math> is the number of metrics and <math alttext="M_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m2.1"><semantics id="S4.SS1.p1.7.m2.1a"><msub id="S4.SS1.p1.7.m2.1.1" xref="S4.SS1.p1.7.m2.1.1.cmml"><mi id="S4.SS1.p1.7.m2.1.1.2" xref="S4.SS1.p1.7.m2.1.1.2.cmml">M</mi><mi id="S4.SS1.p1.7.m2.1.1.3" xref="S4.SS1.p1.7.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m2.1b"><apply id="S4.SS1.p1.7.m2.1.1.cmml" xref="S4.SS1.p1.7.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m2.1.1.1.cmml" xref="S4.SS1.p1.7.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.7.m2.1.1.2.cmml" xref="S4.SS1.p1.7.m2.1.1.2">𝑀</ci><ci id="S4.SS1.p1.7.m2.1.1.3.cmml" xref="S4.SS1.p1.7.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m2.1c">M_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m2.1d">italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="R_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m3.1"><semantics id="S4.SS1.p1.8.m3.1a"><msub id="S4.SS1.p1.8.m3.1.1" xref="S4.SS1.p1.8.m3.1.1.cmml"><mi id="S4.SS1.p1.8.m3.1.1.2" xref="S4.SS1.p1.8.m3.1.1.2.cmml">R</mi><mi id="S4.SS1.p1.8.m3.1.1.3" xref="S4.SS1.p1.8.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m3.1b"><apply id="S4.SS1.p1.8.m3.1.1.cmml" xref="S4.SS1.p1.8.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.8.m3.1.1.1.cmml" xref="S4.SS1.p1.8.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.8.m3.1.1.2.cmml" xref="S4.SS1.p1.8.m3.1.1.2">𝑅</ci><ci id="S4.SS1.p1.8.m3.1.1.3.cmml" xref="S4.SS1.p1.8.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m3.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m3.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> refer to the i-th metric of the tested model and the reference one, respectively. In our evaluation, we set the reference model to be SAM-H. In addition to these metrics, we also report the runtime and throughput of the models. For accuracy evaluation, we use mean intersection over union (<math alttext="mIoU" class="ltx_Math" display="inline" id="S4.SS1.p1.9.m4.1"><semantics id="S4.SS1.p1.9.m4.1a"><mrow id="S4.SS1.p1.9.m4.1.1" xref="S4.SS1.p1.9.m4.1.1.cmml"><mi id="S4.SS1.p1.9.m4.1.1.2" xref="S4.SS1.p1.9.m4.1.1.2.cmml">m</mi><mo id="S4.SS1.p1.9.m4.1.1.1" xref="S4.SS1.p1.9.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.9.m4.1.1.3" xref="S4.SS1.p1.9.m4.1.1.3.cmml">I</mi><mo id="S4.SS1.p1.9.m4.1.1.1a" xref="S4.SS1.p1.9.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.9.m4.1.1.4" xref="S4.SS1.p1.9.m4.1.1.4.cmml">o</mi><mo id="S4.SS1.p1.9.m4.1.1.1b" xref="S4.SS1.p1.9.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.9.m4.1.1.5" xref="S4.SS1.p1.9.m4.1.1.5.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m4.1b"><apply id="S4.SS1.p1.9.m4.1.1.cmml" xref="S4.SS1.p1.9.m4.1.1"><times id="S4.SS1.p1.9.m4.1.1.1.cmml" xref="S4.SS1.p1.9.m4.1.1.1"></times><ci id="S4.SS1.p1.9.m4.1.1.2.cmml" xref="S4.SS1.p1.9.m4.1.1.2">𝑚</ci><ci id="S4.SS1.p1.9.m4.1.1.3.cmml" xref="S4.SS1.p1.9.m4.1.1.3">𝐼</ci><ci id="S4.SS1.p1.9.m4.1.1.4.cmml" xref="S4.SS1.p1.9.m4.1.1.4">𝑜</ci><ci id="S4.SS1.p1.9.m4.1.1.5.cmml" xref="S4.SS1.p1.9.m4.1.1.5">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m4.1c">mIoU</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.9.m4.1d">italic_m italic_I italic_o italic_U</annotation></semantics></math>) for the SegAny task and mean average precision (<math alttext="AP" class="ltx_Math" display="inline" id="S4.SS1.p1.10.m5.1"><semantics id="S4.SS1.p1.10.m5.1a"><mrow id="S4.SS1.p1.10.m5.1.1" xref="S4.SS1.p1.10.m5.1.1.cmml"><mi id="S4.SS1.p1.10.m5.1.1.2" xref="S4.SS1.p1.10.m5.1.1.2.cmml">A</mi><mo id="S4.SS1.p1.10.m5.1.1.1" xref="S4.SS1.p1.10.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS1.p1.10.m5.1.1.3" xref="S4.SS1.p1.10.m5.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m5.1b"><apply id="S4.SS1.p1.10.m5.1.1.cmml" xref="S4.SS1.p1.10.m5.1.1"><times id="S4.SS1.p1.10.m5.1.1.1.cmml" xref="S4.SS1.p1.10.m5.1.1.1"></times><ci id="S4.SS1.p1.10.m5.1.1.2.cmml" xref="S4.SS1.p1.10.m5.1.1.2">𝐴</ci><ci id="S4.SS1.p1.10.m5.1.1.3.cmml" xref="S4.SS1.p1.10.m5.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m5.1c">AP</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.10.m5.1d">italic_A italic_P</annotation></semantics></math>) for instance segmentation.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Efficiency Comparison</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.8">We first report the efficiency results of SAM and its variants.
With the picture <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.8.1">groceries.jpg<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote1.1.1.1">1</span></span><span class="ltx_text ltx_font_upright" id="footnote1.9">https://github.com/facebookresearch/segment-anything/blob/main/notebooks/images/groceries.jpg</span></span></span></span></span> used in SAM’s official example as input, we utilize a bounding box as prompt and evaluate models’ <math alttext="\#Params" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" mathvariant="normal" xref="S4.SS2.p1.1.m1.1.1.2.cmml">#</mi><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">P</mi><mo id="S4.SS2.p1.1.m1.1.1.1a" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.1.m1.1.1.4" xref="S4.SS2.p1.1.m1.1.1.4.cmml">a</mi><mo id="S4.SS2.p1.1.m1.1.1.1b" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.1.m1.1.1.5" xref="S4.SS2.p1.1.m1.1.1.5.cmml">r</mi><mo id="S4.SS2.p1.1.m1.1.1.1c" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.1.m1.1.1.6" xref="S4.SS2.p1.1.m1.1.1.6.cmml">a</mi><mo id="S4.SS2.p1.1.m1.1.1.1d" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.1.m1.1.1.7" xref="S4.SS2.p1.1.m1.1.1.7.cmml">m</mi><mo id="S4.SS2.p1.1.m1.1.1.1e" xref="S4.SS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.1.m1.1.1.8" xref="S4.SS2.p1.1.m1.1.1.8.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">#</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">𝑃</ci><ci id="S4.SS2.p1.1.m1.1.1.4.cmml" xref="S4.SS2.p1.1.m1.1.1.4">𝑎</ci><ci id="S4.SS2.p1.1.m1.1.1.5.cmml" xref="S4.SS2.p1.1.m1.1.1.5">𝑟</ci><ci id="S4.SS2.p1.1.m1.1.1.6.cmml" xref="S4.SS2.p1.1.m1.1.1.6">𝑎</ci><ci id="S4.SS2.p1.1.m1.1.1.7.cmml" xref="S4.SS2.p1.1.m1.1.1.7">𝑚</ci><ci id="S4.SS2.p1.1.m1.1.1.8.cmml" xref="S4.SS2.p1.1.m1.1.1.8">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\#Params</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d"># italic_P italic_a italic_r italic_a italic_m italic_s</annotation></semantics></math>, <math alttext="FLOPs" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">F</mi><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">L</mi><mo id="S4.SS2.p1.2.m2.1.1.1a" xref="S4.SS2.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.2.m2.1.1.4" xref="S4.SS2.p1.2.m2.1.1.4.cmml">O</mi><mo id="S4.SS2.p1.2.m2.1.1.1b" xref="S4.SS2.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.2.m2.1.1.5" xref="S4.SS2.p1.2.m2.1.1.5.cmml">P</mi><mo id="S4.SS2.p1.2.m2.1.1.1c" xref="S4.SS2.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.2.m2.1.1.6" xref="S4.SS2.p1.2.m2.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><times id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></times><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝐹</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">𝐿</ci><ci id="S4.SS2.p1.2.m2.1.1.4.cmml" xref="S4.SS2.p1.2.m2.1.1.4">𝑂</ci><ci id="S4.SS2.p1.2.m2.1.1.5.cmml" xref="S4.SS2.p1.2.m2.1.1.5">𝑃</ci><ci id="S4.SS2.p1.2.m2.1.1.6.cmml" xref="S4.SS2.p1.2.m2.1.1.6">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">FLOPs</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_F italic_L italic_O italic_P italic_s</annotation></semantics></math> and <math alttext="MACs" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">M</mi><mo id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">A</mi><mo id="S4.SS2.p1.3.m3.1.1.1a" xref="S4.SS2.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.3.m3.1.1.4" xref="S4.SS2.p1.3.m3.1.1.4.cmml">C</mi><mo id="S4.SS2.p1.3.m3.1.1.1b" xref="S4.SS2.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.3.m3.1.1.5" xref="S4.SS2.p1.3.m3.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><times id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></times><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">𝑀</ci><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">𝐴</ci><ci id="S4.SS2.p1.3.m3.1.1.4.cmml" xref="S4.SS2.p1.3.m3.1.1.4">𝐶</ci><ci id="S4.SS2.p1.3.m3.1.1.5.cmml" xref="S4.SS2.p1.3.m3.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">MACs</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">italic_M italic_A italic_C italic_s</annotation></semantics></math> by leveraging the tool <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.8.2">calflops<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote2.1.1.1">2</span></span><span class="ltx_text ltx_font_upright" id="footnote2.9">https://github.com/MrYxJ/calculate-flops.pytorch</span></span></span></span></span>. We also calculate the <math alttext="ERR" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">E</mi><mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">R</mi><mo id="S4.SS2.p1.4.m4.1.1.1a" xref="S4.SS2.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.4.m4.1.1.4" xref="S4.SS2.p1.4.m4.1.1.4.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><times id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></times><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">𝐸</ci><ci id="S4.SS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.3">𝑅</ci><ci id="S4.SS2.p1.4.m4.1.1.4.cmml" xref="S4.SS2.p1.4.m4.1.1.4">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">ERR</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">italic_E italic_R italic_R</annotation></semantics></math> for comprehensive comparison. The results are illustrated in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T2" title="Table 2 ‣ 4.2 Efficiency Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>. Among the efficient variants, we observe that EdgeSAM has the lowest number of parameters, <math alttext="FLOPs" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">F</mi><mo id="S4.SS2.p1.5.m5.1.1.1" xref="S4.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">L</mi><mo id="S4.SS2.p1.5.m5.1.1.1a" xref="S4.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.5.m5.1.1.4" xref="S4.SS2.p1.5.m5.1.1.4.cmml">O</mi><mo id="S4.SS2.p1.5.m5.1.1.1b" xref="S4.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.5.m5.1.1.5" xref="S4.SS2.p1.5.m5.1.1.5.cmml">P</mi><mo id="S4.SS2.p1.5.m5.1.1.1c" xref="S4.SS2.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.5.m5.1.1.6" xref="S4.SS2.p1.5.m5.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><times id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1"></times><ci id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">𝐹</ci><ci id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">𝐿</ci><ci id="S4.SS2.p1.5.m5.1.1.4.cmml" xref="S4.SS2.p1.5.m5.1.1.4">𝑂</ci><ci id="S4.SS2.p1.5.m5.1.1.5.cmml" xref="S4.SS2.p1.5.m5.1.1.5">𝑃</ci><ci id="S4.SS2.p1.5.m5.1.1.6.cmml" xref="S4.SS2.p1.5.m5.1.1.6">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">FLOPs</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.5.m5.1d">italic_F italic_L italic_O italic_P italic_s</annotation></semantics></math>, <math alttext="MACs" class="ltx_Math" display="inline" id="S4.SS2.p1.6.m6.1"><semantics id="S4.SS2.p1.6.m6.1a"><mrow id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mi id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">M</mi><mo id="S4.SS2.p1.6.m6.1.1.1" xref="S4.SS2.p1.6.m6.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml">A</mi><mo id="S4.SS2.p1.6.m6.1.1.1a" xref="S4.SS2.p1.6.m6.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.6.m6.1.1.4" xref="S4.SS2.p1.6.m6.1.1.4.cmml">C</mi><mo id="S4.SS2.p1.6.m6.1.1.1b" xref="S4.SS2.p1.6.m6.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.6.m6.1.1.5" xref="S4.SS2.p1.6.m6.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><times id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1.1"></times><ci id="S4.SS2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.p1.6.m6.1.1.2">𝑀</ci><ci id="S4.SS2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3">𝐴</ci><ci id="S4.SS2.p1.6.m6.1.1.4.cmml" xref="S4.SS2.p1.6.m6.1.1.4">𝐶</ci><ci id="S4.SS2.p1.6.m6.1.1.5.cmml" xref="S4.SS2.p1.6.m6.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">MACs</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.6.m6.1d">italic_M italic_A italic_C italic_s</annotation></semantics></math> and consequently the <math alttext="EER" class="ltx_Math" display="inline" id="S4.SS2.p1.7.m7.1"><semantics id="S4.SS2.p1.7.m7.1a"><mrow id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml"><mi id="S4.SS2.p1.7.m7.1.1.2" xref="S4.SS2.p1.7.m7.1.1.2.cmml">E</mi><mo id="S4.SS2.p1.7.m7.1.1.1" xref="S4.SS2.p1.7.m7.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.7.m7.1.1.3" xref="S4.SS2.p1.7.m7.1.1.3.cmml">E</mi><mo id="S4.SS2.p1.7.m7.1.1.1a" xref="S4.SS2.p1.7.m7.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.7.m7.1.1.4" xref="S4.SS2.p1.7.m7.1.1.4.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><apply id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1"><times id="S4.SS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1.1"></times><ci id="S4.SS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2">𝐸</ci><ci id="S4.SS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.3">𝐸</ci><ci id="S4.SS2.p1.7.m7.1.1.4.cmml" xref="S4.SS2.p1.7.m7.1.1.4">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">EER</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.7.m7.1d">italic_E italic_E italic_R</annotation></semantics></math>, while EfficientViT-SAM-XL1 takes the highest numbers whose <math alttext="EER" class="ltx_Math" display="inline" id="S4.SS2.p1.8.m8.1"><semantics id="S4.SS2.p1.8.m8.1a"><mrow id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml"><mi id="S4.SS2.p1.8.m8.1.1.2" xref="S4.SS2.p1.8.m8.1.1.2.cmml">E</mi><mo id="S4.SS2.p1.8.m8.1.1.1" xref="S4.SS2.p1.8.m8.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.8.m8.1.1.3" xref="S4.SS2.p1.8.m8.1.1.3.cmml">E</mi><mo id="S4.SS2.p1.8.m8.1.1.1a" xref="S4.SS2.p1.8.m8.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.8.m8.1.1.4" xref="S4.SS2.p1.8.m8.1.1.4.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><apply id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1"><times id="S4.SS2.p1.8.m8.1.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1.1"></times><ci id="S4.SS2.p1.8.m8.1.1.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2">𝐸</ci><ci id="S4.SS2.p1.8.m8.1.1.3.cmml" xref="S4.SS2.p1.8.m8.1.1.3">𝐸</ci><ci id="S4.SS2.p1.8.m8.1.1.4.cmml" xref="S4.SS2.p1.8.m8.1.1.4">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">EER</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.8.m8.1d">italic_E italic_E italic_R</annotation></semantics></math> is 3% more than SAM-B. When compared to the heaviest SAM-H, all variants present obvious reduction in both model size and calculation.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.10.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.10.1.1.1"><span class="ltx_text" id="S4.T2.10.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.10.1.1.2"><span class="ltx_text" id="S4.T2.10.1.1.2.1" style="font-size:90%;">#Params</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.10.1.1.3"><span class="ltx_text" id="S4.T2.10.1.1.3.1" style="font-size:90%;">GFLOPs</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T2.10.1.1.4"><span class="ltx_text" id="S4.T2.10.1.1.4.1" style="font-size:90%;">GMACs</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.10.1.1.5"><span class="ltx_text" id="S4.T2.10.1.1.5.1" style="font-size:90%;">EER (%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.10.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.10.2.1.1"><span class="ltx_text" id="S4.T2.10.2.1.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.2.1.2"><span class="ltx_text" id="S4.T2.10.2.1.2.1" style="font-size:90%;">641.09M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.2.1.3"><span class="ltx_text" id="S4.T2.10.2.1.3.1" style="font-size:90%;">5490</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.10.2.1.4"><span class="ltx_text" id="S4.T2.10.2.1.4.1" style="font-size:90%;">2730</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.10.2.1.5"><span class="ltx_text" id="S4.T2.10.2.1.5.1" style="font-size:90%;">100</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.3.2.1"><span class="ltx_text" id="S4.T2.10.3.2.1.1" style="font-size:90%;">SAM-L</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.3.2.2"><span class="ltx_text" id="S4.T2.10.3.2.2.1" style="font-size:90%;">312.34M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.3.2.3"><span class="ltx_text" id="S4.T2.10.3.2.3.1" style="font-size:90%;">2640</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.3.2.4"><span class="ltx_text" id="S4.T2.10.3.2.4.1" style="font-size:90%;">1310</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.3.2.5"><span class="ltx_text" id="S4.T2.10.3.2.5.1" style="font-size:90%;">48.26</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.4.3.1"><span class="ltx_text" id="S4.T2.10.4.3.1.1" style="font-size:90%;">SAM-B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.4.3.2"><span class="ltx_text" id="S4.T2.10.4.3.2.1" style="font-size:90%;">93.74M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.4.3.3"><span class="ltx_text" id="S4.T2.10.4.3.3.1" style="font-size:90%;">746.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.4.3.4"><span class="ltx_text" id="S4.T2.10.4.3.4.1" style="font-size:90%;">370.47</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.4.3.5"><span class="ltx_text" id="S4.T2.10.4.3.5.1" style="font-size:90%;">13.93</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.5.4.1"><span class="ltx_text" id="S4.T2.10.5.4.1.1" style="font-size:90%;">SAM2-B+</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.5.4.2"><span class="ltx_text" id="S4.T2.10.5.4.2.1" style="font-size:90%;">80.83M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.5.4.3"><span class="ltx_text" id="S4.T2.10.5.4.3.1" style="font-size:90%;">533.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.5.4.4"><span class="ltx_text" id="S4.T2.10.5.4.4.1" style="font-size:90%;">266.44</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.5.4.5"><span class="ltx_text" id="S4.T2.10.5.4.5.1" style="font-size:90%;">10.70</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.6.5.1"><span class="ltx_text" id="S4.T2.10.6.5.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.6.5.2"><span class="ltx_text" id="S4.T2.10.6.5.2.1" style="font-size:90%;">68M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.6.5.3"><span class="ltx_text" id="S4.T2.10.6.5.3.1" style="font-size:90%;">887.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.6.5.4"><span class="ltx_text" id="S4.T2.10.6.5.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.6.5.5"><span class="ltx_text" id="S4.T2.10.6.5.5.1" style="font-size:90%;">13.39</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.7.6.1"><span class="ltx_text" id="S4.T2.10.7.6.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.7.6.2"><span class="ltx_text" id="S4.T2.10.7.6.2.1" style="font-size:90%;">10.13M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.7.6.3"><span class="ltx_text" id="S4.T2.10.7.6.3.1" style="font-size:90%;">76.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.7.6.4"><span class="ltx_text" id="S4.T2.10.7.6.4.1" style="font-size:90%;">37.49</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.7.6.5"><span class="ltx_text" id="S4.T2.10.7.6.5.1" style="font-size:90%;">1.45</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.8.7.1"><span class="ltx_text ltx_font_bold" id="S4.T2.10.8.7.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.8.7.2"><span class="ltx_text ltx_font_bold" id="S4.T2.10.8.7.2.1" style="font-size:90%;">9.58M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.8.7.3"><span class="ltx_text ltx_font_bold" id="S4.T2.10.8.7.3.1" style="font-size:90%;">44.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.8.7.4"><span class="ltx_text ltx_font_bold" id="S4.T2.10.8.7.4.1" style="font-size:90%;">21.81</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.8.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.10.8.7.5.1" style="font-size:90%;">1.03</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.9.8.1"><span class="ltx_text" id="S4.T2.10.9.8.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.8.2"><span class="ltx_text" id="S4.T2.10.9.8.2.1" style="font-size:90%;">10.22M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.9.8.3"><span class="ltx_text" id="S4.T2.10.9.8.3.1" style="font-size:90%;">53.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.9.8.4"><span class="ltx_text" id="S4.T2.10.9.8.4.1" style="font-size:90%;">26.74</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.9.8.5"><span class="ltx_text" id="S4.T2.10.9.8.5.1" style="font-size:90%;">1.18</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.10.9.1"><span class="ltx_text" id="S4.T2.10.10.9.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.10.9.2"><span class="ltx_text" id="S4.T2.10.10.9.2.1" style="font-size:90%;">26.41M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.10.9.3"><span class="ltx_text" id="S4.T2.10.10.9.3.1" style="font-size:90%;">371.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.10.9.4"><span class="ltx_text" id="S4.T2.10.10.9.4.1" style="font-size:90%;">185.56</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.10.9.5"><span class="ltx_text" id="S4.T2.10.10.9.5.1" style="font-size:90%;">5.90</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.11.10.1"><span class="ltx_text" id="S4.T2.10.11.10.1.1" style="font-size:90%;">RepVit-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.11.10.2"><span class="ltx_text" id="S4.T2.10.11.10.2.1" style="font-size:90%;">27.22M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.11.10.3"><span class="ltx_text" id="S4.T2.10.11.10.3.1" style="font-size:90%;">231.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.11.10.4"><span class="ltx_text" id="S4.T2.10.11.10.4.1" style="font-size:90%;">115.07</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.11.10.5"><span class="ltx_text" id="S4.T2.10.11.10.5.1" style="font-size:90%;">4.23</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.12.11.1"><span class="ltx_text" id="S4.T2.10.12.11.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.12.11.2"><span class="ltx_text" id="S4.T2.10.12.11.2.1" style="font-size:90%;">34.79M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.12.11.3"><span class="ltx_text" id="S4.T2.10.12.11.3.1" style="font-size:90%;">154.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.12.11.4"><span class="ltx_text" id="S4.T2.10.12.11.4.1" style="font-size:90%;">76.89</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.12.11.5"><span class="ltx_text" id="S4.T2.10.12.11.5.1" style="font-size:90%;">3.68</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.13.12.1"><span class="ltx_text" id="S4.T2.10.13.12.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.13.12.2"><span class="ltx_text" id="S4.T2.10.13.12.2.1" style="font-size:90%;">203.35M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.13.12.3"><span class="ltx_text" id="S4.T2.10.13.12.3.1" style="font-size:90%;">523.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.13.12.4"><span class="ltx_text" id="S4.T2.10.13.12.4.1" style="font-size:90%;">261.21</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.13.12.5"><span class="ltx_text" id="S4.T2.10.13.12.5.1" style="font-size:90%;">16.94</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.14.13.1"><span class="ltx_text" id="S4.T2.10.14.13.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.14.13.2"><span class="ltx_text" id="S4.T2.10.14.13.2.1" style="font-size:90%;">28.01M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.14.13.3"><span class="ltx_text" id="S4.T2.10.14.13.3.1" style="font-size:90%;">196.21</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.14.13.4"><span class="ltx_text" id="S4.T2.10.14.13.4.1" style="font-size:90%;">96.73</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.14.13.5"><span class="ltx_text" id="S4.T2.10.14.13.5.1" style="font-size:90%;">3.83</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.10.15.14.1"><span class="ltx_text" id="S4.T2.10.15.14.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.10.15.14.2"><span class="ltx_text" id="S4.T2.10.15.14.2.1" style="font-size:90%;">9.85M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.10.15.14.3"><span class="ltx_text" id="S4.T2.10.15.14.3.1" style="font-size:90%;">47.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.10.15.14.4"><span class="ltx_text" id="S4.T2.10.15.14.4.1" style="font-size:90%;">23.19</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.10.15.14.5"><span class="ltx_text" id="S4.T2.10.15.14.5.1" style="font-size:90%;">1.08</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T2.10.16.15.1"><span class="ltx_text" id="S4.T2.10.16.15.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.16.15.2"><span class="ltx_text" id="S4.T2.10.16.15.2.1" style="font-size:90%;">10.13M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.10.16.15.3"><span class="ltx_text" id="S4.T2.10.16.15.3.1" style="font-size:90%;">76.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.10.16.15.4"><span class="ltx_text" id="S4.T2.10.16.15.4.1" style="font-size:90%;">37.94</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T2.10.16.15.5"><span class="ltx_text" id="S4.T2.10.16.15.5.1" style="font-size:90%;">1.45</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Quantitative results of <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.27.1">#Params</span>, <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.28.2">GFLOPs</span>, <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.29.3">GMACs</span> and <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S4.T2.30.4">EER</span>. P.S. The results of FastSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib161" title=""><span class="ltx_text" style="font-size:90%;">161</span></a>]</cite> are collected from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>]</cite> and others are evaluated under our framework.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="390" id="S4.F16.g1" src="x15.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F16.2.1.1" style="font-size:90%;">Figure 16</span>: </span><span class="ltx_text" id="S4.F16.3.2" style="font-size:90%;">Latency results on GPU with increasing numbers of box prompts.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We also measure the models’ inference time in both SegAny and SegEvery modes, using 100 images from the COCO validation set as evaluation data. For the SegAny task, each image is prompted with 50 fixed bounding boxes. We report the cumulative time for every 10 boxes through a curve chart (shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.F16" title="Figure 16 ‣ 4.2 Efficiency Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">16</span></a>). Based on this, we calculate the average time required to process one image with one box prompt and report it as the inference time for the SegAny task. The evaluation is conducted on both CPU and GPU environments, and we simultaneously record GPU memory usage. Additionally, we test the throughput of each variant on the COCO validation set, using the ground truth boxes. The results are summarized in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T3" title="Table 3 ‣ 4.2 Efficiency Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>.
Our findings reveal that EfficientViT-SAM-L0 achieves the shortest inference time for the SegAny task, offering nearly 30x acceleration on GPU and almost 50x acceleration on CPU compared to the heaviest model, SAM-H. EdgeSAM also shows impressive performance with a low CPU latency of 259 ms, while NanoSAM achieves a 20 ms latency on GPU, both coming close to the best results. In the throughput test on the COCO dataset, NanoSAM leads with 27.9 images processed per second. Two other variants, EfficientSAM-Ti and EfficientViT-SAM-L0, also demonstrate strong throughput, each exceeding 20 images per second.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T3.2.1.1.1"><span class="ltx_text" id="S4.T3.2.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.1.1.2"><span class="ltx_text" id="S4.T3.2.1.1.2.1" style="font-size:90%;">Memory (GB)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.1.1.3"><span class="ltx_text" id="S4.T3.2.1.1.3.1" style="font-size:90%;">Latency-CPU (ms)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T3.2.1.1.4"><span class="ltx_text" id="S4.T3.2.1.1.4.1" style="font-size:90%;">Latency-GPU (ms)</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.1.1.5"><span class="ltx_text" id="S4.T3.2.1.1.5.1" style="font-size:90%;">Throughput (img/s)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.2.2.1.1"><span class="ltx_text" id="S4.T3.2.2.1.1.1" style="font-size:90%;">SAM-H</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.1.2"><span class="ltx_text" id="S4.T3.2.2.1.2.1" style="font-size:90%;">7.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.1.3"><span class="ltx_text" id="S4.T3.2.2.1.3.1" style="font-size:90%;">9470</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.2.1.4"><span class="ltx_text" id="S4.T3.2.2.1.4.1" style="font-size:90%;">472</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T3.2.2.1.5"><span class="ltx_text" id="S4.T3.2.2.1.5.1" style="font-size:90%;">2.04</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.3.2.1"><span class="ltx_text" id="S4.T3.2.3.2.1.1" style="font-size:90%;">SAM-L</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.2"><span class="ltx_text" id="S4.T3.2.3.2.2.1" style="font-size:90%;">6.03</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.2.3"><span class="ltx_text" id="S4.T3.2.3.2.3.1" style="font-size:90%;">6800</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.3.2.4"><span class="ltx_text" id="S4.T3.2.3.2.4.1" style="font-size:90%;">289</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.3.2.5"><span class="ltx_text" id="S4.T3.2.3.2.5.1" style="font-size:90%;">3.33</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.4.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.4.3.1"><span class="ltx_text" id="S4.T3.2.4.3.1.1" style="font-size:90%;">SAM-B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.2"><span class="ltx_text" id="S4.T3.2.4.3.2.1" style="font-size:90%;">4.39</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.3.3"><span class="ltx_text" id="S4.T3.2.4.3.3.1" style="font-size:90%;">3294</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.4.3.4"><span class="ltx_text" id="S4.T3.2.4.3.4.1" style="font-size:90%;">129</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.4.3.5"><span class="ltx_text" id="S4.T3.2.4.3.5.1" style="font-size:90%;">6.78</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.5.4.1"><span class="ltx_text" id="S4.T3.2.5.4.1.1" style="font-size:90%;">SAMfast-H</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.5.4.2"><span class="ltx_text" id="S4.T3.2.5.4.2.1" style="font-size:90%;">2.13</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.5.4.3"><span class="ltx_text" id="S4.T3.2.5.4.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.5.4.4"><span class="ltx_text" id="S4.T3.2.5.4.4.1" style="font-size:90%;">127</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.5.4.5"><span class="ltx_text" id="S4.T3.2.5.4.5.1" style="font-size:90%;">6.36</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.6.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.6.5.1"><span class="ltx_text" id="S4.T3.2.6.5.1.1" style="font-size:90%;">SAM2-B+</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.5.2"><span class="ltx_text" id="S4.T3.2.6.5.2.1" style="font-size:90%;">1.38</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.5.3"><span class="ltx_text" id="S4.T3.2.6.5.3.1" style="font-size:90%;">1221</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.6.5.4"><span class="ltx_text" id="S4.T3.2.6.5.4.1" style="font-size:90%;">46</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.6.5.5"><span class="ltx_text" id="S4.T3.2.6.5.5.1" style="font-size:90%;">13.82</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.7.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.7.6.1"><span class="ltx_text" id="S4.T3.2.7.6.1.1" style="font-size:90%;">FastSAM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.7.6.2"><span class="ltx_text" id="S4.T3.2.7.6.2.1" style="font-size:90%;">4.96</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.7.6.3"><span class="ltx_text" id="S4.T3.2.7.6.3.1" style="font-size:90%;">850</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.7.6.4"><span class="ltx_text" id="S4.T3.2.7.6.4.1" style="font-size:90%;">103</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.7.6.5"><span class="ltx_text" id="S4.T3.2.7.6.5.1" style="font-size:90%;">8.42</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.8.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.8.7.1"><span class="ltx_text" id="S4.T3.2.8.7.1.1" style="font-size:90%;">MobileSAM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.8.7.2"><span class="ltx_text" id="S4.T3.2.8.7.2.1" style="font-size:90%;">1.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.8.7.3"><span class="ltx_text" id="S4.T3.2.8.7.3.1" style="font-size:90%;">424</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.8.7.4"><span class="ltx_text" id="S4.T3.2.8.7.4.1" style="font-size:90%;">44</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.8.7.5"><span class="ltx_text" id="S4.T3.2.8.7.5.1" style="font-size:90%;">16.79</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.9.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.9.8.1"><span class="ltx_text" id="S4.T3.2.9.8.1.1" style="font-size:90%;">EdgeSAM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.9.8.2"><span class="ltx_text" id="S4.T3.2.9.8.2.1" style="font-size:90%;">1.72</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.9.8.3"><span class="ltx_text" id="S4.T3.2.9.8.3.1" style="font-size:90%;">259</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.9.8.4"><span class="ltx_text" id="S4.T3.2.9.8.4.1" style="font-size:90%;">49</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.9.8.5"><span class="ltx_text" id="S4.T3.2.9.8.5.1" style="font-size:90%;">17.56</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.10.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.10.9.1"><span class="ltx_text" id="S4.T3.2.10.9.1.1" style="font-size:90%;">EfficientSAM-Ti</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.10.9.2"><span class="ltx_text" id="S4.T3.2.10.9.2.1" style="font-size:90%;">4.46</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.10.9.3"><span class="ltx_text" id="S4.T3.2.10.9.3.1" style="font-size:90%;">1159</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.10.9.4"><span class="ltx_text" id="S4.T3.2.10.9.4.1" style="font-size:90%;">61</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.10.9.5"><span class="ltx_text" id="S4.T3.2.10.9.5.1" style="font-size:90%;">20.04</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.11.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.11.10.1"><span class="ltx_text" id="S4.T3.2.11.10.1.1" style="font-size:90%;">EfficientSAM-S</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.11.10.2"><span class="ltx_text" id="S4.T3.2.11.10.2.1" style="font-size:90%;">7.53</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.11.10.3"><span class="ltx_text" id="S4.T3.2.11.10.3.1" style="font-size:90%;">2605</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.11.10.4"><span class="ltx_text" id="S4.T3.2.11.10.4.1" style="font-size:90%;">86</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.11.10.5"><span class="ltx_text" id="S4.T3.2.11.10.5.1" style="font-size:90%;">19.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.12.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.12.11.1"><span class="ltx_text" id="S4.T3.2.12.11.1.1" style="font-size:90%;">RepVit-SAM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.12.11.2"><span class="ltx_text" id="S4.T3.2.12.11.2.1" style="font-size:90%;">1.87</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.12.11.3"><span class="ltx_text" id="S4.T3.2.12.11.3.1" style="font-size:90%;">1013</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.12.11.4"><span class="ltx_text" id="S4.T3.2.12.11.4.1" style="font-size:90%;">59</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.12.11.5"><span class="ltx_text" id="S4.T3.2.12.11.5.1" style="font-size:90%;">13.49</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.13.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.13.12.1"><span class="ltx_text" id="S4.T3.2.13.12.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.13.12.2"><span class="ltx_text" id="S4.T3.2.13.12.2.1" style="font-size:90%;">1.73</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.13.12.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.13.12.3.1" style="font-size:90%;">194</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.13.12.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.13.12.4.1" style="font-size:90%;">16</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.13.12.5"><span class="ltx_text" id="S4.T3.2.13.12.5.1" style="font-size:90%;">20.92</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.14.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.14.13.1"><span class="ltx_text" id="S4.T3.2.14.13.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.14.13.2"><span class="ltx_text" id="S4.T3.2.14.13.2.1" style="font-size:90%;">2.57</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.14.13.3"><span class="ltx_text" id="S4.T3.2.14.13.3.1" style="font-size:90%;">1334</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.14.13.4"><span class="ltx_text" id="S4.T3.2.14.13.4.1" style="font-size:90%;">67</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.14.13.5"><span class="ltx_text" id="S4.T3.2.14.13.5.1" style="font-size:90%;">12.28</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.15.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.15.14.1"><span class="ltx_text" id="S4.T3.2.15.14.1.1" style="font-size:90%;">SlimSAM-50</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.15.14.2"><span class="ltx_text" id="S4.T3.2.15.14.2.1" style="font-size:90%;">4.49</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.15.14.3"><span class="ltx_text" id="S4.T3.2.15.14.3.1" style="font-size:90%;">2312</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.15.14.4"><span class="ltx_text" id="S4.T3.2.15.14.4.1" style="font-size:90%;">87</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.15.14.5"><span class="ltx_text" id="S4.T3.2.15.14.5.1" style="font-size:90%;">9.13</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.16.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.16.15.1"><span class="ltx_text" id="S4.T3.2.16.15.1.1" style="font-size:90%;">SlimSAM-77</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.16.15.2"><span class="ltx_text" id="S4.T3.2.16.15.2.1" style="font-size:90%;">4.34</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.16.15.3"><span class="ltx_text" id="S4.T3.2.16.15.3.1" style="font-size:90%;">2230</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.16.15.4"><span class="ltx_text" id="S4.T3.2.16.15.4.1" style="font-size:90%;">73</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.16.15.5"><span class="ltx_text" id="S4.T3.2.16.15.5.1" style="font-size:90%;">10.28</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.17.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.17.16.1"><span class="ltx_text" id="S4.T3.2.17.16.1.1" style="font-size:90%;">TinySAM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.17.16.2"><span class="ltx_text" id="S4.T3.2.17.16.2.1" style="font-size:90%;">2.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.17.16.3"><span class="ltx_text" id="S4.T3.2.17.16.3.1" style="font-size:90%;">422</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.17.16.4"><span class="ltx_text" id="S4.T3.2.17.16.4.1" style="font-size:90%;">42</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.17.16.5"><span class="ltx_text" id="S4.T3.2.17.16.5.1" style="font-size:90%;">16.53</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.18.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.2.18.17.1"><span class="ltx_text" id="S4.T3.2.18.17.1.1" style="font-size:90%;">Q-TinySAM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.18.17.2"><span class="ltx_text" id="S4.T3.2.18.17.2.1" style="font-size:90%;">2.34</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.18.17.3"><span class="ltx_text" id="S4.T3.2.18.17.3.1" style="font-size:90%;">697</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.2.18.17.4"><span class="ltx_text" id="S4.T3.2.18.17.4.1" style="font-size:90%;">73</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.2.18.17.5"><span class="ltx_text" id="S4.T3.2.18.17.5.1" style="font-size:90%;">7.03</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.19.18">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T3.2.19.18.1"><span class="ltx_text" id="S4.T3.2.19.18.1.1" style="font-size:90%;">NanoSAM</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.19.18.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.19.18.2.1" style="font-size:90%;">0.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.19.18.3"><span class="ltx_text" id="S4.T3.2.19.18.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.2.19.18.4"><span class="ltx_text" id="S4.T3.2.19.18.4.1" style="font-size:90%;">20</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T3.2.19.18.5"><span class="ltx_text ltx_font_bold" id="S4.T3.2.19.18.5.1" style="font-size:90%;">27.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Quantitative results of <span class="ltx_text ltx_font_bold" id="S4.T3.15.1">inference latency</span> of SegAny task and <span class="ltx_text ltx_font_bold" id="S4.T3.16.2">throughput</span> on COCO dataset. P.S. 1) We also report the GPU memory usage in first column when models are inferring on GPU; 2) SAMfast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib88" title=""><span class="ltx_text" style="font-size:90%;">88</span></a>]</cite> and NanoSAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib84" title=""><span class="ltx_text" style="font-size:90%;">84</span></a>]</cite> can not run on CPU environment.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.2.1.1.1"><span class="ltx_text" id="S4.T4.2.1.1.1.1" style="font-size:90%;">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.2.1.1.2"><span class="ltx_text" id="S4.T4.2.1.1.2.1" style="font-size:90%;">16*16 grid (ms)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.2.1.1.3"><span class="ltx_text" id="S4.T4.2.1.1.3.1" style="font-size:90%;">32*32 grid (ms)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.2.1.1.4"><span class="ltx_text" id="S4.T4.2.1.1.4.1" style="font-size:90%;">64*64 grid (ms)</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="S4.T4.2.1.1.5"><span class="ltx_text" id="S4.T4.2.1.1.5.1" style="font-size:90%;">other prompt strategies (ms)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.2.2.2.1"><span class="ltx_text" id="S4.T4.2.2.2.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.2.2"><span class="ltx_text" id="S4.T4.2.2.2.2.1" style="font-size:90%;">824</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.2.3"><span class="ltx_text" id="S4.T4.2.2.2.3.1" style="font-size:90%;">2269</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.2.2.2.4"><span class="ltx_text" id="S4.T4.2.2.2.4.1" style="font-size:90%;">8103</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.2.2.2.5"><span class="ltx_text" id="S4.T4.2.2.2.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.3.3.1"><span class="ltx_text" id="S4.T4.2.3.3.1.1" style="font-size:90%;">SAM-L</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.3.2"><span class="ltx_text" id="S4.T4.2.3.3.2.1" style="font-size:90%;">665</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.3.3"><span class="ltx_text" id="S4.T4.2.3.3.3.1" style="font-size:90%;">2053</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.3.3.4"><span class="ltx_text" id="S4.T4.2.3.3.4.1" style="font-size:90%;">7518</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.3.3.5"><span class="ltx_text" id="S4.T4.2.3.3.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.4.4.1"><span class="ltx_text" id="S4.T4.2.4.4.1.1" style="font-size:90%;">SAM-B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.4.4.2"><span class="ltx_text" id="S4.T4.2.4.4.2.1" style="font-size:90%;">422</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.4.4.3"><span class="ltx_text" id="S4.T4.2.4.4.3.1" style="font-size:90%;">1399</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.4.4.4"><span class="ltx_text" id="S4.T4.2.4.4.4.1" style="font-size:90%;">5417</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.4.4.5"><span class="ltx_text" id="S4.T4.2.4.4.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.5.5.1"><span class="ltx_text" id="S4.T4.2.5.5.1.1" style="font-size:90%;">SAMfast-H</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.5.5.2"><span class="ltx_text" id="S4.T4.2.5.5.2.1" style="font-size:90%;">315</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.5.5.3"><span class="ltx_text ltx_font_bold" id="S4.T4.2.5.5.3.1" style="font-size:90%;">848</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.5.5.4"><span class="ltx_text" id="S4.T4.2.5.5.4.1" style="font-size:90%;">OOM</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.5.5.5"><span class="ltx_text" id="S4.T4.2.5.5.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.6.6.1"><span class="ltx_text" id="S4.T4.2.6.6.1.1" style="font-size:90%;">SAM2-B+</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.6.6.2"><span class="ltx_text" id="S4.T4.2.6.6.2.1" style="font-size:90%;">442</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.6.6.3"><span class="ltx_text" id="S4.T4.2.6.6.3.1" style="font-size:90%;">1610</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.6.6.4"><span class="ltx_text" id="S4.T4.2.6.6.4.1" style="font-size:90%;">6356</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.6.6.5"><span class="ltx_text" id="S4.T4.2.6.6.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.7.7.1"><span class="ltx_text" id="S4.T4.2.7.7.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.7.7.2"><span class="ltx_text" id="S4.T4.2.7.7.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.7.7.3"><span class="ltx_text" id="S4.T4.2.7.7.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.7.7.4"><span class="ltx_text" id="S4.T4.2.7.7.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T4.2.7.7.5.1" style="font-size:90%;">106</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.8.8.1"><span class="ltx_text" id="S4.T4.2.8.8.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.8.8.2"><span class="ltx_text" id="S4.T4.2.8.8.2.1" style="font-size:90%;">347</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.8.8.3"><span class="ltx_text" id="S4.T4.2.8.8.3.1" style="font-size:90%;">1313</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.8.8.4"><span class="ltx_text" id="S4.T4.2.8.8.4.1" style="font-size:90%;">5022</span></td>
<td class="ltx_td ltx_nopad_r" id="S4.T4.2.8.8.5"></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.9.9.1"><span class="ltx_text" id="S4.T4.2.9.9.1.1" style="font-size:90%;">MobileSAMv2</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.9.9.2"><span class="ltx_text" id="S4.T4.2.9.9.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.9.9.3"><span class="ltx_text" id="S4.T4.2.9.9.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.9.9.4"><span class="ltx_text" id="S4.T4.2.9.9.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.9.9.5"><span class="ltx_text" id="S4.T4.2.9.9.5.1" style="font-size:90%;">173</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.10.10.1"><span class="ltx_text" id="S4.T4.2.10.10.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.10.10.2"><span class="ltx_text" id="S4.T4.2.10.10.2.1" style="font-size:90%;">404</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.10.10.3"><span class="ltx_text" id="S4.T4.2.10.10.3.1" style="font-size:90%;">1553</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.10.10.4"><span class="ltx_text" id="S4.T4.2.10.10.4.1" style="font-size:90%;">5877</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.10.10.5"><span class="ltx_text" id="S4.T4.2.10.10.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.11.11.1"><span class="ltx_text" id="S4.T4.2.11.11.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.11.11.2"><span class="ltx_text" id="S4.T4.2.11.11.2.1" style="font-size:90%;">753</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.11.11.3"><span class="ltx_text" id="S4.T4.2.11.11.3.1" style="font-size:90%;">1833</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.11.11.4"><span class="ltx_text" id="S4.T4.2.11.11.4.1" style="font-size:90%;">5670</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.11.11.5"><span class="ltx_text" id="S4.T4.2.11.11.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.12.12.1"><span class="ltx_text" id="S4.T4.2.12.12.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.12.12.2"><span class="ltx_text" id="S4.T4.2.12.12.2.1" style="font-size:90%;">1100</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.12.12.3"><span class="ltx_text" id="S4.T4.2.12.12.3.1" style="font-size:90%;">2290</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.12.12.4"><span class="ltx_text" id="S4.T4.2.12.12.4.1" style="font-size:90%;">6210</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.12.12.5"><span class="ltx_text" id="S4.T4.2.12.12.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.13.13.1"><span class="ltx_text" id="S4.T4.2.13.13.1.1" style="font-size:90%;">RepVit-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.13.13.2"><span class="ltx_text" id="S4.T4.2.13.13.2.1" style="font-size:90%;">512</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.13.13.3"><span class="ltx_text" id="S4.T4.2.13.13.3.1" style="font-size:90%;">1890</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.13.13.4"><span class="ltx_text" id="S4.T4.2.13.13.4.1" style="font-size:90%;">7437</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.13.13.5"><span class="ltx_text" id="S4.T4.2.13.13.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.14.14.1"><span class="ltx_text" id="S4.T4.2.14.14.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.14.14.2"><span class="ltx_text ltx_font_bold" id="S4.T4.2.14.14.2.1" style="font-size:90%;">258</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.14.14.3"><span class="ltx_text" id="S4.T4.2.14.14.3.1" style="font-size:90%;">1023</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.14.14.4"><span class="ltx_text ltx_font_bold" id="S4.T4.2.14.14.4.1" style="font-size:90%;">3938</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.14.14.5"><span class="ltx_text" id="S4.T4.2.14.14.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.15.15.1"><span class="ltx_text" id="S4.T4.2.15.15.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.15.15.2"><span class="ltx_text" id="S4.T4.2.15.15.2.1" style="font-size:90%;">432</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.15.15.3"><span class="ltx_text" id="S4.T4.2.15.15.3.1" style="font-size:90%;">1546</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.15.15.4"><span class="ltx_text" id="S4.T4.2.15.15.4.1" style="font-size:90%;">6094</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.15.15.5"><span class="ltx_text" id="S4.T4.2.15.15.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.16.16.1"><span class="ltx_text" id="S4.T4.2.16.16.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.16.16.2"><span class="ltx_text" id="S4.T4.2.16.16.2.1" style="font-size:90%;">400</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.16.16.3"><span class="ltx_text" id="S4.T4.2.16.16.3.1" style="font-size:90%;">1374</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.16.16.4"><span class="ltx_text" id="S4.T4.2.16.16.4.1" style="font-size:90%;">5213</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.16.16.5"><span class="ltx_text" id="S4.T4.2.16.16.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.17.17.1"><span class="ltx_text" id="S4.T4.2.17.17.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.17.17.2"><span class="ltx_text" id="S4.T4.2.17.17.2.1" style="font-size:90%;">385</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.17.17.3"><span class="ltx_text" id="S4.T4.2.17.17.3.1" style="font-size:90%;">1342</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.17.17.4"><span class="ltx_text" id="S4.T4.2.17.17.4.1" style="font-size:90%;">5148</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.17.17.5"><span class="ltx_text" id="S4.T4.2.17.17.5.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.18.18.1"><span class="ltx_text" id="S4.T4.2.18.18.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.18.18.2"><span class="ltx_text" id="S4.T4.2.18.18.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.18.18.3"><span class="ltx_text" id="S4.T4.2.18.18.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.18.18.4"><span class="ltx_text" id="S4.T4.2.18.18.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T4.2.18.18.5"><span class="ltx_text" id="S4.T4.2.18.18.5.1" style="font-size:90%;">776</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T4.2.19.19.1"><span class="ltx_text" id="S4.T4.2.19.19.1.1" style="font-size:90%;">Q-TinySAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.2.19.19.2"><span class="ltx_text" id="S4.T4.2.19.19.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.2.19.19.3"><span class="ltx_text" id="S4.T4.2.19.19.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.2.19.19.4"><span class="ltx_text" id="S4.T4.2.19.19.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T4.2.19.19.5"><span class="ltx_text" id="S4.T4.2.19.19.5.1" style="font-size:90%;">1318</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Quantitative results of <span class="ltx_text ltx_font_bold" id="S4.T4.7.1">inference latency</span> of SegEvery task with grid sampling in different scales or other efficient strategies. P.S. OOM denotes out-of-memory. </figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">For the SegEvery task, we report the mean time required to generate all masks for an image using different point grid sizes (16*16, 32*32, 64*64) or specialized sampling strategies. The results are presented in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T4" title="Table 4 ‣ 4.2 Efficiency Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>. With the default 32*32 grid, SAMfast-H demonstrates the highest efficiency, with a latency of 848 ms—more than twice as fast as SAM-H. EfficientViT-SAM-L0 performs best with the 16*16 and 64*64 grids, achieving latencies of 258 ms and 3938 ms, respectively.
Interestingly, we observe that EfficientSAM-S is slower than SAM-H when using lower grid densities, showing latencies of 1100 ms for the 16x16 grid and 2290 ms for the 32*32 grid. Models employing alternative sampling strategies demonstrate significant improvements in efficiency, particularly FastSAM, which records a latency of 196 ms, and MobileSAMv2, with a latency of 173 ms.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Accuracy Comparison</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In this subsection, we report the accuracy results of SAM and its variants on SegAny task (with point/box prompts) and instance segmentation task, respectively. We follow the evaluation framework in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite> and adapt it by introducing other evaluation modules to conduct a unified evaluation on variants.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.6.7.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T5.6.7.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S4.T5.6.7.1.2"><span class="ltx_text" id="S4.T5.6.7.1.2.1" style="font-size:90%;">COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T5.6.7.1.3"><span class="ltx_text" id="S4.T5.6.7.1.3.1" style="font-size:90%;">LVIS</span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T5.6.6.7"><span class="ltx_text" id="S4.T5.6.6.7.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.1.1.1"><math alttext="pt_{1}" class="ltx_Math" display="inline" id="S4.T5.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.m1.1a"><mrow id="S4.T5.1.1.1.m1.1.1" xref="S4.T5.1.1.1.m1.1.1.cmml"><mi id="S4.T5.1.1.1.m1.1.1.2" mathsize="90%" xref="S4.T5.1.1.1.m1.1.1.2.cmml">p</mi><mo id="S4.T5.1.1.1.m1.1.1.1" xref="S4.T5.1.1.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.1.1.1.m1.1.1.3" xref="S4.T5.1.1.1.m1.1.1.3.cmml"><mi id="S4.T5.1.1.1.m1.1.1.3.2" mathsize="90%" xref="S4.T5.1.1.1.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.1.1.1.m1.1.1.3.3" mathsize="90%" xref="S4.T5.1.1.1.m1.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1"><times id="S4.T5.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1.1"></times><ci id="S4.T5.1.1.1.m1.1.1.2.cmml" xref="S4.T5.1.1.1.m1.1.1.2">𝑝</ci><apply id="S4.T5.1.1.1.m1.1.1.3.cmml" xref="S4.T5.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.1.1.1.m1.1.1.3.1.cmml" xref="S4.T5.1.1.1.m1.1.1.3">subscript</csymbol><ci id="S4.T5.1.1.1.m1.1.1.3.2.cmml" xref="S4.T5.1.1.1.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.1.1.1.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.1.1.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">pt_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.m1.1d">italic_p italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.2.2.2">
<span class="ltx_text" id="S4.T5.2.2.2.1" style="font-size:90%;">1*</span><math alttext="pt_{2}" class="ltx_Math" display="inline" id="S4.T5.2.2.2.m1.1"><semantics id="S4.T5.2.2.2.m1.1a"><mrow id="S4.T5.2.2.2.m1.1.1" xref="S4.T5.2.2.2.m1.1.1.cmml"><mi id="S4.T5.2.2.2.m1.1.1.2" mathsize="90%" xref="S4.T5.2.2.2.m1.1.1.2.cmml">p</mi><mo id="S4.T5.2.2.2.m1.1.1.1" xref="S4.T5.2.2.2.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.2.2.2.m1.1.1.3" xref="S4.T5.2.2.2.m1.1.1.3.cmml"><mi id="S4.T5.2.2.2.m1.1.1.3.2" mathsize="90%" xref="S4.T5.2.2.2.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.2.2.2.m1.1.1.3.3" mathsize="90%" xref="S4.T5.2.2.2.m1.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m1.1b"><apply id="S4.T5.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1"><times id="S4.T5.2.2.2.m1.1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1.1"></times><ci id="S4.T5.2.2.2.m1.1.1.2.cmml" xref="S4.T5.2.2.2.m1.1.1.2">𝑝</ci><apply id="S4.T5.2.2.2.m1.1.1.3.cmml" xref="S4.T5.2.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.2.2.2.m1.1.1.3.1.cmml" xref="S4.T5.2.2.2.m1.1.1.3">subscript</csymbol><ci id="S4.T5.2.2.2.m1.1.1.3.2.cmml" xref="S4.T5.2.2.2.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.2.2.2.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.2.2.2.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.m1.1c">pt_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.m1.1d">italic_p italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T5.3.3.3">
<span class="ltx_text" id="S4.T5.3.3.3.1" style="font-size:90%;">3*</span><math alttext="pt_{2}" class="ltx_Math" display="inline" id="S4.T5.3.3.3.m1.1"><semantics id="S4.T5.3.3.3.m1.1a"><mrow id="S4.T5.3.3.3.m1.1.1" xref="S4.T5.3.3.3.m1.1.1.cmml"><mi id="S4.T5.3.3.3.m1.1.1.2" mathsize="90%" xref="S4.T5.3.3.3.m1.1.1.2.cmml">p</mi><mo id="S4.T5.3.3.3.m1.1.1.1" xref="S4.T5.3.3.3.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.3.3.3.m1.1.1.3" xref="S4.T5.3.3.3.m1.1.1.3.cmml"><mi id="S4.T5.3.3.3.m1.1.1.3.2" mathsize="90%" xref="S4.T5.3.3.3.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.3.3.3.m1.1.1.3.3" mathsize="90%" xref="S4.T5.3.3.3.m1.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><apply id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1"><times id="S4.T5.3.3.3.m1.1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1.1"></times><ci id="S4.T5.3.3.3.m1.1.1.2.cmml" xref="S4.T5.3.3.3.m1.1.1.2">𝑝</ci><apply id="S4.T5.3.3.3.m1.1.1.3.cmml" xref="S4.T5.3.3.3.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.3.3.3.m1.1.1.3.1.cmml" xref="S4.T5.3.3.3.m1.1.1.3">subscript</csymbol><ci id="S4.T5.3.3.3.m1.1.1.3.2.cmml" xref="S4.T5.3.3.3.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.3.3.3.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.3.3.3.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">pt_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.m1.1d">italic_p italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.4.4.4"><math alttext="pt_{1}" class="ltx_Math" display="inline" id="S4.T5.4.4.4.m1.1"><semantics id="S4.T5.4.4.4.m1.1a"><mrow id="S4.T5.4.4.4.m1.1.1" xref="S4.T5.4.4.4.m1.1.1.cmml"><mi id="S4.T5.4.4.4.m1.1.1.2" mathsize="90%" xref="S4.T5.4.4.4.m1.1.1.2.cmml">p</mi><mo id="S4.T5.4.4.4.m1.1.1.1" xref="S4.T5.4.4.4.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.4.4.4.m1.1.1.3" xref="S4.T5.4.4.4.m1.1.1.3.cmml"><mi id="S4.T5.4.4.4.m1.1.1.3.2" mathsize="90%" xref="S4.T5.4.4.4.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.4.4.4.m1.1.1.3.3" mathsize="90%" xref="S4.T5.4.4.4.m1.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.m1.1b"><apply id="S4.T5.4.4.4.m1.1.1.cmml" xref="S4.T5.4.4.4.m1.1.1"><times id="S4.T5.4.4.4.m1.1.1.1.cmml" xref="S4.T5.4.4.4.m1.1.1.1"></times><ci id="S4.T5.4.4.4.m1.1.1.2.cmml" xref="S4.T5.4.4.4.m1.1.1.2">𝑝</ci><apply id="S4.T5.4.4.4.m1.1.1.3.cmml" xref="S4.T5.4.4.4.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.4.4.4.m1.1.1.3.1.cmml" xref="S4.T5.4.4.4.m1.1.1.3">subscript</csymbol><ci id="S4.T5.4.4.4.m1.1.1.3.2.cmml" xref="S4.T5.4.4.4.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.4.4.4.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.4.4.4.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.4.m1.1c">pt_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.4.4.4.m1.1d">italic_p italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.5.5.5">
<span class="ltx_text" id="S4.T5.5.5.5.1" style="font-size:90%;">1*</span><math alttext="pt_{2}" class="ltx_Math" display="inline" id="S4.T5.5.5.5.m1.1"><semantics id="S4.T5.5.5.5.m1.1a"><mrow id="S4.T5.5.5.5.m1.1.1" xref="S4.T5.5.5.5.m1.1.1.cmml"><mi id="S4.T5.5.5.5.m1.1.1.2" mathsize="90%" xref="S4.T5.5.5.5.m1.1.1.2.cmml">p</mi><mo id="S4.T5.5.5.5.m1.1.1.1" xref="S4.T5.5.5.5.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.5.5.5.m1.1.1.3" xref="S4.T5.5.5.5.m1.1.1.3.cmml"><mi id="S4.T5.5.5.5.m1.1.1.3.2" mathsize="90%" xref="S4.T5.5.5.5.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.5.5.5.m1.1.1.3.3" mathsize="90%" xref="S4.T5.5.5.5.m1.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.5.m1.1b"><apply id="S4.T5.5.5.5.m1.1.1.cmml" xref="S4.T5.5.5.5.m1.1.1"><times id="S4.T5.5.5.5.m1.1.1.1.cmml" xref="S4.T5.5.5.5.m1.1.1.1"></times><ci id="S4.T5.5.5.5.m1.1.1.2.cmml" xref="S4.T5.5.5.5.m1.1.1.2">𝑝</ci><apply id="S4.T5.5.5.5.m1.1.1.3.cmml" xref="S4.T5.5.5.5.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.5.5.5.m1.1.1.3.1.cmml" xref="S4.T5.5.5.5.m1.1.1.3">subscript</csymbol><ci id="S4.T5.5.5.5.m1.1.1.3.2.cmml" xref="S4.T5.5.5.5.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.5.5.5.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.5.5.5.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.5.m1.1c">pt_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.5.5.5.m1.1d">italic_p italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T5.6.6.6">
<span class="ltx_text" id="S4.T5.6.6.6.1" style="font-size:90%;">3*</span><math alttext="pt_{2}" class="ltx_Math" display="inline" id="S4.T5.6.6.6.m1.1"><semantics id="S4.T5.6.6.6.m1.1a"><mrow id="S4.T5.6.6.6.m1.1.1" xref="S4.T5.6.6.6.m1.1.1.cmml"><mi id="S4.T5.6.6.6.m1.1.1.2" mathsize="90%" xref="S4.T5.6.6.6.m1.1.1.2.cmml">p</mi><mo id="S4.T5.6.6.6.m1.1.1.1" xref="S4.T5.6.6.6.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.6.6.6.m1.1.1.3" xref="S4.T5.6.6.6.m1.1.1.3.cmml"><mi id="S4.T5.6.6.6.m1.1.1.3.2" mathsize="90%" xref="S4.T5.6.6.6.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.6.6.6.m1.1.1.3.3" mathsize="90%" xref="S4.T5.6.6.6.m1.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.6.m1.1b"><apply id="S4.T5.6.6.6.m1.1.1.cmml" xref="S4.T5.6.6.6.m1.1.1"><times id="S4.T5.6.6.6.m1.1.1.1.cmml" xref="S4.T5.6.6.6.m1.1.1.1"></times><ci id="S4.T5.6.6.6.m1.1.1.2.cmml" xref="S4.T5.6.6.6.m1.1.1.2">𝑝</ci><apply id="S4.T5.6.6.6.m1.1.1.3.cmml" xref="S4.T5.6.6.6.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.6.6.6.m1.1.1.3.1.cmml" xref="S4.T5.6.6.6.m1.1.1.3">subscript</csymbol><ci id="S4.T5.6.6.6.m1.1.1.3.2.cmml" xref="S4.T5.6.6.6.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.6.6.6.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.6.6.6.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.6.m1.1c">pt_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.6.6.6.m1.1d">italic_p italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.6.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.6.8.1.1"><span class="ltx_text" id="S4.T5.6.8.1.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.6.8.1.2"><span class="ltx_text" id="S4.T5.6.8.1.2.1" style="font-size:90%;">53.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.6.8.1.3"><span class="ltx_text" id="S4.T5.6.8.1.3.1" style="font-size:90%;">55.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.6.8.1.4"><span class="ltx_text" id="S4.T5.6.8.1.4.1" style="font-size:90%;">67.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.6.8.1.5"><span class="ltx_text" id="S4.T5.6.8.1.5.1" style="font-size:90%;">60</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.6.8.1.6"><span class="ltx_text" id="S4.T5.6.8.1.6.1" style="font-size:90%;">59.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.6.8.1.7"><span class="ltx_text" id="S4.T5.6.8.1.7.1" style="font-size:90%;">65.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.9.2.1"><span class="ltx_text" id="S4.T5.6.9.2.1.1" style="font-size:90%;">SAMfast-H</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.9.2.2"><span class="ltx_text" id="S4.T5.6.9.2.2.1" style="font-size:90%;">52.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.9.2.3"><span class="ltx_text" id="S4.T5.6.9.2.3.1" style="font-size:90%;">54.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.9.2.4"><span class="ltx_text" id="S4.T5.6.9.2.4.1" style="font-size:90%;">67.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.9.2.5"><span class="ltx_text ltx_font_bold" id="S4.T5.6.9.2.5.1" style="font-size:90%;">53.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.9.2.6"><span class="ltx_text ltx_font_bold" id="S4.T5.6.9.2.6.1" style="font-size:90%;">57.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.9.2.7"><span class="ltx_text" id="S4.T5.6.9.2.7.1" style="font-size:90%;">60.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.10.3.1"><span class="ltx_text" id="S4.T5.6.10.3.1.1" style="font-size:90%;">SAM2-B+</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.10.3.2"><span class="ltx_text ltx_font_bold" id="S4.T5.6.10.3.2.1" style="font-size:90%;">54.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.10.3.3"><span class="ltx_text" id="S4.T5.6.10.3.3.1" style="font-size:90%;">54.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.10.3.4"><span class="ltx_text" id="S4.T5.6.10.3.4.1" style="font-size:90%;">68.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.10.3.5"><span class="ltx_text" id="S4.T5.6.10.3.5.1" style="font-size:90%;">53.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.10.3.6"><span class="ltx_text" id="S4.T5.6.10.3.6.1" style="font-size:90%;">55.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.10.3.7"><span class="ltx_text" id="S4.T5.6.10.3.7.1" style="font-size:90%;">62.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.11.4.1"><span class="ltx_text" id="S4.T5.6.11.4.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.11.4.2"><span class="ltx_text" id="S4.T5.6.11.4.2.1" style="font-size:90%;">46.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.11.4.3"><span class="ltx_text" id="S4.T5.6.11.4.3.1" style="font-size:90%;">47.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.11.4.4"><span class="ltx_text" id="S4.T5.6.11.4.4.1" style="font-size:90%;">48.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.11.4.5"><span class="ltx_text" id="S4.T5.6.11.4.5.1" style="font-size:90%;">28.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.11.4.6"><span class="ltx_text" id="S4.T5.6.11.4.6.1" style="font-size:90%;">29.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.11.4.7"><span class="ltx_text" id="S4.T5.6.11.4.7.1" style="font-size:90%;">29.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.12.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.12.5.1"><span class="ltx_text" id="S4.T5.6.12.5.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.12.5.2"><span class="ltx_text" id="S4.T5.6.12.5.2.1" style="font-size:90%;">48.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.12.5.3"><span class="ltx_text" id="S4.T5.6.12.5.3.1" style="font-size:90%;">49.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.12.5.4"><span class="ltx_text" id="S4.T5.6.12.5.4.1" style="font-size:90%;">59.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.12.5.5"><span class="ltx_text" id="S4.T5.6.12.5.5.1" style="font-size:90%;">45.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.12.5.6"><span class="ltx_text" id="S4.T5.6.12.5.6.1" style="font-size:90%;">47.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.12.5.7"><span class="ltx_text" id="S4.T5.6.12.5.7.1" style="font-size:90%;">50.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.13.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.13.6.1"><span class="ltx_text" id="S4.T5.6.13.6.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.13.6.2"><span class="ltx_text" id="S4.T5.6.13.6.2.1" style="font-size:90%;">47.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.13.6.3"><span class="ltx_text" id="S4.T5.6.13.6.3.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.13.6.4"><span class="ltx_text" id="S4.T5.6.13.6.4.1" style="font-size:90%;">61.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.13.6.5"><span class="ltx_text" id="S4.T5.6.13.6.5.1" style="font-size:90%;">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.13.6.6"><span class="ltx_text" id="S4.T5.6.13.6.6.1" style="font-size:90%;">46.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.13.6.7"><span class="ltx_text" id="S4.T5.6.13.6.7.1" style="font-size:90%;">54.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.14.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.14.7.1"><span class="ltx_text" id="S4.T5.6.14.7.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.14.7.2"><span class="ltx_text" id="S4.T5.6.14.7.2.1" style="font-size:90%;">43.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.14.7.3"><span class="ltx_text" id="S4.T5.6.14.7.3.1" style="font-size:90%;">44.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.14.7.4"><span class="ltx_text" id="S4.T5.6.14.7.4.1" style="font-size:90%;">61.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.14.7.5"><span class="ltx_text" id="S4.T5.6.14.7.5.1" style="font-size:90%;">25.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.14.7.6"><span class="ltx_text" id="S4.T5.6.14.7.6.1" style="font-size:90%;">26.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.14.7.7"><span class="ltx_text" id="S4.T5.6.14.7.7.1" style="font-size:90%;">52.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.15.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.15.8.1"><span class="ltx_text" id="S4.T5.6.15.8.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.15.8.2"><span class="ltx_text" id="S4.T5.6.15.8.2.1" style="font-size:90%;">41.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.15.8.3"><span class="ltx_text" id="S4.T5.6.15.8.3.1" style="font-size:90%;">39.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.15.8.4"><span class="ltx_text" id="S4.T5.6.15.8.4.1" style="font-size:90%;">60.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.15.8.5"><span class="ltx_text" id="S4.T5.6.15.8.5.1" style="font-size:90%;">52.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.15.8.6"><span class="ltx_text" id="S4.T5.6.15.8.6.1" style="font-size:90%;">53.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.15.8.7"><span class="ltx_text ltx_font_bold" id="S4.T5.6.15.8.7.1" style="font-size:90%;">66.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.16.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.16.9.1"><span class="ltx_text" id="S4.T5.6.16.9.1.1" style="font-size:90%;">RepViT-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.16.9.2"><span class="ltx_text" id="S4.T5.6.16.9.2.1" style="font-size:90%;">50.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.16.9.3"><span class="ltx_text" id="S4.T5.6.16.9.3.1" style="font-size:90%;">51.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.16.9.4"><span class="ltx_text" id="S4.T5.6.16.9.4.1" style="font-size:90%;">63.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.16.9.5"><span class="ltx_text" id="S4.T5.6.16.9.5.1" style="font-size:90%;">51.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.16.9.6"><span class="ltx_text" id="S4.T5.6.16.9.6.1" style="font-size:90%;">51.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.16.9.7"><span class="ltx_text" id="S4.T5.6.16.9.7.1" style="font-size:90%;">54.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.17.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.17.10.1"><span class="ltx_text" id="S4.T5.6.17.10.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.17.10.2"><span class="ltx_text" id="S4.T5.6.17.10.2.1" style="font-size:90%;">50.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.17.10.3"><span class="ltx_text" id="S4.T5.6.17.10.3.1" style="font-size:90%;">50.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.17.10.4"><span class="ltx_text" id="S4.T5.6.17.10.4.1" style="font-size:90%;">67.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.17.10.5"><span class="ltx_text" id="S4.T5.6.17.10.5.1" style="font-size:90%;">46.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.17.10.6"><span class="ltx_text" id="S4.T5.6.17.10.6.1" style="font-size:90%;">48.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.17.10.7"><span class="ltx_text" id="S4.T5.6.17.10.7.1" style="font-size:90%;">63.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.18.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.18.11.1"><span class="ltx_text" id="S4.T5.6.18.11.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.18.11.2"><span class="ltx_text ltx_font_bold" id="S4.T5.6.18.11.2.1" style="font-size:90%;">54.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.18.11.3"><span class="ltx_text ltx_font_bold" id="S4.T5.6.18.11.3.1" style="font-size:90%;">55.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.18.11.4"><span class="ltx_text ltx_font_bold" id="S4.T5.6.18.11.4.1" style="font-size:90%;">70.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.18.11.5"><span class="ltx_text" id="S4.T5.6.18.11.5.1" style="font-size:90%;">53.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.18.11.6"><span class="ltx_text" id="S4.T5.6.18.11.6.1" style="font-size:90%;">54.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.18.11.7"><span class="ltx_text" id="S4.T5.6.18.11.7.1" style="font-size:90%;">65.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.19.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.19.12.1"><span class="ltx_text" id="S4.T5.6.19.12.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.19.12.2"><span class="ltx_text" id="S4.T5.6.19.12.2.1" style="font-size:90%;">48.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.19.12.3"><span class="ltx_text" id="S4.T5.6.19.12.3.1" style="font-size:90%;">48.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.19.12.4"><span class="ltx_text" id="S4.T5.6.19.12.4.1" style="font-size:90%;">63.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.19.12.5"><span class="ltx_text" id="S4.T5.6.19.12.5.1" style="font-size:90%;">51.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.19.12.6"><span class="ltx_text" id="S4.T5.6.19.12.6.1" style="font-size:90%;">53.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.19.12.7"><span class="ltx_text" id="S4.T5.6.19.12.7.1" style="font-size:90%;">58.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.20.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.20.13.1"><span class="ltx_text" id="S4.T5.6.20.13.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.20.13.2"><span class="ltx_text" id="S4.T5.6.20.13.2.1" style="font-size:90%;">47.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.20.13.3"><span class="ltx_text" id="S4.T5.6.20.13.3.1" style="font-size:90%;">47.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.20.13.4"><span class="ltx_text" id="S4.T5.6.20.13.4.1" style="font-size:90%;">61.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.20.13.5"><span class="ltx_text" id="S4.T5.6.20.13.5.1" style="font-size:90%;">48.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.20.13.6"><span class="ltx_text" id="S4.T5.6.20.13.6.1" style="font-size:90%;">50.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.20.13.7"><span class="ltx_text" id="S4.T5.6.20.13.7.1" style="font-size:90%;">55.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.21.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.6.21.14.1"><span class="ltx_text" id="S4.T5.6.21.14.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T5.6.21.14.2"><span class="ltx_text" id="S4.T5.6.21.14.2.1" style="font-size:90%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.21.14.3"><span class="ltx_text" id="S4.T5.6.21.14.3.1" style="font-size:90%;">42.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.6.21.14.4"><span class="ltx_text" id="S4.T5.6.21.14.4.1" style="font-size:90%;">65.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.21.14.5"><span class="ltx_text" id="S4.T5.6.21.14.5.1" style="font-size:90%;">50.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.6.21.14.6"><span class="ltx_text" id="S4.T5.6.21.14.6.1" style="font-size:90%;">51.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.6.21.14.7"><span class="ltx_text" id="S4.T5.6.21.14.7.1" style="font-size:90%;">60.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.22.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T5.6.22.15.1"><span class="ltx_text" id="S4.T5.6.22.15.1.1" style="font-size:90%;">NanoSAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.6.22.15.2"><span class="ltx_text" id="S4.T5.6.22.15.2.1" style="font-size:90%;">44.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.6.22.15.3"><span class="ltx_text" id="S4.T5.6.22.15.3.1" style="font-size:90%;">42.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T5.6.22.15.4"><span class="ltx_text" id="S4.T5.6.22.15.4.1" style="font-size:90%;">56.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.6.22.15.5"><span class="ltx_text" id="S4.T5.6.22.15.5.1" style="font-size:90%;">42.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.6.22.15.6"><span class="ltx_text" id="S4.T5.6.22.15.6.1" style="font-size:90%;">41.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T5.6.22.15.7"><span class="ltx_text" id="S4.T5.6.22.15.7.1" style="font-size:90%;">48.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>The <span class="ltx_text ltx_font_bold" id="S4.T5.18.1">mIoU</span> results on COCO and LVIS with points as prompts. P.S. <math alttext="pt_{1}" class="ltx_Math" display="inline" id="S4.T5.9.m1.1"><semantics id="S4.T5.9.m1.1b"><mrow id="S4.T5.9.m1.1.1" xref="S4.T5.9.m1.1.1.cmml"><mi id="S4.T5.9.m1.1.1.2" xref="S4.T5.9.m1.1.1.2.cmml">p</mi><mo id="S4.T5.9.m1.1.1.1" xref="S4.T5.9.m1.1.1.1.cmml">⁢</mo><msub id="S4.T5.9.m1.1.1.3" xref="S4.T5.9.m1.1.1.3.cmml"><mi id="S4.T5.9.m1.1.1.3.2" xref="S4.T5.9.m1.1.1.3.2.cmml">t</mi><mn id="S4.T5.9.m1.1.1.3.3" xref="S4.T5.9.m1.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.9.m1.1c"><apply id="S4.T5.9.m1.1.1.cmml" xref="S4.T5.9.m1.1.1"><times id="S4.T5.9.m1.1.1.1.cmml" xref="S4.T5.9.m1.1.1.1"></times><ci id="S4.T5.9.m1.1.1.2.cmml" xref="S4.T5.9.m1.1.1.2">𝑝</ci><apply id="S4.T5.9.m1.1.1.3.cmml" xref="S4.T5.9.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T5.9.m1.1.1.3.1.cmml" xref="S4.T5.9.m1.1.1.3">subscript</csymbol><ci id="S4.T5.9.m1.1.1.3.2.cmml" xref="S4.T5.9.m1.1.1.3.2">𝑡</ci><cn id="S4.T5.9.m1.1.1.3.3.cmml" type="integer" xref="S4.T5.9.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.m1.1d">pt_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.9.m1.1e">italic_p italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> denotes the center point of the ground truth bounding box and <math alttext="pt_{2}" class="ltx_Math" display="inline" id="S4.T5.10.m2.1"><semantics id="S4.T5.10.m2.1b"><mrow id="S4.T5.10.m2.1.1" xref="S4.T5.10.m2.1.1.cmml"><mi id="S4.T5.10.m2.1.1.2" xref="S4.T5.10.m2.1.1.2.cmml">p</mi><mo id="S4.T5.10.m2.1.1.1" xref="S4.T5.10.m2.1.1.1.cmml">⁢</mo><msub id="S4.T5.10.m2.1.1.3" xref="S4.T5.10.m2.1.1.3.cmml"><mi id="S4.T5.10.m2.1.1.3.2" xref="S4.T5.10.m2.1.1.3.2.cmml">t</mi><mn id="S4.T5.10.m2.1.1.3.3" xref="S4.T5.10.m2.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.10.m2.1c"><apply id="S4.T5.10.m2.1.1.cmml" xref="S4.T5.10.m2.1.1"><times id="S4.T5.10.m2.1.1.1.cmml" xref="S4.T5.10.m2.1.1.1"></times><ci id="S4.T5.10.m2.1.1.2.cmml" xref="S4.T5.10.m2.1.1.2">𝑝</ci><apply id="S4.T5.10.m2.1.1.3.cmml" xref="S4.T5.10.m2.1.1.3"><csymbol cd="ambiguous" id="S4.T5.10.m2.1.1.3.1.cmml" xref="S4.T5.10.m2.1.1.3">subscript</csymbol><ci id="S4.T5.10.m2.1.1.3.2.cmml" xref="S4.T5.10.m2.1.1.3.2">𝑡</ci><cn id="S4.T5.10.m2.1.1.3.3.cmml" type="integer" xref="S4.T5.10.m2.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.m2.1d">pt_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T5.10.m2.1e">italic_p italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> denotes points randomly sampled from ground truth masks.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.4.5.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.4.5.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S4.T6.4.5.1.2"><span class="ltx_text" id="S4.T6.4.5.1.2.1" style="font-size:90%;">COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T6.4.5.1.3"><span class="ltx_text" id="S4.T6.4.5.1.3.1" style="font-size:90%;">LVIS</span></th>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T6.4.4.5"><span class="ltx_text" id="S4.T6.4.4.5.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T6.1.1.1"><math alttext="box_{1}" class="ltx_Math" display="inline" id="S4.T6.1.1.1.m1.1"><semantics id="S4.T6.1.1.1.m1.1a"><mrow id="S4.T6.1.1.1.m1.1.1" xref="S4.T6.1.1.1.m1.1.1.cmml"><mi id="S4.T6.1.1.1.m1.1.1.2" mathsize="90%" xref="S4.T6.1.1.1.m1.1.1.2.cmml">b</mi><mo id="S4.T6.1.1.1.m1.1.1.1" xref="S4.T6.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.T6.1.1.1.m1.1.1.3" mathsize="90%" xref="S4.T6.1.1.1.m1.1.1.3.cmml">o</mi><mo id="S4.T6.1.1.1.m1.1.1.1a" xref="S4.T6.1.1.1.m1.1.1.1.cmml">⁢</mo><msub id="S4.T6.1.1.1.m1.1.1.4" xref="S4.T6.1.1.1.m1.1.1.4.cmml"><mi id="S4.T6.1.1.1.m1.1.1.4.2" mathsize="90%" xref="S4.T6.1.1.1.m1.1.1.4.2.cmml">x</mi><mn id="S4.T6.1.1.1.m1.1.1.4.3" mathsize="90%" xref="S4.T6.1.1.1.m1.1.1.4.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.m1.1b"><apply id="S4.T6.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1"><times id="S4.T6.1.1.1.m1.1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1.1"></times><ci id="S4.T6.1.1.1.m1.1.1.2.cmml" xref="S4.T6.1.1.1.m1.1.1.2">𝑏</ci><ci id="S4.T6.1.1.1.m1.1.1.3.cmml" xref="S4.T6.1.1.1.m1.1.1.3">𝑜</ci><apply id="S4.T6.1.1.1.m1.1.1.4.cmml" xref="S4.T6.1.1.1.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.1.1.1.m1.1.1.4.1.cmml" xref="S4.T6.1.1.1.m1.1.1.4">subscript</csymbol><ci id="S4.T6.1.1.1.m1.1.1.4.2.cmml" xref="S4.T6.1.1.1.m1.1.1.4.2">𝑥</ci><cn id="S4.T6.1.1.1.m1.1.1.4.3.cmml" type="integer" xref="S4.T6.1.1.1.m1.1.1.4.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.m1.1c">box_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T6.1.1.1.m1.1d">italic_b italic_o italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T6.2.2.2"><math alttext="box_{2}" class="ltx_Math" display="inline" id="S4.T6.2.2.2.m1.1"><semantics id="S4.T6.2.2.2.m1.1a"><mrow id="S4.T6.2.2.2.m1.1.1" xref="S4.T6.2.2.2.m1.1.1.cmml"><mi id="S4.T6.2.2.2.m1.1.1.2" mathsize="90%" xref="S4.T6.2.2.2.m1.1.1.2.cmml">b</mi><mo id="S4.T6.2.2.2.m1.1.1.1" xref="S4.T6.2.2.2.m1.1.1.1.cmml">⁢</mo><mi id="S4.T6.2.2.2.m1.1.1.3" mathsize="90%" xref="S4.T6.2.2.2.m1.1.1.3.cmml">o</mi><mo id="S4.T6.2.2.2.m1.1.1.1a" xref="S4.T6.2.2.2.m1.1.1.1.cmml">⁢</mo><msub id="S4.T6.2.2.2.m1.1.1.4" xref="S4.T6.2.2.2.m1.1.1.4.cmml"><mi id="S4.T6.2.2.2.m1.1.1.4.2" mathsize="90%" xref="S4.T6.2.2.2.m1.1.1.4.2.cmml">x</mi><mn id="S4.T6.2.2.2.m1.1.1.4.3" mathsize="90%" xref="S4.T6.2.2.2.m1.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.m1.1b"><apply id="S4.T6.2.2.2.m1.1.1.cmml" xref="S4.T6.2.2.2.m1.1.1"><times id="S4.T6.2.2.2.m1.1.1.1.cmml" xref="S4.T6.2.2.2.m1.1.1.1"></times><ci id="S4.T6.2.2.2.m1.1.1.2.cmml" xref="S4.T6.2.2.2.m1.1.1.2">𝑏</ci><ci id="S4.T6.2.2.2.m1.1.1.3.cmml" xref="S4.T6.2.2.2.m1.1.1.3">𝑜</ci><apply id="S4.T6.2.2.2.m1.1.1.4.cmml" xref="S4.T6.2.2.2.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.2.2.2.m1.1.1.4.1.cmml" xref="S4.T6.2.2.2.m1.1.1.4">subscript</csymbol><ci id="S4.T6.2.2.2.m1.1.1.4.2.cmml" xref="S4.T6.2.2.2.m1.1.1.4.2">𝑥</ci><cn id="S4.T6.2.2.2.m1.1.1.4.3.cmml" type="integer" xref="S4.T6.2.2.2.m1.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.m1.1c">box_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T6.2.2.2.m1.1d">italic_b italic_o italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T6.3.3.3"><math alttext="box_{1}" class="ltx_Math" display="inline" id="S4.T6.3.3.3.m1.1"><semantics id="S4.T6.3.3.3.m1.1a"><mrow id="S4.T6.3.3.3.m1.1.1" xref="S4.T6.3.3.3.m1.1.1.cmml"><mi id="S4.T6.3.3.3.m1.1.1.2" mathsize="90%" xref="S4.T6.3.3.3.m1.1.1.2.cmml">b</mi><mo id="S4.T6.3.3.3.m1.1.1.1" xref="S4.T6.3.3.3.m1.1.1.1.cmml">⁢</mo><mi id="S4.T6.3.3.3.m1.1.1.3" mathsize="90%" xref="S4.T6.3.3.3.m1.1.1.3.cmml">o</mi><mo id="S4.T6.3.3.3.m1.1.1.1a" xref="S4.T6.3.3.3.m1.1.1.1.cmml">⁢</mo><msub id="S4.T6.3.3.3.m1.1.1.4" xref="S4.T6.3.3.3.m1.1.1.4.cmml"><mi id="S4.T6.3.3.3.m1.1.1.4.2" mathsize="90%" xref="S4.T6.3.3.3.m1.1.1.4.2.cmml">x</mi><mn id="S4.T6.3.3.3.m1.1.1.4.3" mathsize="90%" xref="S4.T6.3.3.3.m1.1.1.4.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.m1.1b"><apply id="S4.T6.3.3.3.m1.1.1.cmml" xref="S4.T6.3.3.3.m1.1.1"><times id="S4.T6.3.3.3.m1.1.1.1.cmml" xref="S4.T6.3.3.3.m1.1.1.1"></times><ci id="S4.T6.3.3.3.m1.1.1.2.cmml" xref="S4.T6.3.3.3.m1.1.1.2">𝑏</ci><ci id="S4.T6.3.3.3.m1.1.1.3.cmml" xref="S4.T6.3.3.3.m1.1.1.3">𝑜</ci><apply id="S4.T6.3.3.3.m1.1.1.4.cmml" xref="S4.T6.3.3.3.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.3.3.3.m1.1.1.4.1.cmml" xref="S4.T6.3.3.3.m1.1.1.4">subscript</csymbol><ci id="S4.T6.3.3.3.m1.1.1.4.2.cmml" xref="S4.T6.3.3.3.m1.1.1.4.2">𝑥</ci><cn id="S4.T6.3.3.3.m1.1.1.4.3.cmml" type="integer" xref="S4.T6.3.3.3.m1.1.1.4.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.m1.1c">box_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T6.3.3.3.m1.1d">italic_b italic_o italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T6.4.4.4"><math alttext="box_{2}" class="ltx_Math" display="inline" id="S4.T6.4.4.4.m1.1"><semantics id="S4.T6.4.4.4.m1.1a"><mrow id="S4.T6.4.4.4.m1.1.1" xref="S4.T6.4.4.4.m1.1.1.cmml"><mi id="S4.T6.4.4.4.m1.1.1.2" mathsize="90%" xref="S4.T6.4.4.4.m1.1.1.2.cmml">b</mi><mo id="S4.T6.4.4.4.m1.1.1.1" xref="S4.T6.4.4.4.m1.1.1.1.cmml">⁢</mo><mi id="S4.T6.4.4.4.m1.1.1.3" mathsize="90%" xref="S4.T6.4.4.4.m1.1.1.3.cmml">o</mi><mo id="S4.T6.4.4.4.m1.1.1.1a" xref="S4.T6.4.4.4.m1.1.1.1.cmml">⁢</mo><msub id="S4.T6.4.4.4.m1.1.1.4" xref="S4.T6.4.4.4.m1.1.1.4.cmml"><mi id="S4.T6.4.4.4.m1.1.1.4.2" mathsize="90%" xref="S4.T6.4.4.4.m1.1.1.4.2.cmml">x</mi><mn id="S4.T6.4.4.4.m1.1.1.4.3" mathsize="90%" xref="S4.T6.4.4.4.m1.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.4.m1.1b"><apply id="S4.T6.4.4.4.m1.1.1.cmml" xref="S4.T6.4.4.4.m1.1.1"><times id="S4.T6.4.4.4.m1.1.1.1.cmml" xref="S4.T6.4.4.4.m1.1.1.1"></times><ci id="S4.T6.4.4.4.m1.1.1.2.cmml" xref="S4.T6.4.4.4.m1.1.1.2">𝑏</ci><ci id="S4.T6.4.4.4.m1.1.1.3.cmml" xref="S4.T6.4.4.4.m1.1.1.3">𝑜</ci><apply id="S4.T6.4.4.4.m1.1.1.4.cmml" xref="S4.T6.4.4.4.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.4.4.4.m1.1.1.4.1.cmml" xref="S4.T6.4.4.4.m1.1.1.4">subscript</csymbol><ci id="S4.T6.4.4.4.m1.1.1.4.2.cmml" xref="S4.T6.4.4.4.m1.1.1.4.2">𝑥</ci><cn id="S4.T6.4.4.4.m1.1.1.4.3.cmml" type="integer" xref="S4.T6.4.4.4.m1.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.4.m1.1c">box_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T6.4.4.4.m1.1d">italic_b italic_o italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.4.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.4.6.1.1"><span class="ltx_text" id="S4.T6.4.6.1.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.6.1.2"><span class="ltx_text" id="S4.T6.4.6.1.2.1" style="font-size:90%;">77.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T6.4.6.1.3"><span class="ltx_text" id="S4.T6.4.6.1.3.1" style="font-size:90%;">77.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.6.1.4"><span class="ltx_text" id="S4.T6.4.6.1.4.1" style="font-size:90%;">78.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T6.4.6.1.5"><span class="ltx_text" id="S4.T6.4.6.1.5.1" style="font-size:90%;">79.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.7.2.1"><span class="ltx_text" id="S4.T6.4.7.2.1.1" style="font-size:90%;">SAMfast-H</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.7.2.2"><span class="ltx_text" id="S4.T6.4.7.2.2.1" style="font-size:90%;">77.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.7.2.3"><span class="ltx_text" id="S4.T6.4.7.2.3.1" style="font-size:90%;">77.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.7.2.4"><span class="ltx_text" id="S4.T6.4.7.2.4.1" style="font-size:90%;">77.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.7.2.5"><span class="ltx_text" id="S4.T6.4.7.2.5.1" style="font-size:90%;">78.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.8.3.1"><span class="ltx_text" id="S4.T6.4.8.3.1.1" style="font-size:90%;">SAM2-B+</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.8.3.2"><span class="ltx_text" id="S4.T6.4.8.3.2.1" style="font-size:90%;">75.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.8.3.3"><span class="ltx_text" id="S4.T6.4.8.3.3.1" style="font-size:90%;">76.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.8.3.4"><span class="ltx_text" id="S4.T6.4.8.3.4.1" style="font-size:90%;">70.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.8.3.5"><span class="ltx_text" id="S4.T6.4.8.3.5.1" style="font-size:90%;">72.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.9.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.9.4.1"><span class="ltx_text" id="S4.T6.4.9.4.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.9.4.2"><span class="ltx_text" id="S4.T6.4.9.4.2.1" style="font-size:90%;">60.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.9.4.3"><span class="ltx_text" id="S4.T6.4.9.4.3.1" style="font-size:90%;">60.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.9.4.4"><span class="ltx_text" id="S4.T6.4.9.4.4.1" style="font-size:90%;">50.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.9.4.5"><span class="ltx_text" id="S4.T6.4.9.4.5.1" style="font-size:90%;">50.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.10.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.10.5.1"><span class="ltx_text" id="S4.T6.4.10.5.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.10.5.2"><span class="ltx_text" id="S4.T6.4.10.5.2.1" style="font-size:90%;">73.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.10.5.3"><span class="ltx_text" id="S4.T6.4.10.5.3.1" style="font-size:90%;">74.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.10.5.4"><span class="ltx_text" id="S4.T6.4.10.5.4.1" style="font-size:90%;">74.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.10.5.5"><span class="ltx_text" id="S4.T6.4.10.5.5.1" style="font-size:90%;">74.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.11.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.11.6.1"><span class="ltx_text" id="S4.T6.4.11.6.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.11.6.2"><span class="ltx_text" id="S4.T6.4.11.6.2.1" style="font-size:90%;">75.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.11.6.3"><span class="ltx_text" id="S4.T6.4.11.6.3.1" style="font-size:90%;">76.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.11.6.4"><span class="ltx_text" id="S4.T6.4.11.6.4.1" style="font-size:90%;">74.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.11.6.5"><span class="ltx_text" id="S4.T6.4.11.6.5.1" style="font-size:90%;">74.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.12.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.12.7.1"><span class="ltx_text" id="S4.T6.4.12.7.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.12.7.2"><span class="ltx_text" id="S4.T6.4.12.7.2.1" style="font-size:90%;">72.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.12.7.3"><span class="ltx_text" id="S4.T6.4.12.7.3.1" style="font-size:90%;">73.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.12.7.4"><span class="ltx_text" id="S4.T6.4.12.7.4.1" style="font-size:90%;">72.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.12.7.5"><span class="ltx_text" id="S4.T6.4.12.7.5.1" style="font-size:90%;">74.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.13.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.13.8.1"><span class="ltx_text" id="S4.T6.4.13.8.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.13.8.2"><span class="ltx_text" id="S4.T6.4.13.8.2.1" style="font-size:90%;">69.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.13.8.3"><span class="ltx_text" id="S4.T6.4.13.8.3.1" style="font-size:90%;">69.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.13.8.4"><span class="ltx_text" id="S4.T6.4.13.8.4.1" style="font-size:90%;">74.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.13.8.5"><span class="ltx_text" id="S4.T6.4.13.8.5.1" style="font-size:90%;">75.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.14.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.14.9.1"><span class="ltx_text" id="S4.T6.4.14.9.1.1" style="font-size:90%;">RepViT-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.14.9.2"><span class="ltx_text" id="S4.T6.4.14.9.2.1" style="font-size:90%;">75.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.14.9.3"><span class="ltx_text" id="S4.T6.4.14.9.3.1" style="font-size:90%;">75.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.14.9.4"><span class="ltx_text" id="S4.T6.4.14.9.4.1" style="font-size:90%;">73.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.14.9.5"><span class="ltx_text" id="S4.T6.4.14.9.5.1" style="font-size:90%;">74.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.15.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.15.10.1"><span class="ltx_text" id="S4.T6.4.15.10.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.15.10.2"><span class="ltx_text" id="S4.T6.4.15.10.2.1" style="font-size:90%;">78.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.15.10.3"><span class="ltx_text" id="S4.T6.4.15.10.3.1" style="font-size:90%;">78.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.15.10.4"><span class="ltx_text" id="S4.T6.4.15.10.4.1" style="font-size:90%;">78.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.15.10.5"><span class="ltx_text" id="S4.T6.4.15.10.5.1" style="font-size:90%;">77.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.16.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.16.11.1"><span class="ltx_text" id="S4.T6.4.16.11.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.16.11.2"><span class="ltx_text ltx_font_bold" id="S4.T6.4.16.11.2.1" style="font-size:90%;">79.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.16.11.3"><span class="ltx_text ltx_font_bold" id="S4.T6.4.16.11.3.1" style="font-size:90%;">79.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.16.11.4"><span class="ltx_text ltx_font_bold" id="S4.T6.4.16.11.4.1" style="font-size:90%;">79.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.16.11.5"><span class="ltx_text ltx_font_bold" id="S4.T6.4.16.11.5.1" style="font-size:90%;">79.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.17.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.17.12.1"><span class="ltx_text" id="S4.T6.4.17.12.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.17.12.2"><span class="ltx_text" id="S4.T6.4.17.12.2.1" style="font-size:90%;">75.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.17.12.3"><span class="ltx_text" id="S4.T6.4.17.12.3.1" style="font-size:90%;">76.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.17.12.4"><span class="ltx_text" id="S4.T6.4.17.12.4.1" style="font-size:90%;">74.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.17.12.5"><span class="ltx_text" id="S4.T6.4.17.12.5.1" style="font-size:90%;">76.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.18.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.18.13.1"><span class="ltx_text" id="S4.T6.4.18.13.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.18.13.2"><span class="ltx_text" id="S4.T6.4.18.13.2.1" style="font-size:90%;">74.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.18.13.3"><span class="ltx_text" id="S4.T6.4.18.13.3.1" style="font-size:90%;">75.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.18.13.4"><span class="ltx_text" id="S4.T6.4.18.13.4.1" style="font-size:90%;">72.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.18.13.5"><span class="ltx_text" id="S4.T6.4.18.13.5.1" style="font-size:90%;">74.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.19.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.19.14.1"><span class="ltx_text" id="S4.T6.4.19.14.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.19.14.2"><span class="ltx_text" id="S4.T6.4.19.14.2.1" style="font-size:90%;">73.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T6.4.19.14.3"><span class="ltx_text" id="S4.T6.4.19.14.3.1" style="font-size:90%;">73.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.19.14.4"><span class="ltx_text" id="S4.T6.4.19.14.4.1" style="font-size:90%;">73.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T6.4.19.14.5"><span class="ltx_text" id="S4.T6.4.19.14.5.1" style="font-size:90%;">74.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.20.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T6.4.20.15.1"><span class="ltx_text" id="S4.T6.4.20.15.1.1" style="font-size:90%;">NanoSAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.20.15.2"><span class="ltx_text" id="S4.T6.4.20.15.2.1" style="font-size:90%;">69.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T6.4.20.15.3"><span class="ltx_text" id="S4.T6.4.20.15.3.1" style="font-size:90%;">70.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.20.15.4"><span class="ltx_text" id="S4.T6.4.20.15.4.1" style="font-size:90%;">65.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T6.4.20.15.5"><span class="ltx_text" id="S4.T6.4.20.15.5.1" style="font-size:90%;">66.5</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>The <span class="ltx_text ltx_font_bold" id="S4.T6.16.1">mIoU</span> results on COCO and LVIS with boxes as prompts. P.S. <math alttext="box_{1}" class="ltx_Math" display="inline" id="S4.T6.7.m1.1"><semantics id="S4.T6.7.m1.1b"><mrow id="S4.T6.7.m1.1.1" xref="S4.T6.7.m1.1.1.cmml"><mi id="S4.T6.7.m1.1.1.2" xref="S4.T6.7.m1.1.1.2.cmml">b</mi><mo id="S4.T6.7.m1.1.1.1" xref="S4.T6.7.m1.1.1.1.cmml">⁢</mo><mi id="S4.T6.7.m1.1.1.3" xref="S4.T6.7.m1.1.1.3.cmml">o</mi><mo id="S4.T6.7.m1.1.1.1b" xref="S4.T6.7.m1.1.1.1.cmml">⁢</mo><msub id="S4.T6.7.m1.1.1.4" xref="S4.T6.7.m1.1.1.4.cmml"><mi id="S4.T6.7.m1.1.1.4.2" xref="S4.T6.7.m1.1.1.4.2.cmml">x</mi><mn id="S4.T6.7.m1.1.1.4.3" xref="S4.T6.7.m1.1.1.4.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.7.m1.1c"><apply id="S4.T6.7.m1.1.1.cmml" xref="S4.T6.7.m1.1.1"><times id="S4.T6.7.m1.1.1.1.cmml" xref="S4.T6.7.m1.1.1.1"></times><ci id="S4.T6.7.m1.1.1.2.cmml" xref="S4.T6.7.m1.1.1.2">𝑏</ci><ci id="S4.T6.7.m1.1.1.3.cmml" xref="S4.T6.7.m1.1.1.3">𝑜</ci><apply id="S4.T6.7.m1.1.1.4.cmml" xref="S4.T6.7.m1.1.1.4"><csymbol cd="ambiguous" id="S4.T6.7.m1.1.1.4.1.cmml" xref="S4.T6.7.m1.1.1.4">subscript</csymbol><ci id="S4.T6.7.m1.1.1.4.2.cmml" xref="S4.T6.7.m1.1.1.4.2">𝑥</ci><cn id="S4.T6.7.m1.1.1.4.3.cmml" type="integer" xref="S4.T6.7.m1.1.1.4.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.m1.1d">box_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T6.7.m1.1e">italic_b italic_o italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> denotes the ground truth bounding box and <math alttext="pt_{2}" class="ltx_Math" display="inline" id="S4.T6.8.m2.1"><semantics id="S4.T6.8.m2.1b"><mrow id="S4.T6.8.m2.1.1" xref="S4.T6.8.m2.1.1.cmml"><mi id="S4.T6.8.m2.1.1.2" xref="S4.T6.8.m2.1.1.2.cmml">p</mi><mo id="S4.T6.8.m2.1.1.1" xref="S4.T6.8.m2.1.1.1.cmml">⁢</mo><msub id="S4.T6.8.m2.1.1.3" xref="S4.T6.8.m2.1.1.3.cmml"><mi id="S4.T6.8.m2.1.1.3.2" xref="S4.T6.8.m2.1.1.3.2.cmml">t</mi><mn id="S4.T6.8.m2.1.1.3.3" xref="S4.T6.8.m2.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.8.m2.1c"><apply id="S4.T6.8.m2.1.1.cmml" xref="S4.T6.8.m2.1.1"><times id="S4.T6.8.m2.1.1.1.cmml" xref="S4.T6.8.m2.1.1.1"></times><ci id="S4.T6.8.m2.1.1.2.cmml" xref="S4.T6.8.m2.1.1.2">𝑝</ci><apply id="S4.T6.8.m2.1.1.3.cmml" xref="S4.T6.8.m2.1.1.3"><csymbol cd="ambiguous" id="S4.T6.8.m2.1.1.3.1.cmml" xref="S4.T6.8.m2.1.1.3">subscript</csymbol><ci id="S4.T6.8.m2.1.1.3.2.cmml" xref="S4.T6.8.m2.1.1.3.2">𝑡</ci><cn id="S4.T6.8.m2.1.1.3.3.cmml" type="integer" xref="S4.T6.8.m2.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.m2.1d">pt_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T6.8.m2.1e">italic_p italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> denotes the tightest bounding box with respect to the ground truth mask.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">To evaluate on the SegAny task, we adopt two types of points as prompts: 1) the center point of the ground truth bounding box, and 2) random points uniformly sampled from ground truth masks, following the setting in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib131" title=""><span class="ltx_text" style="font-size:90%;">131</span></a>]</cite>. We evaluate the variants on COCO and LVIS, and the mean intersection over union (mIoU) is reported in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T5" title="Table 5 ‣ 4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>. When prompted with the center point, SAM2-B+ and EfficientViT-SAM-XL1 achieve the highest mIoU of 54.3% on COCO, surpassing SAM-H with 53.6% mIoU, while SAMfast-H, also with 53.6%, exhibits the best performance among variants on LVIS.
Under the setting of random point prompts, it is demonstrated that EfficientViT-SAM-XL1 performs better than SAM-H, particularly when prompted with 3 points, with an increase of 2.7% and 0.7%, respectively. From the perspective of datasets, we observe that the results on LVIS are generally lower than those on COCO, especially for FastSAM and EfficientSAM-Ti, whose accuracy decreases to below 30% on LVIS.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Moreover, we also evaluate the accuracy on SegAny task with two types of box prompts: 1) The ground truth bounding box and 2) The tightest bounding box corresponding to the ground truth mask, inspired by the experiments in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib131" title=""><span class="ltx_text" style="font-size:90%;">131</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite>. We reported the results of mIoU on COCO and LVIS which are illustrated in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T6" title="Table 6 ‣ 4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a>. We observe that EfficientViT-SAM-XL1 demonstrate the highest accuracy in every setting which exceeds SAM-H by 1.5%, 1.1%, 1.9% and 0.6%, respectively. SAMfast-H and EfficientViT-SAM-L0 also present performance close to SAM-H in the box-prompted segmentation tasks.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.8.9.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.8.9.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="4" id="S4.T7.8.9.1.2"><span class="ltx_text" id="S4.T7.8.9.1.2.1" style="font-size:90%;">COCO</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S4.T7.8.9.1.3"><span class="ltx_text" id="S4.T7.8.9.1.3.1" style="font-size:90%;">LVIS</span></th>
</tr>
<tr class="ltx_tr" id="S4.T7.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T7.8.8.9"><span class="ltx_text" id="S4.T7.8.8.9.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.1.1.1"><math alttext="\rm AP" class="ltx_Math" display="inline" id="S4.T7.1.1.1.m1.1"><semantics id="S4.T7.1.1.1.m1.1a"><mi id="S4.T7.1.1.1.m1.1.1" mathsize="90%" xref="S4.T7.1.1.1.m1.1.1.cmml">AP</mi><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.m1.1b"><ci id="S4.T7.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.m1.1.1">AP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.m1.1c">\rm AP</annotation><annotation encoding="application/x-llamapun" id="S4.T7.1.1.1.m1.1d">roman_AP</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.2.2.2"><math alttext="\rm AP^{S}" class="ltx_Math" display="inline" id="S4.T7.2.2.2.m1.1"><semantics id="S4.T7.2.2.2.m1.1a"><msup id="S4.T7.2.2.2.m1.1.1" xref="S4.T7.2.2.2.m1.1.1.cmml"><mi id="S4.T7.2.2.2.m1.1.1.2" mathsize="90%" xref="S4.T7.2.2.2.m1.1.1.2.cmml">AP</mi><mi id="S4.T7.2.2.2.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T7.2.2.2.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.2.m1.1b"><apply id="S4.T7.2.2.2.m1.1.1.cmml" xref="S4.T7.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.2.2.2.m1.1.1.1.cmml" xref="S4.T7.2.2.2.m1.1.1">superscript</csymbol><ci id="S4.T7.2.2.2.m1.1.1.2.cmml" xref="S4.T7.2.2.2.m1.1.1.2">AP</ci><ci id="S4.T7.2.2.2.m1.1.1.3.cmml" xref="S4.T7.2.2.2.m1.1.1.3">S</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.2.m1.1c">\rm AP^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.2.2.2.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.3.3.3"><math alttext="\rm AP^{M}" class="ltx_Math" display="inline" id="S4.T7.3.3.3.m1.1"><semantics id="S4.T7.3.3.3.m1.1a"><msup id="S4.T7.3.3.3.m1.1.1" xref="S4.T7.3.3.3.m1.1.1.cmml"><mi id="S4.T7.3.3.3.m1.1.1.2" mathsize="90%" xref="S4.T7.3.3.3.m1.1.1.2.cmml">AP</mi><mi id="S4.T7.3.3.3.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T7.3.3.3.m1.1.1.3.cmml">M</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T7.3.3.3.m1.1b"><apply id="S4.T7.3.3.3.m1.1.1.cmml" xref="S4.T7.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.3.3.3.m1.1.1.1.cmml" xref="S4.T7.3.3.3.m1.1.1">superscript</csymbol><ci id="S4.T7.3.3.3.m1.1.1.2.cmml" xref="S4.T7.3.3.3.m1.1.1.2">AP</ci><ci id="S4.T7.3.3.3.m1.1.1.3.cmml" xref="S4.T7.3.3.3.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.3.3.m1.1c">\rm AP^{M}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.3.3.3.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T7.4.4.4"><math alttext="\rm AP^{L}" class="ltx_Math" display="inline" id="S4.T7.4.4.4.m1.1"><semantics id="S4.T7.4.4.4.m1.1a"><msup id="S4.T7.4.4.4.m1.1.1" xref="S4.T7.4.4.4.m1.1.1.cmml"><mi id="S4.T7.4.4.4.m1.1.1.2" mathsize="90%" xref="S4.T7.4.4.4.m1.1.1.2.cmml">AP</mi><mi id="S4.T7.4.4.4.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T7.4.4.4.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T7.4.4.4.m1.1b"><apply id="S4.T7.4.4.4.m1.1.1.cmml" xref="S4.T7.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.4.4.4.m1.1.1.1.cmml" xref="S4.T7.4.4.4.m1.1.1">superscript</csymbol><ci id="S4.T7.4.4.4.m1.1.1.2.cmml" xref="S4.T7.4.4.4.m1.1.1.2">AP</ci><ci id="S4.T7.4.4.4.m1.1.1.3.cmml" xref="S4.T7.4.4.4.m1.1.1.3">L</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.4.4.4.m1.1c">\rm AP^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.4.4.4.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.5.5.5"><math alttext="\rm AP" class="ltx_Math" display="inline" id="S4.T7.5.5.5.m1.1"><semantics id="S4.T7.5.5.5.m1.1a"><mi id="S4.T7.5.5.5.m1.1.1" mathsize="90%" xref="S4.T7.5.5.5.m1.1.1.cmml">AP</mi><annotation-xml encoding="MathML-Content" id="S4.T7.5.5.5.m1.1b"><ci id="S4.T7.5.5.5.m1.1.1.cmml" xref="S4.T7.5.5.5.m1.1.1">AP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.5.5.5.m1.1c">\rm AP</annotation><annotation encoding="application/x-llamapun" id="S4.T7.5.5.5.m1.1d">roman_AP</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.6.6.6"><math alttext="\rm AP^{S}" class="ltx_Math" display="inline" id="S4.T7.6.6.6.m1.1"><semantics id="S4.T7.6.6.6.m1.1a"><msup id="S4.T7.6.6.6.m1.1.1" xref="S4.T7.6.6.6.m1.1.1.cmml"><mi id="S4.T7.6.6.6.m1.1.1.2" mathsize="90%" xref="S4.T7.6.6.6.m1.1.1.2.cmml">AP</mi><mi id="S4.T7.6.6.6.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T7.6.6.6.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T7.6.6.6.m1.1b"><apply id="S4.T7.6.6.6.m1.1.1.cmml" xref="S4.T7.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.6.6.6.m1.1.1.1.cmml" xref="S4.T7.6.6.6.m1.1.1">superscript</csymbol><ci id="S4.T7.6.6.6.m1.1.1.2.cmml" xref="S4.T7.6.6.6.m1.1.1.2">AP</ci><ci id="S4.T7.6.6.6.m1.1.1.3.cmml" xref="S4.T7.6.6.6.m1.1.1.3">S</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.6.6.6.m1.1c">\rm AP^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.6.6.6.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.7.7.7"><math alttext="\rm AP^{M}" class="ltx_Math" display="inline" id="S4.T7.7.7.7.m1.1"><semantics id="S4.T7.7.7.7.m1.1a"><msup id="S4.T7.7.7.7.m1.1.1" xref="S4.T7.7.7.7.m1.1.1.cmml"><mi id="S4.T7.7.7.7.m1.1.1.2" mathsize="90%" xref="S4.T7.7.7.7.m1.1.1.2.cmml">AP</mi><mi id="S4.T7.7.7.7.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T7.7.7.7.m1.1.1.3.cmml">M</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T7.7.7.7.m1.1b"><apply id="S4.T7.7.7.7.m1.1.1.cmml" xref="S4.T7.7.7.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.7.7.7.m1.1.1.1.cmml" xref="S4.T7.7.7.7.m1.1.1">superscript</csymbol><ci id="S4.T7.7.7.7.m1.1.1.2.cmml" xref="S4.T7.7.7.7.m1.1.1.2">AP</ci><ci id="S4.T7.7.7.7.m1.1.1.3.cmml" xref="S4.T7.7.7.7.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.7.7.7.m1.1c">\rm AP^{M}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.7.7.7.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T7.8.8.8"><math alttext="\rm AP^{L}" class="ltx_Math" display="inline" id="S4.T7.8.8.8.m1.1"><semantics id="S4.T7.8.8.8.m1.1a"><msup id="S4.T7.8.8.8.m1.1.1" xref="S4.T7.8.8.8.m1.1.1.cmml"><mi id="S4.T7.8.8.8.m1.1.1.2" mathsize="90%" xref="S4.T7.8.8.8.m1.1.1.2.cmml">AP</mi><mi id="S4.T7.8.8.8.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T7.8.8.8.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T7.8.8.8.m1.1b"><apply id="S4.T7.8.8.8.m1.1.1.cmml" xref="S4.T7.8.8.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T7.8.8.8.m1.1.1.1.cmml" xref="S4.T7.8.8.8.m1.1.1">superscript</csymbol><ci id="S4.T7.8.8.8.m1.1.1.2.cmml" xref="S4.T7.8.8.8.m1.1.1.2">AP</ci><ci id="S4.T7.8.8.8.m1.1.1.3.cmml" xref="S4.T7.8.8.8.m1.1.1.3">L</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.8.8.8.m1.1c">\rm AP^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.T7.8.8.8.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.8.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.8.10.1.1"><span class="ltx_text" id="S4.T7.8.10.1.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.8.10.1.2"><span class="ltx_text" id="S4.T7.8.10.1.2.1" style="font-size:90%;">46.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.8.10.1.3"><span class="ltx_text" id="S4.T7.8.10.1.3.1" style="font-size:90%;">30.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.8.10.1.4"><span class="ltx_text" id="S4.T7.8.10.1.4.1" style="font-size:90%;">51.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.8.10.1.5"><span class="ltx_text" id="S4.T7.8.10.1.5.1" style="font-size:90%;">61.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.8.10.1.6"><span class="ltx_text" id="S4.T7.8.10.1.6.1" style="font-size:90%;">44.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.8.10.1.7"><span class="ltx_text" id="S4.T7.8.10.1.7.1" style="font-size:90%;">32.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.8.10.1.8"><span class="ltx_text" id="S4.T7.8.10.1.8.1" style="font-size:90%;">57.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T7.8.10.1.9"><span class="ltx_text" id="S4.T7.8.10.1.9.1" style="font-size:90%;">65.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.11.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.11.2.1"><span class="ltx_text" id="S4.T7.8.11.2.1.1" style="font-size:90%;">SAMfast-H</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.11.2.2"><span class="ltx_text" id="S4.T7.8.11.2.2.1" style="font-size:90%;">46.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.11.2.3"><span class="ltx_text" id="S4.T7.8.11.2.3.1" style="font-size:90%;">30.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.11.2.4"><span class="ltx_text" id="S4.T7.8.11.2.4.1" style="font-size:90%;">50.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.11.2.5"><span class="ltx_text" id="S4.T7.8.11.2.5.1" style="font-size:90%;">61.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.11.2.6"><span class="ltx_text ltx_font_bold" id="S4.T7.8.11.2.6.1" style="font-size:90%;">44.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.11.2.7"><span class="ltx_text ltx_font_bold" id="S4.T7.8.11.2.7.1" style="font-size:90%;">32.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.11.2.8"><span class="ltx_text ltx_font_bold" id="S4.T7.8.11.2.8.1" style="font-size:90%;">57.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.11.2.9"><span class="ltx_text" id="S4.T7.8.11.2.9.1" style="font-size:90%;">65.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.12.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.12.3.1"><span class="ltx_text" id="S4.T7.8.12.3.1.1" style="font-size:90%;">SAM2-B+</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.12.3.2"><span class="ltx_text" id="S4.T7.8.12.3.2.1" style="font-size:90%;">44.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.12.3.3"><span class="ltx_text" id="S4.T7.8.12.3.3.1" style="font-size:90%;">27.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.12.3.4"><span class="ltx_text" id="S4.T7.8.12.3.4.1" style="font-size:90%;">49.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.12.3.5"><span class="ltx_text" id="S4.T7.8.12.3.5.1" style="font-size:90%;">62.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.12.3.6"><span class="ltx_text" id="S4.T7.8.12.3.6.1" style="font-size:90%;">42.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.12.3.7"><span class="ltx_text" id="S4.T7.8.12.3.7.1" style="font-size:90%;">30.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.12.3.8"><span class="ltx_text" id="S4.T7.8.12.3.8.1" style="font-size:90%;">57.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.12.3.9"><span class="ltx_text" id="S4.T7.8.12.3.9.1" style="font-size:90%;">65.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.13.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.13.4.1"><span class="ltx_text" id="S4.T7.8.13.4.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.13.4.2"><span class="ltx_text" id="S4.T7.8.13.4.2.1" style="font-size:90%;">37.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.13.4.3"><span class="ltx_text" id="S4.T7.8.13.4.3.1" style="font-size:90%;">23.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.13.4.4"><span class="ltx_text" id="S4.T7.8.13.4.4.1" style="font-size:90%;">43.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.13.4.5"><span class="ltx_text" id="S4.T7.8.13.4.5.1" style="font-size:90%;">50.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.13.4.6"><span class="ltx_text" id="S4.T7.8.13.4.6.1" style="font-size:90%;">34.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.13.4.7"><span class="ltx_text" id="S4.T7.8.13.4.7.1" style="font-size:90%;">24.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.13.4.8"><span class="ltx_text" id="S4.T7.8.13.4.8.1" style="font-size:90%;">46.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.13.4.9"><span class="ltx_text" id="S4.T7.8.13.4.9.1" style="font-size:90%;">50.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.14.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.14.5.1"><span class="ltx_text" id="S4.T7.8.14.5.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.14.5.2"><span class="ltx_text" id="S4.T7.8.14.5.2.1" style="font-size:90%;">38.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.14.5.3"><span class="ltx_text" id="S4.T7.8.14.5.3.1" style="font-size:90%;">23.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.14.5.4"><span class="ltx_text" id="S4.T7.8.14.5.4.1" style="font-size:90%;">42.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.14.5.5"><span class="ltx_text" id="S4.T7.8.14.5.5.1" style="font-size:90%;">54.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.14.5.6"><span class="ltx_text" id="S4.T7.8.14.5.6.1" style="font-size:90%;">37.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.14.5.7"><span class="ltx_text" id="S4.T7.8.14.5.7.1" style="font-size:90%;">24.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.14.5.8"><span class="ltx_text" id="S4.T7.8.14.5.8.1" style="font-size:90%;">47.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.14.5.9"><span class="ltx_text" id="S4.T7.8.14.5.9.1" style="font-size:90%;">59.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.15.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.15.6.1"><span class="ltx_text" id="S4.T7.8.15.6.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.15.6.2"><span class="ltx_text" id="S4.T7.8.15.6.2.1" style="font-size:90%;">42.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.15.6.3"><span class="ltx_text" id="S4.T7.8.15.6.3.1" style="font-size:90%;">26.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.15.6.4"><span class="ltx_text" id="S4.T7.8.15.6.4.1" style="font-size:90%;">46.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.15.6.5"><span class="ltx_text" id="S4.T7.8.15.6.5.1" style="font-size:90%;">56.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.15.6.6"><span class="ltx_text" id="S4.T7.8.15.6.6.1" style="font-size:90%;">39.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.15.6.7"><span class="ltx_text" id="S4.T7.8.15.6.7.1" style="font-size:90%;">28.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.15.6.8"><span class="ltx_text" id="S4.T7.8.15.6.8.1" style="font-size:90%;">51.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.15.6.9"><span class="ltx_text" id="S4.T7.8.15.6.9.1" style="font-size:90%;">59.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.16.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.16.7.1"><span class="ltx_text" id="S4.T7.8.16.7.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.16.7.2"><span class="ltx_text" id="S4.T7.8.16.7.2.1" style="font-size:90%;">42.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.16.7.3"><span class="ltx_text" id="S4.T7.8.16.7.3.1" style="font-size:90%;">26.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.16.7.4"><span class="ltx_text" id="S4.T7.8.16.7.4.1" style="font-size:90%;">46.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.16.7.5"><span class="ltx_text" id="S4.T7.8.16.7.5.1" style="font-size:90%;">57.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.16.7.6"><span class="ltx_text" id="S4.T7.8.16.7.6.1" style="font-size:90%;">39.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.16.7.7"><span class="ltx_text" id="S4.T7.8.16.7.7.1" style="font-size:90%;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.16.7.8"><span class="ltx_text" id="S4.T7.8.16.7.8.1" style="font-size:90%;">51.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.16.7.9"><span class="ltx_text" id="S4.T7.8.16.7.9.1" style="font-size:90%;">59.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.17.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.17.8.1"><span class="ltx_text" id="S4.T7.8.17.8.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.17.8.2"><span class="ltx_text" id="S4.T7.8.17.8.2.1" style="font-size:90%;">35.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.17.8.3"><span class="ltx_text" id="S4.T7.8.17.8.3.1" style="font-size:90%;">27.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.17.8.4"><span class="ltx_text" id="S4.T7.8.17.8.4.1" style="font-size:90%;">41.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.17.8.5"><span class="ltx_text" id="S4.T7.8.17.8.5.1" style="font-size:90%;">42.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.17.8.6"><span class="ltx_text" id="S4.T7.8.17.8.6.1" style="font-size:90%;">31.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.17.8.7"><span class="ltx_text" id="S4.T7.8.17.8.7.1" style="font-size:90%;">29.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.17.8.8"><span class="ltx_text" id="S4.T7.8.17.8.8.1" style="font-size:90%;">43.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.17.8.9"><span class="ltx_text" id="S4.T7.8.17.8.9.1" style="font-size:90%;">44.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.18.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.18.9.1"><span class="ltx_text" id="S4.T7.8.18.9.1.1" style="font-size:90%;">RepViT-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.18.9.2"><span class="ltx_text" id="S4.T7.8.18.9.2.1" style="font-size:90%;">43.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.18.9.3"><span class="ltx_text" id="S4.T7.8.18.9.3.1" style="font-size:90%;">27.</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.18.9.4"><span class="ltx_text" id="S4.T7.8.18.9.4.1" style="font-size:90%;">47.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.18.9.5"><span class="ltx_text" id="S4.T7.8.18.9.5.1" style="font-size:90%;">59.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.18.9.6"><span class="ltx_text" id="S4.T7.8.18.9.6.1" style="font-size:90%;">40.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.18.9.7"><span class="ltx_text" id="S4.T7.8.18.9.7.1" style="font-size:90%;">28.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.18.9.8"><span class="ltx_text" id="S4.T7.8.18.9.8.1" style="font-size:90%;">52.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.18.9.9"><span class="ltx_text" id="S4.T7.8.18.9.9.1" style="font-size:90%;">61.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.19.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.19.10.1"><span class="ltx_text" id="S4.T7.8.19.10.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.19.10.2"><span class="ltx_text" id="S4.T7.8.19.10.2.1" style="font-size:90%;">42.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.19.10.3"><span class="ltx_text" id="S4.T7.8.19.10.3.1" style="font-size:90%;">27.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.19.10.4"><span class="ltx_text" id="S4.T7.8.19.10.4.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.19.10.5"><span class="ltx_text" id="S4.T7.8.19.10.5.1" style="font-size:90%;">58.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.19.10.6"><span class="ltx_text" id="S4.T7.8.19.10.6.1" style="font-size:90%;">40.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.19.10.7"><span class="ltx_text" id="S4.T7.8.19.10.7.1" style="font-size:90%;">28.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.19.10.8"><span class="ltx_text" id="S4.T7.8.19.10.8.1" style="font-size:90%;">51.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.19.10.9"><span class="ltx_text" id="S4.T7.8.19.10.9.1" style="font-size:90%;">60.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.20.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.20.11.1"><span class="ltx_text" id="S4.T7.8.20.11.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.20.11.2"><span class="ltx_text" id="S4.T7.8.20.11.2.1" style="font-size:90%;">41.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.20.11.3"><span class="ltx_text" id="S4.T7.8.20.11.3.1" style="font-size:90%;">25.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.20.11.4"><span class="ltx_text" id="S4.T7.8.20.11.4.1" style="font-size:90%;">44.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.20.11.5"><span class="ltx_text" id="S4.T7.8.20.11.5.1" style="font-size:90%;">57.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.20.11.6"><span class="ltx_text" id="S4.T7.8.20.11.6.1" style="font-size:90%;">38.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.20.11.7"><span class="ltx_text" id="S4.T7.8.20.11.7.1" style="font-size:90%;">26.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.20.11.8"><span class="ltx_text" id="S4.T7.8.20.11.8.1" style="font-size:90%;">49.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.20.11.9"><span class="ltx_text" id="S4.T7.8.20.11.9.1" style="font-size:90%;">59</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.21.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.21.12.1"><span class="ltx_text" id="S4.T7.8.21.12.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.21.12.2"><span class="ltx_text" id="S4.T7.8.21.12.2.1" style="font-size:90%;">42.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.21.12.3"><span class="ltx_text" id="S4.T7.8.21.12.3.1" style="font-size:90%;">26.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.21.12.4"><span class="ltx_text" id="S4.T7.8.21.12.4.1" style="font-size:90%;">45.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.21.12.5"><span class="ltx_text" id="S4.T7.8.21.12.5.1" style="font-size:90%;">58.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.21.12.6"><span class="ltx_text" id="S4.T7.8.21.12.6.1" style="font-size:90%;">38.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.21.12.7"><span class="ltx_text" id="S4.T7.8.21.12.7.1" style="font-size:90%;">27.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.21.12.8"><span class="ltx_text" id="S4.T7.8.21.12.8.1" style="font-size:90%;">50.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.21.12.9"><span class="ltx_text" id="S4.T7.8.21.12.9.1" style="font-size:90%;">60.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.22.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.22.13.1"><span class="ltx_text" id="S4.T7.8.22.13.1.1" style="font-size:90%;">Q-TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.22.13.2"><span class="ltx_text" id="S4.T7.8.22.13.2.1" style="font-size:90%;">41.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.22.13.3"><span class="ltx_text" id="S4.T7.8.22.13.3.1" style="font-size:90%;">25.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.22.13.4"><span class="ltx_text" id="S4.T7.8.22.13.4.1" style="font-size:90%;">45.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.22.13.5"><span class="ltx_text" id="S4.T7.8.22.13.5.1" style="font-size:90%;">57.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.22.13.6"><span class="ltx_text" id="S4.T7.8.22.13.6.1" style="font-size:90%;">38.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.22.13.7"><span class="ltx_text" id="S4.T7.8.22.13.7.1" style="font-size:90%;">26.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.22.13.8"><span class="ltx_text" id="S4.T7.8.22.13.8.1" style="font-size:90%;">49.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.22.13.9"><span class="ltx_text" id="S4.T7.8.22.13.9.1" style="font-size:90%;">59.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.23.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.23.14.1"><span class="ltx_text" id="S4.T7.8.23.14.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.23.14.2"><span class="ltx_text" id="S4.T7.8.23.14.2.1" style="font-size:90%;">45.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.23.14.3"><span class="ltx_text" id="S4.T7.8.23.14.3.1" style="font-size:90%;">28.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.23.14.4"><span class="ltx_text" id="S4.T7.8.23.14.4.1" style="font-size:90%;">49.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.23.14.5"><span class="ltx_text" id="S4.T7.8.23.14.5.1" style="font-size:90%;">63.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.23.14.6"><span class="ltx_text" id="S4.T7.8.23.14.6.1" style="font-size:90%;">41.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.23.14.7"><span class="ltx_text" id="S4.T7.8.23.14.7.1" style="font-size:90%;">28.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.23.14.8"><span class="ltx_text" id="S4.T7.8.23.14.8.1" style="font-size:90%;">53.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.23.14.9"><span class="ltx_text" id="S4.T7.8.23.14.9.1" style="font-size:90%;">64.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.24.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.8.24.15.1"><span class="ltx_text" id="S4.T7.8.24.15.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T7.8.24.15.2"><span class="ltx_text ltx_font_bold" id="S4.T7.8.24.15.2.1" style="font-size:90%;">47.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.24.15.3"><span class="ltx_text ltx_font_bold" id="S4.T7.8.24.15.3.1" style="font-size:90%;">30.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.24.15.4"><span class="ltx_text ltx_font_bold" id="S4.T7.8.24.15.4.1" style="font-size:90%;">51.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.8.24.15.5"><span class="ltx_text ltx_font_bold" id="S4.T7.8.24.15.5.1" style="font-size:90%;">64.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.24.15.6"><span class="ltx_text" id="S4.T7.8.24.15.6.1" style="font-size:90%;">44.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.24.15.7"><span class="ltx_text" id="S4.T7.8.24.15.7.1" style="font-size:90%;">31.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.8.24.15.8"><span class="ltx_text" id="S4.T7.8.24.15.8.1" style="font-size:90%;">57.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T7.8.24.15.9"><span class="ltx_text ltx_font_bold" id="S4.T7.8.24.15.9.1" style="font-size:90%;">66.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.8.25.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T7.8.25.16.1"><span class="ltx_text" id="S4.T7.8.25.16.1.1" style="font-size:90%;">NanoSAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.2"><span class="ltx_text" id="S4.T7.8.25.16.2.1" style="font-size:90%;">35.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.3"><span class="ltx_text" id="S4.T7.8.25.16.3.1" style="font-size:90%;">20.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.4"><span class="ltx_text" id="S4.T7.8.25.16.4.1" style="font-size:90%;">40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T7.8.25.16.5"><span class="ltx_text" id="S4.T7.8.25.16.5.1" style="font-size:90%;">52.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.6"><span class="ltx_text" id="S4.T7.8.25.16.6.1" style="font-size:90%;">31.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.7"><span class="ltx_text" id="S4.T7.8.25.16.7.1" style="font-size:90%;">19.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.8"><span class="ltx_text" id="S4.T7.8.25.16.8.1" style="font-size:90%;">42.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T7.8.25.16.9"><span class="ltx_text" id="S4.T7.8.25.16.9.1" style="font-size:90%;">53.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Quantitative results of instance segmentation on COCO and LVIS with ViTDet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib59" title=""><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite> as object detector.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T8.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T8.8.9.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T8.8.9.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="4" id="S4.T8.8.9.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.9.1.2.1" style="font-size:90%;">YOLOv8</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S4.T8.8.9.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.9.1.3.1" style="font-size:90%;">GroundingDINO</span></th>
</tr>
<tr class="ltx_tr" id="S4.T8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T8.8.8.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.8.9.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T8.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP" class="ltx_Math" display="inline" id="S4.T8.1.1.1.m1.1"><semantics id="S4.T8.1.1.1.m1.1a"><mi id="S4.T8.1.1.1.m1.1.1" mathsize="90%" xref="S4.T8.1.1.1.m1.1.1.cmml">AP</mi><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.m1.1b"><ci id="S4.T8.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1">AP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.m1.1c">\rm AP</annotation><annotation encoding="application/x-llamapun" id="S4.T8.1.1.1.m1.1d">roman_AP</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T8.2.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{S}" class="ltx_Math" display="inline" id="S4.T8.2.2.2.m1.1"><semantics id="S4.T8.2.2.2.m1.1a"><msup id="S4.T8.2.2.2.m1.1.1" xref="S4.T8.2.2.2.m1.1.1.cmml"><mi id="S4.T8.2.2.2.m1.1.1.2" mathsize="90%" xref="S4.T8.2.2.2.m1.1.1.2.cmml">AP</mi><mi id="S4.T8.2.2.2.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T8.2.2.2.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.m1.1b"><apply id="S4.T8.2.2.2.m1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.2.2.2.m1.1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1">superscript</csymbol><ci id="S4.T8.2.2.2.m1.1.1.2.cmml" xref="S4.T8.2.2.2.m1.1.1.2">AP</ci><ci id="S4.T8.2.2.2.m1.1.1.3.cmml" xref="S4.T8.2.2.2.m1.1.1.3">S</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.m1.1c">\rm AP^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.2.2.2.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T8.3.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{M}" class="ltx_Math" display="inline" id="S4.T8.3.3.3.m1.1"><semantics id="S4.T8.3.3.3.m1.1a"><msup id="S4.T8.3.3.3.m1.1.1" xref="S4.T8.3.3.3.m1.1.1.cmml"><mi id="S4.T8.3.3.3.m1.1.1.2" mathsize="90%" xref="S4.T8.3.3.3.m1.1.1.2.cmml">AP</mi><mi id="S4.T8.3.3.3.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T8.3.3.3.m1.1.1.3.cmml">M</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.m1.1b"><apply id="S4.T8.3.3.3.m1.1.1.cmml" xref="S4.T8.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.3.3.3.m1.1.1.1.cmml" xref="S4.T8.3.3.3.m1.1.1">superscript</csymbol><ci id="S4.T8.3.3.3.m1.1.1.2.cmml" xref="S4.T8.3.3.3.m1.1.1.2">AP</ci><ci id="S4.T8.3.3.3.m1.1.1.3.cmml" xref="S4.T8.3.3.3.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.m1.1c">\rm AP^{M}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.3.3.3.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T8.4.4.4" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{L}" class="ltx_Math" display="inline" id="S4.T8.4.4.4.m1.1"><semantics id="S4.T8.4.4.4.m1.1a"><msup id="S4.T8.4.4.4.m1.1.1" xref="S4.T8.4.4.4.m1.1.1.cmml"><mi id="S4.T8.4.4.4.m1.1.1.2" mathsize="90%" xref="S4.T8.4.4.4.m1.1.1.2.cmml">AP</mi><mi id="S4.T8.4.4.4.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T8.4.4.4.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T8.4.4.4.m1.1b"><apply id="S4.T8.4.4.4.m1.1.1.cmml" xref="S4.T8.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.4.4.4.m1.1.1.1.cmml" xref="S4.T8.4.4.4.m1.1.1">superscript</csymbol><ci id="S4.T8.4.4.4.m1.1.1.2.cmml" xref="S4.T8.4.4.4.m1.1.1.2">AP</ci><ci id="S4.T8.4.4.4.m1.1.1.3.cmml" xref="S4.T8.4.4.4.m1.1.1.3">L</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.4.4.m1.1c">\rm AP^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.4.4.4.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T8.5.5.5" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP" class="ltx_Math" display="inline" id="S4.T8.5.5.5.m1.1"><semantics id="S4.T8.5.5.5.m1.1a"><mi id="S4.T8.5.5.5.m1.1.1" mathsize="90%" xref="S4.T8.5.5.5.m1.1.1.cmml">AP</mi><annotation-xml encoding="MathML-Content" id="S4.T8.5.5.5.m1.1b"><ci id="S4.T8.5.5.5.m1.1.1.cmml" xref="S4.T8.5.5.5.m1.1.1">AP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.5.5.m1.1c">\rm AP</annotation><annotation encoding="application/x-llamapun" id="S4.T8.5.5.5.m1.1d">roman_AP</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T8.6.6.6" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{S}" class="ltx_Math" display="inline" id="S4.T8.6.6.6.m1.1"><semantics id="S4.T8.6.6.6.m1.1a"><msup id="S4.T8.6.6.6.m1.1.1" xref="S4.T8.6.6.6.m1.1.1.cmml"><mi id="S4.T8.6.6.6.m1.1.1.2" mathsize="90%" xref="S4.T8.6.6.6.m1.1.1.2.cmml">AP</mi><mi id="S4.T8.6.6.6.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T8.6.6.6.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T8.6.6.6.m1.1b"><apply id="S4.T8.6.6.6.m1.1.1.cmml" xref="S4.T8.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.6.6.6.m1.1.1.1.cmml" xref="S4.T8.6.6.6.m1.1.1">superscript</csymbol><ci id="S4.T8.6.6.6.m1.1.1.2.cmml" xref="S4.T8.6.6.6.m1.1.1.2">AP</ci><ci id="S4.T8.6.6.6.m1.1.1.3.cmml" xref="S4.T8.6.6.6.m1.1.1.3">S</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.6.6.m1.1c">\rm AP^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.6.6.6.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T8.7.7.7" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{M}" class="ltx_Math" display="inline" id="S4.T8.7.7.7.m1.1"><semantics id="S4.T8.7.7.7.m1.1a"><msup id="S4.T8.7.7.7.m1.1.1" xref="S4.T8.7.7.7.m1.1.1.cmml"><mi id="S4.T8.7.7.7.m1.1.1.2" mathsize="90%" xref="S4.T8.7.7.7.m1.1.1.2.cmml">AP</mi><mi id="S4.T8.7.7.7.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T8.7.7.7.m1.1.1.3.cmml">M</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T8.7.7.7.m1.1b"><apply id="S4.T8.7.7.7.m1.1.1.cmml" xref="S4.T8.7.7.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.7.7.7.m1.1.1.1.cmml" xref="S4.T8.7.7.7.m1.1.1">superscript</csymbol><ci id="S4.T8.7.7.7.m1.1.1.2.cmml" xref="S4.T8.7.7.7.m1.1.1.2">AP</ci><ci id="S4.T8.7.7.7.m1.1.1.3.cmml" xref="S4.T8.7.7.7.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.7.7.m1.1c">\rm AP^{M}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.7.7.7.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T8.8.8.8" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{L}" class="ltx_Math" display="inline" id="S4.T8.8.8.8.m1.1"><semantics id="S4.T8.8.8.8.m1.1a"><msup id="S4.T8.8.8.8.m1.1.1" xref="S4.T8.8.8.8.m1.1.1.cmml"><mi id="S4.T8.8.8.8.m1.1.1.2" mathsize="90%" xref="S4.T8.8.8.8.m1.1.1.2.cmml">AP</mi><mi id="S4.T8.8.8.8.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T8.8.8.8.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T8.8.8.8.m1.1b"><apply id="S4.T8.8.8.8.m1.1.1.cmml" xref="S4.T8.8.8.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T8.8.8.8.m1.1.1.1.cmml" xref="S4.T8.8.8.8.m1.1.1">superscript</csymbol><ci id="S4.T8.8.8.8.m1.1.1.2.cmml" xref="S4.T8.8.8.8.m1.1.1.2">AP</ci><ci id="S4.T8.8.8.8.m1.1.1.3.cmml" xref="S4.T8.8.8.8.m1.1.1.3">L</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.8.8.8.m1.1c">\rm AP^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.T8.8.8.8.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.8.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.8.10.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.8.10.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.2.1" style="font-size:90%;">43.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.8.10.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.3.1" style="font-size:90%;">26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.8.10.1.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.4.1" style="font-size:90%;">48.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T8.8.10.1.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.5.1" style="font-size:90%;">60.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.8.10.1.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.6.1" style="font-size:90%;">46.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.8.10.1.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.7.1" style="font-size:90%;">31.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.8.10.1.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.8.1" style="font-size:90%;">51.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T8.8.10.1.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.10.1.9.1" style="font-size:90%;">64.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.11.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.11.2.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.1.1" style="font-size:90%;">SAMfast-H</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.11.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.2.1" style="font-size:90%;">43.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.11.2.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.11.2.3.1" style="font-size:90%;">26.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.11.2.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.4.1" style="font-size:90%;">47.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.11.2.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.5.1" style="font-size:90%;">60.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.11.2.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.6.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.11.2.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.11.2.7.1" style="font-size:90%;">31.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.11.2.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.8.1" style="font-size:90%;">51.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.11.2.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.11.2.9.1" style="font-size:90%;">64.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.12.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.12.3.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.1.1" style="font-size:90%;">SAM2-B+</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.12.3.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.2.1" style="font-size:90%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.12.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.3.1" style="font-size:90%;">24.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.12.3.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.4.1" style="font-size:90%;">47.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.12.3.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.5.1" style="font-size:90%;">60.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.12.3.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.6.1" style="font-size:90%;">45.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.12.3.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.7.1" style="font-size:90%;">28.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.12.3.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.8.1" style="font-size:90%;">50.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.12.3.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.12.3.9.1" style="font-size:90%;">64.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.13.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.13.4.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.13.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.2.1" style="font-size:90%;">34.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.13.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.3.1" style="font-size:90%;">19.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.13.4.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.4.1" style="font-size:90%;">40.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.13.4.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.5.1" style="font-size:90%;">46.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.13.4.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.6.1" style="font-size:90%;">35.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.13.4.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.7.1" style="font-size:90%;">22.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.13.4.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.8.1" style="font-size:90%;">42.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.13.4.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.13.4.9.1" style="font-size:90%;">48.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.14.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.14.5.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.14.5.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.2.1" style="font-size:90%;">39.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.14.5.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.3.1" style="font-size:90%;">21.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.14.5.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.4.1" style="font-size:90%;">42.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.14.5.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.5.1" style="font-size:90%;">56.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.14.5.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.6.1" style="font-size:90%;">41.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.14.5.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.7.1" style="font-size:90%;">25.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.14.5.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.8.1" style="font-size:90%;">45.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.14.5.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.14.5.9.1" style="font-size:90%;">60.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.15.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.15.6.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.15.6.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.2.1" style="font-size:90%;">39.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.15.6.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.3.1" style="font-size:90%;">22.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.15.6.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.4.1" style="font-size:90%;">43.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.15.6.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.5.1" style="font-size:90%;">56.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.15.6.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.6.1" style="font-size:90%;">42.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.15.6.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.7.1" style="font-size:90%;">27.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.15.6.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.8.1" style="font-size:90%;">46.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.15.6.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.15.6.9.1" style="font-size:90%;">59.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.16.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.16.7.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.16.7.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.2.1" style="font-size:90%;">36.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.16.7.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.3.1" style="font-size:90%;">23.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.16.7.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.4.1" style="font-size:90%;">41.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.16.7.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.5.1" style="font-size:90%;">49.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.16.7.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.6.1" style="font-size:90%;">39.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.16.7.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.7.1" style="font-size:90%;">27.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.16.7.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.8.1" style="font-size:90%;">44.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.16.7.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.16.7.9.1" style="font-size:90%;">53.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.17.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.17.8.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.17.8.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.2.1" style="font-size:90%;">32.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.17.8.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.3.1" style="font-size:90%;">24.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.17.8.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.4.1" style="font-size:90%;">38.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.17.8.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.5.1" style="font-size:90%;">40.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.17.8.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.6.1" style="font-size:90%;">36.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.17.8.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.7.1" style="font-size:90%;">29.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.17.8.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.8.1" style="font-size:90%;">42.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.17.8.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.17.8.9.1" style="font-size:90%;">44.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.18.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.18.9.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.1.1" style="font-size:90%;">RepViT-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.18.9.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.2.1" style="font-size:90%;">41.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.18.9.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.3.1" style="font-size:90%;">23.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.18.9.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.4.1" style="font-size:90%;">45.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.18.9.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.5.1" style="font-size:90%;">57.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.18.9.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.6.1" style="font-size:90%;">43.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.18.9.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.7.1" style="font-size:90%;">28.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.18.9.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.8.1" style="font-size:90%;">48.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.18.9.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.18.9.9.1" style="font-size:90%;">61.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.19.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.19.10.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.19.10.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.2.1" style="font-size:90%;">40.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.19.10.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.3.1" style="font-size:90%;">23.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.19.10.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.4.1" style="font-size:90%;">44.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.19.10.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.5.1" style="font-size:90%;">57.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.19.10.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.6.1" style="font-size:90%;">43.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.19.10.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.7.1" style="font-size:90%;">28.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.19.10.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.8.1" style="font-size:90%;">47.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.19.10.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.19.10.9.1" style="font-size:90%;">60.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.20.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.20.11.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.20.11.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.2.1" style="font-size:90%;">39.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.20.11.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.3.1" style="font-size:90%;">22.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.20.11.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.4.1" style="font-size:90%;">43.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.20.11.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.5.1" style="font-size:90%;">55.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.20.11.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.6.1" style="font-size:90%;">42.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.20.11.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.7.1" style="font-size:90%;">27.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.20.11.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.8.1" style="font-size:90%;">46.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.20.11.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.20.11.9.1" style="font-size:90%;">59.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.21.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.21.12.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.21.12.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.2.1" style="font-size:90%;">39.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.21.12.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.3.1" style="font-size:90%;">22.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.21.12.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.4.1" style="font-size:90%;">43.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.21.12.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.5.1" style="font-size:90%;">56.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.21.12.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.6.1" style="font-size:90%;">42.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.21.12.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.7.1" style="font-size:90%;">27.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.21.12.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.8.1" style="font-size:90%;">46.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.21.12.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.21.12.9.1" style="font-size:90%;">60.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.22.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.22.13.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.22.13.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.2.1" style="font-size:90%;">42.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.22.13.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.3.1" style="font-size:90%;">24.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.22.13.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.4.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.22.13.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.5.1" style="font-size:90%;">61.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.22.13.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.6.1" style="font-size:90%;">46.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.22.13.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.7.1" style="font-size:90%;">29.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.22.13.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.8.1" style="font-size:90%;">50.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.22.13.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.22.13.9.1" style="font-size:90%;">65.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.23.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.8.23.14.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.23.14.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T8.8.23.14.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.2.1" style="font-size:90%;">44.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.23.14.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.3.1" style="font-size:90%;">26.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.23.14.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.4.1" style="font-size:90%;">48.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T8.8.23.14.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.5.1" style="font-size:90%;">62.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.23.14.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.6.1" style="font-size:90%;">48.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.23.14.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.7.1" style="font-size:90%;">31.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T8.8.23.14.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.8.1" style="font-size:90%;">52.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T8.8.23.14.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T8.8.23.14.9.1" style="font-size:90%;">67.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.24.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T8.8.24.15.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.1.1" style="font-size:90%;">NanoSAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.2.1" style="font-size:90%;">34.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.3.1" style="font-size:90%;">18.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.4.1" style="font-size:90%;">38.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T8.8.24.15.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.5.1" style="font-size:90%;">50.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.6.1" style="font-size:90%;">36.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.7.1" style="font-size:90%;">21.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.8.1" style="font-size:90%;">41.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T8.8.24.15.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T8.8.24.15.9.1" style="font-size:90%;">54.5</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 8: </span>Quantitative results of instance segmentation on COCO with YOLOv8 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite> or GrounddingDINO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib69" title=""><span class="ltx_text" style="font-size:90%;">69</span></a>]</cite> as object detector.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T9.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T9.8.9.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T9.8.9.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="4" id="S4.T9.8.9.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.9.1.2.1" style="font-size:90%;">Detic</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S4.T9.8.9.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.9.1.3.1" style="font-size:90%;">H-Deformable-DETR</span></th>
</tr>
<tr class="ltx_tr" id="S4.T9.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T9.8.8.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.8.9.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T9.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP" class="ltx_Math" display="inline" id="S4.T9.1.1.1.m1.1"><semantics id="S4.T9.1.1.1.m1.1a"><mi id="S4.T9.1.1.1.m1.1.1" mathsize="90%" xref="S4.T9.1.1.1.m1.1.1.cmml">AP</mi><annotation-xml encoding="MathML-Content" id="S4.T9.1.1.1.m1.1b"><ci id="S4.T9.1.1.1.m1.1.1.cmml" xref="S4.T9.1.1.1.m1.1.1">AP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.1.1.1.m1.1c">\rm AP</annotation><annotation encoding="application/x-llamapun" id="S4.T9.1.1.1.m1.1d">roman_AP</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T9.2.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{S}" class="ltx_Math" display="inline" id="S4.T9.2.2.2.m1.1"><semantics id="S4.T9.2.2.2.m1.1a"><msup id="S4.T9.2.2.2.m1.1.1" xref="S4.T9.2.2.2.m1.1.1.cmml"><mi id="S4.T9.2.2.2.m1.1.1.2" mathsize="90%" xref="S4.T9.2.2.2.m1.1.1.2.cmml">AP</mi><mi id="S4.T9.2.2.2.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T9.2.2.2.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T9.2.2.2.m1.1b"><apply id="S4.T9.2.2.2.m1.1.1.cmml" xref="S4.T9.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.2.2.2.m1.1.1.1.cmml" xref="S4.T9.2.2.2.m1.1.1">superscript</csymbol><ci id="S4.T9.2.2.2.m1.1.1.2.cmml" xref="S4.T9.2.2.2.m1.1.1.2">AP</ci><ci id="S4.T9.2.2.2.m1.1.1.3.cmml" xref="S4.T9.2.2.2.m1.1.1.3">S</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.2.2.2.m1.1c">\rm AP^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.T9.2.2.2.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T9.3.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{M}" class="ltx_Math" display="inline" id="S4.T9.3.3.3.m1.1"><semantics id="S4.T9.3.3.3.m1.1a"><msup id="S4.T9.3.3.3.m1.1.1" xref="S4.T9.3.3.3.m1.1.1.cmml"><mi id="S4.T9.3.3.3.m1.1.1.2" mathsize="90%" xref="S4.T9.3.3.3.m1.1.1.2.cmml">AP</mi><mi id="S4.T9.3.3.3.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T9.3.3.3.m1.1.1.3.cmml">M</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T9.3.3.3.m1.1b"><apply id="S4.T9.3.3.3.m1.1.1.cmml" xref="S4.T9.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.3.3.3.m1.1.1.1.cmml" xref="S4.T9.3.3.3.m1.1.1">superscript</csymbol><ci id="S4.T9.3.3.3.m1.1.1.2.cmml" xref="S4.T9.3.3.3.m1.1.1.2">AP</ci><ci id="S4.T9.3.3.3.m1.1.1.3.cmml" xref="S4.T9.3.3.3.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.3.3.3.m1.1c">\rm AP^{M}</annotation><annotation encoding="application/x-llamapun" id="S4.T9.3.3.3.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T9.4.4.4" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{L}" class="ltx_Math" display="inline" id="S4.T9.4.4.4.m1.1"><semantics id="S4.T9.4.4.4.m1.1a"><msup id="S4.T9.4.4.4.m1.1.1" xref="S4.T9.4.4.4.m1.1.1.cmml"><mi id="S4.T9.4.4.4.m1.1.1.2" mathsize="90%" xref="S4.T9.4.4.4.m1.1.1.2.cmml">AP</mi><mi id="S4.T9.4.4.4.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T9.4.4.4.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T9.4.4.4.m1.1b"><apply id="S4.T9.4.4.4.m1.1.1.cmml" xref="S4.T9.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.4.4.4.m1.1.1.1.cmml" xref="S4.T9.4.4.4.m1.1.1">superscript</csymbol><ci id="S4.T9.4.4.4.m1.1.1.2.cmml" xref="S4.T9.4.4.4.m1.1.1.2">AP</ci><ci id="S4.T9.4.4.4.m1.1.1.3.cmml" xref="S4.T9.4.4.4.m1.1.1.3">L</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.4.4.4.m1.1c">\rm AP^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.T9.4.4.4.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T9.5.5.5" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP" class="ltx_Math" display="inline" id="S4.T9.5.5.5.m1.1"><semantics id="S4.T9.5.5.5.m1.1a"><mi id="S4.T9.5.5.5.m1.1.1" mathsize="90%" xref="S4.T9.5.5.5.m1.1.1.cmml">AP</mi><annotation-xml encoding="MathML-Content" id="S4.T9.5.5.5.m1.1b"><ci id="S4.T9.5.5.5.m1.1.1.cmml" xref="S4.T9.5.5.5.m1.1.1">AP</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.5.5.5.m1.1c">\rm AP</annotation><annotation encoding="application/x-llamapun" id="S4.T9.5.5.5.m1.1d">roman_AP</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T9.6.6.6" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{S}" class="ltx_Math" display="inline" id="S4.T9.6.6.6.m1.1"><semantics id="S4.T9.6.6.6.m1.1a"><msup id="S4.T9.6.6.6.m1.1.1" xref="S4.T9.6.6.6.m1.1.1.cmml"><mi id="S4.T9.6.6.6.m1.1.1.2" mathsize="90%" xref="S4.T9.6.6.6.m1.1.1.2.cmml">AP</mi><mi id="S4.T9.6.6.6.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T9.6.6.6.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T9.6.6.6.m1.1b"><apply id="S4.T9.6.6.6.m1.1.1.cmml" xref="S4.T9.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.6.6.6.m1.1.1.1.cmml" xref="S4.T9.6.6.6.m1.1.1">superscript</csymbol><ci id="S4.T9.6.6.6.m1.1.1.2.cmml" xref="S4.T9.6.6.6.m1.1.1.2">AP</ci><ci id="S4.T9.6.6.6.m1.1.1.3.cmml" xref="S4.T9.6.6.6.m1.1.1.3">S</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.6.6.6.m1.1c">\rm AP^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.T9.6.6.6.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T9.7.7.7" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{M}" class="ltx_Math" display="inline" id="S4.T9.7.7.7.m1.1"><semantics id="S4.T9.7.7.7.m1.1a"><msup id="S4.T9.7.7.7.m1.1.1" xref="S4.T9.7.7.7.m1.1.1.cmml"><mi id="S4.T9.7.7.7.m1.1.1.2" mathsize="90%" xref="S4.T9.7.7.7.m1.1.1.2.cmml">AP</mi><mi id="S4.T9.7.7.7.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T9.7.7.7.m1.1.1.3.cmml">M</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T9.7.7.7.m1.1b"><apply id="S4.T9.7.7.7.m1.1.1.cmml" xref="S4.T9.7.7.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.7.7.7.m1.1.1.1.cmml" xref="S4.T9.7.7.7.m1.1.1">superscript</csymbol><ci id="S4.T9.7.7.7.m1.1.1.2.cmml" xref="S4.T9.7.7.7.m1.1.1.2">AP</ci><ci id="S4.T9.7.7.7.m1.1.1.3.cmml" xref="S4.T9.7.7.7.m1.1.1.3">M</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.7.7.7.m1.1c">\rm AP^{M}</annotation><annotation encoding="application/x-llamapun" id="S4.T9.7.7.7.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_M end_POSTSUPERSCRIPT</annotation></semantics></math></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T9.8.8.8" style="padding-left:3.0pt;padding-right:3.0pt;"><math alttext="\rm AP^{L}" class="ltx_Math" display="inline" id="S4.T9.8.8.8.m1.1"><semantics id="S4.T9.8.8.8.m1.1a"><msup id="S4.T9.8.8.8.m1.1.1" xref="S4.T9.8.8.8.m1.1.1.cmml"><mi id="S4.T9.8.8.8.m1.1.1.2" mathsize="90%" xref="S4.T9.8.8.8.m1.1.1.2.cmml">AP</mi><mi id="S4.T9.8.8.8.m1.1.1.3" mathsize="90%" mathvariant="normal" xref="S4.T9.8.8.8.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T9.8.8.8.m1.1b"><apply id="S4.T9.8.8.8.m1.1.1.cmml" xref="S4.T9.8.8.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.8.8.8.m1.1.1.1.cmml" xref="S4.T9.8.8.8.m1.1.1">superscript</csymbol><ci id="S4.T9.8.8.8.m1.1.1.2.cmml" xref="S4.T9.8.8.8.m1.1.1.2">AP</ci><ci id="S4.T9.8.8.8.m1.1.1.3.cmml" xref="S4.T9.8.8.8.m1.1.1.3">L</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.8.8.8.m1.1c">\rm AP^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.T9.8.8.8.m1.1d">roman_AP start_POSTSUPERSCRIPT roman_L end_POSTSUPERSCRIPT</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T9.8.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T9.8.10.1.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.1.1" style="font-size:90%;">SAM-H</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.8.10.1.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.2.1" style="font-size:90%;">39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.8.10.1.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.3.1" style="font-size:90%;">26.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.8.10.1.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.4.1" style="font-size:90%;">44.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T9.8.10.1.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.5.1" style="font-size:90%;">51.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.8.10.1.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.6.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.8.10.1.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.7.1" style="font-size:90%;">31.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.8.10.1.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.8.1" style="font-size:90%;">51.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T9.8.10.1.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.10.1.9.1" style="font-size:90%;">63.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.11.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.11.2.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.1.1" style="font-size:90%;">FastSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.11.2.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.2.1" style="font-size:90%;">31.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.11.2.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.3.1" style="font-size:90%;">19.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.11.2.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.4.1" style="font-size:90%;">38.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.11.2.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.5.1" style="font-size:90%;">40.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.11.2.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.6.1" style="font-size:90%;">35.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.11.2.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.7.1" style="font-size:90%;">21.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.11.2.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.8.1" style="font-size:90%;">41.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.11.2.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.11.2.9.1" style="font-size:90%;">48.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.12.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.12.3.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.1.1" style="font-size:90%;">MobileSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.12.3.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.2.1" style="font-size:90%;">34.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.12.3.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.3.1" style="font-size:90%;">22.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.12.3.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.4.1" style="font-size:90%;">39.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.12.3.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.5.1" style="font-size:90%;">47.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.12.3.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.6.1" style="font-size:90%;">42.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.12.3.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.7.1" style="font-size:90%;">27.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.12.3.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.8.1" style="font-size:90%;">46.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.12.3.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.12.3.9.1" style="font-size:90%;">61.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.13.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.13.4.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.1.1" style="font-size:90%;">EdgeSAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.13.4.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.2.1" style="font-size:90%;">35.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.13.4.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.3.1" style="font-size:90%;">23.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.13.4.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.4.1" style="font-size:90%;">40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.13.4.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.5.1" style="font-size:90%;">46.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.13.4.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.6.1" style="font-size:90%;">32.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.13.4.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.7.1" style="font-size:90%;">21.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.13.4.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.8.1" style="font-size:90%;">44.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.13.4.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.13.4.9.1" style="font-size:90%;">59.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.14.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.14.5.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.1.1" style="font-size:90%;">EfficientSAM-Ti</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.14.5.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.2.1" style="font-size:90%;">32.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.14.5.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.3.1" style="font-size:90%;">22.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.14.5.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.4.1" style="font-size:90%;">39.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.14.5.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.5.1" style="font-size:90%;">41.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.14.5.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.6.1" style="font-size:90%;">38.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.14.5.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.7.1" style="font-size:90%;">26.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.14.5.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.8.1" style="font-size:90%;">43.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.14.5.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.14.5.9.1" style="font-size:90%;">53.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.15.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.15.6.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.1.1" style="font-size:90%;">EfficientSAM-S</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.15.6.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.2.1" style="font-size:90%;">30.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.15.6.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.3.1" style="font-size:90%;">25.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.15.6.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.4.1" style="font-size:90%;">38.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.15.6.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.5.1" style="font-size:90%;">33.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.15.6.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.6.1" style="font-size:90%;">35.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.15.6.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.7.1" style="font-size:90%;">27.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.15.6.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.8.1" style="font-size:90%;">41.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.15.6.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.15.6.9.1" style="font-size:90%;">44.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.16.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.16.7.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.16.7.1.1" style="font-size:90%;">RepViT-SAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.16.7.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.16.7.2.1" style="font-size:90%;">36.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.16.7.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.16.7.3.1" style="font-size:90%;">24.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.16.7.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.16.7.4.1" style="font-size:90%;">41.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.16.7.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.16.7.5.1" style="font-size:90%;">48.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.16.7.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.16.7.6.1" style="font-size:90%;">44.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.16.7.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.16.7.7.1" style="font-size:90%;">29.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.16.7.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.16.7.8.1" style="font-size:90%;">48.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.16.7.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.16.7.9.1" style="font-size:90%;">61.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.17.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.17.8.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.1.1" style="font-size:90%;">SlimSAM-50</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.17.8.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.2.1" style="font-size:90%;">34.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.17.8.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.3.1" style="font-size:90%;">24.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.17.8.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.4.1" style="font-size:90%;">40.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.17.8.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.5.1" style="font-size:90%;">43.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.17.8.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.6.1" style="font-size:90%;">42.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.17.8.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.7.1" style="font-size:90%;">29.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.17.8.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.8.1" style="font-size:90%;">46.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.17.8.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.17.8.9.1" style="font-size:90%;">56.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.18.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.18.9.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.1.1" style="font-size:90%;">SlimSAM-77</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.18.9.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.2.1" style="font-size:90%;">34.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.18.9.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.3.1" style="font-size:90%;">22.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.18.9.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.4.1" style="font-size:90%;">39.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.18.9.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.5.1" style="font-size:90%;">47.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.18.9.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.6.1" style="font-size:90%;">26.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.18.9.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.7.1" style="font-size:90%;">21.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.18.9.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.8.1" style="font-size:90%;">43.9</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.18.9.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.18.9.9.1" style="font-size:90%;">59.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.19.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.19.10.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.1.1" style="font-size:90%;">TinySAM</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.19.10.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.2.1" style="font-size:90%;">35.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.19.10.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.3.1" style="font-size:90%;">23.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.19.10.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.4.1" style="font-size:90%;">39.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.19.10.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.5.1" style="font-size:90%;">47.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.19.10.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.6.1" style="font-size:90%;">43.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.19.10.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.7.1" style="font-size:90%;">27.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.19.10.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.8.1" style="font-size:90%;">46.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.19.10.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.19.10.9.1" style="font-size:90%;">61.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.20.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.20.11.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.1.1" style="font-size:90%;">EfficientViT-SAM-L0</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.20.11.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.2.1" style="font-size:90%;">37.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.20.11.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.3.1" style="font-size:90%;">24.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.20.11.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.4.1" style="font-size:90%;">42.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.20.11.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.5.1" style="font-size:90%;">51.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.20.11.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.6.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.20.11.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.7.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.20.11.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.8.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.20.11.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.20.11.9.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.21.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.8.21.12.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.21.12.1.1" style="font-size:90%;">EfficientViT-SAM-XL1</span></th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.21.12.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.21.12.2.1" style="font-size:90%;">39.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.21.12.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.21.12.3.1" style="font-size:90%;">26.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.21.12.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.21.12.4.1" style="font-size:90%;">44.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T9.8.21.12.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T9.8.21.12.5.1" style="font-size:90%;">52.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.21.12.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.21.12.6.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.21.12.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.21.12.7.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.21.12.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.21.12.8.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.21.12.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.21.12.9.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.22.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T9.8.22.13.1" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.1.1" style="font-size:90%;">NanoSAM</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.2.1" style="font-size:90%;">25.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.3.1" style="font-size:90%;">13.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.4.1" style="font-size:90%;">31.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T9.8.22.13.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.5.1" style="font-size:90%;">37.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.6.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.7.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.8.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T9.8.22.13.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T9.8.22.13.9.1" style="font-size:90%;">-</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 9: </span>Quantitative results of instance segmentation on COCO with Detic <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib165" title=""><span class="ltx_text" style="font-size:90%;">165</span></a>]</cite> or H-Deformable-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib52" title=""><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> as the object detector.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">For instance segmentation tasks, we adopt the ViTDet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib59" title=""><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite>, YOLOv8 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">53</span></a>]</cite>, GrounddingDINO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib69" title=""><span class="ltx_text" style="font-size:90%;">69</span></a>]</cite>, Detic <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib165" title=""><span class="ltx_text" style="font-size:90%;">165</span></a>]</cite> and H-Deformable-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib52" title=""><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> with Swin-L <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib71" title=""><span class="ltx_text" style="font-size:90%;">71</span></a>]</cite> as the object detectors which helps to generate bounding boxes of latent objects, with reference to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib117" title=""><span class="ltx_text" style="font-size:90%;">117</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib164" title=""><span class="ltx_text" style="font-size:90%;">164</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#bib.bib159" title=""><span class="ltx_text" style="font-size:90%;">159</span></a>]</cite>. We evaluate the average precision (AP) of all objects, as well as AP of small, medium, and large objects. The results are reported in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T7" title="Table 7 ‣ 4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T8" title="Table 8 ‣ 4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">8</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.T9" title="Table 9 ‣ 4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">9</span></a>. Similar to the previous results, we find that on COCO dataset EfficientViT-SAM-XL1 always presents the highest AP with any of the detectors (except H-Deformable-DETR). Under the setting of equipping ViTDet as detector and testing on LVIS dataset, SAMfast-H surpass all other variants with AP of 44.5%.</p>
</div>
<figure class="ltx_figure" id="S4.F17"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S4.F17.g1" src="x16.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F17.2.1.1" style="font-size:90%;">Figure 17</span>: </span><span class="ltx_text" id="S4.F17.3.2" style="font-size:90%;">The trade-off between throughput and mIoU of SAM and its variants. The scale of circles responses to models’ size.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">Based on the results in Section<a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS2" title="4.2 Efficiency Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4.2</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.SS3" title="4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we further make a throughput-mIoU scatter to observe variants’ efficiency-accuracy trade-off. Specifically, we select the throughput and mIoU that are evaluated on COCO dataset with ground truth bounding boxes as prompts. The results are illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.04960v1#S4.F17" title="Figure 17 ‣ 4.3 Accuracy Comparison ‣ 4 Evaluation ‣ On Efficient Variants of Segment Anything Model: A Survey"><span class="ltx_text ltx_ref_tag">17</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this survey, we have primarily discussed and evaluated the prominent works that focus on methods to efficiently segment anything and segment everything with reduced resource consumption and lower latency. For efficient SegAny tasks, most works adopt the approach of replacing either the image encoder or the entire architecture with a lightweight alternative, followed by training from scratch or through knowledge distillation. Other works aim to compress the original model by leveraging techniques such as quantization, pruning, or local optimization. For efficient SegEvery tasks, adopting an effective and efficient sampling strategy for prompt generation is essential.
After reviewing these methods in detail, we have also outlined four potential future research directions that may drive new trends in this area. Additionally, we have evaluated the efficiency, accuracy, and the corresponding trade-offs of these models in a consistent environment, providing a fair and valuable comparison. Our analysis shows that some variants have already outperformed the original SAM in specific scenarios, and we believe their success will inspire further exploration and innovation in this field.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.5.5.1" style="font-size:90%;">Achiam et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.7.1" style="font-size:90%;">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.8.1" style="font-size:90%;">Gpt-4 technical report.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.9.1" style="font-size:90%;">arXiv preprint arXiv:2303.08774</em><span class="ltx_text" id="bib.bib1.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.5.5.1" style="font-size:90%;">Ahmadi et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">
Mohsen Ahmadi, Ahmad Gholizadeh Lonbar, Abbas Sharifi, Ali Tarlani Beris, Mohammadsadegh Nouri, and Amir Sharifzadeh Javidi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.8.1" style="font-size:90%;">Application of segment anything model for civil infrastructure defect assessment.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.12600</em><span class="ltx_text" id="bib.bib2.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.5.5.1" style="font-size:90%;">Anil et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.7.1" style="font-size:90%;">
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.8.1" style="font-size:90%;">Palm 2 technical report.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.10403</em><span class="ltx_text" id="bib.bib3.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.5.5.1" style="font-size:90%;">Anwar et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.7.1" style="font-size:90%;">
Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.8.1" style="font-size:90%;">Structured pruning of deep convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.9.1" style="font-size:90%;">ACM Journal on Emerging Technologies in Computing Systems (JETC)</em><span class="ltx_text" id="bib.bib4.10.2" style="font-size:90%;">, 13(3):1–18, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.5.5.1" style="font-size:90%;">Ba et al. [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.8.1" style="font-size:90%;">Layer normalization.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.9.1" style="font-size:90%;">arXiv preprint arXiv:1607.06450</em><span class="ltx_text" id="bib.bib5.10.2" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">Banner et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
Ron Banner, Yury Nahshan, and Daniel Soudry.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">Post training 4-bit quantization of convolutional networks for rapid-deployment.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib6.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib6.11.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.5.5.1" style="font-size:90%;">Bolya et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.7.1" style="font-size:90%;">
Daniel Bolya, Chong Zhou, Fanyi Xiao, and Yong Jae Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.8.1" style="font-size:90%;">Yolact: Real-time instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span class="ltx_text" id="bib.bib7.11.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">Bommasani et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.7.1" style="font-size:90%;">
Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.8.1" style="font-size:90%;">On the opportunities and risks of foundation models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.9.1" style="font-size:90%;">arXiv preprint arXiv:2108.07258</em><span class="ltx_text" id="bib.bib8.10.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.5.5.1" style="font-size:90%;">Brown et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.7.1" style="font-size:90%;">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.8.1" style="font-size:90%;">Language models are few-shot learners.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib9.11.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.5.5.1" style="font-size:90%;">Cai et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.7.1" style="font-size:90%;">
Han Cai, Junyan Li, Muyan Hu, Chuang Gan, and Song Han.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.8.1" style="font-size:90%;">Efficientvit: Multi-scale linear attention for high-resolution dense prediction.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.9.1" style="font-size:90%;">arXiv preprint arXiv:2205.14756</em><span class="ltx_text" id="bib.bib10.10.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">Cao et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.7.1" style="font-size:90%;">
Yunkang Cao, Xiaohao Xu, Chen Sun, Yuqi Cheng, Zongwei Du, Liang Gao, and Weiming Shen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.8.1" style="font-size:90%;">Segment any anomaly without training via hybrid prompt regularization.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.10724</em><span class="ltx_text" id="bib.bib11.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">Chang et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
Qi Chang, Danish Ahmad, Jennifer Toth, Rebecca Bascom, and William E Higgins.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">Esfpnet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib12.10.2" style="font-size:90%;">Medical Imaging 2023: Biomedical Applications in Molecular, Structural, and Functional Imaging</em><span class="ltx_text" id="bib.bib12.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.5.5.1" style="font-size:90%;">Chen et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">
Pengguang Chen, Shu Liu, Hengshuang Zhao, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.8.1" style="font-size:90%;">Distilling knowledge via knowledge review.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib13.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">Chen et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.7.1" style="font-size:90%;">
Tianrun Chen, Lanyun Zhu, Chaotao Deng, Runlong Cao, Yan Wang, Shangzhan Zhang, Zejian Li, Lingyun Sun, Ying Zang, and Papa Mao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.8.1" style="font-size:90%;">Sam-adapter: Adapting segment anything in underperformed scenes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib14.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib14.11.3" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">Chen et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.7.1" style="font-size:90%;">
Tianrun Chen, Lanyun Zhu, Chaotao Ding, Runlong Cao, Yan Wang, Zejian Li, Lingyun Sun, Papa Mao, and Ying Zang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.8.1" style="font-size:90%;">Sam fails to segment anything?–sam-adapter: Adapting sam in underperformed scenes: Camouflage, shadow, medical image segmentation, and more.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.09148</em><span class="ltx_text" id="bib.bib15.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.5.5.1" style="font-size:90%;">Chen et al. [2020a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">
Xizi Chen, Jingyang Zhu, Jingbo Jiang, and Chi-Ying Tsui.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">Tight compression: Compressing cnn model tightly through unstructured pruning and simulated annealing based permutation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.10.2" style="font-size:90%;">2020 57th ACM/IEEE Design Automation Conference (DAC)</em><span class="ltx_text" id="bib.bib16.11.3" style="font-size:90%;">, 2020a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">Chen et al. [2020b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.7.1" style="font-size:90%;">
Yinpeng Chen, Xiyang Dai, Mengchen Liu, Dongdong Chen, Lu Yuan, and Zicheng Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.8.1" style="font-size:90%;">Dynamic convolution: Attention over convolution kernels.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib17.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib17.11.3" style="font-size:90%;">, 2020b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.5.5.1" style="font-size:90%;">Chen et al. [2023c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">
Zigeng Chen, Gongfan Fang, Xinyin Ma, and Xinchao Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.8.1" style="font-size:90%;">0.1% data makes segment anything slim.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.05284</em><span class="ltx_text" id="bib.bib18.10.2" style="font-size:90%;">, 2023c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.5.5.1" style="font-size:90%;">Cheng et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">
Ho Kei Cheng, Seoung Wug Oh, Brian Price, Alexander Schwing, and Joon-Young Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.8.1" style="font-size:90%;">Tracking anything with decoupled video segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib19.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib19.11.3" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">Cheng et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, and Yi Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">Segment and track anything.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.06558</em><span class="ltx_text" id="bib.bib20.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.5.5.1" style="font-size:90%;">Chowdhery et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.7.1" style="font-size:90%;">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.8.1" style="font-size:90%;">Palm: Scaling language modeling with pathways.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.9.1" style="font-size:90%;">Journal of Machine Learning Research</em><span class="ltx_text" id="bib.bib21.10.2" style="font-size:90%;">, 24(240):1–113, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.5.5.1" style="font-size:90%;">Dai et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.7.1" style="font-size:90%;">
Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.8.1" style="font-size:90%;">Deformable convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.10.2" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</em><span class="ltx_text" id="bib.bib22.11.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.5.5.1" style="font-size:90%;">Dao et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.7.1" style="font-size:90%;">
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.8.1" style="font-size:90%;">Flashattention: Fast and memory-efficient exact attention with io-awareness.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib23.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib23.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">Delatolas et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
Thanos Delatolas, Vicky Kalogeiton, and Dim P Papadopoulos.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">Learning the what and how of annotation in video object segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib24.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em><span class="ltx_text" id="bib.bib24.11.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">Deng et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
Ruining Deng, Can Cui, Quan Liu, Tianyuan Yao, Lucas W Remedios, Shunxing Bao, Bennett A Landman, Lee E Wheless, Lori A Coburn, Keith T Wilson, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">Segment anything model (sam) for digital pathology: Assess zero-shot segmentation on whole slide imaging.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.04155</em><span class="ltx_text" id="bib.bib25.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">Ding et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, Nanning Zheng, and Furu Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">Longnet: Scaling transformers to 1,000,000,000 tokens.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.9.1" style="font-size:90%;">arXiv preprint arXiv:2307.02486</em><span class="ltx_text" id="bib.bib26.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">Dong et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.7.1" style="font-size:90%;">
Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, and Maciej A Mazurowski.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.8.1" style="font-size:90%;">Segment anything model 2: an application to 2d and 3d medical images.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.00756</em><span class="ltx_text" id="bib.bib27.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">Dong et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
Shichao Dong, Fayao Liu, and Guosheng Lin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">Leveraging large-scale pretrained vision foundation models for label-efficient 3d point cloud segmentation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.9.1" style="font-size:90%;">arXiv preprint arXiv:2311.01989</em><span class="ltx_text" id="bib.bib28.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.5.5.1" style="font-size:90%;">Dosovitskiy et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.8.1" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at scale.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.9.1" style="font-size:90%;">arXiv preprint arXiv:2010.11929</em><span class="ltx_text" id="bib.bib29.10.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">Duan et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.7.1" style="font-size:90%;">
Yuchen Duan, Weiyun Wang, Zhe Chen, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Hongsheng Li, Jifeng Dai, and Wenhai Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.8.1" style="font-size:90%;">Vision-rwkv: Efficient and scalable visual perception with rwkv-like architectures.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.9.1" style="font-size:90%;">arXiv preprint arXiv:2403.02308</em><span class="ltx_text" id="bib.bib30.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">Edalati et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.7.1" style="font-size:90%;">
Ali Edalati, Marzieh Tahaei, Ahmad Rashid, Vahid Partovi Nia, James J Clark, and Mehdi Rezagholizadeh.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.8.1" style="font-size:90%;">Kronecker decomposition for gpt compression.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.9.1" style="font-size:90%;">arXiv preprint arXiv:2110.08152</em><span class="ltx_text" id="bib.bib31.10.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">Frantar et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.7.1" style="font-size:90%;">
Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.8.1" style="font-size:90%;">Gptq: Accurate post-training quantization for generative pre-trained transformers.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.9.1" style="font-size:90%;">arXiv preprint arXiv:2210.17323</em><span class="ltx_text" id="bib.bib32.10.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.5.5.1" style="font-size:90%;">Fu et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.7.1" style="font-size:90%;">
Jianhai Fu, Yuanjie Yu, Ningchuan Li, Yi Zhang, Qichao Chen, Jianping Xiong, Jun Yin, and Zhiyu Xiang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.8.1" style="font-size:90%;">Lite-sam is actually what you need for segment everything.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.9.1" style="font-size:90%;">arXiv preprint arXiv:2407.08965</em><span class="ltx_text" id="bib.bib33.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.5.5.1" style="font-size:90%;">Gan et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.7.1" style="font-size:90%;">
Zhe Gan, Linjie Li, Chunyuan Li, Lijuan Wang, Zicheng Liu, Jianfeng Gao, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.8.1" style="font-size:90%;">Vision-language pre-training: Basics, recent advances, and future trends.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.9.1" style="font-size:90%;">Foundations and Trends® in Computer Graphics and Vision</em><span class="ltx_text" id="bib.bib34.10.2" style="font-size:90%;">, 14(3–4):163–352, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.5.5.1" style="font-size:90%;">Gao et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">
Ruochen Gao, Donghang Lyu, and Marius Staring.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.8.1" style="font-size:90%;">Swin-litemedsam: A lightweight box-based segment anything model for large-scale medical image datasets.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.9.1" style="font-size:90%;">arXiv preprint arXiv:2409.07172</em><span class="ltx_text" id="bib.bib35.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.5.5.1" style="font-size:90%;">Giannakis et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.7.1" style="font-size:90%;">
Iraklis Giannakis, Anshuman Bhardwaj, Lydia Sam, and Georgios Leontidis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.8.1" style="font-size:90%;">Deep learning universal crater detection using segment anything model (sam).
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.07764</em><span class="ltx_text" id="bib.bib36.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.5.5.1" style="font-size:90%;">Grachev et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.7.1" style="font-size:90%;">
Artem M Grachev, Dmitry I Ignatov, and Andrey V Savchenko.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.8.1" style="font-size:90%;">Neural networks compression for language modeling.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib37.10.2" style="font-size:90%;">International Conference on Pattern Recognition and Machine Intelligence</em><span class="ltx_text" id="bib.bib37.11.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.5.5.1" style="font-size:90%;">Graham et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.7.1" style="font-size:90%;">
Benjamin Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Hervé Jégou, and Matthijs Douze.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.8.1" style="font-size:90%;">Levit: a vision transformer in convnet’s clothing for faster inference.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib38.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span class="ltx_text" id="bib.bib38.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.4.4.1" style="font-size:90%;">Gu and Dao [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.6.1" style="font-size:90%;">
Albert Gu and Tri Dao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.7.1" style="font-size:90%;">Mamba: Linear-time sequence modeling with selective state spaces.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.8.1" style="font-size:90%;">arXiv preprint arXiv:2312.00752</em><span class="ltx_text" id="bib.bib39.9.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.5.5.1" style="font-size:90%;">Gupta et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.7.1" style="font-size:90%;">
Agrim Gupta, Piotr Dollar, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.8.1" style="font-size:90%;">Lvis: A dataset for large vocabulary instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib40.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib40.11.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.5.5.1" style="font-size:90%;">Hajimolahoseini et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.7.1" style="font-size:90%;">
Habib Hajimolahoseini, Walid Ahmed, Mehdi Rezagholizadeh, Vahid Partovinia, and Yang Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.8.1" style="font-size:90%;">Strategies for applying low rank decomposition to transformer-based models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib41.10.2" style="font-size:90%;">36th Conference on Neural Information Processing Systems (NeurIPS2022)</em><span class="ltx_text" id="bib.bib41.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.5.5.1" style="font-size:90%;">He et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.7.1" style="font-size:90%;">
Haibin He, Jing Zhang, Mengyang Xu, Juhua Liu, Bo Du, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.8.1" style="font-size:90%;">Scalable mask annotation for video text spotting.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.01443</em><span class="ltx_text" id="bib.bib42.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.5.5.1" style="font-size:90%;">He et al. [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.7.1" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.8.1" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib43.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib43.11.3" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.5.5.1" style="font-size:90%;">He et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.7.1" style="font-size:90%;">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.8.1" style="font-size:90%;">Masked autoencoders are scalable vision learners.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib44.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib44.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.5.5.1" style="font-size:90%;">Hinton et al. [2015]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.7.1" style="font-size:90%;">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.8.1" style="font-size:90%;">Distilling the knowledge in a neural network.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.9.1" style="font-size:90%;">arXiv preprint arXiv:1503.02531</em><span class="ltx_text" id="bib.bib45.10.2" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.5.5.1" style="font-size:90%;">Hu et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.7.1" style="font-size:90%;">
Chuanfei Hu, Tianyi Xia, Shenghong Ju, and Xinde Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.8.1" style="font-size:90%;">When sam meets medical images: An investigation of segment anything model (sam) on multi-phase liver tumor segmentation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.08506</em><span class="ltx_text" id="bib.bib46.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.5.5.1" style="font-size:90%;">Hu et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.7.1" style="font-size:90%;">
Jie Hu, Li Shen, and Gang Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.8.1" style="font-size:90%;">Squeeze-and-excitation networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib47.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib47.11.3" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.5.5.1" style="font-size:90%;">Hu et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.7.1" style="font-size:90%;">
Mingzhe Hu, Yuheng Li, and Xiaofeng Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.8.1" style="font-size:90%;">Skinsam: Empowering skin cancer segmentation with segment anything model.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.13973</em><span class="ltx_text" id="bib.bib48.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.5.5.1" style="font-size:90%;">Huang et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.7.1" style="font-size:90%;">
You Huang, Wenbin Lai, Jiayi Ji, Liujuan Cao, Shengchuan Zhang, and Rongrong Ji.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.8.1" style="font-size:90%;">Hrsam: Efficiently segment anything in high-resolution images.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.9.1" style="font-size:90%;">arXiv preprint arXiv:2407.02109</em><span class="ltx_text" id="bib.bib49.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib50.4.4.1" style="font-size:90%;">Ioffe [2015]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.6.1" style="font-size:90%;">
Sergey Ioffe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.7.1" style="font-size:90%;">Batch normalization: Accelerating deep network training by reducing internal covariate shift.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.8.1" style="font-size:90%;">arXiv preprint arXiv:1502.03167</em><span class="ltx_text" id="bib.bib50.9.2" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib51.5.5.1" style="font-size:90%;">Ji et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.7.1" style="font-size:90%;">
Wei Ji, Jingjing Li, Qi Bi, Tingwei Liu, Wenbo Li, and Li Cheng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.8.1" style="font-size:90%;">Segment anything is not always perfect: An investigation of sam on different real-world applications.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.9.1" style="font-size:90%;">Machine Intelligence Research</em><span class="ltx_text" id="bib.bib51.10.2" style="font-size:90%;">, 21:617–630, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib52.5.5.1" style="font-size:90%;">Jia et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.7.1" style="font-size:90%;">
Ding Jia, Yuhui Yuan, Haodi He, Xiaopei Wu, Haojun Yu, Weihong Lin, Lei Sun, Chao Zhang, and Han Hu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.8.1" style="font-size:90%;">Detrs with hybrid matching.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib52.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib52.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib53.5.5.1" style="font-size:90%;">Jocher et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.7.1" style="font-size:90%;">
Glenn Jocher, Ayush Chaurasia, and Jing Qiu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.8.1" style="font-size:90%;">Yolo by ultralytics, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib54.5.5.1" style="font-size:90%;">Ke et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.7.1" style="font-size:90%;">
Lei Ke, Mingqiao Ye, Martin Danelljan, Yifan liu, Yu-Wing Tai, Chi-Keung Tang, and Fisher Yu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.8.1" style="font-size:90%;">Segment anything in high quality.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib54.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib54.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib55.5.5.1" style="font-size:90%;">Kirillov et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.7.1" style="font-size:90%;">
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.8.1" style="font-size:90%;">Segment anything.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib55.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib55.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib56.5.5.1" style="font-size:90%;">Laurent et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.7.1" style="font-size:90%;">
César Laurent, Camille Ballas, Thomas George, Nicolas Ballas, and Pascal Vincent.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.8.1" style="font-size:90%;">Revisiting loss modelling for unstructured pruning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.9.1" style="font-size:90%;">arXiv preprint arXiv:2006.12279</em><span class="ltx_text" id="bib.bib56.10.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib57.5.5.1" style="font-size:90%;">Le et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.7.1" style="font-size:90%;">
Bao-Hiep Le, Dang-Khoa Nguyen-Vu, Trong-Hieu Nguyen-Mau, Hai-Dang Nguyen, and Minh-Triet Tran.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.8.1" style="font-size:90%;">Medficientsam: A robust medical segmentation model with optimized inference pipeline for limited clinical settings.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib57.10.2" style="font-size:90%;">Submitted to CVPR 2024: Segment Anything In Medical Images On Laptop</em><span class="ltx_text" id="bib.bib57.11.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib58.5.5.1" style="font-size:90%;">Li et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.7.1" style="font-size:90%;">
Chunyuan Li, Zhe Gan, Zhengyuan Yang, Jianwei Yang, Linjie Li, Lijuan Wang, Jianfeng Gao, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.8.1" style="font-size:90%;">Multimodal foundation models: From specialists to general-purpose assistants.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.9.1" style="font-size:90%;">Foundations and Trends® in Computer Graphics and Vision</em><span class="ltx_text" id="bib.bib58.10.2" style="font-size:90%;">, 16(1-2):1–214, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib59.5.5.1" style="font-size:90%;">Li et al. [2022a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.7.1" style="font-size:90%;">
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.8.1" style="font-size:90%;">Exploring plain vision transformer backbones for object detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib59.10.2" style="font-size:90%;">European conference on computer vision</em><span class="ltx_text" id="bib.bib59.11.3" style="font-size:90%;">, 2022a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib60.5.5.1" style="font-size:90%;">Li et al. [2022b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.7.1" style="font-size:90%;">
Yanghao Li, Chao-Yuan Wu, Haoqi Fan, Karttikeya Mangalam, Bo Xiong, Jitendra Malik, and Christoph Feichtenhofer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.8.1" style="font-size:90%;">Mvitv2: Improved multiscale vision transformers for classification and detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib60.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib60.11.3" style="font-size:90%;">, 2022b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib61.5.5.1" style="font-size:90%;">Li et al. [2022c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.7.1" style="font-size:90%;">
Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, and Jian Ren.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.8.1" style="font-size:90%;">Efficientformer: Vision transformers at mobilenet speed.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib61.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib61.11.3" style="font-size:90%;">, 2022c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib62.5.5.1" style="font-size:90%;">Li et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.7.1" style="font-size:90%;">
Yanyu Li, Ju Hu, Yang Wen, Georgios Evangelidis, Kamyar Salahi, Yanzhi Wang, Sergey Tulyakov, and Jian Ren.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.8.1" style="font-size:90%;">Rethinking vision transformers for mobilenet size and speed.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib62.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib62.11.3" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib63.5.5.1" style="font-size:90%;">Li et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.7.1" style="font-size:90%;">
Yaqin Li, Dandan Wang, Cao Yuan, Hao Li, and Jing Hu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.8.1" style="font-size:90%;">Enhancing agricultural image segmentation with an agricultural segment anything model adapter.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.9.1" style="font-size:90%;">Sensors</em><span class="ltx_text" id="bib.bib63.10.2" style="font-size:90%;">, 23(18):7884, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib64.5.5.1" style="font-size:90%;">Li et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.7.1" style="font-size:90%;">
Yuheng Li, Mingzhe Hu, and Xiaofeng Yang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.8.1" style="font-size:90%;">Polyp-sam: Transfer sam for polyp segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib64.10.2" style="font-size:90%;">Medical Imaging 2024: Computer-Aided Diagnosis</em><span class="ltx_text" id="bib.bib64.11.3" style="font-size:90%;">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib65.5.5.1" style="font-size:90%;">Lin et al. [2014]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.7.1" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.8.1" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib65.10.2" style="font-size:90%;">European conference on computer vision</em><span class="ltx_text" id="bib.bib65.11.3" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib66.5.5.1" style="font-size:90%;">Lin et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.7.1" style="font-size:90%;">
Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.8.1" style="font-size:90%;">Feature pyramid networks for object detection.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib66.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib66.11.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib67.5.5.1" style="font-size:90%;">Liu et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.7.1" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.8.1" style="font-size:90%;">Visual instruction tuning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib67.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib67.11.3" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib68.5.5.1" style="font-size:90%;">Liu et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.7.1" style="font-size:90%;">
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.8.1" style="font-size:90%;">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.9.1" style="font-size:90%;">ACM Computing Surveys</em><span class="ltx_text" id="bib.bib68.10.2" style="font-size:90%;">, 55(9):1–35, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib69.5.5.1" style="font-size:90%;">Liu et al. [2023c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.7.1" style="font-size:90%;">
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.8.1" style="font-size:90%;">Grounding dino: Marrying dino with grounded pre-training for open-set object detection.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.9.1" style="font-size:90%;">arXiv preprint arXiv:2303.05499</em><span class="ltx_text" id="bib.bib69.10.2" style="font-size:90%;">, 2023c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib70.5.5.1" style="font-size:90%;">Liu et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.7.1" style="font-size:90%;">
Xinyu Liu, Jing Zhang, Kexin Zhang, Xu Liu, and Lingling Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.8.1" style="font-size:90%;">Lsvos challenge 3rd place report: Sam2 and cutie based vos.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.10469</em><span class="ltx_text" id="bib.bib70.10.2" style="font-size:90%;">, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib71.5.5.1" style="font-size:90%;">Liu et al. [2021a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.7.1" style="font-size:90%;">
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.8.1" style="font-size:90%;">Swin transformer: Hierarchical vision transformer using shifted windows.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib71.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span class="ltx_text" id="bib.bib71.11.3" style="font-size:90%;">, 2021a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib72.5.5.1" style="font-size:90%;">Liu et al. [2021b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.7.1" style="font-size:90%;">
Zhenhua Liu, Yunhe Wang, Kai Han, Wei Zhang, Siwei Ma, and Wen Gao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.8.1" style="font-size:90%;">Post-training quantization for vision transformer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib72.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib72.11.3" style="font-size:90%;">, 2021b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib73.5.5.1" style="font-size:90%;">Liu et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.7.1" style="font-size:90%;">
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.8.1" style="font-size:90%;">A convnet for the 2020s.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib73.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib73.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib74.5.5.1" style="font-size:90%;">Liu et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.7.1" style="font-size:90%;">
Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y Hou, and Max Tegmark.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.8.1" style="font-size:90%;">Kan: Kolmogorov-arnold networks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.9.1" style="font-size:90%;">arXiv preprint arXiv:2404.19756</em><span class="ltx_text" id="bib.bib74.10.2" style="font-size:90%;">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib75.5.5.1" style="font-size:90%;">Lou et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.7.1" style="font-size:90%;">
Ange Lou, Yamin Li, Yike Zhang, Robert F Labadie, and Jack Noble.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.8.1" style="font-size:90%;">Zero-shot surgical tool segmentation in monocular video using segment anything model 2.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib75.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.01648</em><span class="ltx_text" id="bib.bib75.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib76.5.5.1" style="font-size:90%;">Lu et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.7.1" style="font-size:90%;">
Zhihe Lu, Zeyu Xiao, Jiawang Bai, Zhiwei Xiong, and Xinchao Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.8.1" style="font-size:90%;">Can sam boost video super-resolution?
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib76.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.06524</em><span class="ltx_text" id="bib.bib76.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib77.5.5.1" style="font-size:90%;">Lv et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.7.1" style="font-size:90%;">
Chengtao Lv, Hong Chen, Jinyang Guo, Yifu Ding, and Xianglong Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.8.1" style="font-size:90%;">Ptq4sam: Post-training quantization for segment anything.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib77.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib77.11.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib78.5.5.1" style="font-size:90%;">Ma et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.7.1" style="font-size:90%;">
Jun Ma, Yuting He, Feifei Li, Lin Han, Chenyu You, and Bo Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.8.1" style="font-size:90%;">Segment anything in medical images.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.9.1" style="font-size:90%;">Nature Communications</em><span class="ltx_text" id="bib.bib78.10.2" style="font-size:90%;">, 15(1):654, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib79.5.5.1" style="font-size:90%;">Maaz et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.7.1" style="font-size:90%;">
Muhammad Maaz, Hanoona Rasheed, Salman Khan, and Fahad Shahbaz Khan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.8.1" style="font-size:90%;">Video-chatgpt: Towards detailed video understanding via large vision and language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.9.1" style="font-size:90%;">arXiv preprint arXiv:2306.05424</em><span class="ltx_text" id="bib.bib79.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib80.4.4.1" style="font-size:90%;">Mehta and Rastegari [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib80.6.1" style="font-size:90%;">
Sachin Mehta and Mohammad Rastegari.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib80.7.1" style="font-size:90%;">Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.8.1" style="font-size:90%;">arXiv preprint arXiv:2110.02178</em><span class="ltx_text" id="bib.bib80.9.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib81.5.5.1" style="font-size:90%;">Miyashita et al. [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib81.7.1" style="font-size:90%;">
Daisuke Miyashita, Edward H Lee, and Boris Murmann.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib81.8.1" style="font-size:90%;">Convolutional neural networks using logarithmic data representation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.9.1" style="font-size:90%;">arXiv preprint arXiv:1603.01025</em><span class="ltx_text" id="bib.bib81.10.2" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib82.5.5.1" style="font-size:90%;">Mohapatra et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib82.7.1" style="font-size:90%;">
Sovesh Mohapatra, Advait Gosai, and Gottfried Schlaug.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib82.8.1" style="font-size:90%;">Sam vs bet: A comparative study for brain extraction and segmentation of magnetic resonance images using deep learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.04738</em><span class="ltx_text" id="bib.bib82.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib83.5.5.1" style="font-size:90%;">Nahshan et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib83.7.1" style="font-size:90%;">
Yury Nahshan, Brian Chmiel, Chaim Baskin, Evgenii Zheltonozhskii, Ron Banner, Alex M Bronstein, and Avi Mendelson.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib83.8.1" style="font-size:90%;">Loss aware post-training quantization.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib83.9.1" style="font-size:90%;">Machine Learning</em><span class="ltx_text" id="bib.bib83.10.2" style="font-size:90%;">, 110(11):3245–3262, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib84.4.4.1" style="font-size:90%;">NVIDIA-AI-IOT [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib84.6.1" style="font-size:90%;">
NVIDIA-AI-IOT.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib84.7.1" style="font-size:90%;">Nanosam, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib85.5.5.1" style="font-size:90%;">Osco et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib85.7.1" style="font-size:90%;">
Lucas Prado Osco, Qiusheng Wu, Eduardo Lopes de Lemos, Wesley Nunes Gonçalves, Ana Paula Marques Ramos, Jonathan Li, and José Marcato Junior.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib85.8.1" style="font-size:90%;">The segment anything model (sam) for remote sensing applications: From zero to one shot.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.9.1" style="font-size:90%;">International Journal of Applied Earth Observation and Geoinformation</em><span class="ltx_text" id="bib.bib85.10.2" style="font-size:90%;">, 124:103540, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib86.5.5.1" style="font-size:90%;">Papa et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib86.7.1" style="font-size:90%;">
Lorenzo Papa, Paolo Russo, Irene Amerini, and Luping Zhou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib86.8.1" style="font-size:90%;">A survey on efficient vision transformers: algorithms, techniques, and performance benchmarking.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.9.1" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span class="ltx_text" id="bib.bib86.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib87.5.5.1" style="font-size:90%;">Peng et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib87.7.1" style="font-size:90%;">
Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Stella Biderman, Huanqi Cao, Xin Cheng, Michael Chung, Matteo Grella, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib87.8.1" style="font-size:90%;">Rwkv: Reinventing rnns for the transformer era.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib87.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.13048</em><span class="ltx_text" id="bib.bib87.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib88.4.4.1" style="font-size:90%;">PyTorch [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib88.6.1" style="font-size:90%;">
PyTorch.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib88.7.1" style="font-size:90%;">Accelerating generative ai with pytorch: Segment anything, fast, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib89.5.5.1" style="font-size:90%;">Radford et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib89.7.1" style="font-size:90%;">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib89.8.1" style="font-size:90%;">Learning transferable visual models from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib89.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib89.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib89.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib90.5.5.1" style="font-size:90%;">Radosavovic et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.7.1" style="font-size:90%;">
Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Dollár.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.8.1" style="font-size:90%;">Designing network design spaces.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib90.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib90.11.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib91.5.5.1" style="font-size:90%;">Rafaeli et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib91.7.1" style="font-size:90%;">
Osher Rafaeli, Tal Svoray, and Ariel Nahlieli.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib91.8.1" style="font-size:90%;">Prompt-based segmentation at multiple resolutions and lighting conditions using segment anything model 2.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib91.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.06970</em><span class="ltx_text" id="bib.bib91.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib92.5.5.1" style="font-size:90%;">Rajič et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib92.7.1" style="font-size:90%;">
Frano Rajič, Lei Ke, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, and Fisher Yu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib92.8.1" style="font-size:90%;">Segment anything meets point tracking.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.9.1" style="font-size:90%;">arXiv preprint arXiv:2307.01197</em><span class="ltx_text" id="bib.bib92.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib93.5.5.1" style="font-size:90%;">Ravi et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib93.7.1" style="font-size:90%;">
Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib93.8.1" style="font-size:90%;">Sam 2: Segment anything in images and videos.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib93.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.00714</em><span class="ltx_text" id="bib.bib93.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib94.5.5.1" style="font-size:90%;">Ronneberger et al. [2015]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.7.1" style="font-size:90%;">
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.8.1" style="font-size:90%;">U-net: Convolutional networks for biomedical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib94.10.2" style="font-size:90%;">International Conference on Medical Image Computing and Computer-Assisted Intervention</em><span class="ltx_text" id="bib.bib94.11.3" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib95.5.5.1" style="font-size:90%;">Roy et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib95.7.1" style="font-size:90%;">
Saikat Roy, Tassilo Wald, Gregor Koehler, Maximilian R Rokuss, Nico Disch, Julius Holzschuh, David Zimmerer, and Klaus H Maier-Hein.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib95.8.1" style="font-size:90%;">Sam. md: Zero-shot medical image segmentation capabilities of the segment anything model.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib95.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.05396</em><span class="ltx_text" id="bib.bib95.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib96.5.5.1" style="font-size:90%;">Ryali et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib96.7.1" style="font-size:90%;">
Chaitanya Ryali, Yuan-Ting Hu, Daniel Bolya, Chen Wei, Haoqi Fan, Po-Yao Huang, Vaibhav Aggarwal, Arkabandhu Chowdhury, Omid Poursaeed, Judy Hoffman, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib96.8.1" style="font-size:90%;">Hiera: A hierarchical vision transformer without the bells-and-whistles.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib96.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib96.10.2" style="font-size:90%;">International Conference on Machine Learning</em><span class="ltx_text" id="bib.bib96.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib97.5.5.1" style="font-size:90%;">Sandler et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib97.7.1" style="font-size:90%;">
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib97.8.1" style="font-size:90%;">Mobilenetv2: Inverted residuals and linear bottlenecks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib97.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib97.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib97.11.3" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib98.5.5.1" style="font-size:90%;">Shaharabany et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib98.7.1" style="font-size:90%;">
Tal Shaharabany, Aviad Dahan, Raja Giryes, and Lior Wolf.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib98.8.1" style="font-size:90%;">Autosam: Adapting sam to medical images by overloading the prompt encoder.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.9.1" style="font-size:90%;">arXiv preprint arXiv:2306.06370</em><span class="ltx_text" id="bib.bib98.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib99.5.5.1" style="font-size:90%;">Shen et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib99.7.1" style="font-size:90%;">
Chuyun Shen, Wenhao Li, Yuhang Shi, and Xiangfeng Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib99.8.1" style="font-size:90%;">Interactive 3d medical image segmentation with sam 2.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.02635</em><span class="ltx_text" id="bib.bib99.10.2" style="font-size:90%;">, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib100.5.5.1" style="font-size:90%;">Shen et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib100.7.1" style="font-size:90%;">
Qiuhong Shen, Xingyi Yang, and Xinchao Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib100.8.1" style="font-size:90%;">Anything-3d: Towards single-view anything reconstruction in the wild.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.10261</em><span class="ltx_text" id="bib.bib100.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib101.5.5.1" style="font-size:90%;">Shen et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib101.7.1" style="font-size:90%;">
Yiqing Shen, Jingxing Li, Xinyuan Shao, Blanca Inigo Romillo, Ankush Jindal, David Dreizin, and Mathias Unberath.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib101.8.1" style="font-size:90%;">Fastsam3d: An efficient segment anything model for 3d volumetric medical images.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.9.1" style="font-size:90%;">arXiv preprint arXiv:2403.09827</em><span class="ltx_text" id="bib.bib101.10.2" style="font-size:90%;">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib102.5.5.1" style="font-size:90%;">Shu et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib102.7.1" style="font-size:90%;">
Changyong Shu, Yifan Liu, Jianfei Gao, Zheng Yan, and Chunhua Shen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib102.8.1" style="font-size:90%;">Channel-wise knowledge distillation for dense prediction.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib102.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib102.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span class="ltx_text" id="bib.bib102.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib103.5.5.1" style="font-size:90%;">Shu et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib103.7.1" style="font-size:90%;">
Han Shu, Wenshuo Li, Yehui Tang, Yiman Zhang, Yihao Chen, Houqiang Li, Yunhe Wang, and Xinghao Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib103.8.1" style="font-size:90%;">Tinysam: Pushing the envelope for efficient segment anything model.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib103.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.13789</em><span class="ltx_text" id="bib.bib103.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib104.5.5.1" style="font-size:90%;">Songa et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib104.7.1" style="font-size:90%;">
Yanfei Songa, Bangzheng Pua, Peng Wanga, Hongxu Jiang, Dong Donga, and Yiqing Shen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib104.8.1" style="font-size:90%;">Sam-lightening: A lightweight segment anything model with dilated flash attention to achieve 30 times acceleration.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib104.9.1" style="font-size:90%;">arXiv preprint arXiv:2403.09195</em><span class="ltx_text" id="bib.bib104.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib105.5.5.1" style="font-size:90%;">Sun et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib105.7.1" style="font-size:90%;">
Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, and Furu Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib105.8.1" style="font-size:90%;">Retentive network: A successor to transformer for large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib105.9.1" style="font-size:90%;">arXiv preprint arXiv:2307.08621</em><span class="ltx_text" id="bib.bib105.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib106.5.5.1" style="font-size:90%;">Sun et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib106.7.1" style="font-size:90%;">
Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib106.8.1" style="font-size:90%;">Learning to (learn at test time): Rnns with expressive hidden states.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib106.9.1" style="font-size:90%;">arXiv preprint arXiv:2407.04620</em><span class="ltx_text" id="bib.bib106.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib107.5.5.1" style="font-size:90%;">Tahaei et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib107.7.1" style="font-size:90%;">
Marzieh S Tahaei, Ella Charlaix, Vahid Partovi Nia, Ali Ghodsi, and Mehdi Rezagholizadeh.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib107.8.1" style="font-size:90%;">Kroneckerbert: Learning kronecker decomposition for pre-trained language models via knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib107.9.1" style="font-size:90%;">arXiv preprint arXiv:2109.06243</em><span class="ltx_text" id="bib.bib107.10.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib108.5.5.1" style="font-size:90%;">Tai et al. [2015]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib108.7.1" style="font-size:90%;">
Cheng Tai, Tong Xiao, Yi Zhang, Xiaogang Wang, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib108.8.1" style="font-size:90%;">Convolutional neural networks with low-rank regularization.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib108.9.1" style="font-size:90%;">arXiv preprint arXiv:1511.06067</em><span class="ltx_text" id="bib.bib108.10.2" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib109.5.5.1" style="font-size:90%;">Tang et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib109.7.1" style="font-size:90%;">
George Tang, William Zhao, Logan Ford, David Benhaim, and Paul Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib109.8.1" style="font-size:90%;">Segment any mesh: Zero-shot mesh part segmentation via lifting segment anything 2 to 3d.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib109.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.13679</em><span class="ltx_text" id="bib.bib109.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib110.5.5.1" style="font-size:90%;">Tang et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib110.7.1" style="font-size:90%;">
Yunlong Tang, Jing Bi, Siting Xu, Luchuan Song, Susan Liang, Teng Wang, Daoan Zhang, Jie An, Jingyang Lin, Rongyi Zhu, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib110.8.1" style="font-size:90%;">Video understanding with large language models: A survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib110.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.17432</em><span class="ltx_text" id="bib.bib110.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib111.5.5.1" style="font-size:90%;">Touvron et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib111.7.1" style="font-size:90%;">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib111.8.1" style="font-size:90%;">Llama: Open and efficient foundation language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib111.9.1" style="font-size:90%;">arXiv preprint arXiv:2302.13971</em><span class="ltx_text" id="bib.bib111.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib112.5.5.1" style="font-size:90%;">Touvron et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib112.7.1" style="font-size:90%;">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib112.8.1" style="font-size:90%;">Llama 2: Open foundation and fine-tuned chat models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib112.9.1" style="font-size:90%;">arXiv preprint arXiv:2307.09288</em><span class="ltx_text" id="bib.bib112.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib113.4.4.1" style="font-size:90%;">Tran [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib113.6.1" style="font-size:90%;">
Tuyen Tran.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib113.7.1" style="font-size:90%;">The 2nd solution for lsvos challenge rvos track: Spatial-temporal refinement for consistent semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.8.1" style="font-size:90%;">arXiv preprint arXiv:2408.12447</em><span class="ltx_text" id="bib.bib113.9.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib114.5.5.1" style="font-size:90%;">Varadarajan et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib114.7.1" style="font-size:90%;">
Balakrishnan Varadarajan, Bilge Soran, Forrest Iandola, Xiaoyu Xiang, Yunyang Xiong, Chenchen Zhu, Raghuraman Krishnamoorthi, and Vikas Chandra.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib114.8.1" style="font-size:90%;">Squeezesam: User friendly mobile interactive segmentation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.06736</em><span class="ltx_text" id="bib.bib114.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib115.5.5.1" style="font-size:90%;">Vaswani et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib115.7.1" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib115.8.1" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib115.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib115.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib115.11.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib116.5.5.1" style="font-size:90%;">Wan et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib116.7.1" style="font-size:90%;">
Zhongwei Wan, Xin Wang, Che Liu, Samiul Alam, Yu Zheng, Zhongnan Qu, Shen Yan, Yi Zhu, Quanlu Zhang, Mosharaf Chowdhury, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib116.8.1" style="font-size:90%;">Efficient large language models: A survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib116.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.03863</em><span class="ltx_text" id="bib.bib116.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib117.5.5.1" style="font-size:90%;">Wang et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib117.7.1" style="font-size:90%;">
Ao Wang, Hui Chen, Zijia Lin, Jungong Han, and Guiguang Ding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib117.8.1" style="font-size:90%;">Repvit-sam: Towards real-time segmenting anything.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib117.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.05760</em><span class="ltx_text" id="bib.bib117.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib118.5.5.1" style="font-size:90%;">Wang et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib118.7.1" style="font-size:90%;">
Ao Wang, Hui Chen, Zijia Lin, Jungong Han, and Guiguang Ding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib118.8.1" style="font-size:90%;">Repvit: Revisiting mobile cnn from vit perspective.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib118.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib118.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib118.11.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib119.5.5.1" style="font-size:90%;">Wang et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib119.7.1" style="font-size:90%;">
Di Wang, Jing Zhang, Bo Du, Minqiang Xu, Lin Liu, Dacheng Tao, and Liangpei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib119.8.1" style="font-size:90%;">Samrs: Scaling-up remote sensing segmentation dataset with segment anything model.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib119.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib119.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib119.11.3" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib120.5.5.1" style="font-size:90%;">Wang et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib120.7.1" style="font-size:90%;">
Jinfeng Wang, Qiming Huang, Feilong Tang, Jia Meng, Jionglong Su, and Sifan Song.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib120.8.1" style="font-size:90%;">Stepwise feature fusion: Local guides global.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib120.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib120.10.2" style="font-size:90%;">International Conference on Medical Image Computing and Computer-Assisted Intervention</em><span class="ltx_text" id="bib.bib120.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib121.5.5.1" style="font-size:90%;">Wang et al. [2023c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib121.7.1" style="font-size:90%;">
Teng Wang, Jinrui Zhang, Junjie Fei, Hao Zheng, Yunlong Tang, Zhe Li, Mingqi Gao, and Shanshan Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib121.8.1" style="font-size:90%;">Caption anything: Interactive image description with diverse multimodal controls.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib121.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.02677</em><span class="ltx_text" id="bib.bib121.10.2" style="font-size:90%;">, 2023c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib122.4.4.1" style="font-size:90%;">Wang and Liu [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib122.6.1" style="font-size:90%;">
Yun Wang and Qiang Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib122.7.1" style="font-size:90%;">Aqa: An adaptive post-training quantization method for activations of cnns.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib122.8.1" style="font-size:90%;">IEEE Transactions on Computers</em><span class="ltx_text" id="bib.bib122.9.2" style="font-size:90%;">, 73(08):2025–2035, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib123.5.5.1" style="font-size:90%;">Wang et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib123.7.1" style="font-size:90%;">
Ziheng Wang, Jeremy Wohlwend, and Tao Lei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib123.8.1" style="font-size:90%;">Structured pruning of large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib123.9.1" style="font-size:90%;">arXiv preprint arXiv:1910.04732</em><span class="ltx_text" id="bib.bib123.10.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib124.5.5.1" style="font-size:90%;">Winata et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib124.7.1" style="font-size:90%;">
Genta Indra Winata, Andrea Madotto, Jamin Shin, Elham J Barezi, and Pascale Fung.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib124.8.1" style="font-size:90%;">On the effectiveness of low-rank matrix factorization for lstm model compression.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib124.9.1" style="font-size:90%;">arXiv preprint arXiv:1908.09982</em><span class="ltx_text" id="bib.bib124.10.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib125.5.5.1" style="font-size:90%;">Wu et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib125.7.1" style="font-size:90%;">
Junde Wu, Wei Ji, Yuanpei Liu, Huazhu Fu, Min Xu, Yanwu Xu, and Yueming Jin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib125.8.1" style="font-size:90%;">Medical sam adapter: Adapting segment anything model for medical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.12620</em><span class="ltx_text" id="bib.bib125.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib126.5.5.1" style="font-size:90%;">Wu et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib126.7.1" style="font-size:90%;">
Jay Zhangjie Wu, Xiuyu Li, Difei Gao, Zhen Dong, Jinbin Bai, Aishani Singh, Xiaoyu Xiang, Youzeng Li, Zuwei Huang, Yuanxi Sun, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib126.8.1" style="font-size:90%;">Cvpr 2023 text guided video editing competition.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib126.9.1" style="font-size:90%;">arXiv preprint arXiv:2310.16003</em><span class="ltx_text" id="bib.bib126.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib127.5.5.1" style="font-size:90%;">Wu et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib127.7.1" style="font-size:90%;">
Kan Wu, Jinnian Zhang, Houwen Peng, Mengchen Liu, Bin Xiao, Jianlong Fu, and Lu Yuan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib127.8.1" style="font-size:90%;">Tinyvit: Fast pretraining distillation for small vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib127.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib127.10.2" style="font-size:90%;">European conference on computer vision</em><span class="ltx_text" id="bib.bib127.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib128.5.5.1" style="font-size:90%;">Xiao et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib128.7.1" style="font-size:90%;">
Aoran Xiao, Weihao Xuan, Heli Qi, Yun Xing, Naoto Yokoya, and Shijian Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib128.8.1" style="font-size:90%;">Segment anything with multiple modalities.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.09085</em><span class="ltx_text" id="bib.bib128.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib129.5.5.1" style="font-size:90%;">Xiao et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib129.7.1" style="font-size:90%;">
Tete Xiao, Mannat Singh, Eric Mintun, Trevor Darrell, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib129.8.1" style="font-size:90%;">Early convolutions help transformers see better.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib129.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib129.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib129.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib130.5.5.1" style="font-size:90%;">Xie et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib130.7.1" style="font-size:90%;">
Defeng Xie, Ruichen Wang, Jian Ma, Chen Chen, Haonan Lu, Dong Yang, Fobo Shi, and Xiaodong Lin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib130.8.1" style="font-size:90%;">Edit everything: A text-guided generative system for images editing.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib130.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.14006</em><span class="ltx_text" id="bib.bib130.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib131.5.5.1" style="font-size:90%;">Xiong et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib131.7.1" style="font-size:90%;">
Yunyang Xiong, Bala Varadarajan, Lemeng Wu, Xiaoyu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai, Dilin Wang, Fei Sun, Forrest Iandola, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib131.8.1" style="font-size:90%;">Efficientsam: Leveraged masked image pretraining for efficient segment anything.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib131.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib131.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib131.11.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib132.4.4.1" style="font-size:90%;">Xu and McAuley [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib132.6.1" style="font-size:90%;">
Canwen Xu and Julian McAuley.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib132.7.1" style="font-size:90%;">A survey on model compression and acceleration for pretrained language models.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib132.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib132.9.2" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</em><span class="ltx_text" id="bib.bib132.10.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib133.5.5.1" style="font-size:90%;">Xu et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib133.7.1" style="font-size:90%;">
Shilin Xu, Haobo Yuan, Qingyu Shi, Lu Qi, Jingbo Wang, Yibo Yang, Yining Li, Kai Chen, Yunhai Tong, Bernard Ghanem, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib133.8.1" style="font-size:90%;">Rap-sam: Towards real-time all-purpose segment anything.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib133.9.1" style="font-size:90%;">arXiv preprint arXiv:2401.10228</em><span class="ltx_text" id="bib.bib133.10.2" style="font-size:90%;">, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib134.5.5.1" style="font-size:90%;">Xu et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib134.7.1" style="font-size:90%;">
Xiuwei Xu, Huangxing Chen, Linqing Zhao, Ziwei Wang, Jie Zhou, and Jiwen Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib134.8.1" style="font-size:90%;">Embodiedsam: Online segment any 3d thing in real time.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib134.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.11811</em><span class="ltx_text" id="bib.bib134.10.2" style="font-size:90%;">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib135.5.5.1" style="font-size:90%;">Yamagishi et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib135.7.1" style="font-size:90%;">
Yosuke Yamagishi, Shouhei Hanaoka, Tomohiro Kikuchi, Takahiro Nakao, Yuta Nakamura, Yukihiro Nomura, Soichiro Miki, Takeharu Yoshikawa, and Osamu Abe.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib135.8.1" style="font-size:90%;">Zero-shot 3d segmentation of abdominal organs in ct scans using segment anything model 2: Adapting video tracking capabilities for 3d medical imaging.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib135.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.06170</em><span class="ltx_text" id="bib.bib135.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib136.5.5.1" style="font-size:90%;">Yan et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib136.7.1" style="font-size:90%;">
Zhiling Yan, Weixiang Sun, Rong Zhou, Zhengqing Yuan, Kai Zhang, Yiwei Li, Tianming Liu, Quanzheng Li, Xiang Li, Lifang He, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib136.8.1" style="font-size:90%;">Biomedical sam 2: Segment anything in biomedical images and videos.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib136.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.03286</em><span class="ltx_text" id="bib.bib136.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib137.5.5.1" style="font-size:90%;">Yang et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib137.7.1" style="font-size:90%;">
Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, and Feng Zheng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib137.8.1" style="font-size:90%;">Track anything: Segment anything meets videos.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib137.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.11968</em><span class="ltx_text" id="bib.bib137.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib138.5.5.1" style="font-size:90%;">Yang et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib138.7.1" style="font-size:90%;">
Zhendong Yang, Zhe Li, Xiaohu Jiang, Yuan Gong, Zehuan Yuan, Danpei Zhao, and Chun Yuan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib138.8.1" style="font-size:90%;">Focal and global knowledge distillation for detectors.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib138.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib138.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib138.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib139.5.5.1" style="font-size:90%;">Yao et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib139.7.1" style="font-size:90%;">
Zhewei Yao, Reza Yazdani Aminabadi, Minjia Zhang, Xiaoxia Wu, Conglong Li, and Yuxiong He.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib139.8.1" style="font-size:90%;">Zeroquant: Efficient and affordable post-training quantization for large-scale transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib139.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib139.10.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib139.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib140.5.5.1" style="font-size:90%;">Yu et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib140.7.1" style="font-size:90%;">
Jieming Yu, An Wang, Wenzhen Dong, Mengya Xu, Mobarakol Islam, Jie Wang, Long Bai, and Hongliang Ren.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib140.8.1" style="font-size:90%;">Sam 2 in robotic surgery: An empirical evaluation for robustness and generalization in surgical video segmentation.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib140.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.04593</em><span class="ltx_text" id="bib.bib140.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib141.5.5.1" style="font-size:90%;">Yu et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib141.7.1" style="font-size:90%;">
Tao Yu, Runseng Feng, Ruoyu Feng, Jinming Liu, Xin Jin, Wenjun Zeng, and Zhibo Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib141.8.1" style="font-size:90%;">Inpaint anything: Segment anything meets image inpainting.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib141.9.1" style="font-size:90%;">arXiv preprint arXiv:2304.06790</em><span class="ltx_text" id="bib.bib141.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib142.5.5.1" style="font-size:90%;">Yu et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib142.7.1" style="font-size:90%;">
Weihao Yu, Mi Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi Feng, and Shuicheng Yan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib142.8.1" style="font-size:90%;">Metaformer is actually what you need for vision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib142.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib142.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib142.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib143.5.5.1" style="font-size:90%;">Yu et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib143.7.1" style="font-size:90%;">
Weihao Yu, Chenyang Si, Pan Zhou, Mi Luo, Yichen Zhou, Jiashi Feng, Shuicheng Yan, and Xinchao Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib143.8.1" style="font-size:90%;">Metaformer baselines for vision.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib143.9.1" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span class="ltx_text" id="bib.bib143.10.2" style="font-size:90%;">, 46(02):896–912, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib144.5.5.1" style="font-size:90%;">Yu et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib144.7.1" style="font-size:90%;">
Xiyu Yu, Tongliang Liu, Xinchao Wang, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib144.8.1" style="font-size:90%;">On compressing deep models by low rank and sparse decomposition.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib144.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib144.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib144.11.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib145.5.5.1" style="font-size:90%;">Yuan et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib145.7.1" style="font-size:90%;">
Haobo Yuan, Xiangtai Li, Lu Qi, Tao Zhang, Ming-Hsuan Yang, Shuicheng Yan, and Chen Change Loy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib145.8.1" style="font-size:90%;">Mamba or rwkv: Exploring high-quality and high-efficiency segment anything model.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib145.9.1" style="font-size:90%;">arXiv preprint arXiv:2406.19369</em><span class="ltx_text" id="bib.bib145.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib146.5.5.1" style="font-size:90%;">Yuan et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib146.7.1" style="font-size:90%;">
Zhihang Yuan, Chenhao Xue, Yiqi Chen, Qiang Wu, and Guangyu Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib146.8.1" style="font-size:90%;">Ptq4vit: Post-training quantization for vision transformers with twin uniform quantization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib146.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib146.10.2" style="font-size:90%;">European conference on computer vision</em><span class="ltx_text" id="bib.bib146.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib147.5.5.1" style="font-size:90%;">Zhang et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib147.7.1" style="font-size:90%;">
Chaoning Zhang, Dongshen Han, Yu Qiao, Jung Uk Kim, Sung-Ho Bae, Seungkyu Lee, and Choong Seon Hong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib147.8.1" style="font-size:90%;">Faster segment anything: Towards lightweight sam for mobile applications.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib147.9.1" style="font-size:90%;">arXiv preprint arXiv:2306.14289</em><span class="ltx_text" id="bib.bib147.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib148.5.5.1" style="font-size:90%;">Zhang et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib148.7.1" style="font-size:90%;">
Chaoning Zhang, Dongshen Han, Sheng Zheng, Jinwoo Choi, Tae-Ho Kim, and Choong Seon Hong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib148.8.1" style="font-size:90%;">Mobilesamv2: Faster segment anything to everything.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib148.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.09579</em><span class="ltx_text" id="bib.bib148.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib149.5.5.1" style="font-size:90%;">Zhang et al. [2023c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib149.7.1" style="font-size:90%;">
Chunhui Zhang, Li Liu, Yawen Cui, Guanjie Huang, Weilin Lin, Yiqian Yang, and Yuehong Hu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib149.8.1" style="font-size:90%;">A comprehensive survey on segment anything model for vision and beyond.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib149.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.08196</em><span class="ltx_text" id="bib.bib149.10.2" style="font-size:90%;">, 2023c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib150.5.5.1" style="font-size:90%;">Zhang et al. [2023d]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib150.7.1" style="font-size:90%;">
Chaoning Zhang, Fachrina Dewi Puspitasari, Sheng Zheng, Chenghao Li, Yu Qiao, Taegoo Kang, Xinru Shan, Chenshuang Zhang, Caiyan Qin, Francois Rameau, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib150.8.1" style="font-size:90%;">A survey on segment anything model (sam): Vision foundation model meets prompt engineering.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib150.9.1" style="font-size:90%;">arXiv preprint arXiv:2306.06211</em><span class="ltx_text" id="bib.bib150.10.2" style="font-size:90%;">, 2023d.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib151.5.5.1" style="font-size:90%;">Zhang et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib151.7.1" style="font-size:90%;">
Chunhui Zhang, Yawen Cui, Weilin Lin, Guanjie Huang, Yan Rong, Li Liu, and Shiguang Shan.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib151.8.1" style="font-size:90%;">Segment anything for videos: A systematic survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib151.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.08315</em><span class="ltx_text" id="bib.bib151.10.2" style="font-size:90%;">, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib152.5.5.1" style="font-size:90%;">Zhang et al. [2023e]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib152.7.1" style="font-size:90%;">
Leying Zhang, Xiaokang Deng, and Yu Lu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib152.8.1" style="font-size:90%;">Segment anything model (sam) for medical image segmentation: A preliminary review.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib152.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib152.10.2" style="font-size:90%;">2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em><span class="ltx_text" id="bib.bib152.11.3" style="font-size:90%;">, 2023e.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib153.5.5.1" style="font-size:90%;">Zhang et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib153.7.1" style="font-size:90%;">
Mingya Zhang, Liang Wang, Limei Gu, Zhao Li, Yaohui Wang, Tingshen Ling, and Xianping Tao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib153.8.1" style="font-size:90%;">Sam2-path: A better segment anything model for semantic segmentation in digital pathology.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib153.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.03651</em><span class="ltx_text" id="bib.bib153.10.2" style="font-size:90%;">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib154.5.5.1" style="font-size:90%;">Zhang et al. [2023f]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib154.7.1" style="font-size:90%;">
Renrui Zhang, Zhengkai Jiang, Ziyu Guo, Shilin Yan, Junting Pan, Xianzheng Ma, Hao Dong, Peng Gao, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib154.8.1" style="font-size:90%;">Personalize segment anything model with one shot.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib154.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.03048</em><span class="ltx_text" id="bib.bib154.10.2" style="font-size:90%;">, 2023f.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib155.4.4.1" style="font-size:90%;">Zhang and Shen [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib155.6.1" style="font-size:90%;">
Yichi Zhang and Zhenrong Shen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib155.7.1" style="font-size:90%;">Unleashing the potential of sam2 for biomedical images and videos: A survey.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib155.8.1" style="font-size:90%;">arXiv preprint arXiv:2408.12889</em><span class="ltx_text" id="bib.bib155.9.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib156.5.5.1" style="font-size:90%;">Zhang et al. [2023g]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib156.7.1" style="font-size:90%;">
Yichi Zhang, Yuan Cheng, and Yuan Qi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib156.8.1" style="font-size:90%;">Semisam: Exploring sam for enhancing semi-supervised medical image segmentation with extremely limited annotations.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib156.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.06316</em><span class="ltx_text" id="bib.bib156.10.2" style="font-size:90%;">, 2023g.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib157.5.5.1" style="font-size:90%;">Zhang et al. [2024c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib157.7.1" style="font-size:90%;">
Yichi Zhang, Zhenrong Shen, and Rushi Jiao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib157.8.1" style="font-size:90%;">Segment anything model for medical image segmentation: Current applications and future directions.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib157.9.1" style="font-size:90%;">Computers in Biology and Medicine</em><span class="ltx_text" id="bib.bib157.10.2" style="font-size:90%;">, 171:108238, 2024c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib158.5.5.1" style="font-size:90%;">Zhang et al. [2023h]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib158.7.1" style="font-size:90%;">
Zhenghao Zhang, Zhichao Wei, Shengfan Zhang, Zuozhuo Dai, and Siyu Zhu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib158.8.1" style="font-size:90%;">Uvosam: A mask-free paradigm for unsupervised video object segmentation via segment anything model.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib158.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.12659</em><span class="ltx_text" id="bib.bib158.10.2" style="font-size:90%;">, 2023h.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib159.5.5.1" style="font-size:90%;">Zhang et al. [2024d]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib159.7.1" style="font-size:90%;">
Zhuoyang Zhang, Han Cai, and Song Han.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib159.8.1" style="font-size:90%;">Efficientvit-sam: Accelerated segment anything model without performance loss.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib159.9.1" style="font-size:90%;">arXiv preprint arXiv:2402.05008</em><span class="ltx_text" id="bib.bib159.10.2" style="font-size:90%;">, 2024d.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib160.5.5.1" style="font-size:90%;">Zhao et al. [2023a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib160.7.1" style="font-size:90%;">
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib160.8.1" style="font-size:90%;">A survey of large language models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib160.9.1" style="font-size:90%;">arXiv preprint arXiv:2303.18223</em><span class="ltx_text" id="bib.bib160.10.2" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib161.5.5.1" style="font-size:90%;">Zhao et al. [2023b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib161.7.1" style="font-size:90%;">
Xu Zhao, Wenchao Ding, Yongqi An, Yinglong Du, Tao Yu, Min Li, Ming Tang, and Jinqiao Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib161.8.1" style="font-size:90%;">Fast segment anything.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib161.9.1" style="font-size:90%;">arXiv preprint arXiv:2306.12156</em><span class="ltx_text" id="bib.bib161.10.2" style="font-size:90%;">, 2023b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib162.4.4.1" style="font-size:90%;">Zhao [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib162.6.1" style="font-size:90%;">
Yingwei Zhao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib162.7.1" style="font-size:90%;">Efficient sam for medical image analysis, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib163.5.5.1" style="font-size:90%;">Zhao et al. [2023c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib163.7.1" style="font-size:90%;">
Yuyang Zhao, Enze Xie, Lanqing Hong, Zhenguo Li, and Gim Hee Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib163.8.1" style="font-size:90%;">Make-a-protagonist: Generic video editing with an ensemble of experts.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib163.9.1" style="font-size:90%;">arXiv preprint arXiv:2305.08850</em><span class="ltx_text" id="bib.bib163.10.2" style="font-size:90%;">, 2023c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib164.5.5.1" style="font-size:90%;">Zhou et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib164.7.1" style="font-size:90%;">
Chong Zhou, Xiangtai Li, Chen Change Loy, and Bo Dai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib164.8.1" style="font-size:90%;">Edgesam: Prompt-in-the-loop distillation for on-device deployment of sam.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib164.9.1" style="font-size:90%;">arXiv preprint arXiv:2312.06660</em><span class="ltx_text" id="bib.bib164.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib165.5.5.1" style="font-size:90%;">Zhou et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib165.7.1" style="font-size:90%;">
Xingyi Zhou, Rohit Girdhar, Armand Joulin, Philipp Krähenbühl, and Ishan Misra.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib165.8.1" style="font-size:90%;">Detecting twenty-thousand classes using image-level supervision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib165.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib165.10.2" style="font-size:90%;">European Conference on Computer Vision</em><span class="ltx_text" id="bib.bib165.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib166.5.5.1" style="font-size:90%;">Zhu et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib166.7.1" style="font-size:90%;">
Jiayuan Zhu, Yunli Qi, and Junde Wu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib166.8.1" style="font-size:90%;">Medical sam 2: Segment medical images as video via segment anything model 2.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib166.9.1" style="font-size:90%;">arXiv preprint arXiv:2408.00874</em><span class="ltx_text" id="bib.bib166.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib167.5.5.1" style="font-size:90%;">Zou et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib167.7.1" style="font-size:90%;">
Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Wang, Lijuan Wang, Jianfeng Gao, and Yong Jae Lee.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib167.8.1" style="font-size:90%;">Segment everything everywhere all at once.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib167.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib167.10.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Oct  7 11:16:52 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
