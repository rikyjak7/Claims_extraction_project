<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation</title>
<!--Generated on Fri Sep 13 01:20:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.08461v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S1" title="In VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S2" title="In VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S2.SS1" title="In 2 Related Work ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>SITS Crop Identification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S2.SS2" title="In 2 Related Work ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Attention &amp; Transformers in Vision</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S2.SS3" title="In 2 Related Work ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>SITS for Transformers</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3" title="In VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.SS1" title="In 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Encoder</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.SS1.SSS1" title="In 3.1 Encoder ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Downsampling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.SS1.SSS2" title="In 3.1 Encoder ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Self-Attention</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.SS1.SSS3" title="In 3.1 Encoder ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>FeedForward Network</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.SS2" title="In 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Decoder</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4" title="In VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS1" title="In 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS1.SSS1" title="In 4.1 Datasets ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>MTLCC</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS1.SSS2" title="In 4.1 Datasets ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>PASTIS</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS2" title="In 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS3" title="In 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS4" title="In 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS5" title="In 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Model Scalability</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S5" title="In VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ezra MacDonald 
<br class="ltx_break"/>University of Victoria 
<br class="ltx_break"/>Victoria, BC 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">macdonaldezra@gmail.com</span>
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Derek Jacoby 
<br class="ltx_break"/>University of Victoria 
<br class="ltx_break"/>Victoria, BC 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">derekja@gmail.com</span>
</span></span>
<span class="ltx_author_before">‚ÄÉ‚ÄÉ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yvonne Coady 
<br class="ltx_break"/>University of Victoria 
<br class="ltx_break"/>Victoria, BC 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.1.id1">ycoady@gmail.com</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">We introduce VistaFormer, a lightweight Transformer-based model architecture for the semantic segmentation of remote-sensing images. This model uses a multi-scale Transformer-based encoder with a lightweight decoder that aggregates global and local attention captured in the encoder blocks. VistaFormer uses position-free self-attention layers which simplifies the model architecture and removes the need to interpolate temporal and spatial codes, which can reduce model performance when training and testing image resolutions differ. We investigate simple techniques for filtering noisy input signals like clouds and demonstrate that improved model scalability can be achieved by substituting Multi-Head Self-Attention (MHSA) with Neighbourhood Attention (NA). Experiments on the PASTIS and MTLCC crop type segmentation benchmarks show that VistaFormer achieves better performance than comparable models and requires only 8% of the floating point operations using MHSA and 11% using NA while also using fewer trainable parameters. VistaFormer with MHSA improves on state-of-the-art mIoU scores by 0.1% on the PASTIS benchmark and 3% on the MTLCC benchmark while VistaFormer with NA improves on the MTLCC benchmark by 3.7%.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Semantic segmentation is a foundational task in computer vision that predicts a class category for each pixel, rather than an image-level prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib23" title="">23</a>]</cite>. This computer vision task is useful in remote sensing, especially for satellite image time series (SITS) data, where it is necessary to analyze temporal patterns and changes in specific geographical regions. An important application of SITS data is in identifying crop types, since crops undergo phenological events throughout their growth cycle that can be captured in remote sensing imagery <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite>. Accurately identifying crop types has profound for tasks including estimating agricultural yields, monitoring crop health, understanding food security vulnerabilities, creating climate adaptation strategies, and more.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">While including additional samples increases the breadth of information in a model‚Äôs input, it can dramatically increase the dimensions of input data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite>. Since the earth‚Äôs surface is covered by more than 60% clouds <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib20" title="">20</a>]</cite>, many of these additional inputs may be partially or completely obstructed by cloud coverage. The most performant models applied to crop-type segmentation benchmarks are Transformer-based models that apply self-attention along the temporal dimension <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite> or both the temporal and spatial dimension <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This paper introduces VistaFormer, an encoder-decoder model architecture that applies self-attention along the spatial dimension and uses gated convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib39" title="">39</a>]</cite> to enable downsampling the temporal dimension while rendering profound multi-scale representations. We show that Multi-Head Self-Attention (MHSA) can be substituted with Neighbourhood Attention (NA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib14" title="">14</a>]</cite> which dramatically reduces the number of floating point operations required to achieve optimal performance. To verify the performance of VistaFormer, we use two time-series crop-type segmentation benchmarks, namely the MTLCC and PASTIS benchmarks, both of which include few predicted classes and use Sentinel-2 data as inputs. We find that VistaFormer achieves improved overall Accuracy (oA) and mean-Intersection-over-Union (mIoU) scores relative to state-of-the-art performance while using only 8% of the floating point operations when using MHSA, and 11% with NA, and also using fewer trainable parameters. These advantages are provided by a model that does not require additional position code interpolation which can reduce performance when resolution in train and test datasets differs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib36" title="">36</a>]</cite> and make preparing model inputs simpler than in other proposed Transformer-based architectures.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Given the ease of use of the model and its low computational requirements, VistaFormer offers a valuable contribution to advancing time-series deep learning models in a domain aimed at solving some of Earth‚Äôs most urgent challenges. The code for implementing VistaFormer can be found <a class="ltx_ref ltx_href" href="https://github.com/macdonaldezra/VistaFormer" title="">here</a>, and the repository includes links to all data necessary to reproduce the experiments reported in this paper. This paper expands on the research presented in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib26" title="">26</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">This section reviews research on SITS crop identification, highlighting the progression from traditional machine learning models to advanced neural network approaches, explores the impact of attention mechanisms and Transformer architectures on vision tasks, and discusses the adaptation of these techniques for SITS, comparing our approach to notable models like U-TAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite> and TSViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>]</cite>.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>SITS Crop Identification</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">While some research has been done to use SITS data for identifying general land classes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib13" title="">13</a>]</cite>, crop type classification has been an especially active area of research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib12" title="">12</a>]</cite>. Some of the first models to identify crops using SITS data rely on machine learning models such as support vector machines and random forest classifiers, which struggle to learn complex non-linear relationships and often require thoughtfully engineered input features <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib40" title="">40</a>]</cite>. More recent research has demonstrated that models that include neural network layers like RNNs, LSTMs, and convolutions surpass these traditional models in performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib40" title="">40</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib29" title="">29</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib8" title="">8</a>]</cite> demonstrate improved crop prediction performance using LSTM-based architectures on Sentinel data while <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib12" title="">12</a>]</cite> finds that integrating both recurrent and CNN layers improves performance over pure recurrent layer-based architectures. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a>]</cite> uses CGRU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib3" title="">3</a>]</cite> and CLSTM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib31" title="">31</a>]</cite> layers to extract relevant features from raw optical SITS data and shows that these layers are capable of filtering out clouds from inputs. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib33" title="">33</a>]</cite> show that variations of 3D U-Nets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib42" title="">42</a>]</cite> have comparable performance for crop segmentation to models that integrate 2D U-Nets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib28" title="">28</a>]</cite> and recurrent layers.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Attention &amp; Transformers in Vision</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">While recurrent layers excel at learning deep representations of sequences, they struggle to process data in parallel and are challenged with learning long-range dependencies. The introduction of attention <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib2" title="">2</a>]</cite> and the subsequent introduction of the Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib34" title="">34</a>]</cite> architecture, improved on this layer by introducing self-attention mechanisms that enable parallel processing of global sequences and capturing long-range dependencies more effectively, enhancing both computational efficiency and the ability to understand complex patterns in data. While self-attention is highly parallelizable, its computational complexity scales quadratically with the size of the input, making encoding images as a raw sequence of pixels prohibitive for most images. ViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib9" title="">9</a>]</cite> introduced the first pure Transformer-based model that achieved state-of-the-art performance in image classification. This model reduced the computational complexity of applying the Transformer to vision by encoding images into patches and treating each patch as a sequence of tokens.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">For dense prediction tasks, PVT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib35" title="">35</a>]</cite> introduced a pyramid structure-based pure self-attention backbone that outperformed comparable CNN-based architectures. PVT was then improved on by models like Swin <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib21" title="">21</a>]</cite>, Twins <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib7" title="">7</a>]</cite>, and CoaT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib37" title="">37</a>]</cite> that removed fixed size position embeddings to enhance local feature representations and improve model results on dense prediction. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib36" title="">36</a>]</cite> introduced SegFormer, a more efficient alternative, that among other things introduced a purely data-driven position encoding layer using <math alttext="3\times 3" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mrow id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mn id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">3</mn><mo id="S2.SS2.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS2.p2.1.m1.1.1.1.cmml">√ó</mo><mn id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><times id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.1"></times><cn id="S2.SS2.p2.1.m1.1.1.2.cmml" type="integer" xref="S2.SS2.p2.1.m1.1.1.2">3</cn><cn id="S2.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="S2.SS2.p2.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">3\times 3</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">3 √ó 3</annotation></semantics></math> depth-wise convolutions in the MLP layer of the Transformer. While more recent model architectures like Mask2Former <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib6" title="">6</a>]</cite> and I-JEPA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib1" title="">1</a>]</cite> share structural similarities with the original Transformer architecture, such as employing self-attention mechanisms to process and compare different parts of the input data, the simplicity and effectiveness of the self-attention layer in the Transformer makes it ideal for constructing models that minimize floating point operations and parameter complexity.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>SITS for Transformers</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Previous work introduced U-TAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite> which uses a U-Net architecture with a temporal attention mask that is only computed for the lowest resolution layer and is then upsampled to higher resolution embeddings. These masks are used to collapse the temporal dimension along with a 1D convolution to produce a single map per resolution. We differ from U-TAE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite> most notably by downsampling both spatial and temporal dimensions after the first encoder layer to reduce floating point operations, and by computing spatial attention in each encoder block.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">TSViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>]</cite> proposes an architecture inspired by ViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib9" title="">9</a>]</cite>, that uses input dates to encode temporal positions and uses separate self-attention Transformer layers for computing attention weights along temporal and spatial dimensions. This architecture is effective but computationally expensive in terms of floating point operations since it does not downsample inputs and computes attention on time and space sequences separately. TSViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>]</cite> optimized model performance by encoding temporal positions using dates of the model by encoding also encodes temporal positions using dates, which does not accommodate integrating additional data sources like radar and requires additional data pre-processing for inputs.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">Most recently, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib4" title="">4</a>]</cite> introduced a model architecture that computes the similarity between a temporal context cluster and temporal input features. The temporal module is used to wrap a 2D segmentation model, allowing for enhanced model flexibility. The pre-trained model in their experiments holds state-of-the-art performance in terms of mIoU for crop-class segmentation on the PASTIS and MTLCC benchmarks used for our experiments. We compare our model‚Äôs performance instead to models that have a similar number of trainable parameters, achieve their performance from randomized weights, and report on both mIoU and oA scores as these benchmarks have significant class imbalances.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.7">In SITS semantic segmentation tasks, we are given an input <math alttext="\mathbf{X}\in\mathbb{R}^{C\times T\times H\times W}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">ùêó</mi><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">‚àà</mo><msup id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml"><mi id="S3.p1.1.m1.1.1.3.2" xref="S3.p1.1.m1.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.p1.1.m1.1.1.3.3" xref="S3.p1.1.m1.1.1.3.3.cmml"><mi id="S3.p1.1.m1.1.1.3.3.2" xref="S3.p1.1.m1.1.1.3.3.2.cmml">C</mi><mo id="S3.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.p1.1.m1.1.1.3.3.1.cmml">√ó</mo><mi id="S3.p1.1.m1.1.1.3.3.3" xref="S3.p1.1.m1.1.1.3.3.3.cmml">T</mi><mo id="S3.p1.1.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.p1.1.m1.1.1.3.3.1.cmml">√ó</mo><mi id="S3.p1.1.m1.1.1.3.3.4" xref="S3.p1.1.m1.1.1.3.3.4.cmml">H</mi><mo id="S3.p1.1.m1.1.1.3.3.1b" lspace="0.222em" rspace="0.222em" xref="S3.p1.1.m1.1.1.3.3.1.cmml">√ó</mo><mi id="S3.p1.1.m1.1.1.3.3.5" xref="S3.p1.1.m1.1.1.3.3.5.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><in id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></in><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ùêó</ci><apply id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.3.1.cmml" xref="S3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.p1.1.m1.1.1.3.2.cmml" xref="S3.p1.1.m1.1.1.3.2">‚Ñù</ci><apply id="S3.p1.1.m1.1.1.3.3.cmml" xref="S3.p1.1.m1.1.1.3.3"><times id="S3.p1.1.m1.1.1.3.3.1.cmml" xref="S3.p1.1.m1.1.1.3.3.1"></times><ci id="S3.p1.1.m1.1.1.3.3.2.cmml" xref="S3.p1.1.m1.1.1.3.3.2">ùê∂</ci><ci id="S3.p1.1.m1.1.1.3.3.3.cmml" xref="S3.p1.1.m1.1.1.3.3.3">ùëá</ci><ci id="S3.p1.1.m1.1.1.3.3.4.cmml" xref="S3.p1.1.m1.1.1.3.3.4">ùêª</ci><ci id="S3.p1.1.m1.1.1.3.3.5.cmml" xref="S3.p1.1.m1.1.1.3.3.5">ùëä</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\mathbf{X}\in\mathbb{R}^{C\times T\times H\times W}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">bold_X ‚àà blackboard_R start_POSTSUPERSCRIPT italic_C √ó italic_T √ó italic_H √ó italic_W end_POSTSUPERSCRIPT</annotation></semantics></math> and output <math alttext="\mathbf{Y}\in\mathbb{R}^{K\times H\times W}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">ùêò</mi><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">‚àà</mo><msup id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml"><mi id="S3.p1.2.m2.1.1.3.3.2" xref="S3.p1.2.m2.1.1.3.3.2.cmml">K</mi><mo id="S3.p1.2.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.p1.2.m2.1.1.3.3.1.cmml">√ó</mo><mi id="S3.p1.2.m2.1.1.3.3.3" xref="S3.p1.2.m2.1.1.3.3.3.cmml">H</mi><mo id="S3.p1.2.m2.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.p1.2.m2.1.1.3.3.1.cmml">√ó</mo><mi id="S3.p1.2.m2.1.1.3.3.4" xref="S3.p1.2.m2.1.1.3.3.4.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><in id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></in><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ùêò</ci><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">‚Ñù</ci><apply id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3"><times id="S3.p1.2.m2.1.1.3.3.1.cmml" xref="S3.p1.2.m2.1.1.3.3.1"></times><ci id="S3.p1.2.m2.1.1.3.3.2.cmml" xref="S3.p1.2.m2.1.1.3.3.2">ùêæ</ci><ci id="S3.p1.2.m2.1.1.3.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3.3">ùêª</ci><ci id="S3.p1.2.m2.1.1.3.3.4.cmml" xref="S3.p1.2.m2.1.1.3.3.4">ùëä</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathbf{Y}\in\mathbb{R}^{K\times H\times W}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">bold_Y ‚àà blackboard_R start_POSTSUPERSCRIPT italic_K √ó italic_H √ó italic_W end_POSTSUPERSCRIPT</annotation></semantics></math> where <math alttext="C" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_C</annotation></semantics></math> denotes input channels, <math alttext="H" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">italic_H</annotation></semantics></math> and <math alttext="W" class="ltx_Math" display="inline" id="S3.p1.5.m5.1"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ùëä</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.p1.5.m5.1d">italic_W</annotation></semantics></math> indicate input dimensions, <math alttext="T" class="ltx_Math" display="inline" id="S3.p1.6.m6.1"><semantics id="S3.p1.6.m6.1a"><mi id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.p1.6.m6.1d">italic_T</annotation></semantics></math> the number of samples, and <math alttext="K" class="ltx_Math" display="inline" id="S3.p1.7.m7.1"><semantics id="S3.p1.7.m7.1a"><mi id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.p1.7.m7.1d">italic_K</annotation></semantics></math> defines predicted classes.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="259" id="S3.F1.g1" src="x1.png" width="433"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">The VistaFormer model architecture uses a three-layer encoder-decoder architecture where the encoder blocks downsample inputs and computes self-attention while the decoder blocks are comprised of lightweight upsampling layers that unify features from the encoder outputs to generate dense predictions.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="746" id="S3.F2.sf1.g1" src="x2.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.sf1.2.1.1" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="746" id="S3.F2.sf2.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.sf2.2.1.1" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="746" id="S3.F2.sf3.g1" src="x4.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.sf3.2.1.1" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.5.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F2.6.2" style="font-size:90%;">(a)<span class="ltx_text ltx_font_medium" id="S3.F2.6.2.1"> Each encoder block downsamples inputs using gated convolutions to reduce atmospheric distortions, reshapes them into sequences of tokens, and processes them through self-attention Transformer layers. </span>(b)<span class="ltx_text ltx_font_medium" id="S3.F2.6.2.2"> The use of gated convolutions implemented here enhances the model‚Äôs resilience to obstructions like clouds present in input samples. </span>(c)<span class="ltx_text ltx_font_medium" id="S3.F2.6.2.3"> The decoder block uses trilinear upsampling and a 1D convolution to extract features and align embedding dimensions producing a dense prediction.</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Here we introduce VistaFormer, a Transformer-based model designed to take a careful view from a distance, using a simple model architecture to output a dense prediction. We propose a three-layer encoder-decoder architecture, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.F1" title="Figure 1 ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>, where each encoder block downsamples inputs using gated convolutions and computes self-attention on each of the downsampled inputs. Each of the Transformer layers uses a lightweight depth-wise convolution to encode position information similar to the Transformer blocks used in SegFormer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib36" title="">36</a>]</cite>. The decoder blocks apply trilinear interpolation to increase the dimensions of each multi-scale representation and use a 1D convolution to collapse the temporal dimension and unify the embedding dimension of each encoder block.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Encoder</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Each encoder layer, as can be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.F2.sf1" title="Figure 2(a) ‚Ä£ Figure 2 ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">2(a)</span></a>, is structured such that inputs are downsampled using 3D convolution layers, reshaped to treat each pixel as a token in a sequence, and then fed through Transformer blocks.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Downsampling</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.3">We apply non-overlapping 3D convolutions to each input at each encoder layer and find that using a simplified variation of gated convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib19" title="">19</a>]</cite> provides modest performance improvements. VistaFormer uses a gated convolution on input <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.1.m1.1"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mi id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><ci id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.1.m1.1d">italic_x</annotation></semantics></math> where <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.2.m2.1"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><mi id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml">œï</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><ci id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">italic-œï</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.2.m2.1d">italic_œï</annotation></semantics></math> denotes convolution and <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.3.m3.1"><semantics id="S3.SS1.SSS1.p1.3.m3.1a"><mi id="S3.SS1.SSS1.p1.3.m3.1.1" xref="S3.SS1.SSS1.p1.3.m3.1.1.cmml">œÉ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.3.m3.1b"><ci id="S3.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p1.3.m3.1.1">ùúé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.3.m3.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.3.m3.1d">italic_œÉ</annotation></semantics></math> denotes the sigmoid function:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="m=\phi_{l}(x)\odot\sigma(\phi_{m}(x))\\
" class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mi id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml">m</mi><mo id="S3.E1.m1.3.3.2" xref="S3.E1.m1.3.3.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.cmml"><mrow id="S3.E1.m1.3.3.1.3" xref="S3.E1.m1.3.3.1.3.cmml"><mrow id="S3.E1.m1.3.3.1.3.2" xref="S3.E1.m1.3.3.1.3.2.cmml"><msub id="S3.E1.m1.3.3.1.3.2.2" xref="S3.E1.m1.3.3.1.3.2.2.cmml"><mi id="S3.E1.m1.3.3.1.3.2.2.2" xref="S3.E1.m1.3.3.1.3.2.2.2.cmml">œï</mi><mi id="S3.E1.m1.3.3.1.3.2.2.3" xref="S3.E1.m1.3.3.1.3.2.2.3.cmml">l</mi></msub><mo id="S3.E1.m1.3.3.1.3.2.1" xref="S3.E1.m1.3.3.1.3.2.1.cmml">‚Å¢</mo><mrow id="S3.E1.m1.3.3.1.3.2.3.2" xref="S3.E1.m1.3.3.1.3.2.cmml"><mo id="S3.E1.m1.3.3.1.3.2.3.2.1" stretchy="false" xref="S3.E1.m1.3.3.1.3.2.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">x</mi><mo id="S3.E1.m1.3.3.1.3.2.3.2.2" rspace="0.055em" stretchy="false" xref="S3.E1.m1.3.3.1.3.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.3.1" rspace="0.222em" xref="S3.E1.m1.3.3.1.3.1.cmml">‚äô</mo><mi id="S3.E1.m1.3.3.1.3.3" xref="S3.E1.m1.3.3.1.3.3.cmml">œÉ</mi></mrow><mo id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.2.cmml">‚Å¢</mo><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><msub id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.2.2" xref="S3.E1.m1.3.3.1.1.1.1.2.2.cmml">œï</mi><mi id="S3.E1.m1.3.3.1.1.1.1.2.3" xref="S3.E1.m1.3.3.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml">‚Å¢</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.1.1.1.1.3.2.1" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">x</mi><mo id="S3.E1.m1.3.3.1.1.1.1.3.2.2" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"></eq><ci id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3">ùëö</ci><apply id="S3.E1.m1.3.3.1.cmml" xref="S3.E1.m1.3.3.1"><times id="S3.E1.m1.3.3.1.2.cmml" xref="S3.E1.m1.3.3.1.2"></times><apply id="S3.E1.m1.3.3.1.3.cmml" xref="S3.E1.m1.3.3.1.3"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.3.1.cmml" xref="S3.E1.m1.3.3.1.3.1">direct-product</csymbol><apply id="S3.E1.m1.3.3.1.3.2.cmml" xref="S3.E1.m1.3.3.1.3.2"><times id="S3.E1.m1.3.3.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.3.2.1"></times><apply id="S3.E1.m1.3.3.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.3.2.2.1.cmml" xref="S3.E1.m1.3.3.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.3.2.2.2.cmml" xref="S3.E1.m1.3.3.1.3.2.2.2">italic-œï</ci><ci id="S3.E1.m1.3.3.1.3.2.2.3.cmml" xref="S3.E1.m1.3.3.1.3.2.2.3">ùëô</ci></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ùë•</ci></apply><ci id="S3.E1.m1.3.3.1.3.3.cmml" xref="S3.E1.m1.3.3.1.3.3">ùúé</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"></times><apply id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2.2">italic-œï</ci><ci id="S3.E1.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2.3">ùëö</ci></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ùë•</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">m=\phi_{l}(x)\odot\sigma(\phi_{m}(x))\\
</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">italic_m = italic_œï start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ( italic_x ) ‚äô italic_œÉ ( italic_œï start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( italic_x ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.3">This deviates from the gated convolution presented in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib19" title="">19</a>]</cite> in that we do not apply an activation function on <math alttext="\phi_{l}(x)" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.1.m1.1"><semantics id="S3.SS1.SSS1.p3.1.m1.1a"><mrow id="S3.SS1.SSS1.p3.1.m1.1.2" xref="S3.SS1.SSS1.p3.1.m1.1.2.cmml"><msub id="S3.SS1.SSS1.p3.1.m1.1.2.2" xref="S3.SS1.SSS1.p3.1.m1.1.2.2.cmml"><mi id="S3.SS1.SSS1.p3.1.m1.1.2.2.2" xref="S3.SS1.SSS1.p3.1.m1.1.2.2.2.cmml">œï</mi><mi id="S3.SS1.SSS1.p3.1.m1.1.2.2.3" xref="S3.SS1.SSS1.p3.1.m1.1.2.2.3.cmml">l</mi></msub><mo id="S3.SS1.SSS1.p3.1.m1.1.2.1" xref="S3.SS1.SSS1.p3.1.m1.1.2.1.cmml">‚Å¢</mo><mrow id="S3.SS1.SSS1.p3.1.m1.1.2.3.2" xref="S3.SS1.SSS1.p3.1.m1.1.2.cmml"><mo id="S3.SS1.SSS1.p3.1.m1.1.2.3.2.1" stretchy="false" xref="S3.SS1.SSS1.p3.1.m1.1.2.cmml">(</mo><mi id="S3.SS1.SSS1.p3.1.m1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.cmml">x</mi><mo id="S3.SS1.SSS1.p3.1.m1.1.2.3.2.2" stretchy="false" xref="S3.SS1.SSS1.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.1.m1.1b"><apply id="S3.SS1.SSS1.p3.1.m1.1.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.2"><times id="S3.SS1.SSS1.p3.1.m1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.2.1"></times><apply id="S3.SS1.SSS1.p3.1.m1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.1.2.2.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.2.2">subscript</csymbol><ci id="S3.SS1.SSS1.p3.1.m1.1.2.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.2.2.2">italic-œï</ci><ci id="S3.SS1.SSS1.p3.1.m1.1.2.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.2.2.3">ùëô</ci></apply><ci id="S3.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.1.m1.1c">\phi_{l}(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.1.m1.1d">italic_œï start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ( italic_x )</annotation></semantics></math>, opting to use <math alttext="\sigma(\phi_{m}(x))" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.2.m2.2"><semantics id="S3.SS1.SSS1.p3.2.m2.2a"><mrow id="S3.SS1.SSS1.p3.2.m2.2.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.2.2.3" xref="S3.SS1.SSS1.p3.2.m2.2.2.3.cmml">œÉ</mi><mo id="S3.SS1.SSS1.p3.2.m2.2.2.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.2.cmml">‚Å¢</mo><mrow id="S3.SS1.SSS1.p3.2.m2.2.2.1.1" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml"><mo id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.2" stretchy="false" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml"><msub id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.2.cmml">œï</mi><mi id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.3" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.3.cmml">m</mi></msub><mo id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.1" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.1.cmml">‚Å¢</mo><mrow id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml"><mo id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3.2.1" stretchy="false" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml">(</mo><mi id="S3.SS1.SSS1.p3.2.m2.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.cmml">x</mi><mo id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3.2.2" stretchy="false" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.3" stretchy="false" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.2.m2.2b"><apply id="S3.SS1.SSS1.p3.2.m2.2.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2"><times id="S3.SS1.SSS1.p3.2.m2.2.2.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.2"></times><ci id="S3.SS1.SSS1.p3.2.m2.2.2.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.3">ùúé</ci><apply id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1"><times id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.1"></times><apply id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.2">italic-œï</ci><ci id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.3">ùëö</ci></apply><ci id="S3.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1">ùë•</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.2.m2.2c">\sigma(\phi_{m}(x))</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.2.m2.2d">italic_œÉ ( italic_œï start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( italic_x ) )</annotation></semantics></math> to scale convolution outputs and allow for increased variability in input data. This convolution mechanism was introduced for image in-painting to ignore irrelevant pixels in an input image while computing convolution outputs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib19" title="">19</a>]</cite>. We find this downsampling architecture is similarly suitable for cases where input images may contain visual obstructions based on the merits of this model‚Äôs performance while using gated convolutions that have not been pre-trained to mask out clouds and other atmospheric distortions as seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.T4" title="Table 4 ‚Ä£ 4.3 Results ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a>. Given that the applied context for this model is for datasets where individual pixels account for a considerable area, we carefully downsample inputs along spatial dimensions and do not downsample <math alttext="T" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.3.m3.1"><semantics id="S3.SS1.SSS1.p3.3.m3.1a"><mi id="S3.SS1.SSS1.p3.3.m3.1.1" xref="S3.SS1.SSS1.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.3.m3.1b"><ci id="S3.SS1.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.3.m3.1d">italic_T</annotation></semantics></math> for the first layer of the encoder block.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Self-Attention</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.5">The main computational bottleneck of the encoder is the self-attention Transformer layer. In Multi-Head Self-Attention (MHSA), each of the heads <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.1.m1.1"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><mi id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">ùëÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.1.m1.1d">italic_Q</annotation></semantics></math>, <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.2.m2.1"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><mi id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><ci id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.2.m2.1d">italic_K</annotation></semantics></math>, and <math alttext="V" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.3.m3.1"><semantics id="S3.SS1.SSS2.p1.3.m3.1a"><mi id="S3.SS1.SSS2.p1.3.m3.1.1" xref="S3.SS1.SSS2.p1.3.m3.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.3.m3.1b"><ci id="S3.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1">ùëâ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.3.m3.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.3.m3.1d">italic_V</annotation></semantics></math> have the dimensions <math alttext="N\times C" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.4.m4.1"><semantics id="S3.SS1.SSS2.p1.4.m4.1a"><mrow id="S3.SS1.SSS2.p1.4.m4.1.1" xref="S3.SS1.SSS2.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS2.p1.4.m4.1.1.2" xref="S3.SS1.SSS2.p1.4.m4.1.1.2.cmml">N</mi><mo id="S3.SS1.SSS2.p1.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS2.p1.4.m4.1.1.1.cmml">√ó</mo><mi id="S3.SS1.SSS2.p1.4.m4.1.1.3" xref="S3.SS1.SSS2.p1.4.m4.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.4.m4.1b"><apply id="S3.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1"><times id="S3.SS1.SSS2.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.1"></times><ci id="S3.SS1.SSS2.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.2">ùëÅ</ci><ci id="S3.SS1.SSS2.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS2.p1.4.m4.1.1.3">ùê∂</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.4.m4.1c">N\times C</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.4.m4.1d">italic_N √ó italic_C</annotation></semantics></math>, where <math alttext="N=H\times W" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.5.m5.1"><semantics id="S3.SS1.SSS2.p1.5.m5.1a"><mrow id="S3.SS1.SSS2.p1.5.m5.1.1" xref="S3.SS1.SSS2.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS2.p1.5.m5.1.1.2" xref="S3.SS1.SSS2.p1.5.m5.1.1.2.cmml">N</mi><mo id="S3.SS1.SSS2.p1.5.m5.1.1.1" xref="S3.SS1.SSS2.p1.5.m5.1.1.1.cmml">=</mo><mrow id="S3.SS1.SSS2.p1.5.m5.1.1.3" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.cmml"><mi id="S3.SS1.SSS2.p1.5.m5.1.1.3.2" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.2.cmml">H</mi><mo id="S3.SS1.SSS2.p1.5.m5.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.1.cmml">√ó</mo><mi id="S3.SS1.SSS2.p1.5.m5.1.1.3.3" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.3.cmml">W</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.5.m5.1b"><apply id="S3.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1"><eq id="S3.SS1.SSS2.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.1"></eq><ci id="S3.SS1.SSS2.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.2">ùëÅ</ci><apply id="S3.SS1.SSS2.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.3"><times id="S3.SS1.SSS2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.1"></times><ci id="S3.SS1.SSS2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.2">ùêª</ci><ci id="S3.SS1.SSS2.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.SSS2.p1.5.m5.1.1.3.3">ùëä</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.5.m5.1c">N=H\times W</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.5.m5.1d">italic_N = italic_H √ó italic_W</annotation></semantics></math> is the length of the sequence and the self-attention is computed as:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{Attention}(Q,K,V)=\mbox{Softmax}(\dfrac{QK^{T}}{\sqrt{d_{head}}})V\\
" class="ltx_Math" display="block" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.5" xref="S3.E2.m1.4.5.cmml"><mrow id="S3.E2.m1.4.5.2" xref="S3.E2.m1.4.5.2.cmml"><mtext id="S3.E2.m1.4.5.2.2" xref="S3.E2.m1.4.5.2.2a.cmml">Attention</mtext><mo id="S3.E2.m1.4.5.2.1" xref="S3.E2.m1.4.5.2.1.cmml">‚Å¢</mo><mrow id="S3.E2.m1.4.5.2.3.2" xref="S3.E2.m1.4.5.2.3.1.cmml"><mo id="S3.E2.m1.4.5.2.3.2.1" stretchy="false" xref="S3.E2.m1.4.5.2.3.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">Q</mi><mo id="S3.E2.m1.4.5.2.3.2.2" xref="S3.E2.m1.4.5.2.3.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">K</mi><mo id="S3.E2.m1.4.5.2.3.2.3" xref="S3.E2.m1.4.5.2.3.1.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">V</mi><mo id="S3.E2.m1.4.5.2.3.2.4" stretchy="false" xref="S3.E2.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.4.5.1" xref="S3.E2.m1.4.5.1.cmml">=</mo><mrow id="S3.E2.m1.4.5.3" xref="S3.E2.m1.4.5.3.cmml"><mtext id="S3.E2.m1.4.5.3.2" xref="S3.E2.m1.4.5.3.2a.cmml">Softmax</mtext><mo id="S3.E2.m1.4.5.3.1" xref="S3.E2.m1.4.5.3.1.cmml">‚Å¢</mo><mrow id="S3.E2.m1.4.5.3.3.2" xref="S3.E2.m1.4.4.cmml"><mo id="S3.E2.m1.4.5.3.3.2.1" stretchy="false" xref="S3.E2.m1.4.4.cmml">(</mo><mfrac id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mrow id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml"><mi id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">Q</mi><mo id="S3.E2.m1.4.4.2.1" xref="S3.E2.m1.4.4.2.1.cmml">‚Å¢</mo><msup id="S3.E2.m1.4.4.2.3" xref="S3.E2.m1.4.4.2.3.cmml"><mi id="S3.E2.m1.4.4.2.3.2" xref="S3.E2.m1.4.4.2.3.2.cmml">K</mi><mi id="S3.E2.m1.4.4.2.3.3" xref="S3.E2.m1.4.4.2.3.3.cmml">T</mi></msup></mrow><msqrt id="S3.E2.m1.4.4.3" xref="S3.E2.m1.4.4.3.cmml"><msub id="S3.E2.m1.4.4.3.2" xref="S3.E2.m1.4.4.3.2.cmml"><mi id="S3.E2.m1.4.4.3.2.2" xref="S3.E2.m1.4.4.3.2.2.cmml">d</mi><mrow id="S3.E2.m1.4.4.3.2.3" xref="S3.E2.m1.4.4.3.2.3.cmml"><mi id="S3.E2.m1.4.4.3.2.3.2" xref="S3.E2.m1.4.4.3.2.3.2.cmml">h</mi><mo id="S3.E2.m1.4.4.3.2.3.1" xref="S3.E2.m1.4.4.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.4.4.3.2.3.3" xref="S3.E2.m1.4.4.3.2.3.3.cmml">e</mi><mo id="S3.E2.m1.4.4.3.2.3.1a" xref="S3.E2.m1.4.4.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.4.4.3.2.3.4" xref="S3.E2.m1.4.4.3.2.3.4.cmml">a</mi><mo id="S3.E2.m1.4.4.3.2.3.1b" xref="S3.E2.m1.4.4.3.2.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.4.4.3.2.3.5" xref="S3.E2.m1.4.4.3.2.3.5.cmml">d</mi></mrow></msub></msqrt></mfrac><mo id="S3.E2.m1.4.5.3.3.2.2" stretchy="false" xref="S3.E2.m1.4.4.cmml">)</mo></mrow><mo id="S3.E2.m1.4.5.3.1a" xref="S3.E2.m1.4.5.3.1.cmml">‚Å¢</mo><mi id="S3.E2.m1.4.5.3.4" xref="S3.E2.m1.4.5.3.4.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.5.cmml" xref="S3.E2.m1.4.5"><eq id="S3.E2.m1.4.5.1.cmml" xref="S3.E2.m1.4.5.1"></eq><apply id="S3.E2.m1.4.5.2.cmml" xref="S3.E2.m1.4.5.2"><times id="S3.E2.m1.4.5.2.1.cmml" xref="S3.E2.m1.4.5.2.1"></times><ci id="S3.E2.m1.4.5.2.2a.cmml" xref="S3.E2.m1.4.5.2.2"><mtext id="S3.E2.m1.4.5.2.2.cmml" xref="S3.E2.m1.4.5.2.2">Attention</mtext></ci><vector id="S3.E2.m1.4.5.2.3.1.cmml" xref="S3.E2.m1.4.5.2.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ùëÑ</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ùêæ</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">ùëâ</ci></vector></apply><apply id="S3.E2.m1.4.5.3.cmml" xref="S3.E2.m1.4.5.3"><times id="S3.E2.m1.4.5.3.1.cmml" xref="S3.E2.m1.4.5.3.1"></times><ci id="S3.E2.m1.4.5.3.2a.cmml" xref="S3.E2.m1.4.5.3.2"><mtext id="S3.E2.m1.4.5.3.2.cmml" xref="S3.E2.m1.4.5.3.2">Softmax</mtext></ci><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.5.3.3.2"><divide id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.5.3.3.2"></divide><apply id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"><times id="S3.E2.m1.4.4.2.1.cmml" xref="S3.E2.m1.4.4.2.1"></times><ci id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2">ùëÑ</ci><apply id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.3.1.cmml" xref="S3.E2.m1.4.4.2.3">superscript</csymbol><ci id="S3.E2.m1.4.4.2.3.2.cmml" xref="S3.E2.m1.4.4.2.3.2">ùêæ</ci><ci id="S3.E2.m1.4.4.2.3.3.cmml" xref="S3.E2.m1.4.4.2.3.3">ùëá</ci></apply></apply><apply id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4.3"><root id="S3.E2.m1.4.4.3a.cmml" xref="S3.E2.m1.4.4.3"></root><apply id="S3.E2.m1.4.4.3.2.cmml" xref="S3.E2.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.2.1.cmml" xref="S3.E2.m1.4.4.3.2">subscript</csymbol><ci id="S3.E2.m1.4.4.3.2.2.cmml" xref="S3.E2.m1.4.4.3.2.2">ùëë</ci><apply id="S3.E2.m1.4.4.3.2.3.cmml" xref="S3.E2.m1.4.4.3.2.3"><times id="S3.E2.m1.4.4.3.2.3.1.cmml" xref="S3.E2.m1.4.4.3.2.3.1"></times><ci id="S3.E2.m1.4.4.3.2.3.2.cmml" xref="S3.E2.m1.4.4.3.2.3.2">‚Ñé</ci><ci id="S3.E2.m1.4.4.3.2.3.3.cmml" xref="S3.E2.m1.4.4.3.2.3.3">ùëí</ci><ci id="S3.E2.m1.4.4.3.2.3.4.cmml" xref="S3.E2.m1.4.4.3.2.3.4">ùëé</ci><ci id="S3.E2.m1.4.4.3.2.3.5.cmml" xref="S3.E2.m1.4.4.3.2.3.5">ùëë</ci></apply></apply></apply></apply><ci id="S3.E2.m1.4.5.3.4.cmml" xref="S3.E2.m1.4.5.3.4">ùëâ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\mbox{Attention}(Q,K,V)=\mbox{Softmax}(\dfrac{QK^{T}}{\sqrt{d_{head}}})V\\
</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">Attention ( italic_Q , italic_K , italic_V ) = Softmax ( divide start_ARG italic_Q italic_K start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT end_ARG start_ARG square-root start_ARG italic_d start_POSTSUBSCRIPT italic_h italic_e italic_a italic_d end_POSTSUBSCRIPT end_ARG end_ARG ) italic_V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.5">The computational complexity of this process is <math alttext="O(N^{2})" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.1.m1.1"><semantics id="S3.SS1.SSS2.p3.1.m1.1a"><mrow id="S3.SS1.SSS2.p3.1.m1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p3.1.m1.1.1.3" xref="S3.SS1.SSS2.p3.1.m1.1.1.3.cmml">O</mi><mo id="S3.SS1.SSS2.p3.1.m1.1.1.2" xref="S3.SS1.SSS2.p3.1.m1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.SS1.SSS2.p3.1.m1.1.1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.2.cmml">N</mi><mn id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.1.m1.1b"><apply id="S3.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1"><times id="S3.SS1.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.2"></times><ci id="S3.SS1.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.3">ùëÇ</ci><apply id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.2">ùëÅ</ci><cn id="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS2.p3.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.1.m1.1c">O(N^{2})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.1.m1.1d">italic_O ( italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math> which presents computational challenges when the input dimensions increase or as the number of <math alttext="T" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.2.m2.1"><semantics id="S3.SS1.SSS2.p3.2.m2.1a"><mi id="S3.SS1.SSS2.p3.2.m2.1.1" xref="S3.SS1.SSS2.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.2.m2.1b"><ci id="S3.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.2.m2.1d">italic_T</annotation></semantics></math> samples increases. By substituting MHSA with 2D NA, which computes attention in a localized neighbourhood around each token of size <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.3.m3.1"><semantics id="S3.SS1.SSS2.p3.3.m3.1a"><mi id="S3.SS1.SSS2.p3.3.m3.1.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.3.m3.1b"><ci id="S3.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.3.m3.1d">italic_k</annotation></semantics></math>, we can improve the scalability of VistaFormer by using a neighbourhood <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.4.m4.1"><semantics id="S3.SS1.SSS2.p3.4.m4.1a"><mi id="S3.SS1.SSS2.p3.4.m4.1.1" xref="S3.SS1.SSS2.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.4.m4.1b"><ci id="S3.SS1.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.4.m4.1d">italic_k</annotation></semantics></math> smaller than <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.5.m5.1"><semantics id="S3.SS1.SSS2.p3.5.m5.1a"><mi id="S3.SS1.SSS2.p3.5.m5.1.1" xref="S3.SS1.SSS2.p3.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.5.m5.1b"><ci id="S3.SS1.SSS2.p3.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.5.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.5.m5.1d">italic_N</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib14" title="">14</a>]</cite>. We provide an implementation of VistaFormer which uses MHSA and a separate implementation using NA that scales better as the input dimensions increase.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.6.7.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T1.6.7.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.6.7.1.1.1" style="font-size:80%;">Module</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.6.7.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.6.7.1.2.1" style="font-size:80%;">FLOPs</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.6.7.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.6.7.1.3.1" style="font-size:80%;">Memory</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T1.2.2.3"><span class="ltx_text" id="S3.T1.2.2.3.1" style="font-size:80%;">Self-Attn</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.1"><math alttext="3HWC^{2}+2H^{2}W^{2}C" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.m1.1a"><mrow id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml"><mrow id="S3.T1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.m1.1.1.2.cmml"><mn id="S3.T1.1.1.1.m1.1.1.2.2" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.2.2.cmml">3</mn><mo id="S3.T1.1.1.1.m1.1.1.2.1" xref="S3.T1.1.1.1.m1.1.1.2.1.cmml">‚Å¢</mo><mi id="S3.T1.1.1.1.m1.1.1.2.3" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.2.3.cmml">H</mi><mo id="S3.T1.1.1.1.m1.1.1.2.1a" xref="S3.T1.1.1.1.m1.1.1.2.1.cmml">‚Å¢</mo><mi id="S3.T1.1.1.1.m1.1.1.2.4" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.2.4.cmml">W</mi><mo id="S3.T1.1.1.1.m1.1.1.2.1b" xref="S3.T1.1.1.1.m1.1.1.2.1.cmml">‚Å¢</mo><msup id="S3.T1.1.1.1.m1.1.1.2.5" xref="S3.T1.1.1.1.m1.1.1.2.5.cmml"><mi id="S3.T1.1.1.1.m1.1.1.2.5.2" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.2.5.2.cmml">C</mi><mn id="S3.T1.1.1.1.m1.1.1.2.5.3" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.2.5.3.cmml">2</mn></msup></mrow><mo id="S3.T1.1.1.1.m1.1.1.1" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.1.cmml">+</mo><mrow id="S3.T1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.m1.1.1.3.cmml"><mn id="S3.T1.1.1.1.m1.1.1.3.2" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.3.2.cmml">2</mn><mo id="S3.T1.1.1.1.m1.1.1.3.1" xref="S3.T1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><msup id="S3.T1.1.1.1.m1.1.1.3.3" xref="S3.T1.1.1.1.m1.1.1.3.3.cmml"><mi id="S3.T1.1.1.1.m1.1.1.3.3.2" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.3.3.2.cmml">H</mi><mn id="S3.T1.1.1.1.m1.1.1.3.3.3" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.3.3.3.cmml">2</mn></msup><mo id="S3.T1.1.1.1.m1.1.1.3.1a" xref="S3.T1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><msup id="S3.T1.1.1.1.m1.1.1.3.4" xref="S3.T1.1.1.1.m1.1.1.3.4.cmml"><mi id="S3.T1.1.1.1.m1.1.1.3.4.2" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.3.4.2.cmml">W</mi><mn id="S3.T1.1.1.1.m1.1.1.3.4.3" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.3.4.3.cmml">2</mn></msup><mo id="S3.T1.1.1.1.m1.1.1.3.1b" xref="S3.T1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T1.1.1.1.m1.1.1.3.5" mathsize="80%" xref="S3.T1.1.1.1.m1.1.1.3.5.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1"><plus id="S3.T1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1.1"></plus><apply id="S3.T1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.m1.1.1.2"><times id="S3.T1.1.1.1.m1.1.1.2.1.cmml" xref="S3.T1.1.1.1.m1.1.1.2.1"></times><cn id="S3.T1.1.1.1.m1.1.1.2.2.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1.2.2">3</cn><ci id="S3.T1.1.1.1.m1.1.1.2.3.cmml" xref="S3.T1.1.1.1.m1.1.1.2.3">ùêª</ci><ci id="S3.T1.1.1.1.m1.1.1.2.4.cmml" xref="S3.T1.1.1.1.m1.1.1.2.4">ùëä</ci><apply id="S3.T1.1.1.1.m1.1.1.2.5.cmml" xref="S3.T1.1.1.1.m1.1.1.2.5"><csymbol cd="ambiguous" id="S3.T1.1.1.1.m1.1.1.2.5.1.cmml" xref="S3.T1.1.1.1.m1.1.1.2.5">superscript</csymbol><ci id="S3.T1.1.1.1.m1.1.1.2.5.2.cmml" xref="S3.T1.1.1.1.m1.1.1.2.5.2">ùê∂</ci><cn id="S3.T1.1.1.1.m1.1.1.2.5.3.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1.2.5.3">2</cn></apply></apply><apply id="S3.T1.1.1.1.m1.1.1.3.cmml" xref="S3.T1.1.1.1.m1.1.1.3"><times id="S3.T1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T1.1.1.1.m1.1.1.3.1"></times><cn id="S3.T1.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1.3.2">2</cn><apply id="S3.T1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T1.1.1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.T1.1.1.1.m1.1.1.3.3.1.cmml" xref="S3.T1.1.1.1.m1.1.1.3.3">superscript</csymbol><ci id="S3.T1.1.1.1.m1.1.1.3.3.2.cmml" xref="S3.T1.1.1.1.m1.1.1.3.3.2">ùêª</ci><cn id="S3.T1.1.1.1.m1.1.1.3.3.3.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1.3.3.3">2</cn></apply><apply id="S3.T1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T1.1.1.1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.T1.1.1.1.m1.1.1.3.4.1.cmml" xref="S3.T1.1.1.1.m1.1.1.3.4">superscript</csymbol><ci id="S3.T1.1.1.1.m1.1.1.3.4.2.cmml" xref="S3.T1.1.1.1.m1.1.1.3.4.2">ùëä</ci><cn id="S3.T1.1.1.1.m1.1.1.3.4.3.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1.3.4.3">2</cn></apply><ci id="S3.T1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T1.1.1.1.m1.1.1.3.5">ùê∂</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">3HWC^{2}+2H^{2}W^{2}C</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.m1.1d">3 italic_H italic_W italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 2 italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_W start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_C</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.2.2"><math alttext="3C^{2}+H^{2}W^{2}" class="ltx_Math" display="inline" id="S3.T1.2.2.2.m1.1"><semantics id="S3.T1.2.2.2.m1.1a"><mrow id="S3.T1.2.2.2.m1.1.1" xref="S3.T1.2.2.2.m1.1.1.cmml"><mrow id="S3.T1.2.2.2.m1.1.1.2" xref="S3.T1.2.2.2.m1.1.1.2.cmml"><mn id="S3.T1.2.2.2.m1.1.1.2.2" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.2.2.cmml">3</mn><mo id="S3.T1.2.2.2.m1.1.1.2.1" xref="S3.T1.2.2.2.m1.1.1.2.1.cmml">‚Å¢</mo><msup id="S3.T1.2.2.2.m1.1.1.2.3" xref="S3.T1.2.2.2.m1.1.1.2.3.cmml"><mi id="S3.T1.2.2.2.m1.1.1.2.3.2" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.2.3.2.cmml">C</mi><mn id="S3.T1.2.2.2.m1.1.1.2.3.3" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.2.3.3.cmml">2</mn></msup></mrow><mo id="S3.T1.2.2.2.m1.1.1.1" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.1.cmml">+</mo><mrow id="S3.T1.2.2.2.m1.1.1.3" xref="S3.T1.2.2.2.m1.1.1.3.cmml"><msup id="S3.T1.2.2.2.m1.1.1.3.2" xref="S3.T1.2.2.2.m1.1.1.3.2.cmml"><mi id="S3.T1.2.2.2.m1.1.1.3.2.2" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.3.2.2.cmml">H</mi><mn id="S3.T1.2.2.2.m1.1.1.3.2.3" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.3.2.3.cmml">2</mn></msup><mo id="S3.T1.2.2.2.m1.1.1.3.1" xref="S3.T1.2.2.2.m1.1.1.3.1.cmml">‚Å¢</mo><msup id="S3.T1.2.2.2.m1.1.1.3.3" xref="S3.T1.2.2.2.m1.1.1.3.3.cmml"><mi id="S3.T1.2.2.2.m1.1.1.3.3.2" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.3.3.2.cmml">W</mi><mn id="S3.T1.2.2.2.m1.1.1.3.3.3" mathsize="80%" xref="S3.T1.2.2.2.m1.1.1.3.3.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><apply id="S3.T1.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1"><plus id="S3.T1.2.2.2.m1.1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1.1"></plus><apply id="S3.T1.2.2.2.m1.1.1.2.cmml" xref="S3.T1.2.2.2.m1.1.1.2"><times id="S3.T1.2.2.2.m1.1.1.2.1.cmml" xref="S3.T1.2.2.2.m1.1.1.2.1"></times><cn id="S3.T1.2.2.2.m1.1.1.2.2.cmml" type="integer" xref="S3.T1.2.2.2.m1.1.1.2.2">3</cn><apply id="S3.T1.2.2.2.m1.1.1.2.3.cmml" xref="S3.T1.2.2.2.m1.1.1.2.3"><csymbol cd="ambiguous" id="S3.T1.2.2.2.m1.1.1.2.3.1.cmml" xref="S3.T1.2.2.2.m1.1.1.2.3">superscript</csymbol><ci id="S3.T1.2.2.2.m1.1.1.2.3.2.cmml" xref="S3.T1.2.2.2.m1.1.1.2.3.2">ùê∂</ci><cn id="S3.T1.2.2.2.m1.1.1.2.3.3.cmml" type="integer" xref="S3.T1.2.2.2.m1.1.1.2.3.3">2</cn></apply></apply><apply id="S3.T1.2.2.2.m1.1.1.3.cmml" xref="S3.T1.2.2.2.m1.1.1.3"><times id="S3.T1.2.2.2.m1.1.1.3.1.cmml" xref="S3.T1.2.2.2.m1.1.1.3.1"></times><apply id="S3.T1.2.2.2.m1.1.1.3.2.cmml" xref="S3.T1.2.2.2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.T1.2.2.2.m1.1.1.3.2.1.cmml" xref="S3.T1.2.2.2.m1.1.1.3.2">superscript</csymbol><ci id="S3.T1.2.2.2.m1.1.1.3.2.2.cmml" xref="S3.T1.2.2.2.m1.1.1.3.2.2">ùêª</ci><cn id="S3.T1.2.2.2.m1.1.1.3.2.3.cmml" type="integer" xref="S3.T1.2.2.2.m1.1.1.3.2.3">2</cn></apply><apply id="S3.T1.2.2.2.m1.1.1.3.3.cmml" xref="S3.T1.2.2.2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.T1.2.2.2.m1.1.1.3.3.1.cmml" xref="S3.T1.2.2.2.m1.1.1.3.3">superscript</csymbol><ci id="S3.T1.2.2.2.m1.1.1.3.3.2.cmml" xref="S3.T1.2.2.2.m1.1.1.3.3.2">ùëä</ci><cn id="S3.T1.2.2.2.m1.1.1.3.3.3.cmml" type="integer" xref="S3.T1.2.2.2.m1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">3C^{2}+H^{2}W^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.m1.1d">3 italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_W start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T1.4.4.3"><span class="ltx_text" id="S3.T1.4.4.3.1" style="font-size:80%;">Neighbourhood Attn</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.3.1"><math alttext="3HWC^{2}+2HWCK^{2}" class="ltx_Math" display="inline" id="S3.T1.3.3.1.m1.1"><semantics id="S3.T1.3.3.1.m1.1a"><mrow id="S3.T1.3.3.1.m1.1.1" xref="S3.T1.3.3.1.m1.1.1.cmml"><mrow id="S3.T1.3.3.1.m1.1.1.2" xref="S3.T1.3.3.1.m1.1.1.2.cmml"><mn id="S3.T1.3.3.1.m1.1.1.2.2" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.2.2.cmml">3</mn><mo id="S3.T1.3.3.1.m1.1.1.2.1" xref="S3.T1.3.3.1.m1.1.1.2.1.cmml">‚Å¢</mo><mi id="S3.T1.3.3.1.m1.1.1.2.3" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.2.3.cmml">H</mi><mo id="S3.T1.3.3.1.m1.1.1.2.1a" xref="S3.T1.3.3.1.m1.1.1.2.1.cmml">‚Å¢</mo><mi id="S3.T1.3.3.1.m1.1.1.2.4" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.2.4.cmml">W</mi><mo id="S3.T1.3.3.1.m1.1.1.2.1b" xref="S3.T1.3.3.1.m1.1.1.2.1.cmml">‚Å¢</mo><msup id="S3.T1.3.3.1.m1.1.1.2.5" xref="S3.T1.3.3.1.m1.1.1.2.5.cmml"><mi id="S3.T1.3.3.1.m1.1.1.2.5.2" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.2.5.2.cmml">C</mi><mn id="S3.T1.3.3.1.m1.1.1.2.5.3" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.2.5.3.cmml">2</mn></msup></mrow><mo id="S3.T1.3.3.1.m1.1.1.1" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.1.cmml">+</mo><mrow id="S3.T1.3.3.1.m1.1.1.3" xref="S3.T1.3.3.1.m1.1.1.3.cmml"><mn id="S3.T1.3.3.1.m1.1.1.3.2" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.3.2.cmml">2</mn><mo id="S3.T1.3.3.1.m1.1.1.3.1" xref="S3.T1.3.3.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T1.3.3.1.m1.1.1.3.3" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.3.3.cmml">H</mi><mo id="S3.T1.3.3.1.m1.1.1.3.1a" xref="S3.T1.3.3.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T1.3.3.1.m1.1.1.3.4" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.3.4.cmml">W</mi><mo id="S3.T1.3.3.1.m1.1.1.3.1b" xref="S3.T1.3.3.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T1.3.3.1.m1.1.1.3.5" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.3.5.cmml">C</mi><mo id="S3.T1.3.3.1.m1.1.1.3.1c" xref="S3.T1.3.3.1.m1.1.1.3.1.cmml">‚Å¢</mo><msup id="S3.T1.3.3.1.m1.1.1.3.6" xref="S3.T1.3.3.1.m1.1.1.3.6.cmml"><mi id="S3.T1.3.3.1.m1.1.1.3.6.2" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.3.6.2.cmml">K</mi><mn id="S3.T1.3.3.1.m1.1.1.3.6.3" mathsize="80%" xref="S3.T1.3.3.1.m1.1.1.3.6.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.m1.1b"><apply id="S3.T1.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.1.m1.1.1"><plus id="S3.T1.3.3.1.m1.1.1.1.cmml" xref="S3.T1.3.3.1.m1.1.1.1"></plus><apply id="S3.T1.3.3.1.m1.1.1.2.cmml" xref="S3.T1.3.3.1.m1.1.1.2"><times id="S3.T1.3.3.1.m1.1.1.2.1.cmml" xref="S3.T1.3.3.1.m1.1.1.2.1"></times><cn id="S3.T1.3.3.1.m1.1.1.2.2.cmml" type="integer" xref="S3.T1.3.3.1.m1.1.1.2.2">3</cn><ci id="S3.T1.3.3.1.m1.1.1.2.3.cmml" xref="S3.T1.3.3.1.m1.1.1.2.3">ùêª</ci><ci id="S3.T1.3.3.1.m1.1.1.2.4.cmml" xref="S3.T1.3.3.1.m1.1.1.2.4">ùëä</ci><apply id="S3.T1.3.3.1.m1.1.1.2.5.cmml" xref="S3.T1.3.3.1.m1.1.1.2.5"><csymbol cd="ambiguous" id="S3.T1.3.3.1.m1.1.1.2.5.1.cmml" xref="S3.T1.3.3.1.m1.1.1.2.5">superscript</csymbol><ci id="S3.T1.3.3.1.m1.1.1.2.5.2.cmml" xref="S3.T1.3.3.1.m1.1.1.2.5.2">ùê∂</ci><cn id="S3.T1.3.3.1.m1.1.1.2.5.3.cmml" type="integer" xref="S3.T1.3.3.1.m1.1.1.2.5.3">2</cn></apply></apply><apply id="S3.T1.3.3.1.m1.1.1.3.cmml" xref="S3.T1.3.3.1.m1.1.1.3"><times id="S3.T1.3.3.1.m1.1.1.3.1.cmml" xref="S3.T1.3.3.1.m1.1.1.3.1"></times><cn id="S3.T1.3.3.1.m1.1.1.3.2.cmml" type="integer" xref="S3.T1.3.3.1.m1.1.1.3.2">2</cn><ci id="S3.T1.3.3.1.m1.1.1.3.3.cmml" xref="S3.T1.3.3.1.m1.1.1.3.3">ùêª</ci><ci id="S3.T1.3.3.1.m1.1.1.3.4.cmml" xref="S3.T1.3.3.1.m1.1.1.3.4">ùëä</ci><ci id="S3.T1.3.3.1.m1.1.1.3.5.cmml" xref="S3.T1.3.3.1.m1.1.1.3.5">ùê∂</ci><apply id="S3.T1.3.3.1.m1.1.1.3.6.cmml" xref="S3.T1.3.3.1.m1.1.1.3.6"><csymbol cd="ambiguous" id="S3.T1.3.3.1.m1.1.1.3.6.1.cmml" xref="S3.T1.3.3.1.m1.1.1.3.6">superscript</csymbol><ci id="S3.T1.3.3.1.m1.1.1.3.6.2.cmml" xref="S3.T1.3.3.1.m1.1.1.3.6.2">ùêæ</ci><cn id="S3.T1.3.3.1.m1.1.1.3.6.3.cmml" type="integer" xref="S3.T1.3.3.1.m1.1.1.3.6.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.m1.1c">3HWC^{2}+2HWCK^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.1.m1.1d">3 italic_H italic_W italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 2 italic_H italic_W italic_C italic_K start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.2"><math alttext="3C^{2}+HWK^{2}" class="ltx_Math" display="inline" id="S3.T1.4.4.2.m1.1"><semantics id="S3.T1.4.4.2.m1.1a"><mrow id="S3.T1.4.4.2.m1.1.1" xref="S3.T1.4.4.2.m1.1.1.cmml"><mrow id="S3.T1.4.4.2.m1.1.1.2" xref="S3.T1.4.4.2.m1.1.1.2.cmml"><mn id="S3.T1.4.4.2.m1.1.1.2.2" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.2.2.cmml">3</mn><mo id="S3.T1.4.4.2.m1.1.1.2.1" xref="S3.T1.4.4.2.m1.1.1.2.1.cmml">‚Å¢</mo><msup id="S3.T1.4.4.2.m1.1.1.2.3" xref="S3.T1.4.4.2.m1.1.1.2.3.cmml"><mi id="S3.T1.4.4.2.m1.1.1.2.3.2" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.2.3.2.cmml">C</mi><mn id="S3.T1.4.4.2.m1.1.1.2.3.3" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.2.3.3.cmml">2</mn></msup></mrow><mo id="S3.T1.4.4.2.m1.1.1.1" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.1.cmml">+</mo><mrow id="S3.T1.4.4.2.m1.1.1.3" xref="S3.T1.4.4.2.m1.1.1.3.cmml"><mi id="S3.T1.4.4.2.m1.1.1.3.2" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.3.2.cmml">H</mi><mo id="S3.T1.4.4.2.m1.1.1.3.1" xref="S3.T1.4.4.2.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T1.4.4.2.m1.1.1.3.3" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.3.3.cmml">W</mi><mo id="S3.T1.4.4.2.m1.1.1.3.1a" xref="S3.T1.4.4.2.m1.1.1.3.1.cmml">‚Å¢</mo><msup id="S3.T1.4.4.2.m1.1.1.3.4" xref="S3.T1.4.4.2.m1.1.1.3.4.cmml"><mi id="S3.T1.4.4.2.m1.1.1.3.4.2" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.3.4.2.cmml">K</mi><mn id="S3.T1.4.4.2.m1.1.1.3.4.3" mathsize="80%" xref="S3.T1.4.4.2.m1.1.1.3.4.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.2.m1.1b"><apply id="S3.T1.4.4.2.m1.1.1.cmml" xref="S3.T1.4.4.2.m1.1.1"><plus id="S3.T1.4.4.2.m1.1.1.1.cmml" xref="S3.T1.4.4.2.m1.1.1.1"></plus><apply id="S3.T1.4.4.2.m1.1.1.2.cmml" xref="S3.T1.4.4.2.m1.1.1.2"><times id="S3.T1.4.4.2.m1.1.1.2.1.cmml" xref="S3.T1.4.4.2.m1.1.1.2.1"></times><cn id="S3.T1.4.4.2.m1.1.1.2.2.cmml" type="integer" xref="S3.T1.4.4.2.m1.1.1.2.2">3</cn><apply id="S3.T1.4.4.2.m1.1.1.2.3.cmml" xref="S3.T1.4.4.2.m1.1.1.2.3"><csymbol cd="ambiguous" id="S3.T1.4.4.2.m1.1.1.2.3.1.cmml" xref="S3.T1.4.4.2.m1.1.1.2.3">superscript</csymbol><ci id="S3.T1.4.4.2.m1.1.1.2.3.2.cmml" xref="S3.T1.4.4.2.m1.1.1.2.3.2">ùê∂</ci><cn id="S3.T1.4.4.2.m1.1.1.2.3.3.cmml" type="integer" xref="S3.T1.4.4.2.m1.1.1.2.3.3">2</cn></apply></apply><apply id="S3.T1.4.4.2.m1.1.1.3.cmml" xref="S3.T1.4.4.2.m1.1.1.3"><times id="S3.T1.4.4.2.m1.1.1.3.1.cmml" xref="S3.T1.4.4.2.m1.1.1.3.1"></times><ci id="S3.T1.4.4.2.m1.1.1.3.2.cmml" xref="S3.T1.4.4.2.m1.1.1.3.2">ùêª</ci><ci id="S3.T1.4.4.2.m1.1.1.3.3.cmml" xref="S3.T1.4.4.2.m1.1.1.3.3">ùëä</ci><apply id="S3.T1.4.4.2.m1.1.1.3.4.cmml" xref="S3.T1.4.4.2.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.T1.4.4.2.m1.1.1.3.4.1.cmml" xref="S3.T1.4.4.2.m1.1.1.3.4">superscript</csymbol><ci id="S3.T1.4.4.2.m1.1.1.3.4.2.cmml" xref="S3.T1.4.4.2.m1.1.1.3.4.2">ùêæ</ci><cn id="S3.T1.4.4.2.m1.1.1.3.4.3.cmml" type="integer" xref="S3.T1.4.4.2.m1.1.1.3.4.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.2.m1.1c">3C^{2}+HWK^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.2.m1.1d">3 italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_H italic_W italic_K start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S3.T1.6.6.3"><span class="ltx_text" id="S3.T1.6.6.3.1" style="font-size:80%;">3D Convolution</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.5.5.1"><math alttext="HWC^{2}K^{3}" class="ltx_Math" display="inline" id="S3.T1.5.5.1.m1.1"><semantics id="S3.T1.5.5.1.m1.1a"><mrow id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml"><mi id="S3.T1.5.5.1.m1.1.1.2" mathsize="80%" xref="S3.T1.5.5.1.m1.1.1.2.cmml">H</mi><mo id="S3.T1.5.5.1.m1.1.1.1" xref="S3.T1.5.5.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="S3.T1.5.5.1.m1.1.1.3" mathsize="80%" xref="S3.T1.5.5.1.m1.1.1.3.cmml">W</mi><mo id="S3.T1.5.5.1.m1.1.1.1a" xref="S3.T1.5.5.1.m1.1.1.1.cmml">‚Å¢</mo><msup id="S3.T1.5.5.1.m1.1.1.4" xref="S3.T1.5.5.1.m1.1.1.4.cmml"><mi id="S3.T1.5.5.1.m1.1.1.4.2" mathsize="80%" xref="S3.T1.5.5.1.m1.1.1.4.2.cmml">C</mi><mn id="S3.T1.5.5.1.m1.1.1.4.3" mathsize="80%" xref="S3.T1.5.5.1.m1.1.1.4.3.cmml">2</mn></msup><mo id="S3.T1.5.5.1.m1.1.1.1b" xref="S3.T1.5.5.1.m1.1.1.1.cmml">‚Å¢</mo><msup id="S3.T1.5.5.1.m1.1.1.5" xref="S3.T1.5.5.1.m1.1.1.5.cmml"><mi id="S3.T1.5.5.1.m1.1.1.5.2" mathsize="80%" xref="S3.T1.5.5.1.m1.1.1.5.2.cmml">K</mi><mn id="S3.T1.5.5.1.m1.1.1.5.3" mathsize="80%" xref="S3.T1.5.5.1.m1.1.1.5.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><apply id="S3.T1.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.1.m1.1.1"><times id="S3.T1.5.5.1.m1.1.1.1.cmml" xref="S3.T1.5.5.1.m1.1.1.1"></times><ci id="S3.T1.5.5.1.m1.1.1.2.cmml" xref="S3.T1.5.5.1.m1.1.1.2">ùêª</ci><ci id="S3.T1.5.5.1.m1.1.1.3.cmml" xref="S3.T1.5.5.1.m1.1.1.3">ùëä</ci><apply id="S3.T1.5.5.1.m1.1.1.4.cmml" xref="S3.T1.5.5.1.m1.1.1.4"><csymbol cd="ambiguous" id="S3.T1.5.5.1.m1.1.1.4.1.cmml" xref="S3.T1.5.5.1.m1.1.1.4">superscript</csymbol><ci id="S3.T1.5.5.1.m1.1.1.4.2.cmml" xref="S3.T1.5.5.1.m1.1.1.4.2">ùê∂</ci><cn id="S3.T1.5.5.1.m1.1.1.4.3.cmml" type="integer" xref="S3.T1.5.5.1.m1.1.1.4.3">2</cn></apply><apply id="S3.T1.5.5.1.m1.1.1.5.cmml" xref="S3.T1.5.5.1.m1.1.1.5"><csymbol cd="ambiguous" id="S3.T1.5.5.1.m1.1.1.5.1.cmml" xref="S3.T1.5.5.1.m1.1.1.5">superscript</csymbol><ci id="S3.T1.5.5.1.m1.1.1.5.2.cmml" xref="S3.T1.5.5.1.m1.1.1.5.2">ùêæ</ci><cn id="S3.T1.5.5.1.m1.1.1.5.3.cmml" type="integer" xref="S3.T1.5.5.1.m1.1.1.5.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">HWC^{2}K^{3}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.1.m1.1d">italic_H italic_W italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_K start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.6.6.2"><math alttext="C^{2}K^{3}" class="ltx_Math" display="inline" id="S3.T1.6.6.2.m1.1"><semantics id="S3.T1.6.6.2.m1.1a"><mrow id="S3.T1.6.6.2.m1.1.1" xref="S3.T1.6.6.2.m1.1.1.cmml"><msup id="S3.T1.6.6.2.m1.1.1.2" xref="S3.T1.6.6.2.m1.1.1.2.cmml"><mi id="S3.T1.6.6.2.m1.1.1.2.2" mathsize="80%" xref="S3.T1.6.6.2.m1.1.1.2.2.cmml">C</mi><mn id="S3.T1.6.6.2.m1.1.1.2.3" mathsize="80%" xref="S3.T1.6.6.2.m1.1.1.2.3.cmml">2</mn></msup><mo id="S3.T1.6.6.2.m1.1.1.1" xref="S3.T1.6.6.2.m1.1.1.1.cmml">‚Å¢</mo><msup id="S3.T1.6.6.2.m1.1.1.3" xref="S3.T1.6.6.2.m1.1.1.3.cmml"><mi id="S3.T1.6.6.2.m1.1.1.3.2" mathsize="80%" xref="S3.T1.6.6.2.m1.1.1.3.2.cmml">K</mi><mn id="S3.T1.6.6.2.m1.1.1.3.3" mathsize="80%" xref="S3.T1.6.6.2.m1.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.2.m1.1b"><apply id="S3.T1.6.6.2.m1.1.1.cmml" xref="S3.T1.6.6.2.m1.1.1"><times id="S3.T1.6.6.2.m1.1.1.1.cmml" xref="S3.T1.6.6.2.m1.1.1.1"></times><apply id="S3.T1.6.6.2.m1.1.1.2.cmml" xref="S3.T1.6.6.2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.6.6.2.m1.1.1.2.1.cmml" xref="S3.T1.6.6.2.m1.1.1.2">superscript</csymbol><ci id="S3.T1.6.6.2.m1.1.1.2.2.cmml" xref="S3.T1.6.6.2.m1.1.1.2.2">ùê∂</ci><cn id="S3.T1.6.6.2.m1.1.1.2.3.cmml" type="integer" xref="S3.T1.6.6.2.m1.1.1.2.3">2</cn></apply><apply id="S3.T1.6.6.2.m1.1.1.3.cmml" xref="S3.T1.6.6.2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T1.6.6.2.m1.1.1.3.1.cmml" xref="S3.T1.6.6.2.m1.1.1.3">superscript</csymbol><ci id="S3.T1.6.6.2.m1.1.1.3.2.cmml" xref="S3.T1.6.6.2.m1.1.1.3.2">ùêæ</ci><cn id="S3.T1.6.6.2.m1.1.1.3.3.cmml" type="integer" xref="S3.T1.6.6.2.m1.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.2.m1.1c">C^{2}K^{3}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.2.m1.1d">italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_K start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.12.3.1" style="font-size:113%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.8.2" style="font-size:113%;">The complexity analysis above provided from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib14" title="">14</a>]</cite> uses single-head self-attention for simplicity. Note that in our case we increment the FLOPs used for our purposes by a multiple of <math alttext="T" class="ltx_Math" display="inline" id="S3.T1.7.1.m1.1"><semantics id="S3.T1.7.1.m1.1b"><mi id="S3.T1.7.1.m1.1.1" xref="S3.T1.7.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.T1.7.1.m1.1c"><ci id="S3.T1.7.1.m1.1.1.cmml" xref="S3.T1.7.1.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.1.m1.1d">T</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.1.m1.1e">italic_T</annotation></semantics></math> since we compute self-attention for every sample <math alttext="T" class="ltx_Math" display="inline" id="S3.T1.8.2.m2.1"><semantics id="S3.T1.8.2.m2.1b"><mi id="S3.T1.8.2.m2.1.1" xref="S3.T1.8.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.T1.8.2.m2.1c"><ci id="S3.T1.8.2.m2.1.1.cmml" xref="S3.T1.8.2.m2.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.2.m2.1d">T</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.2.m2.1e">italic_T</annotation></semantics></math>.</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>FeedForward Network</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Models like ViT and TSViT use positional encoding (PE) to introduce location information, which fixes the resolution of positional encodings. This can result in reduced performance when the test resolution differs from the training resolution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib36" title="">36</a>]</cite>. To address this issue and simplify the model implementation, we use a 3 <math alttext="\times" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.1.m1.1"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><mo id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><times id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.1.m1.1d">√ó</annotation></semantics></math> 3 depth-wise convolution directly in the feed-forward network (FFN) which was shown to be sufficient to provide positional information for Transformers in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib36" title="">36</a>]</cite>. To compute the output from the FFN layer we have:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{FFN}(x)=\mbox{Linear}(\mbox{GELU}(\mbox{Conv3d}_{3\times 3}(\mbox{Linear%
}(x))))+x" class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mrow id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml"><mtext id="S3.E3.m1.3.3.3.2" mathsize="90%" xref="S3.E3.m1.3.3.3.2a.cmml">FFN</mtext><mo id="S3.E3.m1.3.3.3.1" xref="S3.E3.m1.3.3.3.1.cmml">‚Å¢</mo><mrow id="S3.E3.m1.3.3.3.3.2" xref="S3.E3.m1.3.3.3.cmml"><mo id="S3.E3.m1.3.3.3.3.2.1" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.3.cmml">(</mo><mi id="S3.E3.m1.1.1" mathsize="90%" xref="S3.E3.m1.1.1.cmml">x</mi><mo id="S3.E3.m1.3.3.3.3.2.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.2" mathsize="90%" xref="S3.E3.m1.3.3.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><mtext id="S3.E3.m1.3.3.1.1.3" mathsize="90%" xref="S3.E3.m1.3.3.1.1.3a.cmml">Linear</mtext><mo id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml"><mtext id="S3.E3.m1.3.3.1.1.1.1.1.3" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.3a.cmml">GELU</mtext><mo id="S3.E3.m1.3.3.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mtext id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2a.cmml">Conv3d</mtext><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml"><mn id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2.cmml">3</mn><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1.cmml">√ó</mo><mn id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3.cmml">3</mn></mrow></msub><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mtext id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2a.cmml">Linear</mtext><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">‚Å¢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.2.2" mathsize="90%" xref="S3.E3.m1.2.2.cmml">x</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.2" mathsize="90%" xref="S3.E3.m1.3.3.1.2.cmml">+</mo><mi id="S3.E3.m1.3.3.1.3" mathsize="90%" xref="S3.E3.m1.3.3.1.3.cmml">x</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></eq><apply id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"><times id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.1"></times><ci id="S3.E3.m1.3.3.3.2a.cmml" xref="S3.E3.m1.3.3.3.2"><mtext id="S3.E3.m1.3.3.3.2.cmml" mathsize="90%" xref="S3.E3.m1.3.3.3.2">FFN</mtext></ci><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ùë•</ci></apply><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><plus id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></plus><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1.1"><times id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"></times><ci id="S3.E3.m1.3.3.1.1.3a.cmml" xref="S3.E3.m1.3.3.1.1.3"><mtext id="S3.E3.m1.3.3.1.1.3.cmml" mathsize="90%" xref="S3.E3.m1.3.3.1.1.3">Linear</mtext></ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.2"></times><ci id="S3.E3.m1.3.3.1.1.1.1.1.3a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.3"><mtext id="S3.E3.m1.3.3.1.1.1.1.1.3.cmml" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.3">GELU</mtext></ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2"><mtext id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.2">Conv3d</mtext></ci><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.1"></times><cn id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2.cmml" type="integer" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.2">3</cn><cn id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.3.3">3</cn></apply></apply><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2"><mtext id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" mathsize="90%" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">Linear</mtext></ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">ùë•</ci></apply></apply></apply></apply><ci id="S3.E3.m1.3.3.1.3.cmml" xref="S3.E3.m1.3.3.1.3">ùë•</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mbox{FFN}(x)=\mbox{Linear}(\mbox{GELU}(\mbox{Conv3d}_{3\times 3}(\mbox{Linear%
}(x))))+x</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">FFN ( italic_x ) = Linear ( GELU ( Conv3d start_POSTSUBSCRIPT 3 √ó 3 end_POSTSUBSCRIPT ( Linear ( italic_x ) ) ) ) + italic_x</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.SSS3.p3">
<p class="ltx_p" id="S3.SS1.SSS3.p3.1"><span class="ltx_text" id="S3.SS1.SSS3.p3.1.1" style="font-size:90%;">Observe that GELU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib15" title="">15</a>]</cite> is a commonly used activation function in FFN and the Conv3d<sub class="ltx_sub" id="S3.SS1.SSS3.p3.1.1.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p3.1.1.1.1">3√ó3</span></sub> layer is a depth-wise convolution used to capture positional information. The Conv3d layer is used as it captures position information efficiently since it applies spatial filtering independently to each channel, preserving channel-specific spatial details while reducing computational complexity compared to standard convolutions. Since we downsample the temporal dimension after the first encoder layer, we use a 3D convolution to encode position information instead of a 2D convolution as used in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib36" title="">36</a>]</cite>.</span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Decoder</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2"><span class="ltx_text" id="S3.SS2.p1.2.1" style="font-size:90%;">VistaFormer uses a lightweight decoder consisting of an upsampling layer, a 1D convolution to collapse the temporal dimension and ensure the embedding dimensions for encoder layers are consistent, and a 2D convolution to output a mask prediction. We first apply trilinear interpolation to the outputs of each encoder block as this allows for including temporal and spatial information in the upsampled blocks. A 1D convolution is applied to each of the upsampled blocks to output a fixed embedding dimension of size </span><math alttext="C" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" mathsize="90%" xref="S3.SS2.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_C</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p1.2.2" style="font-size:90%;"> and collapse the temporal dimension </span><math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" mathsize="90%" xref="S3.SS2.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p1.2.3" style="font-size:90%;">. To combine the multi-scale feature representations, we concatenate each of these layers and use a 2D convolution to output a predicted mask.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}U_{i}&amp;=\mbox{Upsample}(W,H)(E_{i}),\forall i\\
F_{i}&amp;=\mbox{Conv1d}(C_{U_{i}},C)(U_{i}),\forall i\\
G&amp;=\mbox{Concat}(F_{i}),\forall i\\
Y&amp;=\mbox{Conv2d}(C,N_{cls})(G)\end{split}" class="ltx_Math" display="block" id="S3.E4.m1.64"><semantics id="S3.E4.m1.64a"><mtable columnspacing="0pt" displaystyle="true" id="S3.E4.m1.64.64.9" rowspacing="0pt"><mtr id="S3.E4.m1.64.64.9a"><mtd class="ltx_align_right" columnalign="right" id="S3.E4.m1.64.64.9b"><msub id="S3.E4.m1.2.2.2.2.2"><mi id="S3.E4.m1.1.1.1.1.1.1" mathsize="90%" xref="S3.E4.m1.1.1.1.1.1.1.cmml">U</mi><mi id="S3.E4.m1.2.2.2.2.2.2.1" mathsize="90%" xref="S3.E4.m1.2.2.2.2.2.2.1.cmml">i</mi></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.64.64.9c"><mrow id="S3.E4.m1.59.59.4.57.18.16"><mi id="S3.E4.m1.59.59.4.57.18.16.17" xref="S3.E4.m1.57.57.2.3.cmml"></mi><mo id="S3.E4.m1.3.3.3.3.1.1" mathsize="90%" xref="S3.E4.m1.3.3.3.3.1.1.cmml">=</mo><mrow id="S3.E4.m1.59.59.4.57.18.16.16.2"><mrow id="S3.E4.m1.58.58.3.56.17.15.15.1.1"><mtext id="S3.E4.m1.4.4.4.4.2.2" mathsize="90%" xref="S3.E4.m1.4.4.4.4.2.2a.cmml">Upsample</mtext><mo id="S3.E4.m1.58.58.3.56.17.15.15.1.1.2" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.58.58.3.56.17.15.15.1.1.3"><mo id="S3.E4.m1.5.5.5.5.3.3" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><mi id="S3.E4.m1.6.6.6.6.4.4" mathsize="90%" xref="S3.E4.m1.6.6.6.6.4.4.cmml">W</mi><mo id="S3.E4.m1.7.7.7.7.5.5" mathsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">,</mo><mi id="S3.E4.m1.8.8.8.8.6.6" mathsize="90%" xref="S3.E4.m1.8.8.8.8.6.6.cmml">H</mi><mo id="S3.E4.m1.9.9.9.9.7.7" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow><mo id="S3.E4.m1.58.58.3.56.17.15.15.1.1.2a" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.58.58.3.56.17.15.15.1.1.1.1"><mo id="S3.E4.m1.10.10.10.10.8.8" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><msub id="S3.E4.m1.58.58.3.56.17.15.15.1.1.1.1.1"><mi id="S3.E4.m1.11.11.11.11.9.9" mathsize="90%" xref="S3.E4.m1.11.11.11.11.9.9.cmml">E</mi><mi id="S3.E4.m1.12.12.12.12.10.10.1" mathsize="90%" xref="S3.E4.m1.12.12.12.12.10.10.1.cmml">i</mi></msub><mo id="S3.E4.m1.13.13.13.13.11.11" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.14.14.14.14.12.12" mathsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">,</mo><mrow id="S3.E4.m1.59.59.4.57.18.16.16.2.2"><mo id="S3.E4.m1.15.15.15.15.13.13" mathsize="90%" rspace="0.167em" xref="S3.E4.m1.15.15.15.15.13.13.cmml">‚àÄ</mo><mi id="S3.E4.m1.16.16.16.16.14.14" mathsize="90%" xref="S3.E4.m1.16.16.16.16.14.14.cmml">i</mi></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E4.m1.64.64.9d"><mtd class="ltx_align_right" columnalign="right" id="S3.E4.m1.64.64.9e"><msub id="S3.E4.m1.18.18.18.2.2"><mi id="S3.E4.m1.17.17.17.1.1.1" mathsize="90%" xref="S3.E4.m1.17.17.17.1.1.1.cmml">F</mi><mi id="S3.E4.m1.18.18.18.2.2.2.1" mathsize="90%" xref="S3.E4.m1.18.18.18.2.2.2.1.cmml">i</mi></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.64.64.9f"><mrow id="S3.E4.m1.61.61.6.59.19.17"><mi id="S3.E4.m1.61.61.6.59.19.17.18" xref="S3.E4.m1.57.57.2.3.cmml"></mi><mo id="S3.E4.m1.19.19.19.3.1.1" mathsize="90%" xref="S3.E4.m1.19.19.19.3.1.1.cmml">=</mo><mrow id="S3.E4.m1.61.61.6.59.19.17.17.2"><mrow id="S3.E4.m1.60.60.5.58.18.16.16.1.1"><mtext id="S3.E4.m1.20.20.20.4.2.2" mathsize="90%" xref="S3.E4.m1.20.20.20.4.2.2a.cmml">Conv1d</mtext><mo id="S3.E4.m1.60.60.5.58.18.16.16.1.1.3" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.60.60.5.58.18.16.16.1.1.1.1"><mo id="S3.E4.m1.21.21.21.5.3.3" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><msub id="S3.E4.m1.60.60.5.58.18.16.16.1.1.1.1.1"><mi id="S3.E4.m1.22.22.22.6.4.4" mathsize="90%" xref="S3.E4.m1.22.22.22.6.4.4.cmml">C</mi><msub id="S3.E4.m1.23.23.23.7.5.5.1" xref="S3.E4.m1.23.23.23.7.5.5.1.cmml"><mi id="S3.E4.m1.23.23.23.7.5.5.1.2" mathsize="90%" xref="S3.E4.m1.23.23.23.7.5.5.1.2.cmml">U</mi><mi id="S3.E4.m1.23.23.23.7.5.5.1.3" mathsize="90%" xref="S3.E4.m1.23.23.23.7.5.5.1.3.cmml">i</mi></msub></msub><mo id="S3.E4.m1.24.24.24.8.6.6" mathsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">,</mo><mi id="S3.E4.m1.25.25.25.9.7.7" mathsize="90%" xref="S3.E4.m1.25.25.25.9.7.7.cmml">C</mi><mo id="S3.E4.m1.26.26.26.10.8.8" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow><mo id="S3.E4.m1.60.60.5.58.18.16.16.1.1.3a" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.60.60.5.58.18.16.16.1.1.2.1"><mo id="S3.E4.m1.27.27.27.11.9.9" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><msub id="S3.E4.m1.60.60.5.58.18.16.16.1.1.2.1.1"><mi id="S3.E4.m1.28.28.28.12.10.10" mathsize="90%" xref="S3.E4.m1.28.28.28.12.10.10.cmml">U</mi><mi id="S3.E4.m1.29.29.29.13.11.11.1" mathsize="90%" xref="S3.E4.m1.29.29.29.13.11.11.1.cmml">i</mi></msub><mo id="S3.E4.m1.30.30.30.14.12.12" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.31.31.31.15.13.13" mathsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">,</mo><mrow id="S3.E4.m1.61.61.6.59.19.17.17.2.2"><mo id="S3.E4.m1.32.32.32.16.14.14" mathsize="90%" rspace="0.167em" xref="S3.E4.m1.32.32.32.16.14.14.cmml">‚àÄ</mo><mi id="S3.E4.m1.33.33.33.17.15.15" mathsize="90%" xref="S3.E4.m1.33.33.33.17.15.15.cmml">i</mi></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E4.m1.64.64.9g"><mtd class="ltx_align_right" columnalign="right" id="S3.E4.m1.64.64.9h"><mi id="S3.E4.m1.34.34.34.1.1.1" mathsize="90%" xref="S3.E4.m1.34.34.34.1.1.1.cmml">G</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.64.64.9i"><mrow id="S3.E4.m1.63.63.8.61.12.11"><mi id="S3.E4.m1.63.63.8.61.12.11.12" xref="S3.E4.m1.57.57.2.3.cmml"></mi><mo id="S3.E4.m1.35.35.35.2.1.1" mathsize="90%" xref="S3.E4.m1.35.35.35.2.1.1.cmml">=</mo><mrow id="S3.E4.m1.63.63.8.61.12.11.11.2"><mrow id="S3.E4.m1.62.62.7.60.11.10.10.1.1"><mtext id="S3.E4.m1.36.36.36.3.2.2" mathsize="90%" xref="S3.E4.m1.36.36.36.3.2.2a.cmml">Concat</mtext><mo id="S3.E4.m1.62.62.7.60.11.10.10.1.1.2" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.62.62.7.60.11.10.10.1.1.1.1"><mo id="S3.E4.m1.37.37.37.4.3.3" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><msub id="S3.E4.m1.62.62.7.60.11.10.10.1.1.1.1.1"><mi id="S3.E4.m1.38.38.38.5.4.4" mathsize="90%" xref="S3.E4.m1.38.38.38.5.4.4.cmml">F</mi><mi id="S3.E4.m1.39.39.39.6.5.5.1" mathsize="90%" xref="S3.E4.m1.39.39.39.6.5.5.1.cmml">i</mi></msub><mo id="S3.E4.m1.40.40.40.7.6.6" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.41.41.41.8.7.7" mathsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">,</mo><mrow id="S3.E4.m1.63.63.8.61.12.11.11.2.2"><mo id="S3.E4.m1.42.42.42.9.8.8" mathsize="90%" rspace="0.167em" xref="S3.E4.m1.42.42.42.9.8.8.cmml">‚àÄ</mo><mi id="S3.E4.m1.43.43.43.10.9.9" mathsize="90%" xref="S3.E4.m1.43.43.43.10.9.9.cmml">i</mi></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E4.m1.64.64.9j"><mtd class="ltx_align_right" columnalign="right" id="S3.E4.m1.64.64.9k"><mi id="S3.E4.m1.44.44.44.1.1.1" mathsize="90%" xref="S3.E4.m1.44.44.44.1.1.1.cmml">Y</mi></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.64.64.9l"><mrow id="S3.E4.m1.64.64.9.62.13.12"><mi id="S3.E4.m1.64.64.9.62.13.12.13" xref="S3.E4.m1.57.57.2.3.cmml"></mi><mo id="S3.E4.m1.45.45.45.2.1.1" mathsize="90%" xref="S3.E4.m1.45.45.45.2.1.1.cmml">=</mo><mrow id="S3.E4.m1.64.64.9.62.13.12.12"><mtext id="S3.E4.m1.46.46.46.3.2.2" mathsize="90%" xref="S3.E4.m1.46.46.46.3.2.2a.cmml">Conv2d</mtext><mo id="S3.E4.m1.64.64.9.62.13.12.12.2" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.64.64.9.62.13.12.12.1.1"><mo id="S3.E4.m1.47.47.47.4.3.3" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><mi id="S3.E4.m1.48.48.48.5.4.4" mathsize="90%" xref="S3.E4.m1.48.48.48.5.4.4.cmml">C</mi><mo id="S3.E4.m1.49.49.49.6.5.5" mathsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">,</mo><msub id="S3.E4.m1.64.64.9.62.13.12.12.1.1.1"><mi id="S3.E4.m1.50.50.50.7.6.6" mathsize="90%" xref="S3.E4.m1.50.50.50.7.6.6.cmml">N</mi><mrow id="S3.E4.m1.51.51.51.8.7.7.1" xref="S3.E4.m1.51.51.51.8.7.7.1.cmml"><mi id="S3.E4.m1.51.51.51.8.7.7.1.2" mathsize="90%" xref="S3.E4.m1.51.51.51.8.7.7.1.2.cmml">c</mi><mo id="S3.E4.m1.51.51.51.8.7.7.1.1" xref="S3.E4.m1.51.51.51.8.7.7.1.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.51.51.51.8.7.7.1.3" mathsize="90%" xref="S3.E4.m1.51.51.51.8.7.7.1.3.cmml">l</mi><mo id="S3.E4.m1.51.51.51.8.7.7.1.1a" xref="S3.E4.m1.51.51.51.8.7.7.1.1.cmml">‚Å¢</mo><mi id="S3.E4.m1.51.51.51.8.7.7.1.4" mathsize="90%" xref="S3.E4.m1.51.51.51.8.7.7.1.4.cmml">s</mi></mrow></msub><mo id="S3.E4.m1.52.52.52.9.8.8" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow><mo id="S3.E4.m1.64.64.9.62.13.12.12.2a" xref="S3.E4.m1.57.57.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.64.64.9.62.13.12.12.3"><mo id="S3.E4.m1.53.53.53.10.9.9" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">(</mo><mi id="S3.E4.m1.54.54.54.11.10.10" mathsize="90%" xref="S3.E4.m1.54.54.54.11.10.10.cmml">G</mi><mo id="S3.E4.m1.55.55.55.12.11.11" maxsize="90%" minsize="90%" xref="S3.E4.m1.57.57.2.3.cmml">)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E4.m1.64b"><apply id="S3.E4.m1.57.57.2.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.3a.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">formulae-sequence</csymbol><apply id="S3.E4.m1.56.56.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><eq id="S3.E4.m1.3.3.3.3.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1"></eq><apply id="S3.E4.m1.56.56.1.1.1.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.56.56.1.1.1.3.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1">ùëà</ci><ci id="S3.E4.m1.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1">ùëñ</ci></apply><apply id="S3.E4.m1.56.56.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.56.56.1.1.1.1.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.4.4.4.4.2.2a.cmml" xref="S3.E4.m1.4.4.4.4.2.2"><mtext id="S3.E4.m1.4.4.4.4.2.2.cmml" mathsize="90%" xref="S3.E4.m1.4.4.4.4.2.2">Upsample</mtext></ci><interval closure="open" id="S3.E4.m1.56.56.1.1.1.1.4.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><ci id="S3.E4.m1.6.6.6.6.4.4.cmml" xref="S3.E4.m1.6.6.6.6.4.4">ùëä</ci><ci id="S3.E4.m1.8.8.8.8.6.6.cmml" xref="S3.E4.m1.8.8.8.8.6.6">ùêª</ci></interval><apply id="S3.E4.m1.56.56.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.56.56.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.11.11.11.11.9.9.cmml" xref="S3.E4.m1.11.11.11.11.9.9">ùê∏</ci><ci id="S3.E4.m1.12.12.12.12.10.10.1.cmml" xref="S3.E4.m1.12.12.12.12.10.10.1">ùëñ</ci></apply></apply></apply><apply id="S3.E4.m1.57.57.2.2.2.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.3a.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">formulae-sequence</csymbol><apply id="S3.E4.m1.57.57.2.2.2.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><eq id="S3.E4.m1.19.19.19.3.1.1.cmml" xref="S3.E4.m1.19.19.19.3.1.1"></eq><apply id="S3.E4.m1.57.57.2.2.2.1.1.4.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="latexml" id="S3.E4.m1.15.15.15.15.13.13.cmml" xref="S3.E4.m1.15.15.15.15.13.13">for-all</csymbol><apply id="S3.E4.m1.57.57.2.2.2.1.1.4.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.57.57.2.2.2.1.1.4.2.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.16.16.16.16.14.14.cmml" xref="S3.E4.m1.16.16.16.16.14.14">ùëñ</ci><apply id="S3.E4.m1.57.57.2.2.2.1.1.4.2.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.1.1.4.2.3.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.17.17.17.1.1.1.cmml" xref="S3.E4.m1.17.17.17.1.1.1">ùêπ</ci><ci id="S3.E4.m1.18.18.18.2.2.2.1.cmml" xref="S3.E4.m1.18.18.18.2.2.2.1">ùëñ</ci></apply></apply></apply><apply id="S3.E4.m1.57.57.2.2.2.1.1.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.57.57.2.2.2.1.1.2.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.20.20.20.4.2.2a.cmml" xref="S3.E4.m1.20.20.20.4.2.2"><mtext id="S3.E4.m1.20.20.20.4.2.2.cmml" mathsize="90%" xref="S3.E4.m1.20.20.20.4.2.2">Conv1d</mtext></ci><interval closure="open" id="S3.E4.m1.57.57.2.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><apply id="S3.E4.m1.57.57.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.22.22.22.6.4.4.cmml" xref="S3.E4.m1.22.22.22.6.4.4">ùê∂</ci><apply id="S3.E4.m1.23.23.23.7.5.5.1.cmml" xref="S3.E4.m1.23.23.23.7.5.5.1"><csymbol cd="ambiguous" id="S3.E4.m1.23.23.23.7.5.5.1.1.cmml" xref="S3.E4.m1.23.23.23.7.5.5.1">subscript</csymbol><ci id="S3.E4.m1.23.23.23.7.5.5.1.2.cmml" xref="S3.E4.m1.23.23.23.7.5.5.1.2">ùëà</ci><ci id="S3.E4.m1.23.23.23.7.5.5.1.3.cmml" xref="S3.E4.m1.23.23.23.7.5.5.1.3">ùëñ</ci></apply></apply><ci id="S3.E4.m1.25.25.25.9.7.7.cmml" xref="S3.E4.m1.25.25.25.9.7.7">ùê∂</ci></interval><apply id="S3.E4.m1.57.57.2.2.2.1.1.2.2.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.1.1.2.2.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.28.28.28.12.10.10.cmml" xref="S3.E4.m1.28.28.28.12.10.10">ùëà</ci><ci id="S3.E4.m1.29.29.29.13.11.11.1.cmml" xref="S3.E4.m1.29.29.29.13.11.11.1">ùëñ</ci></apply></apply></apply><apply id="S3.E4.m1.57.57.2.2.2.2.2.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.2.2.3a.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">formulae-sequence</csymbol><apply id="S3.E4.m1.57.57.2.2.2.2.2.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><eq id="S3.E4.m1.35.35.35.2.1.1.cmml" xref="S3.E4.m1.35.35.35.2.1.1"></eq><apply id="S3.E4.m1.57.57.2.2.2.2.2.1.1.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="latexml" id="S3.E4.m1.32.32.32.16.14.14.cmml" xref="S3.E4.m1.32.32.32.16.14.14">for-all</csymbol><apply id="S3.E4.m1.57.57.2.2.2.2.2.1.1.3.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.57.57.2.2.2.2.2.1.1.3.2.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.33.33.33.17.15.15.cmml" xref="S3.E4.m1.33.33.33.17.15.15">ùëñ</ci><ci id="S3.E4.m1.34.34.34.1.1.1.cmml" xref="S3.E4.m1.34.34.34.1.1.1">ùê∫</ci></apply></apply><apply id="S3.E4.m1.57.57.2.2.2.2.2.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.57.57.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.36.36.36.3.2.2a.cmml" xref="S3.E4.m1.36.36.36.3.2.2"><mtext id="S3.E4.m1.36.36.36.3.2.2.cmml" mathsize="90%" xref="S3.E4.m1.36.36.36.3.2.2">Concat</mtext></ci><apply id="S3.E4.m1.57.57.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.38.38.38.5.4.4.cmml" xref="S3.E4.m1.38.38.38.5.4.4">ùêπ</ci><ci id="S3.E4.m1.39.39.39.6.5.5.1.cmml" xref="S3.E4.m1.39.39.39.6.5.5.1">ùëñ</ci></apply></apply></apply><apply id="S3.E4.m1.57.57.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><eq id="S3.E4.m1.45.45.45.2.1.1.cmml" xref="S3.E4.m1.45.45.45.2.1.1"></eq><apply id="S3.E4.m1.57.57.2.2.2.2.2.2.2.3.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="latexml" id="S3.E4.m1.42.42.42.9.8.8.cmml" xref="S3.E4.m1.42.42.42.9.8.8">for-all</csymbol><apply id="S3.E4.m1.57.57.2.2.2.2.2.2.2.3.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.57.57.2.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.43.43.43.10.9.9.cmml" xref="S3.E4.m1.43.43.43.10.9.9">ùëñ</ci><ci id="S3.E4.m1.44.44.44.1.1.1.cmml" xref="S3.E4.m1.44.44.44.1.1.1">ùëå</ci></apply></apply><apply id="S3.E4.m1.57.57.2.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><times id="S3.E4.m1.57.57.2.2.2.2.2.2.2.1.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"></times><ci id="S3.E4.m1.46.46.46.3.2.2a.cmml" xref="S3.E4.m1.46.46.46.3.2.2"><mtext id="S3.E4.m1.46.46.46.3.2.2.cmml" mathsize="90%" xref="S3.E4.m1.46.46.46.3.2.2">Conv2d</mtext></ci><interval closure="open" id="S3.E4.m1.57.57.2.2.2.2.2.2.2.1.1.2.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><ci id="S3.E4.m1.48.48.48.5.4.4.cmml" xref="S3.E4.m1.48.48.48.5.4.4">ùê∂</ci><apply id="S3.E4.m1.57.57.2.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17"><csymbol cd="ambiguous" id="S3.E4.m1.57.57.2.2.2.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.59.59.4.57.18.16.17">subscript</csymbol><ci id="S3.E4.m1.50.50.50.7.6.6.cmml" xref="S3.E4.m1.50.50.50.7.6.6">ùëÅ</ci><apply id="S3.E4.m1.51.51.51.8.7.7.1.cmml" xref="S3.E4.m1.51.51.51.8.7.7.1"><times id="S3.E4.m1.51.51.51.8.7.7.1.1.cmml" xref="S3.E4.m1.51.51.51.8.7.7.1.1"></times><ci id="S3.E4.m1.51.51.51.8.7.7.1.2.cmml" xref="S3.E4.m1.51.51.51.8.7.7.1.2">ùëê</ci><ci id="S3.E4.m1.51.51.51.8.7.7.1.3.cmml" xref="S3.E4.m1.51.51.51.8.7.7.1.3">ùëô</ci><ci id="S3.E4.m1.51.51.51.8.7.7.1.4.cmml" xref="S3.E4.m1.51.51.51.8.7.7.1.4">ùë†</ci></apply></apply></interval><ci id="S3.E4.m1.54.54.54.11.10.10.cmml" xref="S3.E4.m1.54.54.54.11.10.10">ùê∫</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.64c">\begin{split}U_{i}&amp;=\mbox{Upsample}(W,H)(E_{i}),\forall i\\
F_{i}&amp;=\mbox{Conv1d}(C_{U_{i}},C)(U_{i}),\forall i\\
G&amp;=\mbox{Concat}(F_{i}),\forall i\\
Y&amp;=\mbox{Conv2d}(C,N_{cls})(G)\end{split}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.64d">start_ROW start_CELL italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_CELL start_CELL = Upsample ( italic_W , italic_H ) ( italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ‚àÄ italic_i end_CELL end_ROW start_ROW start_CELL italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_CELL start_CELL = Conv1d ( italic_C start_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_C ) ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ‚àÄ italic_i end_CELL end_ROW start_ROW start_CELL italic_G end_CELL start_CELL = Concat ( italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ‚àÄ italic_i end_CELL end_ROW start_ROW start_CELL italic_Y end_CELL start_CELL = Conv2d ( italic_C , italic_N start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT ) ( italic_G ) end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.8"><span class="ltx_text" id="S3.SS2.p3.8.1" style="font-size:90%;">where Conv1d</span><math alttext="(C_{in},C_{out})" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.2"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2.2" xref="S3.SS2.p3.1.m1.2.2.3.cmml"><mo id="S3.SS2.p3.1.m1.2.2.2.3" maxsize="90%" minsize="90%" xref="S3.SS2.p3.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.1.m1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.2" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.1.1.2.cmml">C</mi><mrow id="S3.SS2.p3.1.m1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.3.2" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p3.1.m1.1.1.1.1.3.1" xref="S3.SS2.p3.1.m1.1.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.1.m1.1.1.1.1.3.3" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.1.1.3.3.cmml">n</mi></mrow></msub><mo id="S3.SS2.p3.1.m1.2.2.2.4" mathsize="90%" xref="S3.SS2.p3.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.2" mathsize="90%" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml">C</mi><mrow id="S3.SS2.p3.1.m1.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.3.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.3.2" mathsize="90%" xref="S3.SS2.p3.1.m1.2.2.2.2.3.2.cmml">o</mi><mo id="S3.SS2.p3.1.m1.2.2.2.2.3.1" xref="S3.SS2.p3.1.m1.2.2.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.1.m1.2.2.2.2.3.3" mathsize="90%" xref="S3.SS2.p3.1.m1.2.2.2.2.3.3.cmml">u</mi><mo id="S3.SS2.p3.1.m1.2.2.2.2.3.1a" xref="S3.SS2.p3.1.m1.2.2.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.1.m1.2.2.2.2.3.4" mathsize="90%" xref="S3.SS2.p3.1.m1.2.2.2.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS2.p3.1.m1.2.2.2.5" maxsize="90%" minsize="90%" xref="S3.SS2.p3.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><interval closure="open" id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2"><apply id="S3.SS2.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.2">ùê∂</ci><apply id="S3.SS2.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3"><times id="S3.SS2.p3.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.2">ùëñ</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3.3">ùëõ</ci></apply></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">ùê∂</ci><apply id="S3.SS2.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3"><times id="S3.SS2.p3.1.m1.2.2.2.2.3.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.1"></times><ci id="S3.SS2.p3.1.m1.2.2.2.2.3.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.2">ùëú</ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.3.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.3">ùë¢</ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.3.4.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.3.4">ùë°</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">(C_{in},C_{out})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.2d">( italic_C start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.2" style="font-size:90%;"> and Conv2d</span><math alttext="(C_{in},C_{out})" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.2"><semantics id="S3.SS2.p3.2.m2.2a"><mrow id="S3.SS2.p3.2.m2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.3.cmml"><mo id="S3.SS2.p3.2.m2.2.2.2.3" maxsize="90%" minsize="90%" xref="S3.SS2.p3.2.m2.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.2" mathsize="90%" xref="S3.SS2.p3.2.m2.1.1.1.1.2.cmml">C</mi><mrow id="S3.SS2.p3.2.m2.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.3.2" mathsize="90%" xref="S3.SS2.p3.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p3.2.m2.1.1.1.1.3.1" xref="S3.SS2.p3.2.m2.1.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.2.m2.1.1.1.1.3.3" mathsize="90%" xref="S3.SS2.p3.2.m2.1.1.1.1.3.3.cmml">n</mi></mrow></msub><mo id="S3.SS2.p3.2.m2.2.2.2.4" mathsize="90%" xref="S3.SS2.p3.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.2.m2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.cmml"><mi id="S3.SS2.p3.2.m2.2.2.2.2.2" mathsize="90%" xref="S3.SS2.p3.2.m2.2.2.2.2.2.cmml">C</mi><mrow id="S3.SS2.p3.2.m2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.2.3.cmml"><mi id="S3.SS2.p3.2.m2.2.2.2.2.3.2" mathsize="90%" xref="S3.SS2.p3.2.m2.2.2.2.2.3.2.cmml">o</mi><mo id="S3.SS2.p3.2.m2.2.2.2.2.3.1" xref="S3.SS2.p3.2.m2.2.2.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.2.m2.2.2.2.2.3.3" mathsize="90%" xref="S3.SS2.p3.2.m2.2.2.2.2.3.3.cmml">u</mi><mo id="S3.SS2.p3.2.m2.2.2.2.2.3.1a" xref="S3.SS2.p3.2.m2.2.2.2.2.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.2.m2.2.2.2.2.3.4" mathsize="90%" xref="S3.SS2.p3.2.m2.2.2.2.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS2.p3.2.m2.2.2.2.5" maxsize="90%" minsize="90%" xref="S3.SS2.p3.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.2b"><interval closure="open" id="S3.SS2.p3.2.m2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2"><apply id="S3.SS2.p3.2.m2.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.2">ùê∂</ci><apply id="S3.SS2.p3.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.3"><times id="S3.SS2.p3.2.m2.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.3.1"></times><ci id="S3.SS2.p3.2.m2.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.3.2">ùëñ</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.3.3">ùëõ</ci></apply></apply><apply id="S3.SS2.p3.2.m2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.2.2.2.2.1.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2">ùê∂</ci><apply id="S3.SS2.p3.2.m2.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.3"><times id="S3.SS2.p3.2.m2.2.2.2.2.3.1.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.3.1"></times><ci id="S3.SS2.p3.2.m2.2.2.2.2.3.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.3.2">ùëú</ci><ci id="S3.SS2.p3.2.m2.2.2.2.2.3.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.3.3">ùë¢</ci><ci id="S3.SS2.p3.2.m2.2.2.2.2.3.4.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.3.4">ùë°</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.2c">(C_{in},C_{out})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.2d">( italic_C start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT )</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.3" style="font-size:90%;"> denotes the respective convolution layers, </span><math alttext="C_{in}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" mathsize="90%" xref="S3.SS2.p3.3.m3.1.1.2.cmml">C</mi><mrow id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.3.2" mathsize="90%" xref="S3.SS2.p3.3.m3.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p3.3.m3.1.1.3.1" xref="S3.SS2.p3.3.m3.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.3.m3.1.1.3.3" mathsize="90%" xref="S3.SS2.p3.3.m3.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">ùê∂</ci><apply id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3"><times id="S3.SS2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.3.1"></times><ci id="S3.SS2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.3.2">ùëñ</ci><ci id="S3.SS2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3">ùëõ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">C_{in}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_C start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.4" style="font-size:90%;"> denotes the input embedding dimension, and </span><math alttext="C_{out}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" mathsize="90%" xref="S3.SS2.p3.4.m4.1.1.2.cmml">C</mi><mrow id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.3.2" mathsize="90%" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml">o</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.3" mathsize="90%" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">u</mi><mo id="S3.SS2.p3.4.m4.1.1.3.1a" xref="S3.SS2.p3.4.m4.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.4.m4.1.1.3.4" mathsize="90%" xref="S3.SS2.p3.4.m4.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">ùê∂</ci><apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3"><times id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3.1"></times><ci id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">ùëú</ci><ci id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">ùë¢</ci><ci id="S3.SS2.p3.4.m4.1.1.3.4.cmml" xref="S3.SS2.p3.4.m4.1.1.3.4">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">C_{out}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_C start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.5" style="font-size:90%;"> represents the output embedding dimension. Observe also that the Upsample layer uses trilinear interpolation where </span><math alttext="W" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" mathsize="90%" xref="S3.SS2.p3.5.m5.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">ùëä</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_W</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.6" style="font-size:90%;"> and </span><math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><mi id="S3.SS2.p3.6.m6.1.1" mathsize="90%" xref="S3.SS2.p3.6.m6.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_H</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.7" style="font-size:90%;"> correspond to the input dimensions given by </span><math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" mathsize="90%" xref="S3.SS2.p3.7.m7.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_H</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.8" style="font-size:90%;"> and </span><math alttext="W" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m8.1"><semantics id="S3.SS2.p3.8.m8.1a"><mi id="S3.SS2.p3.8.m8.1.1" mathsize="90%" xref="S3.SS2.p3.8.m8.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><ci id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">ùëä</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m8.1d">italic_W</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.8.9" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.3" style="width:496.9pt;height:126.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(106.5pt,-27.0pt) scale(1.75095020671093,1.75095020671093) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.3.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.1"><span class="ltx_text" id="S3.T2.3.3.4.1.1.1" style="font-size:50%;">Encoder Layer</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.2"><span class="ltx_text" id="S3.T2.3.3.4.1.2.1" style="font-size:50%;">Embed Dim</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.3"><span class="ltx_text" id="S3.T2.3.3.4.1.3.1" style="font-size:50%;">Patch</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.4"><span class="ltx_text" id="S3.T2.3.3.4.1.4.1" style="font-size:50%;">Stride</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.5"><span class="ltx_text" id="S3.T2.3.3.4.1.5.1" style="font-size:50%;">Transformer Layers</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.6"><span class="ltx_text" id="S3.T2.3.3.4.1.6.1" style="font-size:50%;">Attention Heads</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.3.3.4.1.7"><span class="ltx_text" id="S3.T2.3.3.4.1.7.1" style="font-size:50%;">MLP Mult</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.1"><math alttext="E_{1}" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.m1.1a"><msub id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.1.1.1.1.m1.1.1.2" mathsize="50%" xref="S3.T2.1.1.1.1.m1.1.1.2.cmml">E</mi><mn id="S3.T2.1.1.1.1.m1.1.1.3" mathsize="50%" xref="S3.T2.1.1.1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.1.1.1.1.m1.1.1.2">ùê∏</ci><cn id="S3.T2.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S3.T2.1.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">E_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.m1.1d">italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.2"><span class="ltx_text" id="S3.T2.1.1.1.2.1" style="font-size:50%;">32</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.3"><span class="ltx_text" id="S3.T2.1.1.1.3.1" style="font-size:50%;">(1, 2, 2)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.4"><span class="ltx_text" id="S3.T2.1.1.1.4.1" style="font-size:50%;">(1, 2, 2)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.5"><span class="ltx_text" id="S3.T2.1.1.1.5.1" style="font-size:50%;">2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.6"><span class="ltx_text" id="S3.T2.1.1.1.6.1" style="font-size:50%;">2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.1.1.7"><span class="ltx_text" id="S3.T2.1.1.1.7.1" style="font-size:50%;">4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.2.2">
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.1"><math alttext="E_{2}" class="ltx_Math" display="inline" id="S3.T2.2.2.2.1.m1.1"><semantics id="S3.T2.2.2.2.1.m1.1a"><msub id="S3.T2.2.2.2.1.m1.1.1" xref="S3.T2.2.2.2.1.m1.1.1.cmml"><mi id="S3.T2.2.2.2.1.m1.1.1.2" mathsize="50%" xref="S3.T2.2.2.2.1.m1.1.1.2.cmml">E</mi><mn id="S3.T2.2.2.2.1.m1.1.1.3" mathsize="50%" xref="S3.T2.2.2.2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b"><apply id="S3.T2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.2.2.2.1.m1.1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1">subscript</csymbol><ci id="S3.T2.2.2.2.1.m1.1.1.2.cmml" xref="S3.T2.2.2.2.1.m1.1.1.2">ùê∏</ci><cn id="S3.T2.2.2.2.1.m1.1.1.3.cmml" type="integer" xref="S3.T2.2.2.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">E_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.1.m1.1d">italic_E start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.2"><span class="ltx_text" id="S3.T2.2.2.2.2.1" style="font-size:50%;">64</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.3"><span class="ltx_text" id="S3.T2.2.2.2.3.1" style="font-size:50%;">(2, 2, 2)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.4"><span class="ltx_text" id="S3.T2.2.2.2.4.1" style="font-size:50%;">(2, 2, 2)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.5"><span class="ltx_text" id="S3.T2.2.2.2.5.1" style="font-size:50%;">2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.6"><span class="ltx_text" id="S3.T2.2.2.2.6.1" style="font-size:50%;">4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.7"><span class="ltx_text" id="S3.T2.2.2.2.7.1" style="font-size:50%;">4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.1"><math alttext="E_{3}" class="ltx_Math" display="inline" id="S3.T2.3.3.3.1.m1.1"><semantics id="S3.T2.3.3.3.1.m1.1a"><msub id="S3.T2.3.3.3.1.m1.1.1" xref="S3.T2.3.3.3.1.m1.1.1.cmml"><mi id="S3.T2.3.3.3.1.m1.1.1.2" mathsize="50%" xref="S3.T2.3.3.3.1.m1.1.1.2.cmml">E</mi><mn id="S3.T2.3.3.3.1.m1.1.1.3" mathsize="50%" xref="S3.T2.3.3.3.1.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><apply id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.3.3.3.1.m1.1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">subscript</csymbol><ci id="S3.T2.3.3.3.1.m1.1.1.2.cmml" xref="S3.T2.3.3.3.1.m1.1.1.2">ùê∏</ci><cn id="S3.T2.3.3.3.1.m1.1.1.3.cmml" type="integer" xref="S3.T2.3.3.3.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">E_{3}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.3.3.1.m1.1d">italic_E start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.2"><span class="ltx_text" id="S3.T2.3.3.3.2.1" style="font-size:50%;">128</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.3"><span class="ltx_text" id="S3.T2.3.3.3.3.1" style="font-size:50%;">(2, 2, 2)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.4"><span class="ltx_text" id="S3.T2.3.3.3.4.1" style="font-size:50%;">(2, 2, 2)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.5"><span class="ltx_text" id="S3.T2.3.3.3.5.1" style="font-size:50%;">2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.6"><span class="ltx_text" id="S3.T2.3.3.3.6.1" style="font-size:50%;">8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.3.3.7"><span class="ltx_text" id="S3.T2.3.3.3.7.1" style="font-size:50%;">4</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Configuration values for the VistaFormer encoder module where <math alttext="E_{i}" class="ltx_Math" display="inline" id="S3.T2.5.m1.1"><semantics id="S3.T2.5.m1.1b"><msub id="S3.T2.5.m1.1.1" xref="S3.T2.5.m1.1.1.cmml"><mi id="S3.T2.5.m1.1.1.2" xref="S3.T2.5.m1.1.1.2.cmml">E</mi><mi id="S3.T2.5.m1.1.1.3" xref="S3.T2.5.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T2.5.m1.1c"><apply id="S3.T2.5.m1.1.1.cmml" xref="S3.T2.5.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.5.m1.1.1.1.cmml" xref="S3.T2.5.m1.1.1">subscript</csymbol><ci id="S3.T2.5.m1.1.1.2.cmml" xref="S3.T2.5.m1.1.1.2">ùê∏</ci><ci id="S3.T2.5.m1.1.1.3.cmml" xref="S3.T2.5.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.m1.1d">E_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.m1.1e">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> corresponds to a given encoder block.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text" id="S4.p1.1.1" style="font-size:90%;">We now evaluate the performance of the VistaFormer models on two crop-type segmentation benchmarks, PASTIS and MTLCC. In Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS3" style="font-size:90%;" title="4.3 Results ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">4.3</span></a><span class="ltx_text" id="S4.p1.1.2" style="font-size:90%;"> we report on the comparison of VistaFormer models to the current state-of-the-art performance, while in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS4" style="font-size:90%;" title="4.4 Ablations ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">4.4</span></a><span class="ltx_text" id="S4.p1.1.3" style="font-size:90%;"> we provide an overview of the performance of some ablations performed on the VistaFormer model that uses MHSA. Finally, we show VistaFormer‚Äôs scalability relative to U-TAE and TSViT models as input and temporal dimensions vary in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS5" style="font-size:90%;" title="4.5 Model Scalability ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">4.5</span></a><span class="ltx_text" id="S4.p1.1.4" style="font-size:90%;">.</span></p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text" id="S4.SS1.p1.1.1" style="font-size:90%;">To evaluate VistaFormer, we use the MTLCC </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a><span class="ltx_text" id="S4.SS1.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.p1.1.4" style="font-size:90%;"> and optical PASTIS </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS1.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.p1.1.7" style="font-size:90%;"> semantic segmentation benchmarks. The datasets we chose for evaluating the performance of our model have the following similar noteworthy characteristics (a) they include samples that are obstructed by cloud coverage (in some cases multiple images are entirely covered by clouds), (b) they are both imbalanced datasets with many of the classes accounting for a tiny percentage of the overall pixels, and (c) they include a large number of background pixels that may or may not be easily confused with crop class pixels.</span></p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>MTLCC</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.2"><span class="ltx_text" id="S4.SS1.SSS1.p1.2.1" style="font-size:90%;">The MTLCC </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS1.p1.2.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a><span class="ltx_text" id="S4.SS1.SSS1.p1.2.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS1.p1.2.4" style="font-size:90%;"> dataset covers an area of 102km </span><math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.1.m1.1"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><mo id="S4.SS1.SSS1.p1.1.m1.1.1" mathsize="90%" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><times id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.1.m1.1d">√ó</annotation></semantics></math><span class="ltx_text" id="S4.SS1.SSS1.p1.2.5" style="font-size:90%;"> 42km north of Munich, Germany and includes 17 crop classes along with an unknown class that accounts for 39.91% of pixels. The dataset includes 13 Sentinel-2 bands split into </span><math alttext="24\times 24" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p1.2.m2.1"><semantics id="S4.SS1.SSS1.p1.2.m2.1a"><mrow id="S4.SS1.SSS1.p1.2.m2.1.1" xref="S4.SS1.SSS1.p1.2.m2.1.1.cmml"><mn id="S4.SS1.SSS1.p1.2.m2.1.1.2" mathsize="90%" xref="S4.SS1.SSS1.p1.2.m2.1.1.2.cmml">24</mn><mo id="S4.SS1.SSS1.p1.2.m2.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS1.SSS1.p1.2.m2.1.1.1.cmml">√ó</mo><mn id="S4.SS1.SSS1.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS1.SSS1.p1.2.m2.1.1.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.2.m2.1b"><apply id="S4.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1"><times id="S4.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1.1"></times><cn id="S4.SS1.SSS1.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS1.SSS1.p1.2.m2.1.1.2">24</cn><cn id="S4.SS1.SSS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.SSS1.p1.2.m2.1.1.3">24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.2.m2.1c">24\times 24</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.2.m2.1d">24 √ó 24</annotation></semantics></math><span class="ltx_text" id="S4.SS1.SSS1.p1.2.6" style="font-size:90%;"> pixels for the highest resolution bands and we up-sample the lower resolution bands using bilinear interpolation to match the dimensions of the highest resolution bands. The dataset includes samples for 2016 which includes 46 samples and 2017 which includes 52 samples. We use the splits provided in the original study for a direct model comparison which has 27k training samples, 8.5k validation samples, and 8.4k test samples. In keeping with the evaluation criteria used in </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS1.p1.2.7.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a><span class="ltx_text" id="S4.SS1.SSS1.p1.2.8.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS1.p1.2.9" style="font-size:90%;">, we use 2016 for train, validation, and test datasets. However, we deviate from results reporting from </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS1.p1.2.10.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a><span class="ltx_text" id="S4.SS1.SSS1.p1.2.11.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS1.p1.2.12" style="font-size:90%;">, in that we record model results both when the unknown class is included and not included. Not including unknown/background classes during training ensures the model is not penalized for making false predictions in that given area, ensuring the resulting model is more likely to predict false positives, making the model unreliable for predicting realistic boundaries for a class in most applied contexts </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS1.p1.2.13.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib41" title="">41</a><span class="ltx_text" id="S4.SS1.SSS1.p1.2.14.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS1.p1.2.15" style="font-size:90%;">. Note that the background class in this benchmark accounts for 43.2% of the overall pixels while 13 of the remaining 17 crop classes account for just 13.57% of the overall pixels.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>PASTIS</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.2"><span class="ltx_text" id="S4.SS1.SSS2.p1.2.1" style="font-size:90%;">The PASTIS </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS2.p1.2.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS1.SSS2.p1.2.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS2.p1.2.4" style="font-size:90%;"> dataset spans over 4,000 km</span><sup class="ltx_sup" id="S4.SS1.SSS2.p1.2.5"><span class="ltx_text" id="S4.SS1.SSS2.p1.2.5.1" style="font-size:90%;">2</span></sup><span class="ltx_text" id="S4.SS1.SSS2.p1.2.6" style="font-size:90%;"> with images taken from four regions in France. Each sequence of images includes 10 Sentinel-2 bands split into </span><math alttext="128\times 128" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p1.2.m2.1"><semantics id="S4.SS1.SSS2.p1.2.m2.1a"><mrow id="S4.SS1.SSS2.p1.2.m2.1.1" xref="S4.SS1.SSS2.p1.2.m2.1.1.cmml"><mn id="S4.SS1.SSS2.p1.2.m2.1.1.2" mathsize="90%" xref="S4.SS1.SSS2.p1.2.m2.1.1.2.cmml">128</mn><mo id="S4.SS1.SSS2.p1.2.m2.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS1.SSS2.p1.2.m2.1.1.1.cmml">√ó</mo><mn id="S4.SS1.SSS2.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS1.SSS2.p1.2.m2.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.2.m2.1b"><apply id="S4.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1"><times id="S4.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1.1"></times><cn id="S4.SS1.SSS2.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS1.SSS2.p1.2.m2.1.1.2">128</cn><cn id="S4.SS1.SSS2.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.SSS2.p1.2.m2.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.2.m2.1c">128\times 128</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.2.m2.1d">128 √ó 128</annotation></semantics></math><span class="ltx_text" id="S4.SS1.SSS2.p1.2.7" style="font-size:90%;"> pixels and includes between 38 and 61 observations taken between September 2018 and November 2019 </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS2.p1.2.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS1.SSS2.p1.2.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS2.p1.2.10" style="font-size:90%;">. The dataset includes 2,433 samples that are split into 5 folds where for each split, three folds are used for training; one fold is used for validation; and the remaining one fold is used for testing. There are 5 combinations of splits used for measuring model performance on the dataset to ensure that each of the splits can be independently used as the test dataset to better ensure the model generalizes well. The dataset includes 20 classes, with 18 crop types, a background (or non-crop) class, and a void class which includes either only partial crop class pixels or crop types the authors were unable to confidently identify. The void label is ignored during loss though the background label is included during training and inference results, as specified in </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS1.SSS2.p1.2.11.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS1.SSS2.p1.2.12.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS1.SSS2.p1.2.13" style="font-size:90%;">. Note that the background class in this benchmark dataset accounts for 39.91% of the overall pixels while 15 of the remaining 18 classes account for 13.86% of the overall pixels.</span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details </h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.3"><span class="ltx_text" id="S4.SS2.p1.3.1" style="font-size:90%;">For both datasets, we train VistaFormer using the weighted Adam optimizer </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p1.3.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib24" title="">24</a><span class="ltx_text" id="S4.SS2.p1.3.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p1.3.4" style="font-size:90%;"> using </span><math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><msub id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2.2" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">Œ≤</mi><mn id="S4.SS2.p1.1.m1.1.1.2.3" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS2.p1.1.m1.1.1.1" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.1.m1.1.1.3" mathsize="90%" xref="S4.SS2.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><eq id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></eq><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">ùõΩ</ci><cn id="S4.SS2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.2.3">1</cn></apply><cn id="S4.SS2.p1.1.m1.1.1.3.cmml" type="float" xref="S4.SS2.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\beta_{1}=0.9</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p1.3.5" style="font-size:90%;"> and </span><math alttext="\beta_{2}=0.999" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><msub id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2.2" mathsize="90%" xref="S4.SS2.p1.2.m2.1.1.2.2.cmml">Œ≤</mi><mn id="S4.SS2.p1.2.m2.1.1.2.3" mathsize="90%" xref="S4.SS2.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS2.p1.2.m2.1.1.1" mathsize="90%" xref="S4.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS2.p1.2.m2.1.1.3.cmml">0.999</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><eq id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1"></eq><apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2.2">ùõΩ</ci><cn id="S4.SS2.p1.2.m2.1.1.2.3.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.2.3">2</cn></apply><cn id="S4.SS2.p1.2.m2.1.1.3.cmml" type="float" xref="S4.SS2.p1.2.m2.1.1.3">0.999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\beta_{2}=0.999</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.999</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p1.3.6" style="font-size:90%;"> as the coefficients for computing running averages of the gradient and it‚Äôs square. We use a one-cycle learning rate scheduler that starts with a learning rate of 0.0004 and increases to a max learning rate of 0.01 after the first 10% of training and is then reduced to a final learning rate of 0.001 in the last epoch. For both datasets, we use a dropout and drop path of 17.5% respectively and use cross-entropy loss for the loss function as in </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p1.3.7.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS2.p1.3.8.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p1.3.9" style="font-size:90%;">. We found using this higher learning rate and learning rate schedule to outperform lower learning rates for both the max learning rate and the scheduled values. For each input, we normalize using techniques detailed in the original papers </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p1.3.10.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a><span class="ltx_text" id="S4.SS2.p1.3.11.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p1.3.12" style="font-size:90%;"> and apply flip and 90</span><sup class="ltx_sup" id="S4.SS2.p1.3.13"><span class="ltx_text ltx_font_italic" id="S4.SS2.p1.3.13.1" style="font-size:90%;">‚àò</span></sup><span class="ltx_text" id="S4.SS2.p1.3.14" style="font-size:90%;"> rotate transformations for inputs during training with 50% likelihood of applying the respective transformation. The models were trained using distributed training on compute nodes with 8 CPUs, 100GB of memory, and two Tesla V100 GPUs for roughly 8-12 hours.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text" id="S4.SS2.p2.1.1" style="font-size:90%;">We trained on the PASTIS dataset with a batch size of 32 and a maximum sequence length of 60, and height and width of 32, while for the MTLCC dataset, we used a batch size of 16 and a maximum sequence length of 46 and a provided input height and width of 24. Given that the model uses 3D convolutional layers for upsampling and downsampling which contribute significantly to the number of trainable parameters (relative to our model size); decreasing the input sequence length results in a considerably smaller model. For the MTLCC dataset, we found that decreasing the sequence length from 60 to 46 reduced the number of trainable parameters by 13%. Reducing the sequence dimension for the MTLCC dataset was done in keeping with the sequence length used in </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a><span class="ltx_text" id="S4.SS2.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p2.1.4" style="font-size:90%;"> and to reduce the number of blank images included with each sample.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text" id="S4.SS2.p3.1.1" style="font-size:90%;">Given the small dimensions of the input images for the datasets used during experimentation and the downsampling rate selected for each encoder level, we found that a model architecture with three input layers outperformed other model architectures that included fewer pairs of encoder-decoder blocks. We also found that the selected batch sizes for both the MTLCC and PASTIS benchmarks were optimal relative to smaller or larger batch sizes. The configurations used for the Encoder are given in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.T2" style="font-size:90%;" title="Table 2 ‚Ä£ 3.2 Decoder ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S4.SS2.p3.1.2" style="font-size:90%;">, while for the decoder, the unique configuration we used for our model was to use 64 output channels for each of the 1D convolution layers which downsample </span><math alttext="T" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" mathsize="90%" xref="S4.SS2.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p3.1.3" style="font-size:90%;">. We found the attention head dimension outperformed smaller or larger sizes and the selected embedding dimension outperformed larger embedding dimensions at each layer.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text" id="S4.SS2.p4.1.1" style="font-size:90%;">For the implementation of VistaFormer that uses 2D NA we chose to use a neighbourhood size </span><math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.p4.1.m1.1"><semantics id="S4.SS2.p4.1.m1.1a"><mi id="S4.SS2.p4.1.m1.1.1" mathsize="90%" xref="S4.SS2.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><ci id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">italic_k</annotation></semantics></math><span class="ltx_text" id="S4.SS2.p4.1.2" style="font-size:90%;"> of 13 to increase the spatial extent used for computing self-attention, which is slightly above the window of size 7 used in the experiments for </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS2.p4.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib14" title="">14</a><span class="ltx_text" id="S4.SS2.p4.1.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS2.p4.1.5" style="font-size:90%;">. We also deviate from the configurations detailed in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.T2" style="font-size:90%;" title="Table 2 ‚Ä£ 3.2 Decoder ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S4.SS2.p4.1.6" style="font-size:90%;"> by using 1, 2, and 4 attention heads respectively in the encoder blocks.</span></p>
</div>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.12" style="width:496.9pt;height:172.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.3pt,18.4pt) scale(0.823443238986848,0.823443238986848) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.12.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.12.12.13.1">
<td class="ltx_td ltx_border_tt" colspan="3" id="S4.T3.12.12.13.1.1" style="padding-bottom:3.87498pt;"></td>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.12.12.13.1.2" style="padding-bottom:3.87498pt;"><span class="ltx_text" id="S4.T3.12.12.13.1.2.1" style="font-size:90%;">PASTIS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.12.12.13.1.3" style="padding-bottom:3.87498pt;"><span class="ltx_text" id="S4.T3.12.12.13.1.3.1" style="font-size:90%;">MTLCC (2016)</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.14.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.12.12.14.2.1"><span class="ltx_text" id="S4.T3.12.12.14.2.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.12.12.14.2.2"><span class="ltx_text" id="S4.T3.12.12.14.2.2.1" style="font-size:90%;">GFLOPs</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.12.12.14.2.3"><span class="ltx_text" id="S4.T3.12.12.14.2.3.1" style="font-size:90%;">Model Params (m)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.12.12.14.2.4"><span class="ltx_text" id="S4.T3.12.12.14.2.4.1" style="font-size:90%;">oA / mIoU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.12.12.14.2.5"><span class="ltx_text" id="S4.T3.12.12.14.2.5.1" style="font-size:90%;">oA / mIoU</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.15.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.12.12.15.3.1">
<span class="ltx_text" id="S4.T3.12.12.15.3.1.1" style="font-size:90%;">FPN + ConvLSTM </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.12.12.15.3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib5" title="">5</a><span class="ltx_text" id="S4.T3.12.12.15.3.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.12.12.15.3.2"><span class="ltx_text" id="S4.T3.12.12.15.3.2.1" style="font-size:90%;">282.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.12.12.15.3.3"><span class="ltx_text" id="S4.T3.12.12.15.3.3.1" style="font-size:90%;">1.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.12.12.15.3.4"><span class="ltx_text" id="S4.T3.12.12.15.3.4.1" style="font-size:90%;">81.6 / 57.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.12.12.15.3.5"><span class="ltx_text" id="S4.T3.12.12.15.3.5.1" style="font-size:90%;">91.8 / 73.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.16.4">
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.16.4.1">
<span class="ltx_text" id="S4.T3.12.12.16.4.1.1" style="font-size:90%;">UNet + ConvLSTM </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.12.12.16.4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib25" title="">25</a><span class="ltx_text" id="S4.T3.12.12.16.4.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.16.4.2"><span class="ltx_text" id="S4.T3.12.12.16.4.2.1" style="font-size:90%;">24.52</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.16.4.3"><span class="ltx_text" id="S4.T3.12.12.16.4.3.1" style="font-size:90%;">1.52</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.16.4.4"><span class="ltx_text" id="S4.T3.12.12.16.4.4.1" style="font-size:90%;">82.1 / 57.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.16.4.5"><span class="ltx_text" id="S4.T3.12.12.16.4.5.1" style="font-size:90%;">92.9 / 76.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.17.5">
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.17.5.1">
<span class="ltx_text" id="S4.T3.12.12.17.5.1.1" style="font-size:90%;">UNet-3D </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.12.12.17.5.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib42" title="">42</a><span class="ltx_text" id="S4.T3.12.12.17.5.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.17.5.2"><span class="ltx_text" id="S4.T3.12.12.17.5.2.1" style="font-size:90%;">48.63</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.17.5.3"><span class="ltx_text" id="S4.T3.12.12.17.5.3.1" style="font-size:90%;">1.55</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.17.5.4"><span class="ltx_text" id="S4.T3.12.12.17.5.4.1" style="font-size:90%;">81.3 / 58.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.17.5.5"><span class="ltx_text" id="S4.T3.12.12.17.5.5.1" style="font-size:90%;">92.4 / 75.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.18.6">
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.18.6.1">
<span class="ltx_text" id="S4.T3.12.12.18.6.1.1" style="font-size:90%;">U-TAE </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.12.12.18.6.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.T3.12.12.18.6.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.18.6.2"><span class="ltx_text" id="S4.T3.12.12.18.6.2.1" style="font-size:90%;">23.06</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.18.6.3"><span class="ltx_text" id="S4.T3.12.12.18.6.3.1" style="font-size:90%;">1.09</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.18.6.4"><span class="ltx_text" id="S4.T3.12.12.18.6.4.1" style="font-size:90%;">83.2 / 63.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.18.6.5"><span class="ltx_text" id="S4.T3.12.12.18.6.5.1" style="font-size:90%;">93.1 / 77.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.19.7">
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.19.7.1">
<span class="ltx_text" id="S4.T3.12.12.19.7.1.1" style="font-size:90%;">TSViT </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T3.12.12.19.7.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a><span class="ltx_text" id="S4.T3.12.12.19.7.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.19.7.2"><span class="ltx_text" id="S4.T3.12.12.19.7.2.1" style="font-size:90%;">91.88</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.19.7.3"><span class="ltx_text" id="S4.T3.12.12.19.7.3.1" style="font-size:90%;">1.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.19.7.4"><span class="ltx_text" id="S4.T3.12.12.19.7.4.1" style="font-size:90%;">83.4 / 65.4*</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.12.12.19.7.5"><span class="ltx_text" id="S4.T3.12.12.19.7.5.1" style="font-size:90%;">95.0 / 84.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.6">
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.7.1" style="font-size:90%;">VistaFormer Neighbourhood (ours)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.6.8"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.8.1" style="font-size:90%;">9.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.6.9"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.9.1" style="font-size:90%;">1.13</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.2.2" style="font-size:90%;">83.7 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.1.m1.1d">¬±</annotation></semantics></math> 0.2 / 65.3 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.2.2.2.2.2.m2.1"><semantics id="S4.T3.2.2.2.2.2.m2.1a"><mo id="S4.T3.2.2.2.2.2.m2.1.1" xref="S4.T3.2.2.2.2.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.2.m2.1b"><csymbol cd="latexml" id="S4.T3.2.2.2.2.2.m2.1.1.cmml" xref="S4.T3.2.2.2.2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.2.2.m2.1d">¬±</annotation></semantics></math> 0.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.6.6.6.6">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.6.6.6.6.4">
<tr class="ltx_tr" id="S4.T3.4.4.4.4.2.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.4.4.4.4.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.4.2.2.2.2" style="font-size:90%;">96.1 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.3.3.3.3.1.1.1.1.m1.1"><semantics id="S4.T3.3.3.3.3.1.1.1.1.m1.1a"><mo id="S4.T3.3.3.3.3.1.1.1.1.m1.1.1" xref="S4.T3.3.3.3.3.1.1.1.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.3.3.3.3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.3.3.3.3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.3.1.1.1.1.m1.1d">¬±</annotation></semantics></math> 0.03 / 88.5 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.4.4.4.4.2.2.2.2.m2.1"><semantics id="S4.T3.4.4.4.4.2.2.2.2.m2.1a"><mo id="S4.T3.4.4.4.4.2.2.2.2.m2.1.1" xref="S4.T3.4.4.4.4.2.2.2.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.2.2.2.2.m2.1b"><csymbol cd="latexml" id="S4.T3.4.4.4.4.2.2.2.2.m2.1.1.cmml" xref="S4.T3.4.4.4.4.2.2.2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.2.2.2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.4.2.2.2.2.m2.1d">¬±</annotation></semantics></math> 0.05</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6.6.6.4.4">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.6.6.6.6.4.4.2"><span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.6.4.4.2.2" style="font-size:90%;">(90.5 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.5.5.5.5.3.3.1.1.m1.1"><semantics id="S4.T3.5.5.5.5.3.3.1.1.m1.1a"><mo id="S4.T3.5.5.5.5.3.3.1.1.m1.1.1" xref="S4.T3.5.5.5.5.3.3.1.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.5.3.3.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.5.5.5.5.3.3.1.1.m1.1.1.cmml" xref="S4.T3.5.5.5.5.3.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.5.3.3.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.5.3.3.1.1.m1.1d">¬±</annotation></semantics></math> 0.08 / 79 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.6.6.6.6.4.4.2.2.m2.1"><semantics id="S4.T3.6.6.6.6.4.4.2.2.m2.1a"><mo id="S4.T3.6.6.6.6.4.4.2.2.m2.1.1" xref="S4.T3.6.6.6.6.4.4.2.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.6.4.4.2.2.m2.1b"><csymbol cd="latexml" id="S4.T3.6.6.6.6.4.4.2.2.m2.1.1.cmml" xref="S4.T3.6.6.6.6.4.4.2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.6.4.4.2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.6.4.4.2.2.m2.1d">¬±</annotation></semantics></math> 0.16)</span></td>
</tr>
</table>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.12">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.12.12.12.7"><span class="ltx_text ltx_font_bold" id="S4.T3.12.12.12.7.1" style="font-size:90%;">VistaFormer (ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.12.12.12.8"><span class="ltx_text ltx_font_bold" id="S4.T3.12.12.12.8.1" style="font-size:90%;">7.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.12.12.12.9"><span class="ltx_text ltx_font_bold" id="S4.T3.12.12.12.9.1" style="font-size:90%;">1.25</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.8.8.8.2"><span class="ltx_text ltx_font_bold" id="S4.T3.8.8.8.2.2" style="font-size:90%;">84.0 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.7.7.7.1.1.m1.1"><semantics id="S4.T3.7.7.7.1.1.m1.1a"><mo id="S4.T3.7.7.7.1.1.m1.1.1" xref="S4.T3.7.7.7.1.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.7.7.7.1.1.m1.1.1.cmml" xref="S4.T3.7.7.7.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.7.1.1.m1.1d">¬±</annotation></semantics></math> 0.1 / 65.5 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.8.8.8.2.2.m2.1"><semantics id="S4.T3.8.8.8.2.2.m2.1a"><mo id="S4.T3.8.8.8.2.2.m2.1.1" xref="S4.T3.8.8.8.2.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.2.2.m2.1b"><csymbol cd="latexml" id="S4.T3.8.8.8.2.2.m2.1.1.cmml" xref="S4.T3.8.8.8.2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.8.8.2.2.m2.1d">¬±</annotation></semantics></math> 0.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.12.12.12.6">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.12.12.12.6.4">
<tr class="ltx_tr" id="S4.T3.10.10.10.4.2.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.10.10.10.4.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.10.10.10.4.2.2.2.2" style="font-size:90%;">95.9 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.9.9.9.3.1.1.1.1.m1.1"><semantics id="S4.T3.9.9.9.3.1.1.1.1.m1.1a"><mo id="S4.T3.9.9.9.3.1.1.1.1.m1.1.1" xref="S4.T3.9.9.9.3.1.1.1.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.9.9.9.3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.9.9.9.3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.3.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.9.9.9.3.1.1.1.1.m1.1d">¬±</annotation></semantics></math> 0.14 / 87.8 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.10.10.10.4.2.2.2.2.m2.1"><semantics id="S4.T3.10.10.10.4.2.2.2.2.m2.1a"><mo id="S4.T3.10.10.10.4.2.2.2.2.m2.1.1" xref="S4.T3.10.10.10.4.2.2.2.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.10.4.2.2.2.2.m2.1b"><csymbol cd="latexml" id="S4.T3.10.10.10.4.2.2.2.2.m2.1.1.cmml" xref="S4.T3.10.10.10.4.2.2.2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.10.4.2.2.2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.10.10.10.4.2.2.2.2.m2.1d">¬±</annotation></semantics></math> 0.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.12.12.12.6.4.4">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.12.12.12.6.4.4.2"><span class="ltx_text ltx_font_bold" id="S4.T3.12.12.12.6.4.4.2.2" style="font-size:90%;">(90.4 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.11.11.11.5.3.3.1.1.m1.1"><semantics id="S4.T3.11.11.11.5.3.3.1.1.m1.1a"><mo id="S4.T3.11.11.11.5.3.3.1.1.m1.1.1" xref="S4.T3.11.11.11.5.3.3.1.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.11.5.3.3.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.11.11.11.5.3.3.1.1.m1.1.1.cmml" xref="S4.T3.11.11.11.5.3.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.11.5.3.3.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.11.11.11.5.3.3.1.1.m1.1d">¬±</annotation></semantics></math> 0.1 / 78.7 <math alttext="\pm" class="ltx_Math" display="inline" id="S4.T3.12.12.12.6.4.4.2.2.m2.1"><semantics id="S4.T3.12.12.12.6.4.4.2.2.m2.1a"><mo id="S4.T3.12.12.12.6.4.4.2.2.m2.1.1" xref="S4.T3.12.12.12.6.4.4.2.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.12.6.4.4.2.2.m2.1b"><csymbol cd="latexml" id="S4.T3.12.12.12.6.4.4.2.2.m2.1.1.cmml" xref="S4.T3.12.12.12.6.4.4.2.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.12.6.4.4.2.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T3.12.12.12.6.4.4.2.2.m2.1d">¬±</annotation></semantics></math> 0.3)</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison with comparable models on semantic segmentation. Results for PASTIS are reported by computing the average performance across all five folds of the dataset provided in all five folds for comparison with <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>]</cite>. For MTLCC, we report results that exclude the unknown class in training and testing in keeping with <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib30" title="">30</a>]</cite> and results including the background/unknown class in parenthesis. Note that results marked with an asterisk for PASTIS were trained using the PASTIS dataset with a height and width of 24.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="269" id="S4.F3.g1" src="x5.png" width="481"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>VistaFormer sample semantic segmentation predictions on the PASTIS benchmark. Under titles <math alttext="T=0,...,3" class="ltx_Math" display="inline" id="S4.F3.1.m1.3"><semantics id="S4.F3.1.m1.3b"><mrow id="S4.F3.1.m1.3.4" xref="S4.F3.1.m1.3.4.cmml"><mi id="S4.F3.1.m1.3.4.2" xref="S4.F3.1.m1.3.4.2.cmml">T</mi><mo id="S4.F3.1.m1.3.4.1" xref="S4.F3.1.m1.3.4.1.cmml">=</mo><mrow id="S4.F3.1.m1.3.4.3.2" xref="S4.F3.1.m1.3.4.3.1.cmml"><mn id="S4.F3.1.m1.1.1" xref="S4.F3.1.m1.1.1.cmml">0</mn><mo id="S4.F3.1.m1.3.4.3.2.1" xref="S4.F3.1.m1.3.4.3.1.cmml">,</mo><mi id="S4.F3.1.m1.2.2" mathvariant="normal" xref="S4.F3.1.m1.2.2.cmml">‚Ä¶</mi><mo id="S4.F3.1.m1.3.4.3.2.2" xref="S4.F3.1.m1.3.4.3.1.cmml">,</mo><mn id="S4.F3.1.m1.3.3" xref="S4.F3.1.m1.3.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.1.m1.3c"><apply id="S4.F3.1.m1.3.4.cmml" xref="S4.F3.1.m1.3.4"><eq id="S4.F3.1.m1.3.4.1.cmml" xref="S4.F3.1.m1.3.4.1"></eq><ci id="S4.F3.1.m1.3.4.2.cmml" xref="S4.F3.1.m1.3.4.2">ùëá</ci><list id="S4.F3.1.m1.3.4.3.1.cmml" xref="S4.F3.1.m1.3.4.3.2"><cn id="S4.F3.1.m1.1.1.cmml" type="integer" xref="S4.F3.1.m1.1.1">0</cn><ci id="S4.F3.1.m1.2.2.cmml" xref="S4.F3.1.m1.2.2">‚Ä¶</ci><cn id="S4.F3.1.m1.3.3.cmml" type="integer" xref="S4.F3.1.m1.3.3">3</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.1.m1.3d">T=0,...,3</annotation><annotation encoding="application/x-llamapun" id="S4.F3.1.m1.3e">italic_T = 0 , ‚Ä¶ , 3</annotation></semantics></math>, we show samples of input RGB channels and include these alongside ground truth annotations, model predictions, attention maps, and Monte Carlo dropout <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib10" title="">10</a>]</cite> predictions to measure the uncertainty of model predictions. We use the dropout settings used during training for Monte Carlo Dropout and the outputs reflect the model certainty measure over 10 iterations.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results </h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text" id="S4.SS3.p1.1.1" style="font-size:90%;">Performance of the model is measured using the mean Intersection over Union (mIoU) score, which computes the averages of the IoU score for each class and the overall Accuracy (oA), which calculates the accuracy summed over all predicted pixels. We find that both VistaFormer models outperform TSViT, the current state-of-the-art model, while using roughly 8% of the floating point operations for VistaFormer with MHSA and 11% for VistaFormer using NA. On average, VistaFormer with NA was outperformed by TSViT in the PASTIS benchmark by 0.1%, though our model improved on the oA score by 0.3% and improved on the MTLCC score of TSViT by 1.1% in terms of oA and 3.7% for mIoU. These metrics were chosen per the metrics used in TSViT </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS3.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a><span class="ltx_text" id="S4.SS3.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS3.p1.1.4" style="font-size:90%;"> and U-TAE </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS3.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS3.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS3.p1.1.7" style="font-size:90%;">. Including oA as well as mIoU in a semantic segmentation task with few classes and many pixels labelled as background or unknown provides a straightforward measure of the model‚Äôs performance across all pixels, ensuring the model effectively distinguishes between relevant and irrelevant regions and maintains performance across all predicted classes. For our model, we report the mean and standard deviation performance over three trials for both benchmarks. GFLOPs are estimated using the FVCore library using an input shape with B=4, T=60, C=10, H=32, and W=32.</span></p>
</div>
<figure class="ltx_table" id="S4.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.30" style="width:496.9pt;height:119.8pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-89.6pt,21.5pt) scale(0.734911721026341,0.734911721026341) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.30.30">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.30.30.31.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T4.30.30.31.1.1"></th>
<td class="ltx_td ltx_border_tt" colspan="2" id="S4.T4.30.30.31.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.30.30.31.1.3"><span class="ltx_text" id="S4.T4.30.30.31.1.3.1" style="font-size:90%;">PASTIS</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.30.30.31.1.4"><span class="ltx_text" id="S4.T4.30.30.31.1.4.1" style="font-size:90%;">MTLCC (2016)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.30.30.32.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.30.30.32.2.1"><span class="ltx_text" id="S4.T4.30.30.32.2.1.1" style="font-size:90%;">Ablation</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.30.30.32.2.2"><span class="ltx_text" id="S4.T4.30.30.32.2.2.1" style="font-size:90%;">Description</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.30.30.32.2.3"><span class="ltx_text" id="S4.T4.30.30.32.2.3.1" style="font-size:90%;">Params (millions)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.30.30.32.2.4"><span class="ltx_text" id="S4.T4.30.30.32.2.4.1" style="font-size:90%;">oA / mIoU</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.30.30.32.2.5"><span class="ltx_text" id="S4.T4.30.30.32.2.5.1" style="font-size:90%;">oA / mIoU</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.5.5.5.6" rowspan="2"><span class="ltx_text" id="S4.T4.5.5.5.6.1" style="font-size:90%;">Encoder Downsampling</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.1.1"><math alttext="T_{1}=\frac{T}{2}" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.m1.1a"><mrow id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml"><msub id="S4.T4.1.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.1.m1.1.1.2.cmml"><mi id="S4.T4.1.1.1.1.m1.1.1.2.2" mathsize="90%" xref="S4.T4.1.1.1.1.m1.1.1.2.2.cmml">T</mi><mn id="S4.T4.1.1.1.1.m1.1.1.2.3" mathsize="90%" xref="S4.T4.1.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.T4.1.1.1.1.m1.1.1.1" mathsize="90%" xref="S4.T4.1.1.1.1.m1.1.1.1.cmml">=</mo><mfrac id="S4.T4.1.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.T4.1.1.1.1.m1.1.1.3.2" mathsize="90%" xref="S4.T4.1.1.1.1.m1.1.1.3.2.cmml">T</mi><mn id="S4.T4.1.1.1.1.m1.1.1.3.3" mathsize="90%" xref="S4.T4.1.1.1.1.m1.1.1.3.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1"><eq id="S4.T4.1.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1.1"></eq><apply id="S4.T4.1.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T4.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="S4.T4.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T4.1.1.1.1.m1.1.1.2.2">ùëá</ci><cn id="S4.T4.1.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.T4.1.1.1.1.m1.1.1.2.3">1</cn></apply><apply id="S4.T4.1.1.1.1.m1.1.1.3.cmml" xref="S4.T4.1.1.1.1.m1.1.1.3"><divide id="S4.T4.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1.3"></divide><ci id="S4.T4.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.T4.1.1.1.1.m1.1.1.3.2">ùëá</ci><cn id="S4.T4.1.1.1.1.m1.1.1.3.3.cmml" type="integer" xref="S4.T4.1.1.1.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">T_{1}=\frac{T}{2}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.m1.1d">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = divide start_ARG italic_T end_ARG start_ARG 2 end_ARG</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.5.7"><span class="ltx_text" id="S4.T4.5.5.5.7.1" style="font-size:90%;">1.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.3.3.3">
<span class="ltx_text" id="S4.T4.3.3.3.3.1" style="font-size:90%;">83.2 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.2.2.2.2.m1.1"><semantics id="S4.T4.2.2.2.2.m1.1a"><mo id="S4.T4.2.2.2.2.m1.1.1" mathsize="90%" xref="S4.T4.2.2.2.2.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T4.2.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.2.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.3.3.3.3.2" style="font-size:90%;"> 0.01 / 63.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.3.3.3.3.m2.1"><semantics id="S4.T4.3.3.3.3.m2.1a"><mo id="S4.T4.3.3.3.3.m2.1.1" mathsize="90%" xref="S4.T4.3.3.3.3.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.m2.1b"><csymbol cd="latexml" id="S4.T4.3.3.3.3.m2.1.1.cmml" xref="S4.T4.3.3.3.3.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.3.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.3.3.3.3.3" style="font-size:90%;"> 0.1</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.5.5">
<span class="ltx_text" id="S4.T4.5.5.5.5.1" style="font-size:90%;">90.15 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.4.4.4.4.m1.1"><semantics id="S4.T4.4.4.4.4.m1.1a"><mo id="S4.T4.4.4.4.4.m1.1.1" mathsize="90%" xref="S4.T4.4.4.4.4.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.4.m1.1b"><csymbol cd="latexml" id="S4.T4.4.4.4.4.m1.1.1.cmml" xref="S4.T4.4.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.4.4.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.5.5.5.5.2" style="font-size:90%;"> 0.01 / 77.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.5.5.5.5.m2.1"><semantics id="S4.T4.5.5.5.5.m2.1a"><mo id="S4.T4.5.5.5.5.m2.1.1" mathsize="90%" xref="S4.T4.5.5.5.5.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.5.m2.1b"><csymbol cd="latexml" id="S4.T4.5.5.5.5.m2.1.1.cmml" xref="S4.T4.5.5.5.5.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.5.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.5.5.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.5.5.5.5.3" style="font-size:90%;"> 0.2</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.10.10">
<td class="ltx_td ltx_align_center" id="S4.T4.6.6.6.1"><math alttext="T_{1},T_{2},T_{3}=T" class="ltx_Math" display="inline" id="S4.T4.6.6.6.1.m1.3"><semantics id="S4.T4.6.6.6.1.m1.3a"><mrow id="S4.T4.6.6.6.1.m1.3.3" xref="S4.T4.6.6.6.1.m1.3.3.cmml"><mrow id="S4.T4.6.6.6.1.m1.3.3.3.3" xref="S4.T4.6.6.6.1.m1.3.3.3.4.cmml"><msub id="S4.T4.6.6.6.1.m1.1.1.1.1.1" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1.cmml"><mi id="S4.T4.6.6.6.1.m1.1.1.1.1.1.2" mathsize="90%" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1.2.cmml">T</mi><mn id="S4.T4.6.6.6.1.m1.1.1.1.1.1.3" mathsize="90%" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.T4.6.6.6.1.m1.3.3.3.3.4" mathsize="90%" xref="S4.T4.6.6.6.1.m1.3.3.3.4.cmml">,</mo><msub id="S4.T4.6.6.6.1.m1.2.2.2.2.2" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2.cmml"><mi id="S4.T4.6.6.6.1.m1.2.2.2.2.2.2" mathsize="90%" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2.2.cmml">T</mi><mn id="S4.T4.6.6.6.1.m1.2.2.2.2.2.3" mathsize="90%" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.T4.6.6.6.1.m1.3.3.3.3.5" mathsize="90%" xref="S4.T4.6.6.6.1.m1.3.3.3.4.cmml">,</mo><msub id="S4.T4.6.6.6.1.m1.3.3.3.3.3" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3.cmml"><mi id="S4.T4.6.6.6.1.m1.3.3.3.3.3.2" mathsize="90%" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3.2.cmml">T</mi><mn id="S4.T4.6.6.6.1.m1.3.3.3.3.3.3" mathsize="90%" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3.3.cmml">3</mn></msub></mrow><mo id="S4.T4.6.6.6.1.m1.3.3.4" mathsize="90%" xref="S4.T4.6.6.6.1.m1.3.3.4.cmml">=</mo><mi id="S4.T4.6.6.6.1.m1.3.3.5" mathsize="90%" xref="S4.T4.6.6.6.1.m1.3.3.5.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.1.m1.3b"><apply id="S4.T4.6.6.6.1.m1.3.3.cmml" xref="S4.T4.6.6.6.1.m1.3.3"><eq id="S4.T4.6.6.6.1.m1.3.3.4.cmml" xref="S4.T4.6.6.6.1.m1.3.3.4"></eq><list id="S4.T4.6.6.6.1.m1.3.3.3.4.cmml" xref="S4.T4.6.6.6.1.m1.3.3.3.3"><apply id="S4.T4.6.6.6.1.m1.1.1.1.1.1.cmml" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.T4.6.6.6.1.m1.1.1.1.1.1.1.cmml" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S4.T4.6.6.6.1.m1.1.1.1.1.1.2.cmml" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1.2">ùëá</ci><cn id="S4.T4.6.6.6.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S4.T4.6.6.6.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S4.T4.6.6.6.1.m1.2.2.2.2.2.cmml" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T4.6.6.6.1.m1.2.2.2.2.2.1.cmml" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T4.6.6.6.1.m1.2.2.2.2.2.2.cmml" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2.2">ùëá</ci><cn id="S4.T4.6.6.6.1.m1.2.2.2.2.2.3.cmml" type="integer" xref="S4.T4.6.6.6.1.m1.2.2.2.2.2.3">2</cn></apply><apply id="S4.T4.6.6.6.1.m1.3.3.3.3.3.cmml" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.T4.6.6.6.1.m1.3.3.3.3.3.1.cmml" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3">subscript</csymbol><ci id="S4.T4.6.6.6.1.m1.3.3.3.3.3.2.cmml" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3.2">ùëá</ci><cn id="S4.T4.6.6.6.1.m1.3.3.3.3.3.3.cmml" type="integer" xref="S4.T4.6.6.6.1.m1.3.3.3.3.3.3">3</cn></apply></list><ci id="S4.T4.6.6.6.1.m1.3.3.5.cmml" xref="S4.T4.6.6.6.1.m1.3.3.5">ùëá</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.1.m1.3c">T_{1},T_{2},T_{3}=T</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.6.1.m1.3d">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = italic_T</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S4.T4.10.10.10.6"><span class="ltx_text" id="S4.T4.10.10.10.6.1" style="font-size:90%;">1.67</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.8.8.8.3">
<span class="ltx_text" id="S4.T4.8.8.8.3.1" style="font-size:90%;">83.5 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.7.7.7.2.m1.1"><semantics id="S4.T4.7.7.7.2.m1.1a"><mo id="S4.T4.7.7.7.2.m1.1.1" mathsize="90%" xref="S4.T4.7.7.7.2.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.2.m1.1b"><csymbol cd="latexml" id="S4.T4.7.7.7.2.m1.1.1.cmml" xref="S4.T4.7.7.7.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.7.7.2.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.8.8.8.3.2" style="font-size:90%;"> 0.1 / 64.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.8.8.8.3.m2.1"><semantics id="S4.T4.8.8.8.3.m2.1a"><mo id="S4.T4.8.8.8.3.m2.1.1" mathsize="90%" xref="S4.T4.8.8.8.3.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.8.3.m2.1b"><csymbol cd="latexml" id="S4.T4.8.8.8.3.m2.1.1.cmml" xref="S4.T4.8.8.8.3.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.8.3.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.8.8.3.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.8.8.8.3.3" style="font-size:90%;"> 0.1</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.10.10.10.5">
<span class="ltx_text" id="S4.T4.10.10.10.5.1" style="font-size:90%;">90.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.9.9.9.4.m1.1"><semantics id="S4.T4.9.9.9.4.m1.1a"><mo id="S4.T4.9.9.9.4.m1.1.1" mathsize="90%" xref="S4.T4.9.9.9.4.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.9.4.m1.1b"><csymbol cd="latexml" id="S4.T4.9.9.9.4.m1.1.1.cmml" xref="S4.T4.9.9.9.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.9.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.9.9.9.4.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.10.10.10.5.2" style="font-size:90%;"> 0.1 / 78.6 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.10.10.10.5.m2.1"><semantics id="S4.T4.10.10.10.5.m2.1a"><mo id="S4.T4.10.10.10.5.m2.1.1" mathsize="90%" xref="S4.T4.10.10.10.5.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.10.5.m2.1b"><csymbol cd="latexml" id="S4.T4.10.10.10.5.m2.1.1.cmml" xref="S4.T4.10.10.10.5.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.10.5.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.10.10.10.5.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.10.10.10.5.3" style="font-size:90%;"> 0.2</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.14.14.14.5" rowspan="2"><span class="ltx_text" id="S4.T4.14.14.14.5.1" style="font-size:90%;">Encoder Layers</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.14.14.14.6"><span class="ltx_text" id="S4.T4.14.14.14.6.1" style="font-size:90%;">w/out Gated Conv</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.14.14.7"><span class="ltx_text" id="S4.T4.14.14.14.7.1" style="font-size:90%;">1.16</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.12.12.12.2">
<span class="ltx_text" id="S4.T4.12.12.12.2.1" style="font-size:90%;">83.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.11.11.11.1.m1.1"><semantics id="S4.T4.11.11.11.1.m1.1a"><mo id="S4.T4.11.11.11.1.m1.1.1" mathsize="90%" xref="S4.T4.11.11.11.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.11.1.m1.1b"><csymbol cd="latexml" id="S4.T4.11.11.11.1.m1.1.1.cmml" xref="S4.T4.11.11.11.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.11.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.11.11.11.1.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.12.12.12.2.2" style="font-size:90%;"> 0.1 / 64.1 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.12.12.12.2.m2.1"><semantics id="S4.T4.12.12.12.2.m2.1a"><mo id="S4.T4.12.12.12.2.m2.1.1" mathsize="90%" xref="S4.T4.12.12.12.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.12.2.m2.1b"><csymbol cd="latexml" id="S4.T4.12.12.12.2.m2.1.1.cmml" xref="S4.T4.12.12.12.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.12.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.12.12.12.2.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.12.12.12.2.3" style="font-size:90%;"> 0.2</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.14.14.4">
<span class="ltx_text" id="S4.T4.14.14.14.4.1" style="font-size:90%;">90.2 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.13.13.13.3.m1.1"><semantics id="S4.T4.13.13.13.3.m1.1a"><mo id="S4.T4.13.13.13.3.m1.1.1" mathsize="90%" xref="S4.T4.13.13.13.3.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.13.13.13.3.m1.1b"><csymbol cd="latexml" id="S4.T4.13.13.13.3.m1.1.1.cmml" xref="S4.T4.13.13.13.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.13.13.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.13.13.13.3.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.14.14.14.4.2" style="font-size:90%;"> 0.1 / 78 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.14.14.14.4.m2.1"><semantics id="S4.T4.14.14.14.4.m2.1a"><mo id="S4.T4.14.14.14.4.m2.1.1" mathsize="90%" xref="S4.T4.14.14.14.4.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.14.14.14.4.m2.1b"><csymbol cd="latexml" id="S4.T4.14.14.14.4.m2.1.1.cmml" xref="S4.T4.14.14.14.4.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.14.14.4.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.14.14.14.4.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.14.14.14.4.3" style="font-size:90%;"> 0.1</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.18.18.18">
<td class="ltx_td ltx_align_center" id="S4.T4.18.18.18.5">
<span class="ltx_text" id="S4.T4.18.18.18.5.1" style="font-size:90%;">Squeeze &amp; Excitation </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.18.18.18.5.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib16" title="">16</a><span class="ltx_text" id="S4.T4.18.18.18.5.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.18.18.18.6"><span class="ltx_text" id="S4.T4.18.18.18.6.1" style="font-size:90%;">1.26</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.16.16.16.2">
<span class="ltx_text" id="S4.T4.16.16.16.2.1" style="font-size:90%;">83.5 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.15.15.15.1.m1.1"><semantics id="S4.T4.15.15.15.1.m1.1a"><mo id="S4.T4.15.15.15.1.m1.1.1" mathsize="90%" xref="S4.T4.15.15.15.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.15.15.15.1.m1.1b"><csymbol cd="latexml" id="S4.T4.15.15.15.1.m1.1.1.cmml" xref="S4.T4.15.15.15.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.15.15.15.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.15.15.15.1.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.16.16.16.2.2" style="font-size:90%;"> 0.1 / 64.7 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.16.16.16.2.m2.1"><semantics id="S4.T4.16.16.16.2.m2.1a"><mo id="S4.T4.16.16.16.2.m2.1.1" mathsize="90%" xref="S4.T4.16.16.16.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.16.16.16.2.m2.1b"><csymbol cd="latexml" id="S4.T4.16.16.16.2.m2.1.1.cmml" xref="S4.T4.16.16.16.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.16.16.16.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.16.16.16.2.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.16.16.16.2.3" style="font-size:90%;"> 0.2</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.18.18.18.4">
<span class="ltx_text" id="S4.T4.18.18.18.4.1" style="font-size:90%;">90.3 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.17.17.17.3.m1.1"><semantics id="S4.T4.17.17.17.3.m1.1a"><mo id="S4.T4.17.17.17.3.m1.1.1" mathsize="90%" xref="S4.T4.17.17.17.3.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.17.17.17.3.m1.1b"><csymbol cd="latexml" id="S4.T4.17.17.17.3.m1.1.1.cmml" xref="S4.T4.17.17.17.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.17.17.17.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.17.17.17.3.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.18.18.18.4.2" style="font-size:90%;"> 0.1 / 78.6 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.18.18.18.4.m2.1"><semantics id="S4.T4.18.18.18.4.m2.1a"><mo id="S4.T4.18.18.18.4.m2.1.1" mathsize="90%" xref="S4.T4.18.18.18.4.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.18.18.18.4.m2.1b"><csymbol cd="latexml" id="S4.T4.18.18.18.4.m2.1.1.cmml" xref="S4.T4.18.18.18.4.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.18.18.18.4.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.18.18.18.4.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.18.18.18.4.3" style="font-size:90%;"> 0.1</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.22.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.22.22.22.5" rowspan="2"><span class="ltx_text" id="S4.T4.22.22.22.5.1" style="font-size:90%;">Decoder Layers</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.22.22.22.6"><span class="ltx_text" id="S4.T4.22.22.22.6.1" style="font-size:90%;">Max Pool</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.22.22.22.7"><span class="ltx_text" id="S4.T4.22.22.22.7.1" style="font-size:90%;">0.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.20.20.20.2">
<span class="ltx_text" id="S4.T4.20.20.20.2.1" style="font-size:90%;">83.3 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.19.19.19.1.m1.1"><semantics id="S4.T4.19.19.19.1.m1.1a"><mo id="S4.T4.19.19.19.1.m1.1.1" mathsize="90%" xref="S4.T4.19.19.19.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.19.19.19.1.m1.1b"><csymbol cd="latexml" id="S4.T4.19.19.19.1.m1.1.1.cmml" xref="S4.T4.19.19.19.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.19.19.19.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.19.19.19.1.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.20.20.20.2.2" style="font-size:90%;"> 0.04 / 64.2 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.20.20.20.2.m2.1"><semantics id="S4.T4.20.20.20.2.m2.1a"><mo id="S4.T4.20.20.20.2.m2.1.1" mathsize="90%" xref="S4.T4.20.20.20.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.20.20.20.2.m2.1b"><csymbol cd="latexml" id="S4.T4.20.20.20.2.m2.1.1.cmml" xref="S4.T4.20.20.20.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.20.20.20.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.20.20.20.2.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.20.20.20.2.3" style="font-size:90%;"> 0.2</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.22.22.22.4">
<span class="ltx_text" id="S4.T4.22.22.22.4.1" style="font-size:90%;">90.3 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.21.21.21.3.m1.1"><semantics id="S4.T4.21.21.21.3.m1.1a"><mo id="S4.T4.21.21.21.3.m1.1.1" mathsize="90%" xref="S4.T4.21.21.21.3.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.21.21.21.3.m1.1b"><csymbol cd="latexml" id="S4.T4.21.21.21.3.m1.1.1.cmml" xref="S4.T4.21.21.21.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.21.21.21.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.21.21.21.3.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.22.22.22.4.2" style="font-size:90%;"> 0.1 / 78.2 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.22.22.22.4.m2.1"><semantics id="S4.T4.22.22.22.4.m2.1a"><mo id="S4.T4.22.22.22.4.m2.1.1" mathsize="90%" xref="S4.T4.22.22.22.4.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.22.22.22.4.m2.1b"><csymbol cd="latexml" id="S4.T4.22.22.22.4.m2.1.1.cmml" xref="S4.T4.22.22.22.4.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.22.22.22.4.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.22.22.22.4.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.22.22.22.4.3" style="font-size:90%;"> 0.1</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.26.26.26">
<td class="ltx_td ltx_align_center" id="S4.T4.26.26.26.5"><span class="ltx_text" id="S4.T4.26.26.26.5.1" style="font-size:90%;">Conv Transpose</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.26.26.26.6"><span class="ltx_text" id="S4.T4.26.26.26.6.1" style="font-size:90%;">2.37</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.24.24.24.2">
<span class="ltx_text" id="S4.T4.24.24.24.2.1" style="font-size:90%;">83.7 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.23.23.23.1.m1.1"><semantics id="S4.T4.23.23.23.1.m1.1a"><mo id="S4.T4.23.23.23.1.m1.1.1" mathsize="90%" xref="S4.T4.23.23.23.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.23.23.23.1.m1.1b"><csymbol cd="latexml" id="S4.T4.23.23.23.1.m1.1.1.cmml" xref="S4.T4.23.23.23.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.23.23.23.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.23.23.23.1.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.24.24.24.2.2" style="font-size:90%;"> 0.1 / 64.7 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.24.24.24.2.m2.1"><semantics id="S4.T4.24.24.24.2.m2.1a"><mo id="S4.T4.24.24.24.2.m2.1.1" mathsize="90%" xref="S4.T4.24.24.24.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.24.24.24.2.m2.1b"><csymbol cd="latexml" id="S4.T4.24.24.24.2.m2.1.1.cmml" xref="S4.T4.24.24.24.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.24.24.24.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.24.24.24.2.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.24.24.24.2.3" style="font-size:90%;"> 0.1</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.26.26.26.4">
<span class="ltx_text" id="S4.T4.26.26.26.4.1" style="font-size:90%;">90.5 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.25.25.25.3.m1.1"><semantics id="S4.T4.25.25.25.3.m1.1a"><mo id="S4.T4.25.25.25.3.m1.1.1" mathsize="90%" xref="S4.T4.25.25.25.3.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.25.25.25.3.m1.1b"><csymbol cd="latexml" id="S4.T4.25.25.25.3.m1.1.1.cmml" xref="S4.T4.25.25.25.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.25.25.25.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.25.25.25.3.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.26.26.26.4.2" style="font-size:90%;"> 0.1 / 78.7 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.26.26.26.4.m2.1"><semantics id="S4.T4.26.26.26.4.m2.1a"><mo id="S4.T4.26.26.26.4.m2.1.1" mathsize="90%" xref="S4.T4.26.26.26.4.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.26.26.26.4.m2.1b"><csymbol cd="latexml" id="S4.T4.26.26.26.4.m2.1.1.cmml" xref="S4.T4.26.26.26.4.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.26.26.26.4.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.26.26.26.4.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.26.26.26.4.3" style="font-size:90%;"> 0.2</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.30.30.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_tt" id="S4.T4.30.30.30.5"><span class="ltx_text" id="S4.T4.30.30.30.5.1" style="font-size:90%;">VistaFormer Performance</span></th>
<td class="ltx_td ltx_border_bb ltx_border_tt" id="S4.T4.30.30.30.6"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="S4.T4.30.30.30.7"><span class="ltx_text" id="S4.T4.30.30.30.7.1" style="font-size:90%;">1.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="S4.T4.28.28.28.2">
<span class="ltx_text" id="S4.T4.28.28.28.2.1" style="font-size:90%;">83.6 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.27.27.27.1.m1.1"><semantics id="S4.T4.27.27.27.1.m1.1a"><mo id="S4.T4.27.27.27.1.m1.1.1" mathsize="90%" xref="S4.T4.27.27.27.1.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.27.27.27.1.m1.1b"><csymbol cd="latexml" id="S4.T4.27.27.27.1.m1.1.1.cmml" xref="S4.T4.27.27.27.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.27.27.27.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.27.27.27.1.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.28.28.28.2.2" style="font-size:90%;"> 0.1 / 64.8 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.28.28.28.2.m2.1"><semantics id="S4.T4.28.28.28.2.m2.1a"><mo id="S4.T4.28.28.28.2.m2.1.1" mathsize="90%" xref="S4.T4.28.28.28.2.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.28.28.28.2.m2.1b"><csymbol cd="latexml" id="S4.T4.28.28.28.2.m2.1.1.cmml" xref="S4.T4.28.28.28.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.28.28.28.2.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.28.28.28.2.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.28.28.28.2.3" style="font-size:90%;"> 0.2</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" id="S4.T4.30.30.30.4">
<span class="ltx_text" id="S4.T4.30.30.30.4.1" style="font-size:90%;">90.4 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.29.29.29.3.m1.1"><semantics id="S4.T4.29.29.29.3.m1.1a"><mo id="S4.T4.29.29.29.3.m1.1.1" mathsize="90%" xref="S4.T4.29.29.29.3.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.29.29.29.3.m1.1b"><csymbol cd="latexml" id="S4.T4.29.29.29.3.m1.1.1.cmml" xref="S4.T4.29.29.29.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.29.29.29.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.29.29.29.3.m1.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.30.30.30.4.2" style="font-size:90%;"> 0.1 / 78.7 </span><math alttext="\pm" class="ltx_Math" display="inline" id="S4.T4.30.30.30.4.m2.1"><semantics id="S4.T4.30.30.30.4.m2.1a"><mo id="S4.T4.30.30.30.4.m2.1.1" mathsize="90%" xref="S4.T4.30.30.30.4.m2.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S4.T4.30.30.30.4.m2.1b"><csymbol cd="latexml" id="S4.T4.30.30.30.4.m2.1.1.cmml" xref="S4.T4.30.30.30.4.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.30.30.30.4.m2.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S4.T4.30.30.30.4.m2.1d">¬±</annotation></semantics></math><span class="ltx_text" id="S4.T4.30.30.30.4.3" style="font-size:90%;"> 0.3</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>We present the ablation analysis results for both the PASTIS and MTLCC benchmarks for semantic segmentation. For the MTLCC benchmark, we include the unknown class and for PASTIS we use fold-1 from the PASTIS benchmark which uses folds 1, 2, and 3 for training, fold 4 for validation; and fold 5 for testing. In keeping with Results in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.SS3" title="4.3 Results ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we report the mean and standard deviation for the mIoU and oA scores over three trials for the chosen PASTIS split and the MTLCC dataset.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="515" id="S4.F4.sf1.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="515" id="S4.F4.sf2.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S4.F4.8.1">(a)</span> Shows the scaling of floating point operations in GFLOPs of VistaFormer with MHSA and NA respectively compared with TSViT and U-TAE models using an input dimension of <math alttext="(B,C,T,H,W)=(4,10,30,x_{i},x_{i})" class="ltx_Math" display="inline" id="S4.F4.1.m1.10"><semantics id="S4.F4.1.m1.10b"><mrow id="S4.F4.1.m1.10.10" xref="S4.F4.1.m1.10.10.cmml"><mrow id="S4.F4.1.m1.10.10.4.2" xref="S4.F4.1.m1.10.10.4.1.cmml"><mo id="S4.F4.1.m1.10.10.4.2.1" stretchy="false" xref="S4.F4.1.m1.10.10.4.1.cmml">(</mo><mi id="S4.F4.1.m1.1.1" xref="S4.F4.1.m1.1.1.cmml">B</mi><mo id="S4.F4.1.m1.10.10.4.2.2" xref="S4.F4.1.m1.10.10.4.1.cmml">,</mo><mi id="S4.F4.1.m1.2.2" xref="S4.F4.1.m1.2.2.cmml">C</mi><mo id="S4.F4.1.m1.10.10.4.2.3" xref="S4.F4.1.m1.10.10.4.1.cmml">,</mo><mi id="S4.F4.1.m1.3.3" xref="S4.F4.1.m1.3.3.cmml">T</mi><mo id="S4.F4.1.m1.10.10.4.2.4" xref="S4.F4.1.m1.10.10.4.1.cmml">,</mo><mi id="S4.F4.1.m1.4.4" xref="S4.F4.1.m1.4.4.cmml">H</mi><mo id="S4.F4.1.m1.10.10.4.2.5" xref="S4.F4.1.m1.10.10.4.1.cmml">,</mo><mi id="S4.F4.1.m1.5.5" xref="S4.F4.1.m1.5.5.cmml">W</mi><mo id="S4.F4.1.m1.10.10.4.2.6" stretchy="false" xref="S4.F4.1.m1.10.10.4.1.cmml">)</mo></mrow><mo id="S4.F4.1.m1.10.10.3" xref="S4.F4.1.m1.10.10.3.cmml">=</mo><mrow id="S4.F4.1.m1.10.10.2.2" xref="S4.F4.1.m1.10.10.2.3.cmml"><mo id="S4.F4.1.m1.10.10.2.2.3" stretchy="false" xref="S4.F4.1.m1.10.10.2.3.cmml">(</mo><mn id="S4.F4.1.m1.6.6" xref="S4.F4.1.m1.6.6.cmml">4</mn><mo id="S4.F4.1.m1.10.10.2.2.4" xref="S4.F4.1.m1.10.10.2.3.cmml">,</mo><mn id="S4.F4.1.m1.7.7" xref="S4.F4.1.m1.7.7.cmml">10</mn><mo id="S4.F4.1.m1.10.10.2.2.5" xref="S4.F4.1.m1.10.10.2.3.cmml">,</mo><mn id="S4.F4.1.m1.8.8" xref="S4.F4.1.m1.8.8.cmml">30</mn><mo id="S4.F4.1.m1.10.10.2.2.6" xref="S4.F4.1.m1.10.10.2.3.cmml">,</mo><msub id="S4.F4.1.m1.9.9.1.1.1" xref="S4.F4.1.m1.9.9.1.1.1.cmml"><mi id="S4.F4.1.m1.9.9.1.1.1.2" xref="S4.F4.1.m1.9.9.1.1.1.2.cmml">x</mi><mi id="S4.F4.1.m1.9.9.1.1.1.3" xref="S4.F4.1.m1.9.9.1.1.1.3.cmml">i</mi></msub><mo id="S4.F4.1.m1.10.10.2.2.7" xref="S4.F4.1.m1.10.10.2.3.cmml">,</mo><msub id="S4.F4.1.m1.10.10.2.2.2" xref="S4.F4.1.m1.10.10.2.2.2.cmml"><mi id="S4.F4.1.m1.10.10.2.2.2.2" xref="S4.F4.1.m1.10.10.2.2.2.2.cmml">x</mi><mi id="S4.F4.1.m1.10.10.2.2.2.3" xref="S4.F4.1.m1.10.10.2.2.2.3.cmml">i</mi></msub><mo id="S4.F4.1.m1.10.10.2.2.8" stretchy="false" xref="S4.F4.1.m1.10.10.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.1.m1.10c"><apply id="S4.F4.1.m1.10.10.cmml" xref="S4.F4.1.m1.10.10"><eq id="S4.F4.1.m1.10.10.3.cmml" xref="S4.F4.1.m1.10.10.3"></eq><vector id="S4.F4.1.m1.10.10.4.1.cmml" xref="S4.F4.1.m1.10.10.4.2"><ci id="S4.F4.1.m1.1.1.cmml" xref="S4.F4.1.m1.1.1">ùêµ</ci><ci id="S4.F4.1.m1.2.2.cmml" xref="S4.F4.1.m1.2.2">ùê∂</ci><ci id="S4.F4.1.m1.3.3.cmml" xref="S4.F4.1.m1.3.3">ùëá</ci><ci id="S4.F4.1.m1.4.4.cmml" xref="S4.F4.1.m1.4.4">ùêª</ci><ci id="S4.F4.1.m1.5.5.cmml" xref="S4.F4.1.m1.5.5">ùëä</ci></vector><vector id="S4.F4.1.m1.10.10.2.3.cmml" xref="S4.F4.1.m1.10.10.2.2"><cn id="S4.F4.1.m1.6.6.cmml" type="integer" xref="S4.F4.1.m1.6.6">4</cn><cn id="S4.F4.1.m1.7.7.cmml" type="integer" xref="S4.F4.1.m1.7.7">10</cn><cn id="S4.F4.1.m1.8.8.cmml" type="integer" xref="S4.F4.1.m1.8.8">30</cn><apply id="S4.F4.1.m1.9.9.1.1.1.cmml" xref="S4.F4.1.m1.9.9.1.1.1"><csymbol cd="ambiguous" id="S4.F4.1.m1.9.9.1.1.1.1.cmml" xref="S4.F4.1.m1.9.9.1.1.1">subscript</csymbol><ci id="S4.F4.1.m1.9.9.1.1.1.2.cmml" xref="S4.F4.1.m1.9.9.1.1.1.2">ùë•</ci><ci id="S4.F4.1.m1.9.9.1.1.1.3.cmml" xref="S4.F4.1.m1.9.9.1.1.1.3">ùëñ</ci></apply><apply id="S4.F4.1.m1.10.10.2.2.2.cmml" xref="S4.F4.1.m1.10.10.2.2.2"><csymbol cd="ambiguous" id="S4.F4.1.m1.10.10.2.2.2.1.cmml" xref="S4.F4.1.m1.10.10.2.2.2">subscript</csymbol><ci id="S4.F4.1.m1.10.10.2.2.2.2.cmml" xref="S4.F4.1.m1.10.10.2.2.2.2">ùë•</ci><ci id="S4.F4.1.m1.10.10.2.2.2.3.cmml" xref="S4.F4.1.m1.10.10.2.2.2.3">ùëñ</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.1.m1.10d">(B,C,T,H,W)=(4,10,30,x_{i},x_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.F4.1.m1.10e">( italic_B , italic_C , italic_T , italic_H , italic_W ) = ( 4 , 10 , 30 , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> where we scale height and width dimensions using <math alttext="x_{i}" class="ltx_Math" display="inline" id="S4.F4.2.m2.1"><semantics id="S4.F4.2.m2.1b"><msub id="S4.F4.2.m2.1.1" xref="S4.F4.2.m2.1.1.cmml"><mi id="S4.F4.2.m2.1.1.2" xref="S4.F4.2.m2.1.1.2.cmml">x</mi><mi id="S4.F4.2.m2.1.1.3" xref="S4.F4.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.2.m2.1c"><apply id="S4.F4.2.m2.1.1.cmml" xref="S4.F4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F4.2.m2.1.1.1.cmml" xref="S4.F4.2.m2.1.1">subscript</csymbol><ci id="S4.F4.2.m2.1.1.2.cmml" xref="S4.F4.2.m2.1.1.2">ùë•</ci><ci id="S4.F4.2.m2.1.1.3.cmml" xref="S4.F4.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.2.m2.1d">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.2.m2.1e">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. <span class="ltx_text ltx_font_bold" id="S4.F4.9.2">(b)</span> Reflects the scaling of VistaFormer in terms of GFLOPs using input dimensions <math alttext="(B,C,T,H,W)=(4,10,t_{i},64,64)" class="ltx_Math" display="inline" id="S4.F4.3.m3.10"><semantics id="S4.F4.3.m3.10b"><mrow id="S4.F4.3.m3.10.10" xref="S4.F4.3.m3.10.10.cmml"><mrow id="S4.F4.3.m3.10.10.3.2" xref="S4.F4.3.m3.10.10.3.1.cmml"><mo id="S4.F4.3.m3.10.10.3.2.1" stretchy="false" xref="S4.F4.3.m3.10.10.3.1.cmml">(</mo><mi id="S4.F4.3.m3.1.1" xref="S4.F4.3.m3.1.1.cmml">B</mi><mo id="S4.F4.3.m3.10.10.3.2.2" xref="S4.F4.3.m3.10.10.3.1.cmml">,</mo><mi id="S4.F4.3.m3.2.2" xref="S4.F4.3.m3.2.2.cmml">C</mi><mo id="S4.F4.3.m3.10.10.3.2.3" xref="S4.F4.3.m3.10.10.3.1.cmml">,</mo><mi id="S4.F4.3.m3.3.3" xref="S4.F4.3.m3.3.3.cmml">T</mi><mo id="S4.F4.3.m3.10.10.3.2.4" xref="S4.F4.3.m3.10.10.3.1.cmml">,</mo><mi id="S4.F4.3.m3.4.4" xref="S4.F4.3.m3.4.4.cmml">H</mi><mo id="S4.F4.3.m3.10.10.3.2.5" xref="S4.F4.3.m3.10.10.3.1.cmml">,</mo><mi id="S4.F4.3.m3.5.5" xref="S4.F4.3.m3.5.5.cmml">W</mi><mo id="S4.F4.3.m3.10.10.3.2.6" stretchy="false" xref="S4.F4.3.m3.10.10.3.1.cmml">)</mo></mrow><mo id="S4.F4.3.m3.10.10.2" xref="S4.F4.3.m3.10.10.2.cmml">=</mo><mrow id="S4.F4.3.m3.10.10.1.1" xref="S4.F4.3.m3.10.10.1.2.cmml"><mo id="S4.F4.3.m3.10.10.1.1.2" stretchy="false" xref="S4.F4.3.m3.10.10.1.2.cmml">(</mo><mn id="S4.F4.3.m3.6.6" xref="S4.F4.3.m3.6.6.cmml">4</mn><mo id="S4.F4.3.m3.10.10.1.1.3" xref="S4.F4.3.m3.10.10.1.2.cmml">,</mo><mn id="S4.F4.3.m3.7.7" xref="S4.F4.3.m3.7.7.cmml">10</mn><mo id="S4.F4.3.m3.10.10.1.1.4" xref="S4.F4.3.m3.10.10.1.2.cmml">,</mo><msub id="S4.F4.3.m3.10.10.1.1.1" xref="S4.F4.3.m3.10.10.1.1.1.cmml"><mi id="S4.F4.3.m3.10.10.1.1.1.2" xref="S4.F4.3.m3.10.10.1.1.1.2.cmml">t</mi><mi id="S4.F4.3.m3.10.10.1.1.1.3" xref="S4.F4.3.m3.10.10.1.1.1.3.cmml">i</mi></msub><mo id="S4.F4.3.m3.10.10.1.1.5" xref="S4.F4.3.m3.10.10.1.2.cmml">,</mo><mn id="S4.F4.3.m3.8.8" xref="S4.F4.3.m3.8.8.cmml">64</mn><mo id="S4.F4.3.m3.10.10.1.1.6" xref="S4.F4.3.m3.10.10.1.2.cmml">,</mo><mn id="S4.F4.3.m3.9.9" xref="S4.F4.3.m3.9.9.cmml">64</mn><mo id="S4.F4.3.m3.10.10.1.1.7" stretchy="false" xref="S4.F4.3.m3.10.10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.3.m3.10c"><apply id="S4.F4.3.m3.10.10.cmml" xref="S4.F4.3.m3.10.10"><eq id="S4.F4.3.m3.10.10.2.cmml" xref="S4.F4.3.m3.10.10.2"></eq><vector id="S4.F4.3.m3.10.10.3.1.cmml" xref="S4.F4.3.m3.10.10.3.2"><ci id="S4.F4.3.m3.1.1.cmml" xref="S4.F4.3.m3.1.1">ùêµ</ci><ci id="S4.F4.3.m3.2.2.cmml" xref="S4.F4.3.m3.2.2">ùê∂</ci><ci id="S4.F4.3.m3.3.3.cmml" xref="S4.F4.3.m3.3.3">ùëá</ci><ci id="S4.F4.3.m3.4.4.cmml" xref="S4.F4.3.m3.4.4">ùêª</ci><ci id="S4.F4.3.m3.5.5.cmml" xref="S4.F4.3.m3.5.5">ùëä</ci></vector><vector id="S4.F4.3.m3.10.10.1.2.cmml" xref="S4.F4.3.m3.10.10.1.1"><cn id="S4.F4.3.m3.6.6.cmml" type="integer" xref="S4.F4.3.m3.6.6">4</cn><cn id="S4.F4.3.m3.7.7.cmml" type="integer" xref="S4.F4.3.m3.7.7">10</cn><apply id="S4.F4.3.m3.10.10.1.1.1.cmml" xref="S4.F4.3.m3.10.10.1.1.1"><csymbol cd="ambiguous" id="S4.F4.3.m3.10.10.1.1.1.1.cmml" xref="S4.F4.3.m3.10.10.1.1.1">subscript</csymbol><ci id="S4.F4.3.m3.10.10.1.1.1.2.cmml" xref="S4.F4.3.m3.10.10.1.1.1.2">ùë°</ci><ci id="S4.F4.3.m3.10.10.1.1.1.3.cmml" xref="S4.F4.3.m3.10.10.1.1.1.3">ùëñ</ci></apply><cn id="S4.F4.3.m3.8.8.cmml" type="integer" xref="S4.F4.3.m3.8.8">64</cn><cn id="S4.F4.3.m3.9.9.cmml" type="integer" xref="S4.F4.3.m3.9.9">64</cn></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.3.m3.10d">(B,C,T,H,W)=(4,10,t_{i},64,64)</annotation><annotation encoding="application/x-llamapun" id="S4.F4.3.m3.10e">( italic_B , italic_C , italic_T , italic_H , italic_W ) = ( 4 , 10 , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , 64 , 64 )</annotation></semantics></math> where we scale <math alttext="x_{i}" class="ltx_Math" display="inline" id="S4.F4.4.m4.1"><semantics id="S4.F4.4.m4.1b"><msub id="S4.F4.4.m4.1.1" xref="S4.F4.4.m4.1.1.cmml"><mi id="S4.F4.4.m4.1.1.2" xref="S4.F4.4.m4.1.1.2.cmml">x</mi><mi id="S4.F4.4.m4.1.1.3" xref="S4.F4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F4.4.m4.1c"><apply id="S4.F4.4.m4.1.1.cmml" xref="S4.F4.4.m4.1.1"><csymbol cd="ambiguous" id="S4.F4.4.m4.1.1.1.cmml" xref="S4.F4.4.m4.1.1">subscript</csymbol><ci id="S4.F4.4.m4.1.1.2.cmml" xref="S4.F4.4.m4.1.1.2">ùë•</ci><ci id="S4.F4.4.m4.1.1.3.cmml" xref="S4.F4.4.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.m4.1d">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.4.m4.1e">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablations </h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1"><span class="ltx_text" id="S4.SS4.p1.1.1" style="font-size:90%;">We report ablations concerning (a) decoder layers, (b) encoder layers, and (c) encoder downsampling. We find that using a max pooling layer instead of a 1D convolution in the decoder decreases model performance only slightly across all results excluding overall accuracy for the MTLCC dataset. We find that replacing trilinear interpolation with a transposed 3D convolution improved results inconsistently across datasets while requiring a considerable number of trainable parameters relative to the model size.</span></p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text" id="S4.SS4.p2.1.1" style="font-size:90%;">For encoder layers, we use gated convolutions by default to reduce input noise and find that not including this layer consistently results in a consistent decrease in both oA and mIoU scores. We introduced a Squeeze and Excitation (SE) </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS4.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib16" title="">16</a><span class="ltx_text" id="S4.SS4.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS4.p2.1.4" style="font-size:90%;"> layer as an additional convolution filtering mechanism in each of the downsampling encoder layers, though we found inconsistent results in our tests and omitted the layer from the chosen architecture to preserve simplicity. This layer was used as a potential noise reduction technique since it adaptively recalibrates channel-wise feature responses which can reduce noise by emphasizing important input features and suppressing irrelevant ones.</span></p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.3"><span class="ltx_text" id="S4.SS4.p3.3.1" style="font-size:90%;">Concerning encoder downsampling, the base model in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S3.F1" style="font-size:90%;" title="Figure 1 ‚Ä£ 3 Methods ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S4.SS4.p3.3.2" style="font-size:90%;"> in effect uses a 2D convolution in the first layer, only downsampling the height and width in keeping with </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS4.p3.3.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a><span class="ltx_text" id="S4.SS4.p3.3.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS4.p3.3.5" style="font-size:90%;">. We find that both downsampling </span><math alttext="T" class="ltx_Math" display="inline" id="S4.SS4.p3.1.m1.1"><semantics id="S4.SS4.p3.1.m1.1a"><mi id="S4.SS4.p3.1.m1.1.1" mathsize="90%" xref="S4.SS4.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><ci id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.1.m1.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p3.3.6" style="font-size:90%;"> in the first encoder, giving us </span><math alttext="T_{1}=\frac{T}{2}" class="ltx_Math" display="inline" id="S4.SS4.p3.2.m2.1"><semantics id="S4.SS4.p3.2.m2.1a"><mrow id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml"><msub id="S4.SS4.p3.2.m2.1.1.2" xref="S4.SS4.p3.2.m2.1.1.2.cmml"><mi id="S4.SS4.p3.2.m2.1.1.2.2" mathsize="90%" xref="S4.SS4.p3.2.m2.1.1.2.2.cmml">T</mi><mn id="S4.SS4.p3.2.m2.1.1.2.3" mathsize="90%" xref="S4.SS4.p3.2.m2.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS4.p3.2.m2.1.1.1" mathsize="90%" xref="S4.SS4.p3.2.m2.1.1.1.cmml">=</mo><mfrac id="S4.SS4.p3.2.m2.1.1.3" xref="S4.SS4.p3.2.m2.1.1.3.cmml"><mi id="S4.SS4.p3.2.m2.1.1.3.2" mathsize="90%" xref="S4.SS4.p3.2.m2.1.1.3.2.cmml">T</mi><mn id="S4.SS4.p3.2.m2.1.1.3.3" mathsize="90%" xref="S4.SS4.p3.2.m2.1.1.3.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><apply id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1"><eq id="S4.SS4.p3.2.m2.1.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1.1"></eq><apply id="S4.SS4.p3.2.m2.1.1.2.cmml" xref="S4.SS4.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.p3.2.m2.1.1.2.1.cmml" xref="S4.SS4.p3.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS4.p3.2.m2.1.1.2.2.cmml" xref="S4.SS4.p3.2.m2.1.1.2.2">ùëá</ci><cn id="S4.SS4.p3.2.m2.1.1.2.3.cmml" type="integer" xref="S4.SS4.p3.2.m2.1.1.2.3">1</cn></apply><apply id="S4.SS4.p3.2.m2.1.1.3.cmml" xref="S4.SS4.p3.2.m2.1.1.3"><divide id="S4.SS4.p3.2.m2.1.1.3.1.cmml" xref="S4.SS4.p3.2.m2.1.1.3"></divide><ci id="S4.SS4.p3.2.m2.1.1.3.2.cmml" xref="S4.SS4.p3.2.m2.1.1.3.2">ùëá</ci><cn id="S4.SS4.p3.2.m2.1.1.3.3.cmml" type="integer" xref="S4.SS4.p3.2.m2.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">T_{1}=\frac{T}{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.2.m2.1d">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = divide start_ARG italic_T end_ARG start_ARG 2 end_ARG</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p3.3.7" style="font-size:90%;">, and not downsampling </span><math alttext="T" class="ltx_Math" display="inline" id="S4.SS4.p3.3.m3.1"><semantics id="S4.SS4.p3.3.m3.1a"><mi id="S4.SS4.p3.3.m3.1.1" mathsize="90%" xref="S4.SS4.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.3.m3.1b"><ci id="S4.SS4.p3.3.m3.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p3.3.m3.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="S4.SS4.p3.3.8" style="font-size:90%;"> in any encoder layer, resulted in decreased model performance relative to our proposed model. These results indicate that downsampling the temporal dimension can be performed effectively for SITS data, contrary to the preservation of the temporal dimension used in </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.SS4.p3.3.9.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib32" title="">32</a><span class="ltx_text" id="S4.SS4.p3.3.10.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S4.SS4.p3.3.11" style="font-size:90%;">, allowing our model to reduce the sequence length used in self-attention layers, and subsequently the complexity of the model.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Model Scalability </h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.3"><span class="ltx_text" id="S4.SS5.p1.3.1" style="font-size:90%;">VistaFormer treats each sequence entry in the temporal dimension </span><math alttext="T" class="ltx_Math" display="inline" id="S4.SS5.p1.1.m1.1"><semantics id="S4.SS5.p1.1.m1.1a"><mi id="S4.SS5.p1.1.m1.1.1" mathsize="90%" xref="S4.SS5.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><ci id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.1.m1.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="S4.SS5.p1.3.2" style="font-size:90%;"> as a unique sample which increases the floating point operations performed, since we compute the attention for each sequence of length </span><math alttext="H\times W" class="ltx_Math" display="inline" id="S4.SS5.p1.2.m2.1"><semantics id="S4.SS5.p1.2.m2.1a"><mrow id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml"><mi id="S4.SS5.p1.2.m2.1.1.2" mathsize="90%" xref="S4.SS5.p1.2.m2.1.1.2.cmml">H</mi><mo id="S4.SS5.p1.2.m2.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS5.p1.2.m2.1.1.1.cmml">√ó</mo><mi id="S4.SS5.p1.2.m2.1.1.3" mathsize="90%" xref="S4.SS5.p1.2.m2.1.1.3.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><apply id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1"><times id="S4.SS5.p1.2.m2.1.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1.1"></times><ci id="S4.SS5.p1.2.m2.1.1.2.cmml" xref="S4.SS5.p1.2.m2.1.1.2">ùêª</ci><ci id="S4.SS5.p1.2.m2.1.1.3.cmml" xref="S4.SS5.p1.2.m2.1.1.3">ùëä</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">H\times W</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.2.m2.1d">italic_H √ó italic_W</annotation></semantics></math><span class="ltx_text" id="S4.SS5.p1.3.3" style="font-size:90%;">, for each of the </span><math alttext="T" class="ltx_Math" display="inline" id="S4.SS5.p1.3.m3.1"><semantics id="S4.SS5.p1.3.m3.1a"><mi id="S4.SS5.p1.3.m3.1.1" mathsize="90%" xref="S4.SS5.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b"><ci id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.3.m3.1d">italic_T</annotation></semantics></math><span class="ltx_text" id="S4.SS5.p1.3.4" style="font-size:90%;"> samples, and we are careful to limit the downsampling used at each layer of the encoder block. To address this, we demonstrate that substituting MHSA with NA dramatically improves the model‚Äôs scalability relative to TSViT by reducing the spatial dimension used for computing self-attention. More specifically, we find that 2D Neighbourhood attention dramatically reduces the number of floating point operations required both for small input dimensions and as the spatial dimensions increase as seen in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#S4.F4" style="font-size:90%;" title="Figure 4 ‚Ä£ 4.3 Results ‚Ä£ 4 Experiments ‚Ä£ VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S4.SS5.p1.3.5" style="font-size:90%;">.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text" id="S5.p1.1.1" style="font-size:90%;">We have demonstrated a lightweight SITS semantic segmentation model that achieves efficiency by (a) downsampling both spatial and temporal dimensions (b) employing gated convolutions to boost model performance without pre-training for masking out clouds or atmospheric distortions, (c) using position-free self-attention layers to simplify the architecture, and (d) proposing a lightweight decoder to reduce computational complexity. Further, the position-free self-attention layers make this model extensible and simpler to use than existing models. We find that VistaFormer outperforms the current state-of-the-art model, TSViT, in terms of oA and mIoU performance while using a small fraction of the number of floating point operations and fewer trainable parameters. The ablation analysis highlights the importance of carefully selecting downsampling strategies and maintaining simplicity in the model architecture to achieve optimal performance.</span></p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text" id="S5.p2.1.1" style="font-size:90%;">We anticipate the model‚Äôs efficiency and straightforward design will provide immediate benefits for remote sensing researchers and practitioners, particularly those with limited computational resources looking to train deep learning models. Our model is designed to be especially simple to train and deploy while offering considerable improvements over compared models. While there is a risk that semantic segmentation models could be used improperly to identify objects with the intent to cause harm, we are confident that the positive outcomes of making this model available will be significantly greater, since identifying crop types plays an important role in ensuring food security and creating climate adaptation strategies.</span></p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text" id="S5.p3.1.1" style="font-size:90%;">Some of the approaches in this model are generalizable. Given the effectiveness of gated convolutions for improving our model results across both benchmarks, we believe that mechanisms like partial convolutions </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.p3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.08461v1#bib.bib19" title="">19</a><span class="ltx_text" id="S5.p3.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S5.p3.1.4" style="font-size:90%;"> or pre-training gated convolutions using cloud masks may be of benefit for filtering noise found in remote sensing inputs. Similarly, our proposed architecture introduces lightweight design patterns that can be adapted for different image time series segmentation tasks. Building on the strengths of our current SITS semantic segmentation model, several follow-up research tasks are proposed to expand its capabilities and refine its performance. The model could be extended to be applied to panoptic segmentation to further investigate the model‚Äôs versatility; and experimentation with additional attention mechanisms like deformable attention, window attention, and additional configurations for neighbourhood attention.</span></p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1"><span class="ltx_text" id="S5.p4.1.1" style="font-size:90%;">These proposed tasks could enhance the model‚Äôs current capabilities and extend the applicability of the proposed architecture to more complex and demanding real-world applications. By continuing to explore these avenues, we hope to push the boundaries of SITS semantic segmentation, ultimately paving the way for more adaptable, efficient, and robust models that address increasingly complex real-world challenges.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.2.1" style="font-size:90%;">Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.3.1" style="font-size:90%;">arXiv preprint arXiv:2301.08243</span><span class="ltx_text" id="bib.bib1.4.2" style="font-size:90%;">, Apr. 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.2.1" style="font-size:90%;">Neural Machine Translation by Jointly Learning to Align and Translate.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.3.1" style="font-size:90%;">arXiv preprint arXiv:1409.0473</span><span class="ltx_text" id="bib.bib2.4.2" style="font-size:90%;">, Sept. 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
Nicolas Ballas, Li Yao, Chris Pal, and Aaron¬†C. Courville.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.2.1" style="font-size:90%;">Delving Deeper into Convolutional Networks for Learning Video Representations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.3.1" style="font-size:90%;">In Yoshua Bengio and Yann LeCun, editors, </span><span class="ltx_text ltx_font_italic" id="bib.bib3.4.2" style="font-size:90%;">4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings</span><span class="ltx_text" id="bib.bib3.5.3" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
Xin Cai, Yaxin Bi, Peter Nicholl, and Roy Sterritt.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.2.1" style="font-size:90%;">Revisiting the Encoding of Satellite Image Time Series.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.3.1" style="font-size:90%;">arXiv preprint arXiv:2305.02086</span><span class="ltx_text" id="bib.bib4.4.2" style="font-size:90%;">, Sept. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.5.1" style="font-size:90%;">arXiv:2305.02086 [cs].
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
Jorge¬†Andres Chamorro¬†Martinez, Laura¬†Elena Cu√© La¬†Rosa, Raul¬†Queiroz Feitosa, Ieda¬†Del‚ÄôArco Sanches, and Patrick¬†Nigri Happ.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.2.1" style="font-size:90%;">Fully convolutional recurrent networks for multidate crop recognition from multitemporal image sequences.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.3.1" style="font-size:90%;">ISPRS Journal of Photogrammetry and Remote Sensing</span><span class="ltx_text" id="bib.bib5.4.2" style="font-size:90%;">, 171:188‚Äì201, Jan. 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
Bowen Cheng, Ishan Misra, Alexander¬†G. Schwing, Alexander Kirillov, and Rohit Girdhar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.2.1" style="font-size:90%;">Masked-attention Mask Transformer for Universal Image Segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.4.2" style="font-size:90%;">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span class="ltx_text" id="bib.bib6.5.3" style="font-size:90%;">, pages 1280‚Äì1289, June 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.6.1" style="font-size:90%;">ISSN: 2575-7075.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo Zhang, Haibing Ren, Xiaolin Wei, Huaxia Xia, and Chunhua Shen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.2.1" style="font-size:90%;">Twins: Revisiting the Design of Spatial Attention in Vision Transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib7.4.2" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib7.5.3" style="font-size:90%;">, volume¬†34, pages 9355‚Äì9366, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Hugo Cris√≥stomo De Castro¬†Filho, Osmar Ab√≠lio De Carvalho¬†J√∫nior, Osmar¬†Luiz Ferreira De¬†Carvalho, Pablo Pozzobon De¬†Bem, Rebeca Dos Santos De¬†Moura, Anesmar Olino De¬†Albuquerque, Cristiano Rosa¬†Silva, Pedro¬†Henrique Guimar√£es¬†Ferreira, Renato Fontes¬†Guimar√£es, and Roberto¬†Arnaldo Trancoso¬†Gomes.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.2.1" style="font-size:90%;">Rice Crop Detection Using LSTM, Bi-LSTM, and Machine Learning Models from Sentinel-1 Time Series.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.3.1" style="font-size:90%;">Remote Sensing</span><span class="ltx_text" id="bib.bib8.4.2" style="font-size:90%;">, 12(16):2655, Aug. 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
A. Dosovitskiy, L. Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, G. Heigold, S. Gelly, Jakob Uszkoreit, and N. Houlsby.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.2.1" style="font-size:90%;">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.3.1" style="font-size:90%;">arXiv preprint arXiv:2010.11929</span><span class="ltx_text" id="bib.bib9.4.2" style="font-size:90%;">, Oct. 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
Yarin Gal and Zoubin Ghahramani.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.2.1" style="font-size:90%;">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib10.4.2" style="font-size:90%;">Proceedings of The 33rd International Conference on Machine Learning</span><span class="ltx_text" id="bib.bib10.5.3" style="font-size:90%;">, pages 1050‚Äì1059. PMLR, June 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
Vivien Sainte¬†Fare Garnot and Loic Landrieu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.2.1" style="font-size:90%;">Panoptic Segmentation of Satellite Image Time Series With Convolutional Temporal Attention Networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib11.4.2" style="font-size:90%;">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</span><span class="ltx_text" id="bib.bib11.5.3" style="font-size:90%;">, pages 4872‚Äì4881, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
V.¬†Sainte¬†Fare Garnot, L. Landrieu, S. Giordano, and N. Chehata.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.2.1" style="font-size:90%;">Time-Space Tradeoff in Deep Learning Models for Crop Classification on Satellite Multi-Spectral Image Time Series.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.4.2" style="font-size:90%;">IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium</span><span class="ltx_text" id="bib.bib12.5.3" style="font-size:90%;">, pages 6247‚Äì6250, July 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.6.1" style="font-size:90%;">ISSN: 2153-7003.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
Cristina G√≥mez, Joanne¬†C. White, and Michael¬†A. Wulder.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.2.1" style="font-size:90%;">Optical remotely sensed time series data for land cover classification: A review.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.3.1" style="font-size:90%;">ISPRS Journal of Photogrammetry and Remote Sensing</span><span class="ltx_text" id="bib.bib13.4.2" style="font-size:90%;">, 116:55‚Äì72, June 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.2.1" style="font-size:90%;">Neighborhood Attention Transformer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib14.4.2" style="font-size:90%;">2023 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span><span class="ltx_text" id="bib.bib14.5.3" style="font-size:90%;">, pages 6185‚Äì6194, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
Dan Hendrycks and Kevin Gimpel.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.2.1" style="font-size:90%;">Gaussian Error Linear Units (GELUs).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.3.1" style="font-size:90%;">arXiv preprint arXiv:1606.08415</span><span class="ltx_text" id="bib.bib15.4.2" style="font-size:90%;">, June 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.5.1" style="font-size:90%;">arXiv:1606.08415 [cs].
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
Jie Hu, Li Shen, and Gang Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.2.1" style="font-size:90%;">Squeeze-and-Excitation Networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib16.4.2" style="font-size:90%;">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span class="ltx_text" id="bib.bib16.5.3" style="font-size:90%;">, pages 7132‚Äì7141, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
Michael¬†D. King, Steven Platnick, W.¬†Paul Menzel, Steven¬†A. Ackerman, and Paul¬†A. Hubanks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.2.1" style="font-size:90%;">Spatial and Temporal Distribution of Clouds Observed by MODIS Onboard the Terra and Aqua Satellites.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.3.1" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</span><span class="ltx_text" id="bib.bib17.4.2" style="font-size:90%;">, 51(7):3826‚Äì3852, July 2013.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
Nataliia Kussul, Mykola Lavreniuk, Sergii Skakun, and Andrii Shelestov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.2.1" style="font-size:90%;">Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.3.1" style="font-size:90%;">IEEE Geoscience and Remote Sensing Letters</span><span class="ltx_text" id="bib.bib18.4.2" style="font-size:90%;">, 14(5):778‚Äì782, May 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
Guilin Liu, Fitsum¬†A. Reda, Kevin¬†J. Shih, Ting-Chun Wang, Andrew Tao, and Bryan Catanzaro.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.2.1" style="font-size:90%;">Image Inpainting for Irregular Holes Using Partial Convolutions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib19.4.2" style="font-size:90%;">European Conference on Computer Vision</span><span class="ltx_text" id="bib.bib19.5.3" style="font-size:90%;">, pages 85‚Äì100, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
Huan Liu, Ilan Koren, Orit Altaratz, and Micka√´l¬†D. Chekroun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.2.1" style="font-size:90%;">Opposing trends of cloud coverage over land and ocean under global warming.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.3.1" style="font-size:90%;">Atmospheric Chemistry and Physics</span><span class="ltx_text" id="bib.bib20.4.2" style="font-size:90%;">, 23(11):6559‚Äì6569, June 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, and Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.2.1" style="font-size:90%;">Swin Transformer V2: Scaling Up Capacity and Resolution.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib21.4.2" style="font-size:90%;">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span class="ltx_text" id="bib.bib21.5.3" style="font-size:90%;">, pages 12009‚Äì12019, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.2.1" style="font-size:90%;">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.3.1" style="font-size:90%;">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</span><span class="ltx_text" id="bib.bib22.4.2" style="font-size:90%;">, pages 9992‚Äì10002, Oct. 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
Jonathan Long, Evan Shelhamer, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.2.1" style="font-size:90%;">Fully Convolutional Networks for Semantic Segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib23.4.2" style="font-size:90%;">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</span><span class="ltx_text" id="bib.bib23.5.3" style="font-size:90%;">, pages 3431‚Äì3440, Mar. 2015.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.6.1" style="font-size:90%;">1063-6919.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
I. Loshchilov and F. Hutter.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.2.1" style="font-size:90%;">Decoupled Weight Decay Regularization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib24.4.2" style="font-size:90%;">International Conference on Learning Representations</span><span class="ltx_text" id="bib.bib24.5.3" style="font-size:90%;">, Nov. 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
Rose M¬†Rustowicz, Robin Cheong, Lijing Wang, Stefano Ermon, Marshall Burke, and David Lobell.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.2.1" style="font-size:90%;">Semantic Segmentation of Crop Type in Africa: A Novel Dataset and Analysis of Deep Learning Methods.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib25.4.2" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span class="ltx_text" id="bib.bib25.5.3" style="font-size:90%;">, pages 75‚Äì82, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
Ezra MacDonald.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.2.1" style="font-size:90%;">Scalable vision transformers for remote sensing semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.3.1" style="font-size:90%;">University of Victoria Library</span><span class="ltx_text" id="bib.bib26.4.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
Waytehad¬†Rose Moskola√Ø, Wahabou Abdou, Albert Dipanda, and Kolyang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.2.1" style="font-size:90%;">Application of Deep Learning Architectures for Satellite Image Time Series Prediction: A Review.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.3.1" style="font-size:90%;">Remote Sensing</span><span class="ltx_text" id="bib.bib27.4.2" style="font-size:90%;">, 13(23):4822, Jan. 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.2.1" style="font-size:90%;">U-Net: Convolutional Networks for Biomedical Image Segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib28.3.1" style="font-size:90%;">arXiv preprint arXiv:1505.04597</span><span class="ltx_text" id="bib.bib28.4.2" style="font-size:90%;">, May 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.1.1" style="font-size:90%;">
Marc Ru√üwurm and Marco K√∂rner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.2.1" style="font-size:90%;">Temporal Vegetation Modelling Using Long Short-Term Memory Networks for Crop Identification from Medium-Resolution Multi-spectral Satellite Images.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib29.4.2" style="font-size:90%;">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</span><span class="ltx_text" id="bib.bib29.5.3" style="font-size:90%;">, pages 1496‚Äì1504, July 2017.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.6.1" style="font-size:90%;">ISSN: 2160-7516.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.1.1" style="font-size:90%;">
Marc Ru√üwurm and Marco K√∂rner.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.2.1" style="font-size:90%;">Multi-Temporal Land Cover Classification with Sequential Recurrent Encoders.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib30.3.1" style="font-size:90%;">ISPRS International Journal of Geo-Information</span><span class="ltx_text" id="bib.bib30.4.2" style="font-size:90%;">, 7(4):129, Apr. 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.1.1" style="font-size:90%;">
Xingjian SHI, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-kin Wong, and Wang-chun WOO.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.2.1" style="font-size:90%;">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib31.4.2" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib31.5.3" style="font-size:90%;">, volume¬†28, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.1.1" style="font-size:90%;">
Michail Tarasiou, Erik Chavez, and Stefanos Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.2.1" style="font-size:90%;">ViTs for SITS: Vision Transformers for Satellite Image Time Series.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib32.4.2" style="font-size:90%;">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span class="ltx_text" id="bib.bib32.5.3" style="font-size:90%;">, pages 10418‚Äì10428, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.1.1" style="font-size:90%;">
Michail Tarasiou, Riza¬†Alp G√ºler, and Stefanos Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.2.1" style="font-size:90%;">Context-Self Contrastive Pretraining for Crop Type Semantic Segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.3.1" style="font-size:90%;">IEEE Transactions on Geoscience and Remote Sensing</span><span class="ltx_text" id="bib.bib33.4.2" style="font-size:90%;">, 60:1‚Äì17, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.1.1" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan¬†N. Gomez, ≈Åukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.2.1" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib34.4.2" style="font-size:90%;">Proceedings of the 31st International Conference on Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib34.5.3" style="font-size:90%;">, NIPS‚Äô17, pages 6000‚Äì6010, Red Hook, NY, USA, Dec. 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.1.1" style="font-size:90%;">
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.2.1" style="font-size:90%;">Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib35.4.2" style="font-size:90%;">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</span><span class="ltx_text" id="bib.bib35.5.3" style="font-size:90%;">, pages 548‚Äì558. IEEE, Oct. 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.1.1" style="font-size:90%;">
Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose¬†M. Alvarez, and Ping Luo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.2.1" style="font-size:90%;">SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib36.4.2" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib36.5.3" style="font-size:90%;">, Nov. 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.1.1" style="font-size:90%;">
Weijian Xu, Yifan Xu, Tyler Chang, and Zhuowen Tu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.2.1" style="font-size:90%;">Co-Scale Conv-Attentional Image Transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib37.4.2" style="font-size:90%;">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</span><span class="ltx_text" id="bib.bib37.5.3" style="font-size:90%;">, pages 9961‚Äì9970. IEEE, Oct. 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.1.1" style="font-size:90%;">
Fengyu Yang and Chenyang Ma.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.2.1" style="font-size:90%;">Sparse and Complete Latent Organization for Geospatial Semantic Segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.3.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib38.4.2" style="font-size:90%;">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span class="ltx_text" id="bib.bib38.5.3" style="font-size:90%;">, pages 1799‚Äì1808, June 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.6.1" style="font-size:90%;">ISSN: 2575-7075.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.1.1" style="font-size:90%;">
Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas Huang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.2.1" style="font-size:90%;">Free-Form Image Inpainting with Gated Convolution.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib39.3.1" style="font-size:90%;">arXiv preprint arXiv:1806.03589</span><span class="ltx_text" id="bib.bib39.4.2" style="font-size:90%;">, Oct. 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.5.1" style="font-size:90%;">arXiv:1806.03589 [cs].
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.1.1" style="font-size:90%;">
Xia Zhao, Limin Wang, Yufei Zhang, Xuming Han, Muhammet Deveci, and Milan Parmar.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.2.1" style="font-size:90%;">A review of convolutional neural networks in computer vision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.3.1" style="font-size:90%;">Artificial Intelligence Review</span><span class="ltx_text" id="bib.bib40.4.2" style="font-size:90%;">, 57(4):99, Mar. 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.1.1" style="font-size:90%;">
Zhuo Zheng, Yanfei Zhong, Junjue Wang, and Ailong Ma.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.2.1" style="font-size:90%;">Foreground-Aware Relation Network for Geospatial Object Segmentation in High Spatial Resolution Remote Sensing Imagery.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib41.3.1" style="font-size:90%;">arXiv preprint arXiv:2011.09766v1</span><span class="ltx_text" id="bib.bib41.4.2" style="font-size:90%;">, Nov. 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.1.1" style="font-size:90%;">
√ñzg√ºn √ái√ßek, Ahmed Abdulkadir, Soeren¬†S. Lienkamp, Thomas Brox, and Olaf Ronneberger.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.2.1" style="font-size:90%;">3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib42.3.1" style="font-size:90%;">arXiv preprint arXiv:1606.06650</span><span class="ltx_text" id="bib.bib42.4.2" style="font-size:90%;">, June 2016.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 13 01:20:54 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
