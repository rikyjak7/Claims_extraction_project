<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning</title>
<!--Generated on Mon Sep 16 15:05:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.10362v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S1" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S2" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S2.SS1" title="In 2 Related Work ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Self-supervised Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S2.SS2" title="In 2 Related Work ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Masked Image Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S2.SS3" title="In 2 Related Work ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Distillation-based Modeling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS1" title="In 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Preliminary and Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS2" title="In 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>FOLK Framework</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS2.SSS1" title="In 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Informed Filters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS2.SSS2" title="In 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Making Backbone Familiar with Natural Images</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS2.SSS3" title="In 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Comprehensive Loss Calculation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS1" title="In 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2" title="In 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experimental Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS1" title="In 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Image Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS2" title="In 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Few Shot Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS3" title="In 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Semantic Segmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS4" title="In 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Ablation Study</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S5" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">A</span> </span><span class="ltx_text" style="font-size:90%;">Implementation Details</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1.SS1" title="In Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Pre-Train Stage</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1.SS2" title="In Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Fine-Tune Stage</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1.SS2.SSS1" title="In A.2 Fine-Tune Stage ‣ Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2.1 </span>Classification Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1.SS2.SSS2" title="In A.2 Fine-Tune Stage ‣ Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2.2 </span>Semantic Segmentation Task</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1.SS3" title="In Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Projection Head</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">B</span> </span><span class="ltx_text" style="font-size:90%;">Extra Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS1" title="In Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Image Classification - CNN Base Modal</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS2" title="In Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Few Shot Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS3" title="In Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Ablation Study - Different Filters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS4" title="In Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.4 </span>Efficiency Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3" title="In Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">C</span> </span><span class="ltx_text" style="font-size:90%;">Prediction Visualization</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_ERROR undefined" id="p1.2.2">\ul</span>
<span class="ltx_text" id="p1.2.3" lang="en"></span></p>
</div>
<h1 class="ltx_title ltx_title_document">Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text ltx_font_bold" id="id1.1.id1">Amin Karimi Monsefi<sup class="ltx_sup" id="id1.1.id1.1">§</sup>,
Mengxi Zhou<sup class="ltx_sup" id="id1.1.id1.2">§</sup>,
Nastaran Karimi Monsefi<sup class="ltx_sup" id="id1.1.id1.3">†</sup>,</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id2.2.id2">Ser-Nam Lim<sup class="ltx_sup" id="id2.2.id2.1">‡</sup>,
Wei-Lun Chao<sup class="ltx_sup" id="id2.2.id2.2">§</sup>,
Rajiv Ramnath<sup class="ltx_sup" id="id2.2.id2.3">§</sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">{karimimonsefi.1, zhou.2656, chao.209, ramnath.6}@osu.edu</span>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id4">k.nastaran1998@gmail.com</span>, <span class="ltx_text ltx_font_typewriter" id="id5.5.id5">sernam@ucf.edu</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id6.6.id6">§</sup>The Ohio State University
<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">†</sup>Hamedan University of Technology 
<br class="ltx_break"/><sup class="ltx_sup" id="id8.8.id8">‡</sup>University of Central Florida 
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id9.id1"><span class="ltx_text" id="id9.id1.1" lang="en">We present a novel <em class="ltx_emph ltx_font_italic" id="id9.id1.1.1">frequency-based</em> Self-Supervised Learning (SSL) approach that significantly enhances its efficacy for pre-training. Prior work in this direction masks out pre-defined frequencies in the input image and employs a reconstruction loss to pre-train the model. While achieving promising results, such an implementation has two fundamental limitations as identified in our paper. First, using pre-defined frequencies overlooks the variability of image frequency responses. Second, pre-trained with frequency-filtered images, the resulting model needs relatively more data to adapt to naturally looking images during fine-tuning.
To address these drawbacks, we propose <span class="ltx_text ltx_font_bold" id="id9.id1.1.2">FO</span>urier transform compression with se<span class="ltx_text ltx_font_bold" id="id9.id1.1.3">L</span>f-<span class="ltx_text ltx_font_bold" id="id9.id1.1.4">K</span>nowledge distillation (<span class="ltx_text ltx_font_bold" id="id9.id1.1.5">FOLK</span>), integrating two dedicated ideas.
First, inspired by image compression, we adaptively select the masked-out frequencies based on image frequency responses, creating more suitable SSL tasks for pre-training. Second, we employ a two-branch framework empowered by knowledge distillation, enabling the model to take both the filtered and original images as input, largely reducing the burden of downstream tasks. Our experimental results demonstrate the effectiveness of <span class="ltx_text ltx_font_bold" id="id9.id1.1.6">FOLK</span> in achieving competitive performance to many state-of-the-art SSL methods across various downstream tasks, including image classification, few-shot learning, and semantic segmentation.</span></p>
</div>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><span class="ltx_text" id="S1.p1.1.1" style="font-size:90%;">In recent years, Self-Supervised Learning (SSL) has gained considerable interest in the context of visual pre-training. This interest stems from its prominent capability of extracting meaningful visual representations from the vast expanse of readily available, unlabeled images without the need for costly manual labeling </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Ben-Shaul et al.</span><span class="ltx_text" id="S1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>; <span class="ltx_text" style="font-size:90%;">Su et al.</span><span class="ltx_text" id="S1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib52" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a>; <span class="ltx_text" style="font-size:90%;">Almalki and Latecki</span><span class="ltx_text" id="S1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a><span class="ltx_text" id="S1.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p1.1.5" style="font-size:90%;">. Key to this advancement is several pre-training methods established with different pretext tasks, including multi-view contrastive learning </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Oord et al.</span><span class="ltx_text" id="S1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">2020b</span></a>; <span class="ltx_text" style="font-size:90%;">Tian et al.</span><span class="ltx_text" id="S1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib56" title=""><span class="ltx_text" style="font-size:90%;">2020b</span></a>; <span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="S1.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p1.1.9" style="font-size:90%;">, Masked Image Modeling (MIM) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p1.1.10.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="S1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">2022a</span></a>; <span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Monsefi et al.</span><span class="ltx_text" id="S1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">2024a</span></a>; <span class="ltx_text" style="font-size:90%;">Oquab et al.</span><span class="ltx_text" id="S1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib45" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a><span class="ltx_text" id="S1.p1.1.12.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p1.1.13" style="font-size:90%;">, Masked Frequency Modeling (MFM) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p1.1.14.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S1.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">Liu et al.</span><span class="ltx_text" id="S1.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">Zheng et al.</span><span class="ltx_text" id="S1.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib69" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a><span class="ltx_text" id="S1.p1.1.16.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p1.1.17" style="font-size:90%;">, and self-supervised Knowledge Distillation (KD) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p1.1.18.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">2020c</span></a>; <span class="ltx_text" style="font-size:90%;">Chen and He</span><span class="ltx_text" id="S1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a>; <span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S1.p1.1.20.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p1.1.21" style="font-size:90%;">. In the recent popular approach of Masked Image Modeling (MIM), a key strategy involves masking portions of an image and then tasking models with either reconstructing these hidden sections or generating feature representations for them </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p1.1.22.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="S1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">2022a</span></a>; <span class="ltx_text" style="font-size:90%;">Yi et al.</span><span class="ltx_text" id="S1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib64" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S1.p1.1.24.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p1.1.25" style="font-size:90%;">. Through this process, the model is encouraged to learn robust feature representations that capture the underlying structure between unmasked and masked image parts, thereby enhancing its understanding of image semantics.</span></p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1"><span class="ltx_text" id="S1.p2.1.1" style="font-size:90%;">Instead of masking in the spatial domain (MIM), Masked Frequency Modeling (MFM) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p2.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S1.p2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S1.p2.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p2.1.5" style="font-size:90%;"> introduced a self-supervised approach that masks frequency components of the input image. Since high-level semantics and low-level details of an image can be separated into different frequency components </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p2.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Oppenheim and Lim</span><span class="ltx_text" id="S1.p2.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">1981</span></a>; <span class="ltx_text" style="font-size:90%;">Piotrowski and Campbell</span><span class="ltx_text" id="S1.p2.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">1982</span></a>; <span class="ltx_text" style="font-size:90%;">Navard and Yilmaz</span><span class="ltx_text" id="S1.p2.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a><span class="ltx_text" id="S1.p2.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p2.1.9" style="font-size:90%;">, the frequency domain offers a more convenient avenue for revealing underlying image patterns. The pretext task in MFM is to predict the masked frequencies from the frequency-filtered image (see Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS1" style="font-size:90%;" title="3.1 Preliminary and Background ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3.1</span></a><span class="ltx_text" id="S1.p2.1.10" style="font-size:90%;">). It has two main advantages: first, it can help avoid issues encountered when analyzing raw pixel values in the spatial domain, such as spatial redundancy </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p2.1.11.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Wang et al.</span><span class="ltx_text" id="S1.p2.1.12.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib58" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S1.p2.1.12.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S1.p2.1.13.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p2.1.14" style="font-size:90%;">; second, unlike the patch-based masking used in MIM which often restricts the model to a Vision Transformer (ViT), MFM is suitable for both ViT and Convolutional Neural Network (CNN)-based models.</span></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text" id="S1.p3.1.1" style="font-size:90%;">However, though MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p3.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S1.p3.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S1.p3.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p3.1.5" style="font-size:90%;"> has demonstrated promising results, it has two fundamental limitations. Firstly, MFM uses constant filters, controlled by a pre-defined hyperparameter </span><span class="ltx_text ltx_font_italic" id="S1.p3.1.6" style="font-size:90%;">radius</span><span class="ltx_text" id="S1.p3.1.7" style="font-size:90%;">, for masking in the frequency spectrum. This disregards the intrinsic structure specific to individual images, which leads to a less challenging task for reconstruction (see Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S1.F1.sf2" style="font-size:90%;" title="In Figure 1 ‣ 1 Introduction ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">1(b)</span></a><span class="ltx_text" id="S1.p3.1.8" style="font-size:90%;"> and Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S1.F1.sf4" style="font-size:90%;" title="In Figure 1 ‣ 1 Introduction ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">1(d)</span></a><span class="ltx_text" id="S1.p3.1.9" style="font-size:90%;">). Secondly, in the pretext stage, MFM only shows frequency-masked images to the model without a mechanism to properly expose the raw information of the original images. This potentially restricts the pre-trained model’s understanding of normal image distribution which further hampers MFM’s training efficiency and model effectiveness, especially making it unsuitable in a few-shot learning scenario (see Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS2" style="font-size:90%;" title="4.2.2 Few Shot Learning ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4.2.2</span></a><span class="ltx_text" id="S1.p3.1.10" style="font-size:90%;">).</span></p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text" id="S1.p4.1.1" style="font-size:90%;">Our motivation is to achieve more effective vision pre-training through MFM, by addressing its aforementioned limitations. To this end, we propose a novel framework that integrates </span><span class="ltx_text ltx_font_bold" id="S1.p4.1.2" style="font-size:90%;">FO</span><span class="ltx_text" id="S1.p4.1.3" style="font-size:90%;">urier transform compression with se</span><span class="ltx_text ltx_font_bold" id="S1.p4.1.4" style="font-size:90%;">L</span><span class="ltx_text" id="S1.p4.1.5" style="font-size:90%;">f-</span><span class="ltx_text ltx_font_bold" id="S1.p4.1.6" style="font-size:90%;">K</span><span class="ltx_text" id="S1.p4.1.7" style="font-size:90%;">nowledge distillation, termed as </span><span class="ltx_text ltx_markedasmath ltx_font_bold" id="S1.p4.1.8" style="font-size:90%;">FOLK</span><span class="ltx_text" id="S1.p4.1.9" style="font-size:90%;">. Similar to MFM and dissimilar to MIM, FOLK applies masking to image frequency responses and embraces both ViT and CNN architectures. Furthermore, it resolves MFM’s problems from two main perspectives.</span></p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf1.g1" src="extracted/5858280/images_folder/not_mfm1/image_512_5.jpg" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(a) </span>Original 
<br class="ltx_break"/>Image</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf2.g1" src="extracted/5858280/images_folder/not_mfm1/low_fil_1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(b) </span>Low-pass Filtered</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf3.g1" src="extracted/5858280/images_folder/not_mfm1/low_res.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(c) </span>Low-pass Result</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf4.g1" src="extracted/5858280/images_folder/not_mfm1/high_fil_1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(d) </span>High-pass Filtered</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf5.g1" src="extracted/5858280/images_folder/not_mfm1/high_res.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(e) </span>High-pass Result</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf6.g1" src="extracted/5858280/images_folder/not_mfm1/com_fil_1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(f) </span><math alttext="Com" class="ltx_Math" display="inline" id="S1.F1.sf6.2.m1.1"><semantics id="S1.F1.sf6.2.m1.1b"><mrow id="S1.F1.sf6.2.m1.1.1" xref="S1.F1.sf6.2.m1.1.1.cmml"><mi id="S1.F1.sf6.2.m1.1.1.2" xref="S1.F1.sf6.2.m1.1.1.2.cmml">C</mi><mo id="S1.F1.sf6.2.m1.1.1.1" xref="S1.F1.sf6.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf6.2.m1.1.1.3" xref="S1.F1.sf6.2.m1.1.1.3.cmml">o</mi><mo id="S1.F1.sf6.2.m1.1.1.1b" xref="S1.F1.sf6.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf6.2.m1.1.1.4" xref="S1.F1.sf6.2.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf6.2.m1.1c"><apply id="S1.F1.sf6.2.m1.1.1.cmml" xref="S1.F1.sf6.2.m1.1.1"><times id="S1.F1.sf6.2.m1.1.1.1.cmml" xref="S1.F1.sf6.2.m1.1.1.1"></times><ci id="S1.F1.sf6.2.m1.1.1.2.cmml" xref="S1.F1.sf6.2.m1.1.1.2">𝐶</ci><ci id="S1.F1.sf6.2.m1.1.1.3.cmml" xref="S1.F1.sf6.2.m1.1.1.3">𝑜</ci><ci id="S1.F1.sf6.2.m1.1.1.4.cmml" xref="S1.F1.sf6.2.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf6.2.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="S1.F1.sf6.2.m1.1e">italic_C italic_o italic_m</annotation></semantics></math> Filtered</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf7.g1" src="extracted/5858280/images_folder/not_mfm1/com_res.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(g) </span><math alttext="Com" class="ltx_Math" display="inline" id="S1.F1.sf7.2.m1.1"><semantics id="S1.F1.sf7.2.m1.1b"><mrow id="S1.F1.sf7.2.m1.1.1" xref="S1.F1.sf7.2.m1.1.1.cmml"><mi id="S1.F1.sf7.2.m1.1.1.2" xref="S1.F1.sf7.2.m1.1.1.2.cmml">C</mi><mo id="S1.F1.sf7.2.m1.1.1.1" xref="S1.F1.sf7.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf7.2.m1.1.1.3" xref="S1.F1.sf7.2.m1.1.1.3.cmml">o</mi><mo id="S1.F1.sf7.2.m1.1.1.1b" xref="S1.F1.sf7.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf7.2.m1.1.1.4" xref="S1.F1.sf7.2.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf7.2.m1.1c"><apply id="S1.F1.sf7.2.m1.1.1.cmml" xref="S1.F1.sf7.2.m1.1.1"><times id="S1.F1.sf7.2.m1.1.1.1.cmml" xref="S1.F1.sf7.2.m1.1.1.1"></times><ci id="S1.F1.sf7.2.m1.1.1.2.cmml" xref="S1.F1.sf7.2.m1.1.1.2">𝐶</ci><ci id="S1.F1.sf7.2.m1.1.1.3.cmml" xref="S1.F1.sf7.2.m1.1.1.3">𝑜</ci><ci id="S1.F1.sf7.2.m1.1.1.4.cmml" xref="S1.F1.sf7.2.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf7.2.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="S1.F1.sf7.2.m1.1e">italic_C italic_o italic_m</annotation></semantics></math> Result</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf8.g1" src="extracted/5858280/images_folder/not_mfm1/rcom_fil_1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(h) </span><math alttext="RCom" class="ltx_Math" display="inline" id="S1.F1.sf8.2.m1.1"><semantics id="S1.F1.sf8.2.m1.1b"><mrow id="S1.F1.sf8.2.m1.1.1" xref="S1.F1.sf8.2.m1.1.1.cmml"><mi id="S1.F1.sf8.2.m1.1.1.2" xref="S1.F1.sf8.2.m1.1.1.2.cmml">R</mi><mo id="S1.F1.sf8.2.m1.1.1.1" xref="S1.F1.sf8.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf8.2.m1.1.1.3" xref="S1.F1.sf8.2.m1.1.1.3.cmml">C</mi><mo id="S1.F1.sf8.2.m1.1.1.1b" xref="S1.F1.sf8.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf8.2.m1.1.1.4" xref="S1.F1.sf8.2.m1.1.1.4.cmml">o</mi><mo id="S1.F1.sf8.2.m1.1.1.1c" xref="S1.F1.sf8.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf8.2.m1.1.1.5" xref="S1.F1.sf8.2.m1.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf8.2.m1.1c"><apply id="S1.F1.sf8.2.m1.1.1.cmml" xref="S1.F1.sf8.2.m1.1.1"><times id="S1.F1.sf8.2.m1.1.1.1.cmml" xref="S1.F1.sf8.2.m1.1.1.1"></times><ci id="S1.F1.sf8.2.m1.1.1.2.cmml" xref="S1.F1.sf8.2.m1.1.1.2">𝑅</ci><ci id="S1.F1.sf8.2.m1.1.1.3.cmml" xref="S1.F1.sf8.2.m1.1.1.3">𝐶</ci><ci id="S1.F1.sf8.2.m1.1.1.4.cmml" xref="S1.F1.sf8.2.m1.1.1.4">𝑜</ci><ci id="S1.F1.sf8.2.m1.1.1.5.cmml" xref="S1.F1.sf8.2.m1.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf8.2.m1.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="S1.F1.sf8.2.m1.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> Filtered</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="598" id="S1.F1.sf9.g1" src="extracted/5858280/images_folder/not_mfm1/rcom_res.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(i) </span><math alttext="RCom" class="ltx_Math" display="inline" id="S1.F1.sf9.2.m1.1"><semantics id="S1.F1.sf9.2.m1.1b"><mrow id="S1.F1.sf9.2.m1.1.1" xref="S1.F1.sf9.2.m1.1.1.cmml"><mi id="S1.F1.sf9.2.m1.1.1.2" xref="S1.F1.sf9.2.m1.1.1.2.cmml">R</mi><mo id="S1.F1.sf9.2.m1.1.1.1" xref="S1.F1.sf9.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf9.2.m1.1.1.3" xref="S1.F1.sf9.2.m1.1.1.3.cmml">C</mi><mo id="S1.F1.sf9.2.m1.1.1.1b" xref="S1.F1.sf9.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf9.2.m1.1.1.4" xref="S1.F1.sf9.2.m1.1.1.4.cmml">o</mi><mo id="S1.F1.sf9.2.m1.1.1.1c" xref="S1.F1.sf9.2.m1.1.1.1.cmml">⁢</mo><mi id="S1.F1.sf9.2.m1.1.1.5" xref="S1.F1.sf9.2.m1.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf9.2.m1.1c"><apply id="S1.F1.sf9.2.m1.1.1.cmml" xref="S1.F1.sf9.2.m1.1.1"><times id="S1.F1.sf9.2.m1.1.1.1.cmml" xref="S1.F1.sf9.2.m1.1.1.1"></times><ci id="S1.F1.sf9.2.m1.1.1.2.cmml" xref="S1.F1.sf9.2.m1.1.1.2">𝑅</ci><ci id="S1.F1.sf9.2.m1.1.1.3.cmml" xref="S1.F1.sf9.2.m1.1.1.3">𝐶</ci><ci id="S1.F1.sf9.2.m1.1.1.4.cmml" xref="S1.F1.sf9.2.m1.1.1.4">𝑜</ci><ci id="S1.F1.sf9.2.m1.1.1.5.cmml" xref="S1.F1.sf9.2.m1.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf9.2.m1.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="S1.F1.sf9.2.m1.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> Result</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Detailed visualizations outlining our proposed masking approach compared to the low/high-pass filters used in the MFM method <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xie et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>. Figures b, d, f, h here show the retained frequencies after applying the corresponding filter (zoom-in views on the shifted spectrum for better comparison). Figures c, e, g, i show the restored image from the retained frequencies. More examples can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3" title="Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">C</span></a>. All images used in this paper are from ImageNet <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Deng et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">2009</span></a>)</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.4"><span class="ltx_text" id="S1.p5.4.1" style="font-size:90%;">Firstly, instead of adopting constant filters, we seek an improved masking scheme that considers each image’s unique frequency responses, to improve the pre-training efficiency and model effectiveness. Inspired by the attention-based masking in MIM approaches such as AttMask </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p5.4.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S1.p5.4.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S1.p5.4.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p5.4.5" style="font-size:90%;">, where the most critical parts of the image are hidden from the student model to create a more challenging pretext task, FOLK utilizes the Fourier transform compression </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S1.p5.4.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Pratt et al.</span><span class="ltx_text" id="S1.p5.4.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">1969</span></a><span class="ltx_text" id="S1.p5.4.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S1.p5.4.9" style="font-size:90%;"> concept to mask the most critical parts in image frequency responses. Two types of filters, the </span><math alttext="\mathbf{Com}" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mi id="S1.p5.1.m1.1.1" mathsize="90%" xref="S1.p5.1.m1.1.1.cmml">𝐂𝐨𝐦</mi><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><ci id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">𝐂𝐨𝐦</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">\mathbf{Com}</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">bold_Com</annotation></semantics></math><span class="ltx_text" id="S1.p5.4.10" style="font-size:90%;"> filter and its counterpart, the </span><math alttext="\mathbf{RCom}" class="ltx_Math" display="inline" id="S1.p5.2.m2.1"><semantics id="S1.p5.2.m2.1a"><mi id="S1.p5.2.m2.1.1" mathsize="90%" xref="S1.p5.2.m2.1.1.cmml">𝐑𝐂𝐨𝐦</mi><annotation-xml encoding="MathML-Content" id="S1.p5.2.m2.1b"><ci id="S1.p5.2.m2.1.1.cmml" xref="S1.p5.2.m2.1.1">𝐑𝐂𝐨𝐦</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">\mathbf{RCom}</annotation><annotation encoding="application/x-llamapun" id="S1.p5.2.m2.1d">bold_RCom</annotation></semantics></math><span class="ltx_text" id="S1.p5.4.11" style="font-size:90%;"> filter, are designed to retain (or remove) the highest coefficient values within the frequency spectrum (see Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S1.F1" style="font-size:90%;" title="Figure 1 ‣ 1 Introduction ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S1.p5.4.12" style="font-size:90%;">). In contrast to the constant filters used in MFM, these </span><math alttext="Com" class="ltx_Math" display="inline" id="S1.p5.3.m3.1"><semantics id="S1.p5.3.m3.1a"><mrow id="S1.p5.3.m3.1.1" xref="S1.p5.3.m3.1.1.cmml"><mi id="S1.p5.3.m3.1.1.2" mathsize="90%" xref="S1.p5.3.m3.1.1.2.cmml">C</mi><mo id="S1.p5.3.m3.1.1.1" xref="S1.p5.3.m3.1.1.1.cmml">⁢</mo><mi id="S1.p5.3.m3.1.1.3" mathsize="90%" xref="S1.p5.3.m3.1.1.3.cmml">o</mi><mo id="S1.p5.3.m3.1.1.1a" xref="S1.p5.3.m3.1.1.1.cmml">⁢</mo><mi id="S1.p5.3.m3.1.1.4" mathsize="90%" xref="S1.p5.3.m3.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.3.m3.1b"><apply id="S1.p5.3.m3.1.1.cmml" xref="S1.p5.3.m3.1.1"><times id="S1.p5.3.m3.1.1.1.cmml" xref="S1.p5.3.m3.1.1.1"></times><ci id="S1.p5.3.m3.1.1.2.cmml" xref="S1.p5.3.m3.1.1.2">𝐶</ci><ci id="S1.p5.3.m3.1.1.3.cmml" xref="S1.p5.3.m3.1.1.3">𝑜</ci><ci id="S1.p5.3.m3.1.1.4.cmml" xref="S1.p5.3.m3.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.3.m3.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S1.p5.3.m3.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S1.p5.4.13" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S1.p5.4.m4.1"><semantics id="S1.p5.4.m4.1a"><mrow id="S1.p5.4.m4.1.1" xref="S1.p5.4.m4.1.1.cmml"><mi id="S1.p5.4.m4.1.1.2" mathsize="90%" xref="S1.p5.4.m4.1.1.2.cmml">R</mi><mo id="S1.p5.4.m4.1.1.1" xref="S1.p5.4.m4.1.1.1.cmml">⁢</mo><mi id="S1.p5.4.m4.1.1.3" mathsize="90%" xref="S1.p5.4.m4.1.1.3.cmml">C</mi><mo id="S1.p5.4.m4.1.1.1a" xref="S1.p5.4.m4.1.1.1.cmml">⁢</mo><mi id="S1.p5.4.m4.1.1.4" mathsize="90%" xref="S1.p5.4.m4.1.1.4.cmml">o</mi><mo id="S1.p5.4.m4.1.1.1b" xref="S1.p5.4.m4.1.1.1.cmml">⁢</mo><mi id="S1.p5.4.m4.1.1.5" mathsize="90%" xref="S1.p5.4.m4.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.4.m4.1b"><apply id="S1.p5.4.m4.1.1.cmml" xref="S1.p5.4.m4.1.1"><times id="S1.p5.4.m4.1.1.1.cmml" xref="S1.p5.4.m4.1.1.1"></times><ci id="S1.p5.4.m4.1.1.2.cmml" xref="S1.p5.4.m4.1.1.2">𝑅</ci><ci id="S1.p5.4.m4.1.1.3.cmml" xref="S1.p5.4.m4.1.1.3">𝐶</ci><ci id="S1.p5.4.m4.1.1.4.cmml" xref="S1.p5.4.m4.1.1.4">𝑜</ci><ci id="S1.p5.4.m4.1.1.5.cmml" xref="S1.p5.4.m4.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.4.m4.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S1.p5.4.m4.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S1.p5.4.14" style="font-size:90%;"> filters adaptively mask the frequencies that carry the essence (or finer details) of each individual image, creating greater variations across training samples. Hence, a more challenging pretext task is presented to the model, enforcing its understanding of macro and micro visual cues uniquely held by each image.</span></p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text" id="S1.p6.1.1" style="font-size:90%;">Secondly, we question how to properly expose natural image information to the model during pre-training to enhance fine-tuning efficiency. To this end, FOLK incorporates a knowledge distillation strategy using a self-supervised teacher-student design. With the original image fed to the teacher model, and the frequency-masked image fed to the student, the student model learns not only to reconstruct the masked frequencies (as what MFM does), but also to reconstruct the original image’s representation (generated by the teacher model) from the frequency-masked view of the same image. This multi-task teacher-student approach allows for model perception on both masked and original image realms, hence enhancing training stability and the pre-trained model’s efficacy when applied to downstream tasks, as demonstrated in our experimental findings (Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2" style="font-size:90%;" title="4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4.2</span></a><span class="ltx_text" id="S1.p6.1.2" style="font-size:90%;">).</span></p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text" id="S1.p7.1.1" style="font-size:90%;">To summarize, our contributions are threefold:</span></p>
</div>
<div class="ltx_para" id="S1.p8">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.2"><span class="ltx_text" id="S1.I1.i1.p1.2.1" style="font-size:90%;">We introduce a novel masking technique in masked frequency modeling with </span><math alttext="Com" class="ltx_Math" display="inline" id="S1.I1.i1.p1.1.m1.1"><semantics id="S1.I1.i1.p1.1.m1.1a"><mrow id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml"><mi id="S1.I1.i1.p1.1.m1.1.1.2" mathsize="90%" xref="S1.I1.i1.p1.1.m1.1.1.2.cmml">C</mi><mo id="S1.I1.i1.p1.1.m1.1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S1.I1.i1.p1.1.m1.1.1.3" mathsize="90%" xref="S1.I1.i1.p1.1.m1.1.1.3.cmml">o</mi><mo id="S1.I1.i1.p1.1.m1.1.1.1a" xref="S1.I1.i1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S1.I1.i1.p1.1.m1.1.1.4" mathsize="90%" xref="S1.I1.i1.p1.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><apply id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1"><times id="S1.I1.i1.p1.1.m1.1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1.1"></times><ci id="S1.I1.i1.p1.1.m1.1.1.2.cmml" xref="S1.I1.i1.p1.1.m1.1.1.2">𝐶</ci><ci id="S1.I1.i1.p1.1.m1.1.1.3.cmml" xref="S1.I1.i1.p1.1.m1.1.1.3">𝑜</ci><ci id="S1.I1.i1.p1.1.m1.1.1.4.cmml" xref="S1.I1.i1.p1.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i1.p1.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S1.I1.i1.p1.2.2" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S1.I1.i1.p1.2.m2.1"><semantics id="S1.I1.i1.p1.2.m2.1a"><mrow id="S1.I1.i1.p1.2.m2.1.1" xref="S1.I1.i1.p1.2.m2.1.1.cmml"><mi id="S1.I1.i1.p1.2.m2.1.1.2" mathsize="90%" xref="S1.I1.i1.p1.2.m2.1.1.2.cmml">R</mi><mo id="S1.I1.i1.p1.2.m2.1.1.1" xref="S1.I1.i1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S1.I1.i1.p1.2.m2.1.1.3" mathsize="90%" xref="S1.I1.i1.p1.2.m2.1.1.3.cmml">C</mi><mo id="S1.I1.i1.p1.2.m2.1.1.1a" xref="S1.I1.i1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S1.I1.i1.p1.2.m2.1.1.4" mathsize="90%" xref="S1.I1.i1.p1.2.m2.1.1.4.cmml">o</mi><mo id="S1.I1.i1.p1.2.m2.1.1.1b" xref="S1.I1.i1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S1.I1.i1.p1.2.m2.1.1.5" mathsize="90%" xref="S1.I1.i1.p1.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.2.m2.1b"><apply id="S1.I1.i1.p1.2.m2.1.1.cmml" xref="S1.I1.i1.p1.2.m2.1.1"><times id="S1.I1.i1.p1.2.m2.1.1.1.cmml" xref="S1.I1.i1.p1.2.m2.1.1.1"></times><ci id="S1.I1.i1.p1.2.m2.1.1.2.cmml" xref="S1.I1.i1.p1.2.m2.1.1.2">𝑅</ci><ci id="S1.I1.i1.p1.2.m2.1.1.3.cmml" xref="S1.I1.i1.p1.2.m2.1.1.3">𝐶</ci><ci id="S1.I1.i1.p1.2.m2.1.1.4.cmml" xref="S1.I1.i1.p1.2.m2.1.1.4">𝑜</ci><ci id="S1.I1.i1.p1.2.m2.1.1.5.cmml" xref="S1.I1.i1.p1.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i1.p1.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S1.I1.i1.p1.2.3" style="font-size:90%;"> filters, which presents a meaningful and considerably more challenging pretext task for efficient SSL.</span></p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text" id="S1.I1.i2.p1.1.1" style="font-size:90%;">We propose the FOLK framework, an innovative multi-task self-supervision methodology with self-knowledge distillation to allow for model perception on both frequency-masked images and original images in the pre-training stage.</span></p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text" id="S1.I1.i3.p1.1.1" style="font-size:90%;">Through extensive experimentation, we demonstrate the efficacy of FOLK. Our findings indicate that FOLK performs on par or better than many state-of-the-art MIM and MFM techniques in various downstream tasks, including image classification, few-shot learning, and semantic segmentation.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Self-supervised Learning</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text" id="S2.SS1.p1.1.1" style="font-size:90%;">Self-supervised Learning (SSL) methods have been developed to exploit large-scale unlabeled data for learning discriminative representations, which can then benefit a variety of downstream tasks </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Chong et al.</span><span class="ltx_text" id="S2.SS1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S2.SS1.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.5" style="font-size:90%;">. Early SSL approaches rely on several pretext tasks, such as rotation prediction </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Gidaris et al.</span><span class="ltx_text" id="S2.SS1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a><span class="ltx_text" id="S2.SS1.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.9" style="font-size:90%;">, jigsaw puzzle </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.10.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Noroozi and Favaro</span><span class="ltx_text" id="S2.SS1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a><span class="ltx_text" id="S2.SS1.p1.1.12.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.13" style="font-size:90%;">, and colorization </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.14.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhang et al.</span><span class="ltx_text" id="S2.SS1.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib67" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a><span class="ltx_text" id="S2.SS1.p1.1.16.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.17" style="font-size:90%;">. A branch of more recent studies follows a contrastive SSL paradigm </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.18.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S2.SS1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">2020b</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib12" title="">c</a>; <span class="ltx_text" style="font-size:90%;">Ci et al.</span><span class="ltx_text" id="S2.SS1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S2.SS1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">2020d</span></a>; <span class="ltx_text" style="font-size:90%;">Tian et al.</span><span class="ltx_text" id="S2.SS1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib56" title=""><span class="ltx_text" style="font-size:90%;">2020b</span></a>; <span class="ltx_text" style="font-size:90%;">Perera et al.</span><span class="ltx_text" id="S2.SS1.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a><span class="ltx_text" id="S2.SS1.p1.1.20.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.21" style="font-size:90%;">. SimCLR </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.22.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S2.SS1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">2020b</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib12" title="">c</a>; <span class="ltx_text" style="font-size:90%;">Monsefi et al.</span><span class="ltx_text" id="S2.SS1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">2024b</span></a>; <span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S2.SS1.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib73" title=""><span class="ltx_text" style="font-size:90%;">2024</span></a><span class="ltx_text" id="S2.SS1.p1.1.24.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.25" style="font-size:90%;"> considers two augmentations of a given image as positives and the augmentations of all other images in the batch as negatives, on top of which a contrastive loss is utilized for model learning. MOCO </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.26.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S2.SS1.p1.1.27.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S2.SS1.p1.1.27.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">2020d</span></a><span class="ltx_text" id="S2.SS1.p1.1.28.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.29" style="font-size:90%;"> maintains a dynamic dictionary of encoded representations with a momentum-updated encoder to generate consistent embeddings for contrastive learning. Instead of relying on negative samples and large training batches, BYOL </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.30.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Grill et al.</span><span class="ltx_text" id="S2.SS1.p1.1.31.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="S2.SS1.p1.1.32.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.33" style="font-size:90%;"> adopts a teacher-student framework that enforces consistency between representations of two augmented views of the same image generated by the two models. More recently, Correlational Image Modeling (CIM) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS1.p1.1.34.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Li et al.</span><span class="ltx_text" id="S2.SS1.p1.1.35.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S2.SS1.p1.1.36.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS1.p1.1.37" style="font-size:90%;"> operates by predicting correlation maps between randomly cropped image regions (exemplars) from a given image (context). It employs a bootstrap learning architecture with online and target encoders and a simple cross-attention mechanism to process the exemplars and context.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Masked Image Modeling</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text" id="S2.SS2.p1.1.1" style="font-size:90%;">Masked Image Modeling (MIM) is an exciting approach to self-supervised visual learning. The central concept is to rebuild or reconstruct the hidden parts of images or to predict general characteristics like the image’s category </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="S2.SS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S2.SS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S2.SS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">2020a</span></a>; <span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S2.SS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Wei et al.</span><span class="ltx_text" id="S2.SS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib59" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S2.SS2.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS2.p1.1.5" style="font-size:90%;">. It draws inspiration from the success of masked language modeling in natural language processing </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Devlin et al.</span><span class="ltx_text" id="S2.SS2.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a>; <span class="ltx_text" style="font-size:90%;">Liu et al.</span><span class="ltx_text" id="S2.SS2.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib37" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="S2.SS2.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS2.p1.1.9" style="font-size:90%;">, adapting the concept to the visual domain. Specifically, BEiT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p1.1.10.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="S2.SS2.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S2.SS2.p1.1.12.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS2.p1.1.13" style="font-size:90%;"> utilizes a discrete pre-trained Variational AutoEncoder (VAE) to create discrete tokens for image patches, then it tasks the model with predicting such discrete tokens of masked patches in images. The iBOT method </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p1.1.14.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S2.SS2.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S2.SS2.p1.1.16.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS2.p1.1.17" style="font-size:90%;"> offers improvements over BEiT by adopting a teacher-student self-distillation strategy where the teacher model simultaneously serves as an online tokenizer, instead of using a pre-trained discrete VAE. MAE </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p1.1.18.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S2.SS2.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">2022a</span></a><span class="ltx_text" id="S2.SS2.p1.1.20.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS2.p1.1.21" style="font-size:90%;"> takes a more aggressive masking strategy, with typically around 75% of patches being masked, and recovers the missing pixels using an autoencoder. To further investigate which parts of an image should be masked for efficient self-supervisory, AttMask </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS2.p1.1.22.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S2.SS2.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S2.SS2.p1.1.24.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS2.p1.1.25" style="font-size:90%;"> proposes the utilization of an attention map generated by a teacher model, and masks the highly attended patches from the image for the student model learning.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Distillation-based Modeling</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1"><span class="ltx_text" id="S2.SS3.p1.1.1" style="font-size:90%;">Knowledge Distillation (KD) in general endeavors to transfer knowledge from a complex, teacher model to its simpler, student counterpart </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Buciluǎ et al.</span><span class="ltx_text" id="S2.SS3.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">2006</span></a>; <span class="ltx_text" style="font-size:90%;">Hinton et al.</span><span class="ltx_text" id="S2.SS3.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">2015</span></a><span class="ltx_text" id="S2.SS3.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.5" style="font-size:90%;">. This is often achieved by aligning the network logits </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Hinton et al.</span><span class="ltx_text" id="S2.SS3.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">2015</span></a>; <span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S2.SS3.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib71" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S2.SS3.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.9" style="font-size:90%;"> or intermediate representations </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.10.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Romero et al.</span><span class="ltx_text" id="S2.SS3.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">2014</span></a><span class="ltx_text" id="S2.SS3.p1.1.12.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.13" style="font-size:90%;">, as well as designated statistics between teach and student models </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.14.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Tian et al.</span><span class="ltx_text" id="S2.SS3.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib55" title=""><span class="ltx_text" style="font-size:90%;">2020a</span></a>; <span class="ltx_text" style="font-size:90%;">Ahn et al.</span><span class="ltx_text" id="S2.SS3.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a>; <span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S2.SS3.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">2022b</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="S2.SS3.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S2.SS3.p1.1.16.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.17" style="font-size:90%;">. In the self-supervised domain, SEED </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.18.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Fang et al.</span><span class="ltx_text" id="S2.SS3.p1.1.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S2.SS3.p1.1.20.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.21" style="font-size:90%;"> innovates by training a student encoder to mirror the similarity score distribution inferred by a larger, pre-trained teacher across a spectrum of instances. The EMA teacher, adopted by numerous SSL methodologies </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.22.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Grill et al.</span><span class="ltx_text" id="S2.SS3.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>; <span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S2.SS3.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>; <span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S2.SS3.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S2.SS3.p1.1.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S2.SS3.p1.1.24.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.25" style="font-size:90%;">, leverages the benefits of knowledge distillation to foster stabilized training and improved model efficacy. Our method extends the single model approach used by MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.26.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S2.SS3.p1.1.27.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S2.SS3.p1.1.28.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S2.SS3.p1.1.29" style="font-size:90%;"> to a teacher-student distillation strategy for robust visual representation learning.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preliminary and Background</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.2"><span class="ltx_text" id="S3.SS1.p1.2.1" style="font-size:90%;">In the domain of self-supervised learning for visual models, MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS1.p1.2.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS1.p1.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS1.p1.2.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS1.p1.2.5" style="font-size:90%;"> introduces a novel approach that diverges from traditional spatial domain masking strategies. By leveraging the frequency domain, which encapsulates both high-frequency details and low-frequency elements, MFM bases its learning process on the masking of frequency components and the prediction of the masked frequencies. More specifically, given a single-channel image</span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>For RGB images, the procedure is applied to each channel independently.</span></span></span><span class="ltx_text" id="S3.SS1.p1.2.6" style="font-size:90%;"> </span><math alttext="x\in\mathbb{R}^{H\times W}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.2.cmml">x</mi><mo id="S3.SS1.p1.1.m1.1.1.1" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.3.2" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.3.3.2.cmml">H</mi><mo id="S3.SS1.p1.1.m1.1.1.3.3.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.SS1.p1.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3.3" mathsize="90%" xref="S3.SS1.p1.1.m1.1.1.3.3.3.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><in id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></in><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑥</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3"><times id="S3.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.2">𝐻</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.3">𝑊</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">x\in\mathbb{R}^{H\times W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_H × italic_W end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.2.7" style="font-size:90%;">, the frequency representation is obtained via 2D Fast Fourier transform (FFT) </span><math alttext="\mathcal{F}(x)" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.2.2" mathsize="90%" xref="S3.SS1.p1.2.m2.1.2.2.cmml">ℱ</mi><mo id="S3.SS1.p1.2.m2.1.2.1" xref="S3.SS1.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p1.2.m2.1.2.3.2" xref="S3.SS1.p1.2.m2.1.2.cmml"><mo id="S3.SS1.p1.2.m2.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS1.p1.2.m2.1.1" mathsize="90%" xref="S3.SS1.p1.2.m2.1.1.cmml">x</mi><mo id="S3.SS1.p1.2.m2.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS1.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.2.cmml" xref="S3.SS1.p1.2.m2.1.2"><times id="S3.SS1.p1.2.m2.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.2.1"></times><ci id="S3.SS1.p1.2.m2.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.2.2">ℱ</ci><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{F}(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">caligraphic_F ( italic_x )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p1.2.8" style="font-size:90%;">:</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{F}(x)(u,v)=\sum_{h=0}^{H-1}\sum_{w=0}^{W-1}x(h,w)e^{-i2\pi(\frac{uh}{%
H}+\frac{vw}{W})}," class="ltx_Math" display="block" id="S3.Ex1.m1.7"><semantics id="S3.Ex1.m1.7a"><mrow id="S3.Ex1.m1.7.7.1" xref="S3.Ex1.m1.7.7.1.1.cmml"><mrow id="S3.Ex1.m1.7.7.1.1" xref="S3.Ex1.m1.7.7.1.1.cmml"><mrow id="S3.Ex1.m1.7.7.1.1.2" xref="S3.Ex1.m1.7.7.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.7.7.1.1.2.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.2.2.cmml">ℱ</mi><mo id="S3.Ex1.m1.7.7.1.1.2.1" xref="S3.Ex1.m1.7.7.1.1.2.1.cmml">⁢</mo><mrow id="S3.Ex1.m1.7.7.1.1.2.3.2" xref="S3.Ex1.m1.7.7.1.1.2.cmml"><mo id="S3.Ex1.m1.7.7.1.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.7.7.1.1.2.cmml">(</mo><mi id="S3.Ex1.m1.2.2" mathsize="90%" xref="S3.Ex1.m1.2.2.cmml">x</mi><mo id="S3.Ex1.m1.7.7.1.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.7.7.1.1.2.cmml">)</mo></mrow><mo id="S3.Ex1.m1.7.7.1.1.2.1a" xref="S3.Ex1.m1.7.7.1.1.2.1.cmml">⁢</mo><mrow id="S3.Ex1.m1.7.7.1.1.2.4.2" xref="S3.Ex1.m1.7.7.1.1.2.4.1.cmml"><mo id="S3.Ex1.m1.7.7.1.1.2.4.2.1" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.7.7.1.1.2.4.1.cmml">(</mo><mi id="S3.Ex1.m1.3.3" mathsize="90%" xref="S3.Ex1.m1.3.3.cmml">u</mi><mo id="S3.Ex1.m1.7.7.1.1.2.4.2.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.2.4.1.cmml">,</mo><mi id="S3.Ex1.m1.4.4" mathsize="90%" xref="S3.Ex1.m1.4.4.cmml">v</mi><mo id="S3.Ex1.m1.7.7.1.1.2.4.2.3" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.7.7.1.1.2.4.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.7.7.1.1.1" mathsize="90%" rspace="0.111em" xref="S3.Ex1.m1.7.7.1.1.1.cmml">=</mo><mrow id="S3.Ex1.m1.7.7.1.1.3" xref="S3.Ex1.m1.7.7.1.1.3.cmml"><munderover id="S3.Ex1.m1.7.7.1.1.3.1" xref="S3.Ex1.m1.7.7.1.1.3.1.cmml"><mo id="S3.Ex1.m1.7.7.1.1.3.1.2.2" maxsize="90%" minsize="90%" movablelimits="false" rspace="0em" stretchy="true" xref="S3.Ex1.m1.7.7.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.Ex1.m1.7.7.1.1.3.1.2.3" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.cmml"><mi id="S3.Ex1.m1.7.7.1.1.3.1.2.3.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.2.cmml">h</mi><mo id="S3.Ex1.m1.7.7.1.1.3.1.2.3.1" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.Ex1.m1.7.7.1.1.3.1.2.3.3" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.3.cmml">0</mn></mrow><mrow id="S3.Ex1.m1.7.7.1.1.3.1.3" xref="S3.Ex1.m1.7.7.1.1.3.1.3.cmml"><mi id="S3.Ex1.m1.7.7.1.1.3.1.3.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.1.3.2.cmml">H</mi><mo id="S3.Ex1.m1.7.7.1.1.3.1.3.1" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.1.3.1.cmml">−</mo><mn id="S3.Ex1.m1.7.7.1.1.3.1.3.3" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.1.3.3.cmml">1</mn></mrow></munderover><mrow id="S3.Ex1.m1.7.7.1.1.3.2" xref="S3.Ex1.m1.7.7.1.1.3.2.cmml"><munderover id="S3.Ex1.m1.7.7.1.1.3.2.1" xref="S3.Ex1.m1.7.7.1.1.3.2.1.cmml"><mo id="S3.Ex1.m1.7.7.1.1.3.2.1.2.2" maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.cmml"><mi id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.2.cmml">w</mi><mo id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.1" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.3" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.3.cmml">0</mn></mrow><mrow id="S3.Ex1.m1.7.7.1.1.3.2.1.3" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.cmml"><mi id="S3.Ex1.m1.7.7.1.1.3.2.1.3.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.2.cmml">W</mi><mo id="S3.Ex1.m1.7.7.1.1.3.2.1.3.1" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.1.cmml">−</mo><mn id="S3.Ex1.m1.7.7.1.1.3.2.1.3.3" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.3.cmml">1</mn></mrow></munderover><mrow id="S3.Ex1.m1.7.7.1.1.3.2.2" xref="S3.Ex1.m1.7.7.1.1.3.2.2.cmml"><mi id="S3.Ex1.m1.7.7.1.1.3.2.2.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.2.2.cmml">x</mi><mo id="S3.Ex1.m1.7.7.1.1.3.2.2.1" xref="S3.Ex1.m1.7.7.1.1.3.2.2.1.cmml">⁢</mo><mrow id="S3.Ex1.m1.7.7.1.1.3.2.2.3.2" xref="S3.Ex1.m1.7.7.1.1.3.2.2.3.1.cmml"><mo id="S3.Ex1.m1.7.7.1.1.3.2.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.2.3.1.cmml">(</mo><mi id="S3.Ex1.m1.5.5" mathsize="90%" xref="S3.Ex1.m1.5.5.cmml">h</mi><mo id="S3.Ex1.m1.7.7.1.1.3.2.2.3.2.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.2.3.1.cmml">,</mo><mi id="S3.Ex1.m1.6.6" mathsize="90%" xref="S3.Ex1.m1.6.6.cmml">w</mi><mo id="S3.Ex1.m1.7.7.1.1.3.2.2.3.2.3" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.2.3.1.cmml">)</mo></mrow><mo id="S3.Ex1.m1.7.7.1.1.3.2.2.1a" xref="S3.Ex1.m1.7.7.1.1.3.2.2.1.cmml">⁢</mo><msup id="S3.Ex1.m1.7.7.1.1.3.2.2.4" xref="S3.Ex1.m1.7.7.1.1.3.2.2.4.cmml"><mi id="S3.Ex1.m1.7.7.1.1.3.2.2.4.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.3.2.2.4.2.cmml">e</mi><mrow id="S3.Ex1.m1.1.1.1" xref="S3.Ex1.m1.1.1.1.cmml"><mo id="S3.Ex1.m1.1.1.1a" mathsize="90%" xref="S3.Ex1.m1.1.1.1.cmml">−</mo><mrow id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.3" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.3.cmml">i</mi><mo id="S3.Ex1.m1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.2.cmml">⁢</mo><mn id="S3.Ex1.m1.1.1.1.1.4" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.4.cmml">2</mn><mo id="S3.Ex1.m1.1.1.1.1.2a" xref="S3.Ex1.m1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.1.5" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.5.cmml">π</mi><mo id="S3.Ex1.m1.1.1.1.1.2b" xref="S3.Ex1.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.cmml"><mfrac id="S3.Ex1.m1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.2" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.2.cmml">u</mi><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.3" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.3.cmml">h</mi></mrow><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.2.3" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.3.cmml">H</mi></mfrac><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.1" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml">+</mo><mfrac id="S3.Ex1.m1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.2" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.2.cmml">v</mi><mo id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.1" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.1.cmml">⁢</mo><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.3" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.3.cmml">w</mi></mrow><mi id="S3.Ex1.m1.1.1.1.1.1.1.1.3.3" mathsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.3.cmml">W</mi></mfrac></mrow><mo id="S3.Ex1.m1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.Ex1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></msup></mrow></mrow></mrow></mrow><mo id="S3.Ex1.m1.7.7.1.2" mathsize="90%" xref="S3.Ex1.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.7b"><apply id="S3.Ex1.m1.7.7.1.1.cmml" xref="S3.Ex1.m1.7.7.1"><eq id="S3.Ex1.m1.7.7.1.1.1.cmml" xref="S3.Ex1.m1.7.7.1.1.1"></eq><apply id="S3.Ex1.m1.7.7.1.1.2.cmml" xref="S3.Ex1.m1.7.7.1.1.2"><times id="S3.Ex1.m1.7.7.1.1.2.1.cmml" xref="S3.Ex1.m1.7.7.1.1.2.1"></times><ci id="S3.Ex1.m1.7.7.1.1.2.2.cmml" xref="S3.Ex1.m1.7.7.1.1.2.2">ℱ</ci><ci id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2">𝑥</ci><interval closure="open" id="S3.Ex1.m1.7.7.1.1.2.4.1.cmml" xref="S3.Ex1.m1.7.7.1.1.2.4.2"><ci id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3">𝑢</ci><ci id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4">𝑣</ci></interval></apply><apply id="S3.Ex1.m1.7.7.1.1.3.cmml" xref="S3.Ex1.m1.7.7.1.1.3"><apply id="S3.Ex1.m1.7.7.1.1.3.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.7.7.1.1.3.1.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1">superscript</csymbol><apply id="S3.Ex1.m1.7.7.1.1.3.1.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.7.7.1.1.3.1.2.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1">subscript</csymbol><sum id="S3.Ex1.m1.7.7.1.1.3.1.2.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.2.2"></sum><apply id="S3.Ex1.m1.7.7.1.1.3.1.2.3.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3"><eq id="S3.Ex1.m1.7.7.1.1.3.1.2.3.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.1"></eq><ci id="S3.Ex1.m1.7.7.1.1.3.1.2.3.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.2">ℎ</ci><cn id="S3.Ex1.m1.7.7.1.1.3.1.2.3.3.cmml" type="integer" xref="S3.Ex1.m1.7.7.1.1.3.1.2.3.3">0</cn></apply></apply><apply id="S3.Ex1.m1.7.7.1.1.3.1.3.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.3"><minus id="S3.Ex1.m1.7.7.1.1.3.1.3.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.3.1"></minus><ci id="S3.Ex1.m1.7.7.1.1.3.1.3.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.1.3.2">𝐻</ci><cn id="S3.Ex1.m1.7.7.1.1.3.1.3.3.cmml" type="integer" xref="S3.Ex1.m1.7.7.1.1.3.1.3.3">1</cn></apply></apply><apply id="S3.Ex1.m1.7.7.1.1.3.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2"><apply id="S3.Ex1.m1.7.7.1.1.3.2.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.7.7.1.1.3.2.1.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1">superscript</csymbol><apply id="S3.Ex1.m1.7.7.1.1.3.2.1.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.7.7.1.1.3.2.1.2.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1">subscript</csymbol><sum id="S3.Ex1.m1.7.7.1.1.3.2.1.2.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.2"></sum><apply id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3"><eq id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.1"></eq><ci id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.2">𝑤</ci><cn id="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.3.cmml" type="integer" xref="S3.Ex1.m1.7.7.1.1.3.2.1.2.3.3">0</cn></apply></apply><apply id="S3.Ex1.m1.7.7.1.1.3.2.1.3.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3"><minus id="S3.Ex1.m1.7.7.1.1.3.2.1.3.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.1"></minus><ci id="S3.Ex1.m1.7.7.1.1.3.2.1.3.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.2">𝑊</ci><cn id="S3.Ex1.m1.7.7.1.1.3.2.1.3.3.cmml" type="integer" xref="S3.Ex1.m1.7.7.1.1.3.2.1.3.3">1</cn></apply></apply><apply id="S3.Ex1.m1.7.7.1.1.3.2.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2"><times id="S3.Ex1.m1.7.7.1.1.3.2.2.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2.1"></times><ci id="S3.Ex1.m1.7.7.1.1.3.2.2.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2.2">𝑥</ci><interval closure="open" id="S3.Ex1.m1.7.7.1.1.3.2.2.3.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2.3.2"><ci id="S3.Ex1.m1.5.5.cmml" xref="S3.Ex1.m1.5.5">ℎ</ci><ci id="S3.Ex1.m1.6.6.cmml" xref="S3.Ex1.m1.6.6">𝑤</ci></interval><apply id="S3.Ex1.m1.7.7.1.1.3.2.2.4.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2.4"><csymbol cd="ambiguous" id="S3.Ex1.m1.7.7.1.1.3.2.2.4.1.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2.4">superscript</csymbol><ci id="S3.Ex1.m1.7.7.1.1.3.2.2.4.2.cmml" xref="S3.Ex1.m1.7.7.1.1.3.2.2.4.2">𝑒</ci><apply id="S3.Ex1.m1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1"><minus id="S3.Ex1.m1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1"></minus><apply id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1"><times id="S3.Ex1.m1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.2"></times><ci id="S3.Ex1.m1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.3">𝑖</ci><cn id="S3.Ex1.m1.1.1.1.1.4.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.4">2</cn><ci id="S3.Ex1.m1.1.1.1.1.5.cmml" xref="S3.Ex1.m1.1.1.1.1.5">𝜋</ci><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><plus id="S3.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.1"></plus><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2"><divide id="S3.Ex1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2"></divide><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2"><times id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.1"></times><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.2">𝑢</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.2.3">ℎ</ci></apply><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.2.3">𝐻</ci></apply><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3"><divide id="S3.Ex1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3"></divide><apply id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2"><times id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.1"></times><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.2">𝑣</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.2.3">𝑤</ci></apply><ci id="S3.Ex1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.1.3.3">𝑊</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.7c">\mathcal{F}(x)(u,v)=\sum_{h=0}^{H-1}\sum_{w=0}^{W-1}x(h,w)e^{-i2\pi(\frac{uh}{%
H}+\frac{vw}{W})},</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.7d">caligraphic_F ( italic_x ) ( italic_u , italic_v ) = ∑ start_POSTSUBSCRIPT italic_h = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_H - 1 end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_w = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_W - 1 end_POSTSUPERSCRIPT italic_x ( italic_h , italic_w ) italic_e start_POSTSUPERSCRIPT - italic_i 2 italic_π ( divide start_ARG italic_u italic_h end_ARG start_ARG italic_H end_ARG + divide start_ARG italic_v italic_w end_ARG start_ARG italic_W end_ARG ) end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.6"><span class="ltx_text" id="S3.SS1.p3.6.1" style="font-size:90%;">where </span><math alttext="x(h,w)" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.2"><semantics id="S3.SS1.p3.1.m1.2a"><mrow id="S3.SS1.p3.1.m1.2.3" xref="S3.SS1.p3.1.m1.2.3.cmml"><mi id="S3.SS1.p3.1.m1.2.3.2" mathsize="90%" xref="S3.SS1.p3.1.m1.2.3.2.cmml">x</mi><mo id="S3.SS1.p3.1.m1.2.3.1" xref="S3.SS1.p3.1.m1.2.3.1.cmml">⁢</mo><mrow id="S3.SS1.p3.1.m1.2.3.3.2" xref="S3.SS1.p3.1.m1.2.3.3.1.cmml"><mo id="S3.SS1.p3.1.m1.2.3.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p3.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p3.1.m1.1.1" mathsize="90%" xref="S3.SS1.p3.1.m1.1.1.cmml">h</mi><mo id="S3.SS1.p3.1.m1.2.3.3.2.2" mathsize="90%" xref="S3.SS1.p3.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p3.1.m1.2.2" mathsize="90%" xref="S3.SS1.p3.1.m1.2.2.cmml">w</mi><mo id="S3.SS1.p3.1.m1.2.3.3.2.3" maxsize="90%" minsize="90%" xref="S3.SS1.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.2b"><apply id="S3.SS1.p3.1.m1.2.3.cmml" xref="S3.SS1.p3.1.m1.2.3"><times id="S3.SS1.p3.1.m1.2.3.1.cmml" xref="S3.SS1.p3.1.m1.2.3.1"></times><ci id="S3.SS1.p3.1.m1.2.3.2.cmml" xref="S3.SS1.p3.1.m1.2.3.2">𝑥</ci><interval closure="open" id="S3.SS1.p3.1.m1.2.3.3.1.cmml" xref="S3.SS1.p3.1.m1.2.3.3.2"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">ℎ</ci><ci id="S3.SS1.p3.1.m1.2.2.cmml" xref="S3.SS1.p3.1.m1.2.2">𝑤</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.2c">x(h,w)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.2d">italic_x ( italic_h , italic_w )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p3.6.2" style="font-size:90%;"> represents the pixel value at the spatial coordinate </span><math alttext="(h,w)" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.2"><semantics id="S3.SS1.p3.2.m2.2a"><mrow id="S3.SS1.p3.2.m2.2.3.2" xref="S3.SS1.p3.2.m2.2.3.1.cmml"><mo id="S3.SS1.p3.2.m2.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p3.2.m2.2.3.1.cmml">(</mo><mi id="S3.SS1.p3.2.m2.1.1" mathsize="90%" xref="S3.SS1.p3.2.m2.1.1.cmml">h</mi><mo id="S3.SS1.p3.2.m2.2.3.2.2" mathsize="90%" xref="S3.SS1.p3.2.m2.2.3.1.cmml">,</mo><mi id="S3.SS1.p3.2.m2.2.2" mathsize="90%" xref="S3.SS1.p3.2.m2.2.2.cmml">w</mi><mo id="S3.SS1.p3.2.m2.2.3.2.3" maxsize="90%" minsize="90%" xref="S3.SS1.p3.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.2b"><interval closure="open" id="S3.SS1.p3.2.m2.2.3.1.cmml" xref="S3.SS1.p3.2.m2.2.3.2"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ℎ</ci><ci id="S3.SS1.p3.2.m2.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2">𝑤</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.2c">(h,w)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.2d">( italic_h , italic_w )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p3.6.3" style="font-size:90%;"> on the image, while </span><math alttext="\mathcal{F}(x)(u,v)" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.3"><semantics id="S3.SS1.p3.3.m3.3a"><mrow id="S3.SS1.p3.3.m3.3.4" xref="S3.SS1.p3.3.m3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.3.4.2" mathsize="90%" xref="S3.SS1.p3.3.m3.3.4.2.cmml">ℱ</mi><mo id="S3.SS1.p3.3.m3.3.4.1" xref="S3.SS1.p3.3.m3.3.4.1.cmml">⁢</mo><mrow id="S3.SS1.p3.3.m3.3.4.3.2" xref="S3.SS1.p3.3.m3.3.4.cmml"><mo id="S3.SS1.p3.3.m3.3.4.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p3.3.m3.3.4.cmml">(</mo><mi id="S3.SS1.p3.3.m3.1.1" mathsize="90%" xref="S3.SS1.p3.3.m3.1.1.cmml">x</mi><mo id="S3.SS1.p3.3.m3.3.4.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS1.p3.3.m3.3.4.cmml">)</mo></mrow><mo id="S3.SS1.p3.3.m3.3.4.1a" xref="S3.SS1.p3.3.m3.3.4.1.cmml">⁢</mo><mrow id="S3.SS1.p3.3.m3.3.4.4.2" xref="S3.SS1.p3.3.m3.3.4.4.1.cmml"><mo id="S3.SS1.p3.3.m3.3.4.4.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p3.3.m3.3.4.4.1.cmml">(</mo><mi id="S3.SS1.p3.3.m3.2.2" mathsize="90%" xref="S3.SS1.p3.3.m3.2.2.cmml">u</mi><mo id="S3.SS1.p3.3.m3.3.4.4.2.2" mathsize="90%" xref="S3.SS1.p3.3.m3.3.4.4.1.cmml">,</mo><mi id="S3.SS1.p3.3.m3.3.3" mathsize="90%" xref="S3.SS1.p3.3.m3.3.3.cmml">v</mi><mo id="S3.SS1.p3.3.m3.3.4.4.2.3" maxsize="90%" minsize="90%" xref="S3.SS1.p3.3.m3.3.4.4.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.3b"><apply id="S3.SS1.p3.3.m3.3.4.cmml" xref="S3.SS1.p3.3.m3.3.4"><times id="S3.SS1.p3.3.m3.3.4.1.cmml" xref="S3.SS1.p3.3.m3.3.4.1"></times><ci id="S3.SS1.p3.3.m3.3.4.2.cmml" xref="S3.SS1.p3.3.m3.3.4.2">ℱ</ci><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">𝑥</ci><interval closure="open" id="S3.SS1.p3.3.m3.3.4.4.1.cmml" xref="S3.SS1.p3.3.m3.3.4.4.2"><ci id="S3.SS1.p3.3.m3.2.2.cmml" xref="S3.SS1.p3.3.m3.2.2">𝑢</ci><ci id="S3.SS1.p3.3.m3.3.3.cmml" xref="S3.SS1.p3.3.m3.3.3">𝑣</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.3c">\mathcal{F}(x)(u,v)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.3d">caligraphic_F ( italic_x ) ( italic_u , italic_v )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p3.6.4" style="font-size:90%;"> denotes the complex frequency value at the coordinate </span><math alttext="(u,v)" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.2"><semantics id="S3.SS1.p3.4.m4.2a"><mrow id="S3.SS1.p3.4.m4.2.3.2" xref="S3.SS1.p3.4.m4.2.3.1.cmml"><mo id="S3.SS1.p3.4.m4.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p3.4.m4.2.3.1.cmml">(</mo><mi id="S3.SS1.p3.4.m4.1.1" mathsize="90%" xref="S3.SS1.p3.4.m4.1.1.cmml">u</mi><mo id="S3.SS1.p3.4.m4.2.3.2.2" mathsize="90%" xref="S3.SS1.p3.4.m4.2.3.1.cmml">,</mo><mi id="S3.SS1.p3.4.m4.2.2" mathsize="90%" xref="S3.SS1.p3.4.m4.2.2.cmml">v</mi><mo id="S3.SS1.p3.4.m4.2.3.2.3" maxsize="90%" minsize="90%" xref="S3.SS1.p3.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.2b"><interval closure="open" id="S3.SS1.p3.4.m4.2.3.1.cmml" xref="S3.SS1.p3.4.m4.2.3.2"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝑢</ci><ci id="S3.SS1.p3.4.m4.2.2.cmml" xref="S3.SS1.p3.4.m4.2.2">𝑣</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.2c">(u,v)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.2d">( italic_u , italic_v )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p3.6.5" style="font-size:90%;"> on the spectrum. Here, </span><math alttext="e" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><mi id="S3.SS1.p3.5.m5.1.1" mathsize="90%" xref="S3.SS1.p3.5.m5.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">e</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">italic_e</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p3.6.6" style="font-size:90%;"> is Euler’s number, and </span><math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p3.6.m6.1"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" mathsize="90%" xref="S3.SS1.p3.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.6.m6.1d">italic_i</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p3.6.7" style="font-size:90%;"> is the imaginary unit.</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text" id="S3.SS1.p4.1.1" style="font-size:90%;">To mask some frequencies from the spectrum and task a model with the reconstruction of these missing frequencies, a frequency-masked image </span><math alttext="\tilde{x}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mover accent="true" id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" mathsize="90%" xref="S3.SS1.p4.1.m1.1.1.2.cmml">x</mi><mo id="S3.SS1.p4.1.m1.1.1.1" mathsize="90%" xref="S3.SS1.p4.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><ci id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1">~</ci><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\tilde{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">over~ start_ARG italic_x end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p4.1.2" style="font-size:90%;"> is first obtained by:</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A3.EGx1">
<tbody id="S3.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\tilde{x}\ " class="ltx_Math" display="inline" id="S3.Ex2.m1.1"><semantics id="S3.Ex2.m1.1a"><mover accent="true" id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml"><mi id="S3.Ex2.m1.1.1.2" mathsize="90%" xref="S3.Ex2.m1.1.1.2.cmml">x</mi><mo id="S3.Ex2.m1.1.1.1" mathsize="90%" xref="S3.Ex2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.1b"><apply id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1"><ci id="S3.Ex2.m1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1">~</ci><ci id="S3.Ex2.m1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.1c">\displaystyle\tilde{x}\ </annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.1d">over~ start_ARG italic_x end_ARG</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\ \mathcal{F}^{-1}(\mathcal{F}(x)\odot M)," class="ltx_Math" display="inline" id="S3.Ex2.m2.2"><semantics id="S3.Ex2.m2.2a"><mrow id="S3.Ex2.m2.2.2.1" xref="S3.Ex2.m2.2.2.1.1.cmml"><mrow id="S3.Ex2.m2.2.2.1.1" xref="S3.Ex2.m2.2.2.1.1.cmml"><mi id="S3.Ex2.m2.2.2.1.1.3" xref="S3.Ex2.m2.2.2.1.1.3.cmml"></mi><mo id="S3.Ex2.m2.2.2.1.1.2" mathsize="90%" rspace="0.728em" xref="S3.Ex2.m2.2.2.1.1.2.cmml">=</mo><mrow id="S3.Ex2.m2.2.2.1.1.1" xref="S3.Ex2.m2.2.2.1.1.1.cmml"><msup id="S3.Ex2.m2.2.2.1.1.1.3" xref="S3.Ex2.m2.2.2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m2.2.2.1.1.1.3.2" mathsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.3.2.cmml">ℱ</mi><mrow id="S3.Ex2.m2.2.2.1.1.1.3.3" xref="S3.Ex2.m2.2.2.1.1.1.3.3.cmml"><mo id="S3.Ex2.m2.2.2.1.1.1.3.3a" mathsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.3.3.cmml">−</mo><mn id="S3.Ex2.m2.2.2.1.1.1.3.3.2" mathsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.3.3.2.cmml">1</mn></mrow></msup><mo id="S3.Ex2.m2.2.2.1.1.1.2" xref="S3.Ex2.m2.2.2.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex2.m2.2.2.1.1.1.1.1" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.cmml"><mo id="S3.Ex2.m2.2.2.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex2.m2.2.2.1.1.1.1.1.1" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.2" mathsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.2.cmml">ℱ</mi><mo id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.1" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.3.2" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.cmml"><mo id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.Ex2.m2.1.1" mathsize="90%" xref="S3.Ex2.m2.1.1.cmml">x</mi><mo id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.3.2.2" maxsize="90%" minsize="90%" rspace="0.055em" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex2.m2.2.2.1.1.1.1.1.1.1" mathsize="90%" rspace="0.222em" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.1.cmml">⊙</mo><mi id="S3.Ex2.m2.2.2.1.1.1.1.1.1.3" mathsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.3.cmml">M</mi></mrow><mo id="S3.Ex2.m2.2.2.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.Ex2.m2.2.2.1.2" mathsize="90%" xref="S3.Ex2.m2.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m2.2b"><apply id="S3.Ex2.m2.2.2.1.1.cmml" xref="S3.Ex2.m2.2.2.1"><eq id="S3.Ex2.m2.2.2.1.1.2.cmml" xref="S3.Ex2.m2.2.2.1.1.2"></eq><csymbol cd="latexml" id="S3.Ex2.m2.2.2.1.1.3.cmml" xref="S3.Ex2.m2.2.2.1.1.3">absent</csymbol><apply id="S3.Ex2.m2.2.2.1.1.1.cmml" xref="S3.Ex2.m2.2.2.1.1.1"><times id="S3.Ex2.m2.2.2.1.1.1.2.cmml" xref="S3.Ex2.m2.2.2.1.1.1.2"></times><apply id="S3.Ex2.m2.2.2.1.1.1.3.cmml" xref="S3.Ex2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex2.m2.2.2.1.1.1.3.1.cmml" xref="S3.Ex2.m2.2.2.1.1.1.3">superscript</csymbol><ci id="S3.Ex2.m2.2.2.1.1.1.3.2.cmml" xref="S3.Ex2.m2.2.2.1.1.1.3.2">ℱ</ci><apply id="S3.Ex2.m2.2.2.1.1.1.3.3.cmml" xref="S3.Ex2.m2.2.2.1.1.1.3.3"><minus id="S3.Ex2.m2.2.2.1.1.1.3.3.1.cmml" xref="S3.Ex2.m2.2.2.1.1.1.3.3"></minus><cn id="S3.Ex2.m2.2.2.1.1.1.3.3.2.cmml" type="integer" xref="S3.Ex2.m2.2.2.1.1.1.3.3.2">1</cn></apply></apply><apply id="S3.Ex2.m2.2.2.1.1.1.1.1.1.cmml" xref="S3.Ex2.m2.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex2.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.1">direct-product</csymbol><apply id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2"><times id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.1"></times><ci id="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.2.2">ℱ</ci><ci id="S3.Ex2.m2.1.1.cmml" xref="S3.Ex2.m2.1.1">𝑥</ci></apply><ci id="S3.Ex2.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.Ex2.m2.2.2.1.1.1.1.1.1.3">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m2.2c">\displaystyle=\ \mathcal{F}^{-1}(\mathcal{F}(x)\odot M),</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m2.2d">= caligraphic_F start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( caligraphic_F ( italic_x ) ⊙ italic_M ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.5"><span class="ltx_text" id="S3.SS1.p6.5.1" style="font-size:90%;">where </span><math alttext="M\in\{0,1\}^{H\times W}" class="ltx_Math" display="inline" id="S3.SS1.p6.1.m1.2"><semantics id="S3.SS1.p6.1.m1.2a"><mrow id="S3.SS1.p6.1.m1.2.3" xref="S3.SS1.p6.1.m1.2.3.cmml"><mi id="S3.SS1.p6.1.m1.2.3.2" mathsize="90%" xref="S3.SS1.p6.1.m1.2.3.2.cmml">M</mi><mo id="S3.SS1.p6.1.m1.2.3.1" mathsize="90%" xref="S3.SS1.p6.1.m1.2.3.1.cmml">∈</mo><msup id="S3.SS1.p6.1.m1.2.3.3" xref="S3.SS1.p6.1.m1.2.3.3.cmml"><mrow id="S3.SS1.p6.1.m1.2.3.3.2.2" xref="S3.SS1.p6.1.m1.2.3.3.2.1.cmml"><mo id="S3.SS1.p6.1.m1.2.3.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p6.1.m1.2.3.3.2.1.cmml">{</mo><mn id="S3.SS1.p6.1.m1.1.1" mathsize="90%" xref="S3.SS1.p6.1.m1.1.1.cmml">0</mn><mo id="S3.SS1.p6.1.m1.2.3.3.2.2.2" mathsize="90%" xref="S3.SS1.p6.1.m1.2.3.3.2.1.cmml">,</mo><mn id="S3.SS1.p6.1.m1.2.2" mathsize="90%" xref="S3.SS1.p6.1.m1.2.2.cmml">1</mn><mo id="S3.SS1.p6.1.m1.2.3.3.2.2.3" maxsize="90%" minsize="90%" xref="S3.SS1.p6.1.m1.2.3.3.2.1.cmml">}</mo></mrow><mrow id="S3.SS1.p6.1.m1.2.3.3.3" xref="S3.SS1.p6.1.m1.2.3.3.3.cmml"><mi id="S3.SS1.p6.1.m1.2.3.3.3.2" mathsize="90%" xref="S3.SS1.p6.1.m1.2.3.3.3.2.cmml">H</mi><mo id="S3.SS1.p6.1.m1.2.3.3.3.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.SS1.p6.1.m1.2.3.3.3.1.cmml">×</mo><mi id="S3.SS1.p6.1.m1.2.3.3.3.3" mathsize="90%" xref="S3.SS1.p6.1.m1.2.3.3.3.3.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.2b"><apply id="S3.SS1.p6.1.m1.2.3.cmml" xref="S3.SS1.p6.1.m1.2.3"><in id="S3.SS1.p6.1.m1.2.3.1.cmml" xref="S3.SS1.p6.1.m1.2.3.1"></in><ci id="S3.SS1.p6.1.m1.2.3.2.cmml" xref="S3.SS1.p6.1.m1.2.3.2">𝑀</ci><apply id="S3.SS1.p6.1.m1.2.3.3.cmml" xref="S3.SS1.p6.1.m1.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.2.3.3.1.cmml" xref="S3.SS1.p6.1.m1.2.3.3">superscript</csymbol><set id="S3.SS1.p6.1.m1.2.3.3.2.1.cmml" xref="S3.SS1.p6.1.m1.2.3.3.2.2"><cn id="S3.SS1.p6.1.m1.1.1.cmml" type="integer" xref="S3.SS1.p6.1.m1.1.1">0</cn><cn id="S3.SS1.p6.1.m1.2.2.cmml" type="integer" xref="S3.SS1.p6.1.m1.2.2">1</cn></set><apply id="S3.SS1.p6.1.m1.2.3.3.3.cmml" xref="S3.SS1.p6.1.m1.2.3.3.3"><times id="S3.SS1.p6.1.m1.2.3.3.3.1.cmml" xref="S3.SS1.p6.1.m1.2.3.3.3.1"></times><ci id="S3.SS1.p6.1.m1.2.3.3.3.2.cmml" xref="S3.SS1.p6.1.m1.2.3.3.3.2">𝐻</ci><ci id="S3.SS1.p6.1.m1.2.3.3.3.3.cmml" xref="S3.SS1.p6.1.m1.2.3.3.3.3">𝑊</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.2c">M\in\{0,1\}^{H\times W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.1.m1.2d">italic_M ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_H × italic_W end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p6.5.2" style="font-size:90%;"> is a mask, with </span><math alttext="0" class="ltx_Math" display="inline" id="S3.SS1.p6.2.m2.1"><semantics id="S3.SS1.p6.2.m2.1a"><mn id="S3.SS1.p6.2.m2.1.1" mathsize="90%" xref="S3.SS1.p6.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.1b"><cn id="S3.SS1.p6.2.m2.1.1.cmml" type="integer" xref="S3.SS1.p6.2.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="S3.SS1.p6.5.3" style="font-size:90%;"> denoting corresponding frequencies being masked and </span><math alttext="1" class="ltx_Math" display="inline" id="S3.SS1.p6.3.m3.1"><semantics id="S3.SS1.p6.3.m3.1a"><mn id="S3.SS1.p6.3.m3.1.1" mathsize="90%" xref="S3.SS1.p6.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><cn id="S3.SS1.p6.3.m3.1.1.cmml" type="integer" xref="S3.SS1.p6.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.3.m3.1d">1</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p6.5.4" style="font-size:90%;"> denoting frequencies being retained. </span><math alttext="\mathcal{F}^{-1}" class="ltx_Math" display="inline" id="S3.SS1.p6.4.m4.1"><semantics id="S3.SS1.p6.4.m4.1a"><msup id="S3.SS1.p6.4.m4.1.1" xref="S3.SS1.p6.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p6.4.m4.1.1.2" mathsize="90%" xref="S3.SS1.p6.4.m4.1.1.2.cmml">ℱ</mi><mrow id="S3.SS1.p6.4.m4.1.1.3" xref="S3.SS1.p6.4.m4.1.1.3.cmml"><mo id="S3.SS1.p6.4.m4.1.1.3a" mathsize="90%" xref="S3.SS1.p6.4.m4.1.1.3.cmml">−</mo><mn id="S3.SS1.p6.4.m4.1.1.3.2" mathsize="90%" xref="S3.SS1.p6.4.m4.1.1.3.2.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m4.1b"><apply id="S3.SS1.p6.4.m4.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.1.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p6.4.m4.1.1.2.cmml" xref="S3.SS1.p6.4.m4.1.1.2">ℱ</ci><apply id="S3.SS1.p6.4.m4.1.1.3.cmml" xref="S3.SS1.p6.4.m4.1.1.3"><minus id="S3.SS1.p6.4.m4.1.1.3.1.cmml" xref="S3.SS1.p6.4.m4.1.1.3"></minus><cn id="S3.SS1.p6.4.m4.1.1.3.2.cmml" type="integer" xref="S3.SS1.p6.4.m4.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m4.1c">\mathcal{F}^{-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.4.m4.1d">caligraphic_F start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p6.5.5" style="font-size:90%;"> denotes the inverse Fourier transform operation, and </span><math alttext="\odot" class="ltx_Math" display="inline" id="S3.SS1.p6.5.m5.1"><semantics id="S3.SS1.p6.5.m5.1a"><mo id="S3.SS1.p6.5.m5.1.1" mathsize="90%" xref="S3.SS1.p6.5.m5.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.5.m5.1b"><csymbol cd="latexml" id="S3.SS1.p6.5.m5.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.5.m5.1c">\odot</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.5.m5.1d">⊙</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p6.5.6" style="font-size:90%;"> signifies element-wise multiplication. The learning objective of MFM, designed to minimize the discrepancy between the reconstructed and the original frequency components, can then be written as:</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{MFM}=\|(\mathcal{F}(x)-\mathcal{F}(g_{\theta}(\tilde{x})))\odot(%
\mathbbm{1}-M)\|_{2}," class="ltx_Math" display="block" id="S3.Ex3.m1.3"><semantics id="S3.Ex3.m1.3a"><mrow id="S3.Ex3.m1.3.3.1" xref="S3.Ex3.m1.3.3.1.1.cmml"><mrow id="S3.Ex3.m1.3.3.1.1" xref="S3.Ex3.m1.3.3.1.1.cmml"><msub id="S3.Ex3.m1.3.3.1.1.3" xref="S3.Ex3.m1.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex3.m1.3.3.1.1.3.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.3.2.cmml">ℒ</mi><mrow id="S3.Ex3.m1.3.3.1.1.3.3" xref="S3.Ex3.m1.3.3.1.1.3.3.cmml"><mi id="S3.Ex3.m1.3.3.1.1.3.3.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.3.3.2.cmml">M</mi><mo id="S3.Ex3.m1.3.3.1.1.3.3.1" xref="S3.Ex3.m1.3.3.1.1.3.3.1.cmml">⁢</mo><mi id="S3.Ex3.m1.3.3.1.1.3.3.3" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.3.3.3.cmml">F</mi><mo id="S3.Ex3.m1.3.3.1.1.3.3.1a" xref="S3.Ex3.m1.3.3.1.1.3.3.1.cmml">⁢</mo><mi id="S3.Ex3.m1.3.3.1.1.3.3.4" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.3.3.4.cmml">M</mi></mrow></msub><mo id="S3.Ex3.m1.3.3.1.1.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.2.cmml">=</mo><msub id="S3.Ex3.m1.3.3.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.cmml"><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">ℱ</mi><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="S3.Ex3.m1.1.1" mathsize="90%" xref="S3.Ex3.m1.1.1.cmml">x</mi><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.2.2" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml">ℱ</mi><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">g</mi><mi id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">θ</mi></msub><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex3.m1.2.2.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.2.2.cmml">(</mo><mover accent="true" id="S3.Ex3.m1.2.2" xref="S3.Ex3.m1.2.2.cmml"><mi id="S3.Ex3.m1.2.2.2" mathsize="90%" xref="S3.Ex3.m1.2.2.2.cmml">x</mi><mo id="S3.Ex3.m1.2.2.1" mathsize="90%" xref="S3.Ex3.m1.2.2.1.cmml">~</mo></mover><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" rspace="0.055em" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.3" mathsize="90%" rspace="0.222em" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.3.cmml">⊙</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.cmml"><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.2" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.cmml"><mn id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.2.cmml">𝟙</mn><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.1" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml">−</mo><mi id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.3" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.3.cmml">M</mi></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.3" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex3.m1.3.3.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.Ex3.m1.3.3.1.1.1.3" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.1.3.cmml">2</mn></msub></mrow><mo id="S3.Ex3.m1.3.3.1.2" mathsize="90%" xref="S3.Ex3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.3b"><apply id="S3.Ex3.m1.3.3.1.1.cmml" xref="S3.Ex3.m1.3.3.1"><eq id="S3.Ex3.m1.3.3.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.2"></eq><apply id="S3.Ex3.m1.3.3.1.1.3.cmml" xref="S3.Ex3.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.3.3.1.1.3.1.cmml" xref="S3.Ex3.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.Ex3.m1.3.3.1.1.3.2.cmml" xref="S3.Ex3.m1.3.3.1.1.3.2">ℒ</ci><apply id="S3.Ex3.m1.3.3.1.1.3.3.cmml" xref="S3.Ex3.m1.3.3.1.1.3.3"><times id="S3.Ex3.m1.3.3.1.1.3.3.1.cmml" xref="S3.Ex3.m1.3.3.1.1.3.3.1"></times><ci id="S3.Ex3.m1.3.3.1.1.3.3.2.cmml" xref="S3.Ex3.m1.3.3.1.1.3.3.2">𝑀</ci><ci id="S3.Ex3.m1.3.3.1.1.3.3.3.cmml" xref="S3.Ex3.m1.3.3.1.1.3.3.3">𝐹</ci><ci id="S3.Ex3.m1.3.3.1.1.3.3.4.cmml" xref="S3.Ex3.m1.3.3.1.1.3.3.4">𝑀</ci></apply></apply><apply id="S3.Ex3.m1.3.3.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.Ex3.m1.3.3.1.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1">subscript</csymbol><apply id="S3.Ex3.m1.3.3.1.1.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex3.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.2">norm</csymbol><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex3.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.3">direct-product</csymbol><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1"><minus id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3"><times id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">ℱ</ci><ci id="S3.Ex3.m1.1.1.cmml" xref="S3.Ex3.m1.1.1">𝑥</ci></apply><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1"><times id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">ℱ</ci><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑔</ci><ci id="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝜃</ci></apply><apply id="S3.Ex3.m1.2.2.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.Ex3.m1.2.2.1.cmml" xref="S3.Ex3.m1.2.2.1">~</ci><ci id="S3.Ex3.m1.2.2.2.cmml" xref="S3.Ex3.m1.2.2.2">𝑥</ci></apply></apply></apply></apply><apply id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1"><minus id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.1"></minus><cn id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.2.cmml" type="integer" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.2">1</cn><ci id="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.3.cmml" xref="S3.Ex3.m1.3.3.1.1.1.1.1.1.2.1.1.3">𝑀</ci></apply></apply></apply><cn id="S3.Ex3.m1.3.3.1.1.1.3.cmml" type="integer" xref="S3.Ex3.m1.3.3.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.3c">\mathcal{L}_{MFM}=\|(\mathcal{F}(x)-\mathcal{F}(g_{\theta}(\tilde{x})))\odot(%
\mathbbm{1}-M)\|_{2},</annotation><annotation encoding="application/x-llamapun" id="S3.Ex3.m1.3d">caligraphic_L start_POSTSUBSCRIPT italic_M italic_F italic_M end_POSTSUBSCRIPT = ∥ ( caligraphic_F ( italic_x ) - caligraphic_F ( italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( over~ start_ARG italic_x end_ARG ) ) ) ⊙ ( blackboard_1 - italic_M ) ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.5"><span class="ltx_text" id="S3.SS1.p8.5.1" style="font-size:90%;">where </span><math alttext="\mathcal{F}(x)" class="ltx_Math" display="inline" id="S3.SS1.p8.1.m1.1"><semantics id="S3.SS1.p8.1.m1.1a"><mrow id="S3.SS1.p8.1.m1.1.2" xref="S3.SS1.p8.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p8.1.m1.1.2.2" mathsize="90%" xref="S3.SS1.p8.1.m1.1.2.2.cmml">ℱ</mi><mo id="S3.SS1.p8.1.m1.1.2.1" xref="S3.SS1.p8.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p8.1.m1.1.2.3.2" xref="S3.SS1.p8.1.m1.1.2.cmml"><mo id="S3.SS1.p8.1.m1.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p8.1.m1.1.2.cmml">(</mo><mi id="S3.SS1.p8.1.m1.1.1" mathsize="90%" xref="S3.SS1.p8.1.m1.1.1.cmml">x</mi><mo id="S3.SS1.p8.1.m1.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS1.p8.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.1.m1.1b"><apply id="S3.SS1.p8.1.m1.1.2.cmml" xref="S3.SS1.p8.1.m1.1.2"><times id="S3.SS1.p8.1.m1.1.2.1.cmml" xref="S3.SS1.p8.1.m1.1.2.1"></times><ci id="S3.SS1.p8.1.m1.1.2.2.cmml" xref="S3.SS1.p8.1.m1.1.2.2">ℱ</ci><ci id="S3.SS1.p8.1.m1.1.1.cmml" xref="S3.SS1.p8.1.m1.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.1.m1.1c">\mathcal{F}(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.1.m1.1d">caligraphic_F ( italic_x )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p8.5.2" style="font-size:90%;"> is the frequency spectrum of the original image, </span><math alttext="\mathcal{F}_{r}(\tilde{x})" class="ltx_Math" display="inline" id="S3.SS1.p8.2.m2.1"><semantics id="S3.SS1.p8.2.m2.1a"><mrow id="S3.SS1.p8.2.m2.1.2" xref="S3.SS1.p8.2.m2.1.2.cmml"><msub id="S3.SS1.p8.2.m2.1.2.2" xref="S3.SS1.p8.2.m2.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p8.2.m2.1.2.2.2" mathsize="90%" xref="S3.SS1.p8.2.m2.1.2.2.2.cmml">ℱ</mi><mi id="S3.SS1.p8.2.m2.1.2.2.3" mathsize="90%" xref="S3.SS1.p8.2.m2.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS1.p8.2.m2.1.2.1" xref="S3.SS1.p8.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS1.p8.2.m2.1.2.3.2" xref="S3.SS1.p8.2.m2.1.1.cmml"><mo id="S3.SS1.p8.2.m2.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS1.p8.2.m2.1.1.cmml">(</mo><mover accent="true" id="S3.SS1.p8.2.m2.1.1" xref="S3.SS1.p8.2.m2.1.1.cmml"><mi id="S3.SS1.p8.2.m2.1.1.2" mathsize="90%" xref="S3.SS1.p8.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS1.p8.2.m2.1.1.1" mathsize="90%" xref="S3.SS1.p8.2.m2.1.1.1.cmml">~</mo></mover><mo id="S3.SS1.p8.2.m2.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS1.p8.2.m2.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.2.m2.1b"><apply id="S3.SS1.p8.2.m2.1.2.cmml" xref="S3.SS1.p8.2.m2.1.2"><times id="S3.SS1.p8.2.m2.1.2.1.cmml" xref="S3.SS1.p8.2.m2.1.2.1"></times><apply id="S3.SS1.p8.2.m2.1.2.2.cmml" xref="S3.SS1.p8.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p8.2.m2.1.2.2.1.cmml" xref="S3.SS1.p8.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS1.p8.2.m2.1.2.2.2.cmml" xref="S3.SS1.p8.2.m2.1.2.2.2">ℱ</ci><ci id="S3.SS1.p8.2.m2.1.2.2.3.cmml" xref="S3.SS1.p8.2.m2.1.2.2.3">𝑟</ci></apply><apply id="S3.SS1.p8.2.m2.1.1.cmml" xref="S3.SS1.p8.2.m2.1.2.3.2"><ci id="S3.SS1.p8.2.m2.1.1.1.cmml" xref="S3.SS1.p8.2.m2.1.1.1">~</ci><ci id="S3.SS1.p8.2.m2.1.1.2.cmml" xref="S3.SS1.p8.2.m2.1.1.2">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.2.m2.1c">\mathcal{F}_{r}(\tilde{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.2.m2.1d">caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( over~ start_ARG italic_x end_ARG )</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p8.5.3" style="font-size:90%;"> is the reconstructed spectrum using a neural network model </span><math alttext="g_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p8.3.m3.1"><semantics id="S3.SS1.p8.3.m3.1a"><msub id="S3.SS1.p8.3.m3.1.1" xref="S3.SS1.p8.3.m3.1.1.cmml"><mi id="S3.SS1.p8.3.m3.1.1.2" mathsize="90%" xref="S3.SS1.p8.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS1.p8.3.m3.1.1.3" mathsize="90%" xref="S3.SS1.p8.3.m3.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.3.m3.1b"><apply id="S3.SS1.p8.3.m3.1.1.cmml" xref="S3.SS1.p8.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p8.3.m3.1.1.1.cmml" xref="S3.SS1.p8.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p8.3.m3.1.1.2.cmml" xref="S3.SS1.p8.3.m3.1.1.2">𝑔</ci><ci id="S3.SS1.p8.3.m3.1.1.3.cmml" xref="S3.SS1.p8.3.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.3.m3.1c">g_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p8.5.4" style="font-size:90%;">, parameterized by </span><math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS1.p8.4.m4.1"><semantics id="S3.SS1.p8.4.m4.1a"><mi id="S3.SS1.p8.4.m4.1.1" mathsize="90%" xref="S3.SS1.p8.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.4.m4.1b"><ci id="S3.SS1.p8.4.m4.1.1.cmml" xref="S3.SS1.p8.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.4.m4.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.4.m4.1d">italic_θ</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p8.5.5" style="font-size:90%;">. And </span><math alttext="\mathbbm{1}-M" class="ltx_Math" display="inline" id="S3.SS1.p8.5.m5.1"><semantics id="S3.SS1.p8.5.m5.1a"><mrow id="S3.SS1.p8.5.m5.1.1" xref="S3.SS1.p8.5.m5.1.1.cmml"><mn id="S3.SS1.p8.5.m5.1.1.2" mathsize="90%" xref="S3.SS1.p8.5.m5.1.1.2.cmml">𝟙</mn><mo id="S3.SS1.p8.5.m5.1.1.1" mathsize="90%" xref="S3.SS1.p8.5.m5.1.1.1.cmml">−</mo><mi id="S3.SS1.p8.5.m5.1.1.3" mathsize="90%" xref="S3.SS1.p8.5.m5.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.5.m5.1b"><apply id="S3.SS1.p8.5.m5.1.1.cmml" xref="S3.SS1.p8.5.m5.1.1"><minus id="S3.SS1.p8.5.m5.1.1.1.cmml" xref="S3.SS1.p8.5.m5.1.1.1"></minus><cn id="S3.SS1.p8.5.m5.1.1.2.cmml" type="integer" xref="S3.SS1.p8.5.m5.1.1.2">1</cn><ci id="S3.SS1.p8.5.m5.1.1.3.cmml" xref="S3.SS1.p8.5.m5.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.5.m5.1c">\mathbbm{1}-M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p8.5.m5.1d">blackboard_1 - italic_M</annotation></semantics></math><span class="ltx_text" id="S3.SS1.p8.5.6" style="font-size:90%;"> indicates that only the masked areas of the frequency spectrum are considered for loss.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>FOLK Framework</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2"><span class="ltx_text" id="S3.SS2.p1.2.1" style="font-size:90%;">Before introducing our proposed method, we start by re-emphasizing the MFM method </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.p1.2.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS2.p1.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS2.p1.2.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.p1.2.5" style="font-size:90%;"> limitations. Firstly, notice that, in Eq. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.Ex3" style="font-size:90%;" title="In 3.1 Preliminary and Background ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS2.p1.2.6" style="font-size:90%;">, the MFM’s loss depends on the filter </span><math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" mathsize="90%" xref="S3.SS2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_M</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p1.2.7" style="font-size:90%;"> applied to the spectrum. However, the low/high-pass filters used in MFM are simple, using a circular area with a fixed radius (see Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S1.F1" style="font-size:90%;" title="Figure 1 ‣ 1 Introduction ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS2.p1.2.8" style="font-size:90%;">). This can lessen the difficulty of the frequency reconstruction task hence hampering the model learning. Another limitation of MFM is that the model only sees frequency-masked images in the pre-training stage, expressed by </span><math alttext="g_{\theta}(\tilde{x})" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.2" xref="S3.SS2.p1.2.m2.1.2.cmml"><msub id="S3.SS2.p1.2.m2.1.2.2" xref="S3.SS2.p1.2.m2.1.2.2.cmml"><mi id="S3.SS2.p1.2.m2.1.2.2.2" mathsize="90%" xref="S3.SS2.p1.2.m2.1.2.2.2.cmml">g</mi><mi id="S3.SS2.p1.2.m2.1.2.2.3" mathsize="90%" xref="S3.SS2.p1.2.m2.1.2.2.3.cmml">θ</mi></msub><mo id="S3.SS2.p1.2.m2.1.2.1" xref="S3.SS2.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.p1.2.m2.1.2.3.2" xref="S3.SS2.p1.2.m2.1.1.cmml"><mo id="S3.SS2.p1.2.m2.1.2.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS2.p1.2.m2.1.1.cmml">(</mo><mover accent="true" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" mathsize="90%" xref="S3.SS2.p1.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS2.p1.2.m2.1.1.1" mathsize="90%" xref="S3.SS2.p1.2.m2.1.1.1.cmml">~</mo></mover><mo id="S3.SS2.p1.2.m2.1.2.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS2.p1.2.m2.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.2.cmml" xref="S3.SS2.p1.2.m2.1.2"><times id="S3.SS2.p1.2.m2.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.2.1"></times><apply id="S3.SS2.p1.2.m2.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.2.2.1.cmml" xref="S3.SS2.p1.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.2.2.2.cmml" xref="S3.SS2.p1.2.m2.1.2.2.2">𝑔</ci><ci id="S3.SS2.p1.2.m2.1.2.2.3.cmml" xref="S3.SS2.p1.2.m2.1.2.2.3">𝜃</ci></apply><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.2.3.2"><ci id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1">~</ci><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">g_{\theta}(\tilde{x})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( over~ start_ARG italic_x end_ARG )</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p1.2.9" style="font-size:90%;"> in Eq. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.Ex3" style="font-size:90%;" title="In 3.1 Preliminary and Background ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS2.p1.2.10" style="font-size:90%;">. As a result, the pre-trained model may be relatively unfamiliar with natural images and requires more data during fine-tuning to adapt effectively (see Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS2" style="font-size:90%;" title="4.2.2 Few Shot Learning ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4.2.2</span></a><span class="ltx_text" id="S3.SS2.p1.2.11" style="font-size:90%;">).</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.2"><span class="ltx_text" id="S3.SS2.p2.2.1" style="font-size:90%;">To overcome these limitations and achieve effective masked frequency modeling, we propose the FOLK framework. Our key ideas involve the creation of informed frequency-based filters, </span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" mathsize="90%" xref="S3.SS2.p2.1.m1.1.1.2.cmml">C</mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.p2.1.m1.1.1.3.cmml">o</mi><mo id="S3.SS2.p2.1.m1.1.1.1a" xref="S3.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.1.m1.1.1.4" mathsize="90%" xref="S3.SS2.p2.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><times id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></times><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝐶</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">𝑜</ci><ci id="S3.SS2.p2.1.m1.1.1.4.cmml" xref="S3.SS2.p2.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p2.2.2" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" mathsize="90%" xref="S3.SS2.p2.2.m2.1.1.2.cmml">R</mi><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3" mathsize="90%" xref="S3.SS2.p2.2.m2.1.1.3.cmml">C</mi><mo id="S3.SS2.p2.2.m2.1.1.1a" xref="S3.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.4" mathsize="90%" xref="S3.SS2.p2.2.m2.1.1.4.cmml">o</mi><mo id="S3.SS2.p2.2.m2.1.1.1b" xref="S3.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.5" mathsize="90%" xref="S3.SS2.p2.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><times id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1"></times><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑅</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝐶</ci><ci id="S3.SS2.p2.2.m2.1.1.4.cmml" xref="S3.SS2.p2.2.m2.1.1.4">𝑜</ci><ci id="S3.SS2.p2.2.m2.1.1.5.cmml" xref="S3.SS2.p2.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p2.2.3" style="font-size:90%;">, as well as a self-distillation strategy based on a teacher-student design.</span></p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Informed Filters</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1"><span class="ltx_text" id="S3.SS2.SSS1.p1.1.1" style="font-size:90%;">Successful vision pre-training largely depends on the suitable and challenging enough pretext task presented to the model. Demonstrated by AttMask </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS1.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S3.SS2.SSS1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S3.SS2.SSS1.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS1.p1.1.5" style="font-size:90%;">, masking the most-attended patches in images creates a more effective training scheme than random masking for MIM approaches. However, for MFM methods, this gap still exists as only constant masking/filters have been explored </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS1.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS2.SSS1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS2.SSS1.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS1.p1.1.9" style="font-size:90%;">, which presumably presents a less challenging task in the pre-training.</span></p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="205" id="S3.F2.g1" src="extracted/5858280/images_folder/filters.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The frequency-based filtering process with our proposed informed filters, <math alttext="Com" class="ltx_Math" display="inline" id="S3.F2.5.m1.1"><semantics id="S3.F2.5.m1.1b"><mrow id="S3.F2.5.m1.1.1" xref="S3.F2.5.m1.1.1.cmml"><mi id="S3.F2.5.m1.1.1.2" xref="S3.F2.5.m1.1.1.2.cmml">C</mi><mo id="S3.F2.5.m1.1.1.1" xref="S3.F2.5.m1.1.1.1.cmml">⁢</mo><mi id="S3.F2.5.m1.1.1.3" xref="S3.F2.5.m1.1.1.3.cmml">o</mi><mo id="S3.F2.5.m1.1.1.1b" xref="S3.F2.5.m1.1.1.1.cmml">⁢</mo><mi id="S3.F2.5.m1.1.1.4" xref="S3.F2.5.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.5.m1.1c"><apply id="S3.F2.5.m1.1.1.cmml" xref="S3.F2.5.m1.1.1"><times id="S3.F2.5.m1.1.1.1.cmml" xref="S3.F2.5.m1.1.1.1"></times><ci id="S3.F2.5.m1.1.1.2.cmml" xref="S3.F2.5.m1.1.1.2">𝐶</ci><ci id="S3.F2.5.m1.1.1.3.cmml" xref="S3.F2.5.m1.1.1.3">𝑜</ci><ci id="S3.F2.5.m1.1.1.4.cmml" xref="S3.F2.5.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="S3.F2.5.m1.1e">italic_C italic_o italic_m</annotation></semantics></math> and <math alttext="RCom" class="ltx_Math" display="inline" id="S3.F2.6.m2.1"><semantics id="S3.F2.6.m2.1b"><mrow id="S3.F2.6.m2.1.1" xref="S3.F2.6.m2.1.1.cmml"><mi id="S3.F2.6.m2.1.1.2" xref="S3.F2.6.m2.1.1.2.cmml">R</mi><mo id="S3.F2.6.m2.1.1.1" xref="S3.F2.6.m2.1.1.1.cmml">⁢</mo><mi id="S3.F2.6.m2.1.1.3" xref="S3.F2.6.m2.1.1.3.cmml">C</mi><mo id="S3.F2.6.m2.1.1.1b" xref="S3.F2.6.m2.1.1.1.cmml">⁢</mo><mi id="S3.F2.6.m2.1.1.4" xref="S3.F2.6.m2.1.1.4.cmml">o</mi><mo id="S3.F2.6.m2.1.1.1c" xref="S3.F2.6.m2.1.1.1.cmml">⁢</mo><mi id="S3.F2.6.m2.1.1.5" xref="S3.F2.6.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.6.m2.1c"><apply id="S3.F2.6.m2.1.1.cmml" xref="S3.F2.6.m2.1.1"><times id="S3.F2.6.m2.1.1.1.cmml" xref="S3.F2.6.m2.1.1.1"></times><ci id="S3.F2.6.m2.1.1.2.cmml" xref="S3.F2.6.m2.1.1.2">𝑅</ci><ci id="S3.F2.6.m2.1.1.3.cmml" xref="S3.F2.6.m2.1.1.3">𝐶</ci><ci id="S3.F2.6.m2.1.1.4.cmml" xref="S3.F2.6.m2.1.1.4">𝑜</ci><ci id="S3.F2.6.m2.1.1.5.cmml" xref="S3.F2.6.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m2.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.F2.6.m2.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math>. A portion of frequencies with the highest magnitude will be determined to create the masks. The process randomly returns the resulting image from the <math alttext="Com" class="ltx_Math" display="inline" id="S3.F2.7.m3.1"><semantics id="S3.F2.7.m3.1b"><mrow id="S3.F2.7.m3.1.1" xref="S3.F2.7.m3.1.1.cmml"><mi id="S3.F2.7.m3.1.1.2" xref="S3.F2.7.m3.1.1.2.cmml">C</mi><mo id="S3.F2.7.m3.1.1.1" xref="S3.F2.7.m3.1.1.1.cmml">⁢</mo><mi id="S3.F2.7.m3.1.1.3" xref="S3.F2.7.m3.1.1.3.cmml">o</mi><mo id="S3.F2.7.m3.1.1.1b" xref="S3.F2.7.m3.1.1.1.cmml">⁢</mo><mi id="S3.F2.7.m3.1.1.4" xref="S3.F2.7.m3.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.7.m3.1c"><apply id="S3.F2.7.m3.1.1.cmml" xref="S3.F2.7.m3.1.1"><times id="S3.F2.7.m3.1.1.1.cmml" xref="S3.F2.7.m3.1.1.1"></times><ci id="S3.F2.7.m3.1.1.2.cmml" xref="S3.F2.7.m3.1.1.2">𝐶</ci><ci id="S3.F2.7.m3.1.1.3.cmml" xref="S3.F2.7.m3.1.1.3">𝑜</ci><ci id="S3.F2.7.m3.1.1.4.cmml" xref="S3.F2.7.m3.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.7.m3.1d">Com</annotation><annotation encoding="application/x-llamapun" id="S3.F2.7.m3.1e">italic_C italic_o italic_m</annotation></semantics></math> or <math alttext="RCom" class="ltx_Math" display="inline" id="S3.F2.8.m4.1"><semantics id="S3.F2.8.m4.1b"><mrow id="S3.F2.8.m4.1.1" xref="S3.F2.8.m4.1.1.cmml"><mi id="S3.F2.8.m4.1.1.2" xref="S3.F2.8.m4.1.1.2.cmml">R</mi><mo id="S3.F2.8.m4.1.1.1" xref="S3.F2.8.m4.1.1.1.cmml">⁢</mo><mi id="S3.F2.8.m4.1.1.3" xref="S3.F2.8.m4.1.1.3.cmml">C</mi><mo id="S3.F2.8.m4.1.1.1b" xref="S3.F2.8.m4.1.1.1.cmml">⁢</mo><mi id="S3.F2.8.m4.1.1.4" xref="S3.F2.8.m4.1.1.4.cmml">o</mi><mo id="S3.F2.8.m4.1.1.1c" xref="S3.F2.8.m4.1.1.1.cmml">⁢</mo><mi id="S3.F2.8.m4.1.1.5" xref="S3.F2.8.m4.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.8.m4.1c"><apply id="S3.F2.8.m4.1.1.cmml" xref="S3.F2.8.m4.1.1"><times id="S3.F2.8.m4.1.1.1.cmml" xref="S3.F2.8.m4.1.1.1"></times><ci id="S3.F2.8.m4.1.1.2.cmml" xref="S3.F2.8.m4.1.1.2">𝑅</ci><ci id="S3.F2.8.m4.1.1.3.cmml" xref="S3.F2.8.m4.1.1.3">𝐶</ci><ci id="S3.F2.8.m4.1.1.4.cmml" xref="S3.F2.8.m4.1.1.4">𝑜</ci><ci id="S3.F2.8.m4.1.1.5.cmml" xref="S3.F2.8.m4.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.8.m4.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.F2.8.m4.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> filter.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.4"><span class="ltx_text" id="S3.SS2.SSS1.p2.4.1" style="font-size:90%;">To bridge this gap, we introduce two types of filters, </span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.1.m1.1"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><mrow id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p2.1.m1.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS1.p2.1.m1.1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml">o</mi><mo id="S3.SS2.SSS1.p2.1.m1.1.1.1a" xref="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.1.m1.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p2.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><apply id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1"><times id="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.1"></times><ci id="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.3">𝑜</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.4.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p2.4.2" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.2.m2.1"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><mrow id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml">R</mi><mo id="S3.SS2.SSS1.p2.2.m2.1.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.2.m2.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml">C</mi><mo id="S3.SS2.SSS1.p2.2.m2.1.1.1a" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.2.m2.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p2.2.m2.1.1.4.cmml">o</mi><mo id="S3.SS2.SSS1.p2.2.m2.1.1.1b" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.2.m2.1.1.5" mathsize="90%" xref="S3.SS2.SSS1.p2.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><apply id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1"><times id="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1"></times><ci id="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.2">𝑅</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.3">𝐶</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.4.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.4">𝑜</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.5.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p2.4.3" style="font-size:90%;">, for informed masking. Inspired by Fourier image compression techniques </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS1.p2.4.4.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Pratt et al.</span><span class="ltx_text" id="S3.SS2.SSS1.p2.4.5.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">1969</span></a><span class="ltx_text" id="S3.SS2.SSS1.p2.4.6.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS1.p2.4.7" style="font-size:90%;">, where the most significant frequencies (those with the highest magnitudes) that carry the bulk of an image’s visual information are preserved while other frequencies are discarded for efficient storage or bandwidth usage, our </span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.3.m3.1"><semantics id="S3.SS2.SSS1.p2.3.m3.1a"><mrow id="S3.SS2.SSS1.p2.3.m3.1.1" xref="S3.SS2.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p2.3.m3.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p2.3.m3.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS1.p2.3.m3.1.1.1" xref="S3.SS2.SSS1.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.3.m3.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p2.3.m3.1.1.3.cmml">o</mi><mo id="S3.SS2.SSS1.p2.3.m3.1.1.1a" xref="S3.SS2.SSS1.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.3.m3.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p2.3.m3.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.3.m3.1b"><apply id="S3.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1"><times id="S3.SS2.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1.1"></times><ci id="S3.SS2.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1.3">𝑜</ci><ci id="S3.SS2.SSS1.p2.3.m3.1.1.4.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.3.m3.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.3.m3.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p2.4.8" style="font-size:90%;"> filters selectively retain these significant frequencies and discard the rest. This approach highlights the main semantics of an image for the model and necessitates the reconstruction of the less significant frequencies that correspond to finer details, such as edges. Conversely, </span><math alttext="RCom" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.4.m4.1"><semantics id="S3.SS2.SSS1.p2.4.m4.1a"><mrow id="S3.SS2.SSS1.p2.4.m4.1.1" xref="S3.SS2.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p2.4.m4.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p2.4.m4.1.1.2.cmml">R</mi><mo id="S3.SS2.SSS1.p2.4.m4.1.1.1" xref="S3.SS2.SSS1.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.4.m4.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p2.4.m4.1.1.3.cmml">C</mi><mo id="S3.SS2.SSS1.p2.4.m4.1.1.1a" xref="S3.SS2.SSS1.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.4.m4.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p2.4.m4.1.1.4.cmml">o</mi><mo id="S3.SS2.SSS1.p2.4.m4.1.1.1b" xref="S3.SS2.SSS1.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.4.m4.1.1.5" mathsize="90%" xref="S3.SS2.SSS1.p2.4.m4.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.4.m4.1b"><apply id="S3.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1"><times id="S3.SS2.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.1"></times><ci id="S3.SS2.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.2">𝑅</ci><ci id="S3.SS2.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.3">𝐶</ci><ci id="S3.SS2.SSS1.p2.4.m4.1.1.4.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.4">𝑜</ci><ci id="S3.SS2.SSS1.p2.4.m4.1.1.5.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.4.m4.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.4.m4.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p2.4.9" style="font-size:90%;"> filters remove the significant frequencies and require their reconstruction from the finer details preserved by the less significant frequencies. By applying both filter types during pre-training, the model is effectively trained to comprehend both macro and micro visual cues, thereby enhancing its generalizability and effectiveness in downstream tasks.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.8"><span class="ltx_text" id="S3.SS2.SSS1.p3.8.1" style="font-size:90%;">The generation of </span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.1.m1.1"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mrow id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml">o</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1a" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p3.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><times id="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1"></times><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3">𝑜</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.4.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.2" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.2.m2.1"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><mrow id="S3.SS2.SSS1.p3.2.m2.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p3.2.m2.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml">R</mi><mo id="S3.SS2.SSS1.p3.2.m2.1.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.2.m2.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml">C</mi><mo id="S3.SS2.SSS1.p3.2.m2.1.1.1a" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.2.m2.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p3.2.m2.1.1.4.cmml">o</mi><mo id="S3.SS2.SSS1.p3.2.m2.1.1.1b" xref="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.2.m2.1.1.5" mathsize="90%" xref="S3.SS2.SSS1.p3.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><apply id="S3.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1"><times id="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.1"></times><ci id="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.2">𝑅</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.3">𝐶</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.4.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.4">𝑜</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.5.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.3" style="font-size:90%;"> filters is illustrated in Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.F2" style="font-size:90%;" title="Figure 2 ‣ 3.2.1 Informed Filters ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS2.SSS1.p3.8.4" style="font-size:90%;">. The input image is first converted to grayscale to ensure the creation of a single common filter for all three RGB channels, as generating and applying filters separately to each channel can result in unnatural and corrupted visual information. The image is converted to a frequency spectrum using 2D FFT, and then the frequency components with the highest magnitudes are identified according to a threshold, which is uniformly sampled from a set of values (</span><math alttext="[0.005,0.01,0.05]" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.3.m3.3"><semantics id="S3.SS2.SSS1.p3.3.m3.3a"><mrow id="S3.SS2.SSS1.p3.3.m3.3.4.2" xref="S3.SS2.SSS1.p3.3.m3.3.4.1.cmml"><mo id="S3.SS2.SSS1.p3.3.m3.3.4.2.1" maxsize="90%" minsize="90%" xref="S3.SS2.SSS1.p3.3.m3.3.4.1.cmml">[</mo><mn id="S3.SS2.SSS1.p3.3.m3.1.1" mathsize="90%" xref="S3.SS2.SSS1.p3.3.m3.1.1.cmml">0.005</mn><mo id="S3.SS2.SSS1.p3.3.m3.3.4.2.2" mathsize="90%" xref="S3.SS2.SSS1.p3.3.m3.3.4.1.cmml">,</mo><mn id="S3.SS2.SSS1.p3.3.m3.2.2" mathsize="90%" xref="S3.SS2.SSS1.p3.3.m3.2.2.cmml">0.01</mn><mo id="S3.SS2.SSS1.p3.3.m3.3.4.2.3" mathsize="90%" xref="S3.SS2.SSS1.p3.3.m3.3.4.1.cmml">,</mo><mn id="S3.SS2.SSS1.p3.3.m3.3.3" mathsize="90%" xref="S3.SS2.SSS1.p3.3.m3.3.3.cmml">0.05</mn><mo id="S3.SS2.SSS1.p3.3.m3.3.4.2.4" maxsize="90%" minsize="90%" xref="S3.SS2.SSS1.p3.3.m3.3.4.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.m3.3b"><list id="S3.SS2.SSS1.p3.3.m3.3.4.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.4.2"><cn id="S3.SS2.SSS1.p3.3.m3.1.1.cmml" type="float" xref="S3.SS2.SSS1.p3.3.m3.1.1">0.005</cn><cn id="S3.SS2.SSS1.p3.3.m3.2.2.cmml" type="float" xref="S3.SS2.SSS1.p3.3.m3.2.2">0.01</cn><cn id="S3.SS2.SSS1.p3.3.m3.3.3.cmml" type="float" xref="S3.SS2.SSS1.p3.3.m3.3.3">0.05</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.m3.3c">[0.005,0.01,0.05]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.3.m3.3d">[ 0.005 , 0.01 , 0.05 ]</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.5" style="font-size:90%;"> in our experiments). The informed filters are then created to retain (</span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.4.m4.1"><semantics id="S3.SS2.SSS1.p3.4.m4.1a"><mrow id="S3.SS2.SSS1.p3.4.m4.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS1.p3.4.m4.1.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.4.m4.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.cmml">o</mi><mo id="S3.SS2.SSS1.p3.4.m4.1.1.1a" xref="S3.SS2.SSS1.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.4.m4.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p3.4.m4.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.4.m4.1b"><apply id="S3.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1"><times id="S3.SS2.SSS1.p3.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.1"></times><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p3.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.3">𝑜</ci><ci id="S3.SS2.SSS1.p3.4.m4.1.1.4.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.4.m4.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.4.m4.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.6" style="font-size:90%;">) or mask (</span><math alttext="Rcom" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.5.m5.1"><semantics id="S3.SS2.SSS1.p3.5.m5.1a"><mrow id="S3.SS2.SSS1.p3.5.m5.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.cmml"><mi id="S3.SS2.SSS1.p3.5.m5.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.5.m5.1.1.2.cmml">R</mi><mo id="S3.SS2.SSS1.p3.5.m5.1.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.5.m5.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p3.5.m5.1.1.3.cmml">c</mi><mo id="S3.SS2.SSS1.p3.5.m5.1.1.1a" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.5.m5.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p3.5.m5.1.1.4.cmml">o</mi><mo id="S3.SS2.SSS1.p3.5.m5.1.1.1b" xref="S3.SS2.SSS1.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.5.m5.1.1.5" mathsize="90%" xref="S3.SS2.SSS1.p3.5.m5.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.5.m5.1b"><apply id="S3.SS2.SSS1.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1"><times id="S3.SS2.SSS1.p3.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.1"></times><ci id="S3.SS2.SSS1.p3.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.2">𝑅</ci><ci id="S3.SS2.SSS1.p3.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.3">𝑐</ci><ci id="S3.SS2.SSS1.p3.5.m5.1.1.4.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.4">𝑜</ci><ci id="S3.SS2.SSS1.p3.5.m5.1.1.5.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.5.m5.1c">Rcom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.5.m5.1d">italic_R italic_c italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.7" style="font-size:90%;">) these frequencies. The two filters are randomly selected with an equal possibility (i.e. </span><math alttext="50\%" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.6.m6.1"><semantics id="S3.SS2.SSS1.p3.6.m6.1a"><mrow id="S3.SS2.SSS1.p3.6.m6.1.1" xref="S3.SS2.SSS1.p3.6.m6.1.1.cmml"><mn id="S3.SS2.SSS1.p3.6.m6.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.6.m6.1.1.2.cmml">50</mn><mo id="S3.SS2.SSS1.p3.6.m6.1.1.1" mathsize="90%" xref="S3.SS2.SSS1.p3.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.6.m6.1b"><apply id="S3.SS2.SSS1.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p3.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1.1">percent</csymbol><cn id="S3.SS2.SSS1.p3.6.m6.1.1.2.cmml" type="integer" xref="S3.SS2.SSS1.p3.6.m6.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.6.m6.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.6.m6.1d">50 %</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.8" style="font-size:90%;">) and applied to the spectrum. By applying inverse FFT to the filtered spectrum, we restore a frequency-masked image which will serve as an input to the model during pre-training. It is important to note that </span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.7.m7.1"><semantics id="S3.SS2.SSS1.p3.7.m7.1a"><mrow id="S3.SS2.SSS1.p3.7.m7.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.cmml"><mi id="S3.SS2.SSS1.p3.7.m7.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.7.m7.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS1.p3.7.m7.1.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.7.m7.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p3.7.m7.1.1.3.cmml">o</mi><mo id="S3.SS2.SSS1.p3.7.m7.1.1.1a" xref="S3.SS2.SSS1.p3.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.7.m7.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p3.7.m7.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.7.m7.1b"><apply id="S3.SS2.SSS1.p3.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1"><times id="S3.SS2.SSS1.p3.7.m7.1.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.1"></times><ci id="S3.SS2.SSS1.p3.7.m7.1.1.2.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.2">𝐶</ci><ci id="S3.SS2.SSS1.p3.7.m7.1.1.3.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.3">𝑜</ci><ci id="S3.SS2.SSS1.p3.7.m7.1.1.4.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.7.m7.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.7.m7.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.9" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.8.m8.1"><semantics id="S3.SS2.SSS1.p3.8.m8.1a"><mrow id="S3.SS2.SSS1.p3.8.m8.1.1" xref="S3.SS2.SSS1.p3.8.m8.1.1.cmml"><mi id="S3.SS2.SSS1.p3.8.m8.1.1.2" mathsize="90%" xref="S3.SS2.SSS1.p3.8.m8.1.1.2.cmml">R</mi><mo id="S3.SS2.SSS1.p3.8.m8.1.1.1" xref="S3.SS2.SSS1.p3.8.m8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.8.m8.1.1.3" mathsize="90%" xref="S3.SS2.SSS1.p3.8.m8.1.1.3.cmml">C</mi><mo id="S3.SS2.SSS1.p3.8.m8.1.1.1a" xref="S3.SS2.SSS1.p3.8.m8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.8.m8.1.1.4" mathsize="90%" xref="S3.SS2.SSS1.p3.8.m8.1.1.4.cmml">o</mi><mo id="S3.SS2.SSS1.p3.8.m8.1.1.1b" xref="S3.SS2.SSS1.p3.8.m8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.8.m8.1.1.5" mathsize="90%" xref="S3.SS2.SSS1.p3.8.m8.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.8.m8.1b"><apply id="S3.SS2.SSS1.p3.8.m8.1.1.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1"><times id="S3.SS2.SSS1.p3.8.m8.1.1.1.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1.1"></times><ci id="S3.SS2.SSS1.p3.8.m8.1.1.2.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1.2">𝑅</ci><ci id="S3.SS2.SSS1.p3.8.m8.1.1.3.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1.3">𝐶</ci><ci id="S3.SS2.SSS1.p3.8.m8.1.1.4.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1.4">𝑜</ci><ci id="S3.SS2.SSS1.p3.8.m8.1.1.5.cmml" xref="S3.SS2.SSS1.p3.8.m8.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.8.m8.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.8.m8.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS1.p3.8.10" style="font-size:90%;"> filters are uniquely generated based on individual images (examples are provided in Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3" style="font-size:90%;" title="Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">C</span></a><span class="ltx_text" id="S3.SS2.SSS1.p3.8.11" style="font-size:90%;">), which introduces greater variation in training samples and presents a harder training task compared to using constant filters. In addition to comparing our approach with the low/high-passed filters used in MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS1.p3.8.12.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS2.SSS1.p3.8.13.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS2.SSS1.p3.8.14.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS1.p3.8.15" style="font-size:90%;">, we also conducted an ablation study using a set of random frequency filters to demonstrate the effectiveness of our proposed informed filters (see Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS3" style="font-size:90%;" title="B.3 Ablation Study - Different Filters ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">B.3</span></a><span class="ltx_text" id="S3.SS2.SSS1.p3.8.16" style="font-size:90%;">).</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Making Backbone Familiar with Natural Images</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1"><span class="ltx_text" id="S3.SS2.SSS2.p1.1.1" style="font-size:90%;">To further improve the training efficiency and model robustness in masked frequency modeling, we incorporate a self-distillation design </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Grill et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a>; <span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a>; <span class="ltx_text" style="font-size:90%;">Tarvainen and Valpola</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib54" title=""><span class="ltx_text" style="font-size:90%;">2017</span></a><span class="ltx_text" id="S3.SS2.SSS2.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p1.1.5" style="font-size:90%;"> in our proposed approach. The original MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS2.SSS2.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p1.1.9" style="font-size:90%;"> method only tasked the model with the reconstruction of missing frequencies from the frequency-masked view of the image. Such an approach potentially overlooked the data distribution of the original image space, as the model only sees frequency-masked images in pre-training, resulting in higher data demands to adapt to naturally looking images during fine-tuning. To resolve this issue, we propose to properly inject the original image information into the training process via a self-distillation technique advocated by works such as BYOL </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p1.1.10.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Grill et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="S3.SS2.SSS2.p1.1.12.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p1.1.13" style="font-size:90%;"> and DINO </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p1.1.14.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S3.SS2.SSS2.p1.1.16.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p1.1.17" style="font-size:90%;">. Here, we present our FOLK framework, detailed in Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.2.2 Making Backbone Familiar with Natural Images ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS2.SSS2.p1.1.18" style="font-size:90%;">. Note that FOLK does not require additional training stages for pre-processing, such as the offline tokenizer employed by BEiT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p1.1.19.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p1.1.20.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S3.SS2.SSS2.p1.1.21.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p1.1.22" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="267" id="S3.F3.g1" src="extracted/5858280/images_folder/main/FOLK.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The Proposed FOLK Framework. Two views (<math alttext="u" class="ltx_Math" display="inline" id="S3.F3.16.m1.1"><semantics id="S3.F3.16.m1.1b"><mi id="S3.F3.16.m1.1.1" xref="S3.F3.16.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.F3.16.m1.1c"><ci id="S3.F3.16.m1.1.1.cmml" xref="S3.F3.16.m1.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.16.m1.1d">u</annotation><annotation encoding="application/x-llamapun" id="S3.F3.16.m1.1e">italic_u</annotation></semantics></math> and <math alttext="v" class="ltx_Math" display="inline" id="S3.F3.17.m2.1"><semantics id="S3.F3.17.m2.1b"><mi id="S3.F3.17.m2.1.1" xref="S3.F3.17.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.F3.17.m2.1c"><ci id="S3.F3.17.m2.1.1.cmml" xref="S3.F3.17.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.17.m2.1d">v</annotation><annotation encoding="application/x-llamapun" id="S3.F3.17.m2.1e">italic_v</annotation></semantics></math>) of the input image are processed through the informed filtering process, introduced in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.F2" title="Figure 2 ‣ 3.2.1 Informed Filters ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">2</span></a>. This yields two frequency-masked views (<math alttext="\tilde{u}" class="ltx_Math" display="inline" id="S3.F3.18.m3.1"><semantics id="S3.F3.18.m3.1b"><mover accent="true" id="S3.F3.18.m3.1.1" xref="S3.F3.18.m3.1.1.cmml"><mi id="S3.F3.18.m3.1.1.2" xref="S3.F3.18.m3.1.1.2.cmml">u</mi><mo id="S3.F3.18.m3.1.1.1" xref="S3.F3.18.m3.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.18.m3.1c"><apply id="S3.F3.18.m3.1.1.cmml" xref="S3.F3.18.m3.1.1"><ci id="S3.F3.18.m3.1.1.1.cmml" xref="S3.F3.18.m3.1.1.1">~</ci><ci id="S3.F3.18.m3.1.1.2.cmml" xref="S3.F3.18.m3.1.1.2">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.18.m3.1d">\tilde{u}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.18.m3.1e">over~ start_ARG italic_u end_ARG</annotation></semantics></math> and <math alttext="\tilde{v}" class="ltx_Math" display="inline" id="S3.F3.19.m4.1"><semantics id="S3.F3.19.m4.1b"><mover accent="true" id="S3.F3.19.m4.1.1" xref="S3.F3.19.m4.1.1.cmml"><mi id="S3.F3.19.m4.1.1.2" xref="S3.F3.19.m4.1.1.2.cmml">v</mi><mo id="S3.F3.19.m4.1.1.1" xref="S3.F3.19.m4.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.19.m4.1c"><apply id="S3.F3.19.m4.1.1.cmml" xref="S3.F3.19.m4.1.1"><ci id="S3.F3.19.m4.1.1.1.cmml" xref="S3.F3.19.m4.1.1.1">~</ci><ci id="S3.F3.19.m4.1.1.2.cmml" xref="S3.F3.19.m4.1.1.2">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.19.m4.1d">\tilde{v}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.19.m4.1e">over~ start_ARG italic_v end_ARG</annotation></semantics></math>) which serve as the input to the student model. The student model is tasked with reconstructing the missing frequencies from the masked view <math alttext="\tilde{u}" class="ltx_Math" display="inline" id="S3.F3.20.m5.1"><semantics id="S3.F3.20.m5.1b"><mover accent="true" id="S3.F3.20.m5.1.1" xref="S3.F3.20.m5.1.1.cmml"><mi id="S3.F3.20.m5.1.1.2" xref="S3.F3.20.m5.1.1.2.cmml">u</mi><mo id="S3.F3.20.m5.1.1.1" xref="S3.F3.20.m5.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.20.m5.1c"><apply id="S3.F3.20.m5.1.1.cmml" xref="S3.F3.20.m5.1.1"><ci id="S3.F3.20.m5.1.1.1.cmml" xref="S3.F3.20.m5.1.1.1">~</ci><ci id="S3.F3.20.m5.1.1.2.cmml" xref="S3.F3.20.m5.1.1.2">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.20.m5.1d">\tilde{u}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.20.m5.1e">over~ start_ARG italic_u end_ARG</annotation></semantics></math> (or <math alttext="\tilde{v}" class="ltx_Math" display="inline" id="S3.F3.21.m6.1"><semantics id="S3.F3.21.m6.1b"><mover accent="true" id="S3.F3.21.m6.1.1" xref="S3.F3.21.m6.1.1.cmml"><mi id="S3.F3.21.m6.1.1.2" xref="S3.F3.21.m6.1.1.2.cmml">v</mi><mo id="S3.F3.21.m6.1.1.1" xref="S3.F3.21.m6.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.21.m6.1c"><apply id="S3.F3.21.m6.1.1.cmml" xref="S3.F3.21.m6.1.1"><ci id="S3.F3.21.m6.1.1.1.cmml" xref="S3.F3.21.m6.1.1.1">~</ci><ci id="S3.F3.21.m6.1.1.2.cmml" xref="S3.F3.21.m6.1.1.2">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.21.m6.1d">\tilde{v}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.21.m6.1e">over~ start_ARG italic_v end_ARG</annotation></semantics></math>), as well as reconstructing the feature representation of the other original view <math alttext="v" class="ltx_Math" display="inline" id="S3.F3.22.m7.1"><semantics id="S3.F3.22.m7.1b"><mi id="S3.F3.22.m7.1.1" xref="S3.F3.22.m7.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.F3.22.m7.1c"><ci id="S3.F3.22.m7.1.1.cmml" xref="S3.F3.22.m7.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.22.m7.1d">v</annotation><annotation encoding="application/x-llamapun" id="S3.F3.22.m7.1e">italic_v</annotation></semantics></math> (or <math alttext="u" class="ltx_Math" display="inline" id="S3.F3.23.m8.1"><semantics id="S3.F3.23.m8.1b"><mi id="S3.F3.23.m8.1.1" xref="S3.F3.23.m8.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.F3.23.m8.1c"><ci id="S3.F3.23.m8.1.1.cmml" xref="S3.F3.23.m8.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.23.m8.1d">u</annotation><annotation encoding="application/x-llamapun" id="S3.F3.23.m8.1e">italic_u</annotation></semantics></math>), generated by the teacher model, using the masked view <math alttext="\tilde{u}" class="ltx_Math" display="inline" id="S3.F3.24.m9.1"><semantics id="S3.F3.24.m9.1b"><mover accent="true" id="S3.F3.24.m9.1.1" xref="S3.F3.24.m9.1.1.cmml"><mi id="S3.F3.24.m9.1.1.2" xref="S3.F3.24.m9.1.1.2.cmml">u</mi><mo id="S3.F3.24.m9.1.1.1" xref="S3.F3.24.m9.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.24.m9.1c"><apply id="S3.F3.24.m9.1.1.cmml" xref="S3.F3.24.m9.1.1"><ci id="S3.F3.24.m9.1.1.1.cmml" xref="S3.F3.24.m9.1.1.1">~</ci><ci id="S3.F3.24.m9.1.1.2.cmml" xref="S3.F3.24.m9.1.1.2">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.24.m9.1d">\tilde{u}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.24.m9.1e">over~ start_ARG italic_u end_ARG</annotation></semantics></math> (or <math alttext="\tilde{v}" class="ltx_Math" display="inline" id="S3.F3.25.m10.1"><semantics id="S3.F3.25.m10.1b"><mover accent="true" id="S3.F3.25.m10.1.1" xref="S3.F3.25.m10.1.1.cmml"><mi id="S3.F3.25.m10.1.1.2" xref="S3.F3.25.m10.1.1.2.cmml">v</mi><mo id="S3.F3.25.m10.1.1.1" xref="S3.F3.25.m10.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.25.m10.1c"><apply id="S3.F3.25.m10.1.1.cmml" xref="S3.F3.25.m10.1.1"><ci id="S3.F3.25.m10.1.1.1.cmml" xref="S3.F3.25.m10.1.1.1">~</ci><ci id="S3.F3.25.m10.1.1.2.cmml" xref="S3.F3.25.m10.1.1.2">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.25.m10.1d">\tilde{v}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.25.m10.1e">over~ start_ARG italic_v end_ARG</annotation></semantics></math>). The student model <math alttext="g_{\theta}" class="ltx_Math" display="inline" id="S3.F3.26.m11.1"><semantics id="S3.F3.26.m11.1b"><msub id="S3.F3.26.m11.1.1" xref="S3.F3.26.m11.1.1.cmml"><mi id="S3.F3.26.m11.1.1.2" xref="S3.F3.26.m11.1.1.2.cmml">g</mi><mi id="S3.F3.26.m11.1.1.3" xref="S3.F3.26.m11.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.26.m11.1c"><apply id="S3.F3.26.m11.1.1.cmml" xref="S3.F3.26.m11.1.1"><csymbol cd="ambiguous" id="S3.F3.26.m11.1.1.1.cmml" xref="S3.F3.26.m11.1.1">subscript</csymbol><ci id="S3.F3.26.m11.1.1.2.cmml" xref="S3.F3.26.m11.1.1.2">𝑔</ci><ci id="S3.F3.26.m11.1.1.3.cmml" xref="S3.F3.26.m11.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.26.m11.1d">g_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.26.m11.1e">italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> and the teacher model <math alttext="g_{\phi}" class="ltx_Math" display="inline" id="S3.F3.27.m12.1"><semantics id="S3.F3.27.m12.1b"><msub id="S3.F3.27.m12.1.1" xref="S3.F3.27.m12.1.1.cmml"><mi id="S3.F3.27.m12.1.1.2" xref="S3.F3.27.m12.1.1.2.cmml">g</mi><mi id="S3.F3.27.m12.1.1.3" xref="S3.F3.27.m12.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.27.m12.1c"><apply id="S3.F3.27.m12.1.1.cmml" xref="S3.F3.27.m12.1.1"><csymbol cd="ambiguous" id="S3.F3.27.m12.1.1.1.cmml" xref="S3.F3.27.m12.1.1">subscript</csymbol><ci id="S3.F3.27.m12.1.1.2.cmml" xref="S3.F3.27.m12.1.1.2">𝑔</ci><ci id="S3.F3.27.m12.1.1.3.cmml" xref="S3.F3.27.m12.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.27.m12.1d">g_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.27.m12.1e">italic_g start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math>, with their corresponding heads <math alttext="h_{\theta}" class="ltx_Math" display="inline" id="S3.F3.28.m13.1"><semantics id="S3.F3.28.m13.1b"><msub id="S3.F3.28.m13.1.1" xref="S3.F3.28.m13.1.1.cmml"><mi id="S3.F3.28.m13.1.1.2" xref="S3.F3.28.m13.1.1.2.cmml">h</mi><mi id="S3.F3.28.m13.1.1.3" xref="S3.F3.28.m13.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.28.m13.1c"><apply id="S3.F3.28.m13.1.1.cmml" xref="S3.F3.28.m13.1.1"><csymbol cd="ambiguous" id="S3.F3.28.m13.1.1.1.cmml" xref="S3.F3.28.m13.1.1">subscript</csymbol><ci id="S3.F3.28.m13.1.1.2.cmml" xref="S3.F3.28.m13.1.1.2">ℎ</ci><ci id="S3.F3.28.m13.1.1.3.cmml" xref="S3.F3.28.m13.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.28.m13.1d">h_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.28.m13.1e">italic_h start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="h_{\phi}" class="ltx_Math" display="inline" id="S3.F3.29.m14.1"><semantics id="S3.F3.29.m14.1b"><msub id="S3.F3.29.m14.1.1" xref="S3.F3.29.m14.1.1.cmml"><mi id="S3.F3.29.m14.1.1.2" xref="S3.F3.29.m14.1.1.2.cmml">h</mi><mi id="S3.F3.29.m14.1.1.3" xref="S3.F3.29.m14.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.29.m14.1c"><apply id="S3.F3.29.m14.1.1.cmml" xref="S3.F3.29.m14.1.1"><csymbol cd="ambiguous" id="S3.F3.29.m14.1.1.1.cmml" xref="S3.F3.29.m14.1.1">subscript</csymbol><ci id="S3.F3.29.m14.1.1.2.cmml" xref="S3.F3.29.m14.1.1.2">ℎ</ci><ci id="S3.F3.29.m14.1.1.3.cmml" xref="S3.F3.29.m14.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.29.m14.1d">h_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.29.m14.1e">italic_h start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math>, have the same architecture but different parameters, except that the student has an additional MFM head <math alttext="\hat{h}_{\theta}" class="ltx_Math" display="inline" id="S3.F3.30.m15.1"><semantics id="S3.F3.30.m15.1b"><msub id="S3.F3.30.m15.1.1" xref="S3.F3.30.m15.1.1.cmml"><mover accent="true" id="S3.F3.30.m15.1.1.2" xref="S3.F3.30.m15.1.1.2.cmml"><mi id="S3.F3.30.m15.1.1.2.2" xref="S3.F3.30.m15.1.1.2.2.cmml">h</mi><mo id="S3.F3.30.m15.1.1.2.1" xref="S3.F3.30.m15.1.1.2.1.cmml">^</mo></mover><mi id="S3.F3.30.m15.1.1.3" xref="S3.F3.30.m15.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F3.30.m15.1c"><apply id="S3.F3.30.m15.1.1.cmml" xref="S3.F3.30.m15.1.1"><csymbol cd="ambiguous" id="S3.F3.30.m15.1.1.1.cmml" xref="S3.F3.30.m15.1.1">subscript</csymbol><apply id="S3.F3.30.m15.1.1.2.cmml" xref="S3.F3.30.m15.1.1.2"><ci id="S3.F3.30.m15.1.1.2.1.cmml" xref="S3.F3.30.m15.1.1.2.1">^</ci><ci id="S3.F3.30.m15.1.1.2.2.cmml" xref="S3.F3.30.m15.1.1.2.2">ℎ</ci></apply><ci id="S3.F3.30.m15.1.1.3.cmml" xref="S3.F3.30.m15.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.30.m15.1d">\hat{h}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.30.m15.1e">over^ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. Only the student model (with its both heads) is updated through back-propagation, while the teacher parameters are periodically updated with an exponential moving average (EMA) of the corresponding student parameters.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.13"><span class="ltx_text" id="S3.SS2.SSS2.p2.13.1" style="font-size:90%;">FOLK starts by generating two views, </span><math alttext="u" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.1.m1.1"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mi id="S3.SS2.SSS2.p2.1.m1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><ci id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.1.m1.1d">italic_u</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.2" style="font-size:90%;"> and </span><math alttext="v" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.2.m2.1"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mi id="S3.SS2.SSS2.p2.2.m2.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><ci id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.2.m2.1d">italic_v</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.3" style="font-size:90%;">, from an input image </span><math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.3.m3.1"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><mi id="S3.SS2.SSS2.p2.3.m3.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><ci id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.3.m3.1d">italic_x</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.4" style="font-size:90%;"> using distinct transformations to create varied perspectives. This follows the methodology employed by DINO </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p2.13.5.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p2.13.6.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S3.SS2.SSS2.p2.13.7.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p2.13.8" style="font-size:90%;"> and the transformations include random cropping, color jittering, etc. Note that, unlike DINO or ATTMask </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p2.13.9.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p2.13.10.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S3.SS2.SSS2.p2.13.11.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p2.13.12" style="font-size:90%;">, we do not utilize the concept of local views, which helps keep an efficient framework. After applying 2D FFT to the view </span><math alttext="u" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.4.m4.1"><semantics id="S3.SS2.SSS2.p2.4.m4.1a"><mi id="S3.SS2.SSS2.p2.4.m4.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.4.m4.1b"><ci id="S3.SS2.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.4.m4.1d">italic_u</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.13" style="font-size:90%;"> (or </span><math alttext="v" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.5.m5.1"><semantics id="S3.SS2.SSS2.p2.5.m5.1a"><mi id="S3.SS2.SSS2.p2.5.m5.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.5.m5.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.5.m5.1b"><ci id="S3.SS2.SSS2.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p2.5.m5.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.5.m5.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.5.m5.1d">italic_v</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.14" style="font-size:90%;">), the </span><math alttext="Com" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.6.m6.1"><semantics id="S3.SS2.SSS2.p2.6.m6.1a"><mrow id="S3.SS2.SSS2.p2.6.m6.1.1" xref="S3.SS2.SSS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p2.6.m6.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p2.6.m6.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS2.p2.6.m6.1.1.1" xref="S3.SS2.SSS2.p2.6.m6.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.6.m6.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p2.6.m6.1.1.3.cmml">o</mi><mo id="S3.SS2.SSS2.p2.6.m6.1.1.1a" xref="S3.SS2.SSS2.p2.6.m6.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.6.m6.1.1.4" mathsize="90%" xref="S3.SS2.SSS2.p2.6.m6.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.6.m6.1b"><apply id="S3.SS2.SSS2.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1"><times id="S3.SS2.SSS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1.1"></times><ci id="S3.SS2.SSS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1.2">𝐶</ci><ci id="S3.SS2.SSS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1.3">𝑜</ci><ci id="S3.SS2.SSS2.p2.6.m6.1.1.4.cmml" xref="S3.SS2.SSS2.p2.6.m6.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.6.m6.1c">Com</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.6.m6.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.15" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.7.m7.1"><semantics id="S3.SS2.SSS2.p2.7.m7.1a"><mrow id="S3.SS2.SSS2.p2.7.m7.1.1" xref="S3.SS2.SSS2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.SSS2.p2.7.m7.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p2.7.m7.1.1.2.cmml">R</mi><mo id="S3.SS2.SSS2.p2.7.m7.1.1.1" xref="S3.SS2.SSS2.p2.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.7.m7.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p2.7.m7.1.1.3.cmml">C</mi><mo id="S3.SS2.SSS2.p2.7.m7.1.1.1a" xref="S3.SS2.SSS2.p2.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.7.m7.1.1.4" mathsize="90%" xref="S3.SS2.SSS2.p2.7.m7.1.1.4.cmml">o</mi><mo id="S3.SS2.SSS2.p2.7.m7.1.1.1b" xref="S3.SS2.SSS2.p2.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.7.m7.1.1.5" mathsize="90%" xref="S3.SS2.SSS2.p2.7.m7.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.7.m7.1b"><apply id="S3.SS2.SSS2.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS2.p2.7.m7.1.1"><times id="S3.SS2.SSS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.SSS2.p2.7.m7.1.1.1"></times><ci id="S3.SS2.SSS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.SSS2.p2.7.m7.1.1.2">𝑅</ci><ci id="S3.SS2.SSS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.SSS2.p2.7.m7.1.1.3">𝐶</ci><ci id="S3.SS2.SSS2.p2.7.m7.1.1.4.cmml" xref="S3.SS2.SSS2.p2.7.m7.1.1.4">𝑜</ci><ci id="S3.SS2.SSS2.p2.7.m7.1.1.5.cmml" xref="S3.SS2.SSS2.p2.7.m7.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.7.m7.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.7.m7.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.16" style="font-size:90%;"> filters are uniquely generated according to this view (detailed in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.SS2.SSS1" style="font-size:90%;" title="3.2.1 Informed Filters ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3.2.1</span></a><span class="ltx_text" id="S3.SS2.SSS2.p2.13.17" style="font-size:90%;"> and Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.F2" style="font-size:90%;" title="Figure 2 ‣ 3.2.1 Informed Filters ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS2.SSS2.p2.13.18" style="font-size:90%;">). One filter is then randomly selected and applied to the frequency spectrum, and the retained frequency components are processed through inverse FFT to restore a frequency-masked view </span><math alttext="\tilde{u}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.8.m8.1"><semantics id="S3.SS2.SSS2.p2.8.m8.1a"><mover accent="true" id="S3.SS2.SSS2.p2.8.m8.1.1" xref="S3.SS2.SSS2.p2.8.m8.1.1.cmml"><mi id="S3.SS2.SSS2.p2.8.m8.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p2.8.m8.1.1.2.cmml">u</mi><mo id="S3.SS2.SSS2.p2.8.m8.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.8.m8.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.8.m8.1b"><apply id="S3.SS2.SSS2.p2.8.m8.1.1.cmml" xref="S3.SS2.SSS2.p2.8.m8.1.1"><ci id="S3.SS2.SSS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.SSS2.p2.8.m8.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.SSS2.p2.8.m8.1.1.2">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.8.m8.1c">\tilde{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.8.m8.1d">over~ start_ARG italic_u end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.19" style="font-size:90%;"> (or </span><math alttext="\tilde{v}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.9.m9.1"><semantics id="S3.SS2.SSS2.p2.9.m9.1a"><mover accent="true" id="S3.SS2.SSS2.p2.9.m9.1.1" xref="S3.SS2.SSS2.p2.9.m9.1.1.cmml"><mi id="S3.SS2.SSS2.p2.9.m9.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p2.9.m9.1.1.2.cmml">v</mi><mo id="S3.SS2.SSS2.p2.9.m9.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.9.m9.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.9.m9.1b"><apply id="S3.SS2.SSS2.p2.9.m9.1.1.cmml" xref="S3.SS2.SSS2.p2.9.m9.1.1"><ci id="S3.SS2.SSS2.p2.9.m9.1.1.1.cmml" xref="S3.SS2.SSS2.p2.9.m9.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.9.m9.1.1.2.cmml" xref="S3.SS2.SSS2.p2.9.m9.1.1.2">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.9.m9.1c">\tilde{v}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.9.m9.1d">over~ start_ARG italic_v end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.20" style="font-size:90%;">), see Equation </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.Ex2" style="font-size:90%;" title="In 3.1 Preliminary and Background ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS2.SSS2.p2.13.21" style="font-size:90%;">. The student model receives this frequency-masked view </span><math alttext="\tilde{u}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.10.m10.1"><semantics id="S3.SS2.SSS2.p2.10.m10.1a"><mover accent="true" id="S3.SS2.SSS2.p2.10.m10.1.1" xref="S3.SS2.SSS2.p2.10.m10.1.1.cmml"><mi id="S3.SS2.SSS2.p2.10.m10.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p2.10.m10.1.1.2.cmml">u</mi><mo id="S3.SS2.SSS2.p2.10.m10.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.10.m10.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.10.m10.1b"><apply id="S3.SS2.SSS2.p2.10.m10.1.1.cmml" xref="S3.SS2.SSS2.p2.10.m10.1.1"><ci id="S3.SS2.SSS2.p2.10.m10.1.1.1.cmml" xref="S3.SS2.SSS2.p2.10.m10.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.10.m10.1.1.2.cmml" xref="S3.SS2.SSS2.p2.10.m10.1.1.2">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.10.m10.1c">\tilde{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.10.m10.1d">over~ start_ARG italic_u end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.22" style="font-size:90%;"> (or </span><math alttext="\tilde{v}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.11.m11.1"><semantics id="S3.SS2.SSS2.p2.11.m11.1a"><mover accent="true" id="S3.SS2.SSS2.p2.11.m11.1.1" xref="S3.SS2.SSS2.p2.11.m11.1.1.cmml"><mi id="S3.SS2.SSS2.p2.11.m11.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p2.11.m11.1.1.2.cmml">v</mi><mo id="S3.SS2.SSS2.p2.11.m11.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.11.m11.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.11.m11.1b"><apply id="S3.SS2.SSS2.p2.11.m11.1.1.cmml" xref="S3.SS2.SSS2.p2.11.m11.1.1"><ci id="S3.SS2.SSS2.p2.11.m11.1.1.1.cmml" xref="S3.SS2.SSS2.p2.11.m11.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.11.m11.1.1.2.cmml" xref="S3.SS2.SSS2.p2.11.m11.1.1.2">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.11.m11.1c">\tilde{v}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.11.m11.1d">over~ start_ARG italic_v end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.23" style="font-size:90%;">) and predicts against two targets: reconstruction of the missing frequencies discarded by the filter, and reconstruction of the feature representation of the other original view </span><math alttext="v" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.12.m12.1"><semantics id="S3.SS2.SSS2.p2.12.m12.1a"><mi id="S3.SS2.SSS2.p2.12.m12.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.12.m12.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.12.m12.1b"><ci id="S3.SS2.SSS2.p2.12.m12.1.1.cmml" xref="S3.SS2.SSS2.p2.12.m12.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.12.m12.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.12.m12.1d">italic_v</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.24" style="font-size:90%;"> (or </span><math alttext="u" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.13.m13.1"><semantics id="S3.SS2.SSS2.p2.13.m13.1a"><mi id="S3.SS2.SSS2.p2.13.m13.1.1" mathsize="90%" xref="S3.SS2.SSS2.p2.13.m13.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.13.m13.1b"><ci id="S3.SS2.SSS2.p2.13.m13.1.1.cmml" xref="S3.SS2.SSS2.p2.13.m13.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.13.m13.1c">u</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.13.m13.1d">italic_u</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p2.13.25" style="font-size:90%;">) generated by the teacher model.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.3"><span class="ltx_text" id="S3.SS2.SSS2.p3.3.1" style="font-size:90%;">Two different heads are appended to the student model, each facilitating one of the prediction tasks. The MFM head </span><math alttext="\hat{h}_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.1.m1.1"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><msub id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS2.p3.1.m1.1.1.2" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS2.p3.1.m1.1.1.2.2" mathsize="90%" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.2.cmml">h</mi><mo id="S3.SS2.SSS2.p3.1.m1.1.1.2.1" mathsize="90%" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.SSS2.p3.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><apply id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2"><ci id="S3.SS2.SSS2.p3.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.1">^</ci><ci id="S3.SS2.SSS2.p3.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.2">ℎ</ci></apply><ci id="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">\hat{h}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.1.m1.1d">over^ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p3.3.2" style="font-size:90%;"> serves to reconstruct the missing frequencies, with a single linear layer implementation following the original design proposed in MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p3.3.3.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p3.3.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS2.SSS2.p3.3.5.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p3.3.6" style="font-size:90%;">. The student head </span><math alttext="h_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.2.m2.1"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><msub id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p3.2.m2.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS2.p3.2.m2.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><apply id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.2">ℎ</ci><ci id="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">h_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.2.m2.1d">italic_h start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p3.3.7" style="font-size:90%;"> (and teacher head </span><math alttext="h_{\phi}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.3.m3.1"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><msub id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p3.3.m3.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS2.p3.3.m3.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><apply id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.2">ℎ</ci><ci id="S3.SS2.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">h_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.3.m3.1d">italic_h start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p3.3.8" style="font-size:90%;">), aiming at the reconstruction of the feature representation of the other original view, adopts a three-layer multi-layer perceptron (MLP) design. Moreover, the student head (and teacher head) is followed by a scaled softmax function to transform the outputs into probability distributions for the computation of a distillation loss (described below). More specifically,</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P_{s}(x)^{(i)}=\frac{exp(f_{\theta}(x)^{(i)}/\tau_{s})}{\sum_{k=1}^{K}exp(f_{%
\theta}(x)^{(k)}/\tau_{s})}," class="ltx_Math" display="block" id="S3.Ex4.m1.9"><semantics id="S3.Ex4.m1.9a"><mrow id="S3.Ex4.m1.9.9.1" xref="S3.Ex4.m1.9.9.1.1.cmml"><mrow id="S3.Ex4.m1.9.9.1.1" xref="S3.Ex4.m1.9.9.1.1.cmml"><mrow id="S3.Ex4.m1.9.9.1.1.2" xref="S3.Ex4.m1.9.9.1.1.2.cmml"><msub id="S3.Ex4.m1.9.9.1.1.2.2" xref="S3.Ex4.m1.9.9.1.1.2.2.cmml"><mi id="S3.Ex4.m1.9.9.1.1.2.2.2" mathsize="90%" xref="S3.Ex4.m1.9.9.1.1.2.2.2.cmml">P</mi><mi id="S3.Ex4.m1.9.9.1.1.2.2.3" mathsize="90%" xref="S3.Ex4.m1.9.9.1.1.2.2.3.cmml">s</mi></msub><mo id="S3.Ex4.m1.9.9.1.1.2.1" xref="S3.Ex4.m1.9.9.1.1.2.1.cmml">⁢</mo><msup id="S3.Ex4.m1.9.9.1.1.2.3" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml"><mrow id="S3.Ex4.m1.9.9.1.1.2.3.2.2" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml"><mo id="S3.Ex4.m1.9.9.1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml">(</mo><mi id="S3.Ex4.m1.8.8" mathsize="90%" xref="S3.Ex4.m1.8.8.cmml">x</mi><mo id="S3.Ex4.m1.9.9.1.1.2.3.2.2.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml">)</mo></mrow><mrow id="S3.Ex4.m1.1.1.1.3" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml"><mo id="S3.Ex4.m1.1.1.1.3.1" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml">(</mo><mi id="S3.Ex4.m1.1.1.1.1" mathsize="90%" xref="S3.Ex4.m1.1.1.1.1.cmml">i</mi><mo id="S3.Ex4.m1.1.1.1.3.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.9.9.1.1.2.3.cmml">)</mo></mrow></msup></mrow><mo id="S3.Ex4.m1.9.9.1.1.1" mathsize="90%" xref="S3.Ex4.m1.9.9.1.1.1.cmml">=</mo><mfrac id="S3.Ex4.m1.7.7" xref="S3.Ex4.m1.7.7.cmml"><mrow id="S3.Ex4.m1.4.4.3" xref="S3.Ex4.m1.4.4.3.cmml"><mi id="S3.Ex4.m1.4.4.3.5" mathsize="90%" xref="S3.Ex4.m1.4.4.3.5.cmml">e</mi><mo id="S3.Ex4.m1.4.4.3.4" xref="S3.Ex4.m1.4.4.3.4.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.3.6" mathsize="90%" xref="S3.Ex4.m1.4.4.3.6.cmml">x</mi><mo id="S3.Ex4.m1.4.4.3.4a" xref="S3.Ex4.m1.4.4.3.4.cmml">⁢</mo><mi id="S3.Ex4.m1.4.4.3.7" mathsize="90%" xref="S3.Ex4.m1.4.4.3.7.cmml">p</mi><mo id="S3.Ex4.m1.4.4.3.4b" xref="S3.Ex4.m1.4.4.3.4.cmml">⁢</mo><mrow id="S3.Ex4.m1.4.4.3.3.1" xref="S3.Ex4.m1.4.4.3.3.1.1.cmml"><mo id="S3.Ex4.m1.4.4.3.3.1.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.cmml">(</mo><mrow id="S3.Ex4.m1.4.4.3.3.1.1" xref="S3.Ex4.m1.4.4.3.3.1.1.cmml"><mrow id="S3.Ex4.m1.4.4.3.3.1.1.2" xref="S3.Ex4.m1.4.4.3.3.1.1.2.cmml"><msub id="S3.Ex4.m1.4.4.3.3.1.1.2.2" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2.cmml"><mi id="S3.Ex4.m1.4.4.3.3.1.1.2.2.2" mathsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2.2.cmml">f</mi><mi id="S3.Ex4.m1.4.4.3.3.1.1.2.2.3" mathsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2.3.cmml">θ</mi></msub><mo id="S3.Ex4.m1.4.4.3.3.1.1.2.1" xref="S3.Ex4.m1.4.4.3.3.1.1.2.1.cmml">⁢</mo><msup id="S3.Ex4.m1.4.4.3.3.1.1.2.3" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml"><mrow id="S3.Ex4.m1.4.4.3.3.1.1.2.3.2.2" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml"><mo id="S3.Ex4.m1.4.4.3.3.1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml">(</mo><mi id="S3.Ex4.m1.3.3.2.2" mathsize="90%" xref="S3.Ex4.m1.3.3.2.2.cmml">x</mi><mo id="S3.Ex4.m1.4.4.3.3.1.1.2.3.2.2.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml">)</mo></mrow><mrow id="S3.Ex4.m1.2.2.1.1.1.3" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml"><mo id="S3.Ex4.m1.2.2.1.1.1.3.1" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml">(</mo><mi id="S3.Ex4.m1.2.2.1.1.1.1" mathsize="90%" xref="S3.Ex4.m1.2.2.1.1.1.1.cmml">i</mi><mo id="S3.Ex4.m1.2.2.1.1.1.3.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml">)</mo></mrow></msup></mrow><mo id="S3.Ex4.m1.4.4.3.3.1.1.1" maxsize="90%" minsize="90%" stretchy="true" symmetric="true" xref="S3.Ex4.m1.4.4.3.3.1.1.1.cmml">/</mo><msub id="S3.Ex4.m1.4.4.3.3.1.1.3" xref="S3.Ex4.m1.4.4.3.3.1.1.3.cmml"><mi id="S3.Ex4.m1.4.4.3.3.1.1.3.2" mathsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.3.2.cmml">τ</mi><mi id="S3.Ex4.m1.4.4.3.3.1.1.3.3" mathsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.3.3.cmml">s</mi></msub></mrow><mo id="S3.Ex4.m1.4.4.3.3.1.3" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.4.4.3.3.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex4.m1.7.7.6" xref="S3.Ex4.m1.7.7.6.cmml"><msubsup id="S3.Ex4.m1.7.7.6.4" xref="S3.Ex4.m1.7.7.6.4.cmml"><mo id="S3.Ex4.m1.7.7.6.4.2.2" maxsize="90%" minsize="90%" stretchy="true" xref="S3.Ex4.m1.7.7.6.4.2.2.cmml">∑</mo><mrow id="S3.Ex4.m1.7.7.6.4.2.3" xref="S3.Ex4.m1.7.7.6.4.2.3.cmml"><mi id="S3.Ex4.m1.7.7.6.4.2.3.2" mathsize="90%" xref="S3.Ex4.m1.7.7.6.4.2.3.2.cmml">k</mi><mo id="S3.Ex4.m1.7.7.6.4.2.3.1" mathsize="90%" xref="S3.Ex4.m1.7.7.6.4.2.3.1.cmml">=</mo><mn id="S3.Ex4.m1.7.7.6.4.2.3.3" mathsize="90%" xref="S3.Ex4.m1.7.7.6.4.2.3.3.cmml">1</mn></mrow><mi id="S3.Ex4.m1.7.7.6.4.3" mathsize="90%" xref="S3.Ex4.m1.7.7.6.4.3.cmml">K</mi></msubsup><mrow id="S3.Ex4.m1.7.7.6.3" xref="S3.Ex4.m1.7.7.6.3.cmml"><mi id="S3.Ex4.m1.7.7.6.3.3" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.3.cmml">e</mi><mo id="S3.Ex4.m1.7.7.6.3.2" xref="S3.Ex4.m1.7.7.6.3.2.cmml">⁢</mo><mi id="S3.Ex4.m1.7.7.6.3.4" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.4.cmml">x</mi><mo id="S3.Ex4.m1.7.7.6.3.2a" xref="S3.Ex4.m1.7.7.6.3.2.cmml">⁢</mo><mi id="S3.Ex4.m1.7.7.6.3.5" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.5.cmml">p</mi><mo id="S3.Ex4.m1.7.7.6.3.2b" xref="S3.Ex4.m1.7.7.6.3.2.cmml">⁢</mo><mrow id="S3.Ex4.m1.7.7.6.3.1.1" xref="S3.Ex4.m1.7.7.6.3.1.1.1.cmml"><mo id="S3.Ex4.m1.7.7.6.3.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.cmml">(</mo><mrow id="S3.Ex4.m1.7.7.6.3.1.1.1" xref="S3.Ex4.m1.7.7.6.3.1.1.1.cmml"><mrow id="S3.Ex4.m1.7.7.6.3.1.1.1.2" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.cmml"><msub id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.cmml"><mi id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.2" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.2.cmml">f</mi><mi id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.3" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.3.cmml">θ</mi></msub><mo id="S3.Ex4.m1.7.7.6.3.1.1.1.2.1" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.1.cmml">⁢</mo><msup id="S3.Ex4.m1.7.7.6.3.1.1.1.2.3" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml"><mrow id="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.2.2" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml"><mo id="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.2.2.1" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml">(</mo><mi id="S3.Ex4.m1.6.6.5.2" mathsize="90%" xref="S3.Ex4.m1.6.6.5.2.cmml">x</mi><mo id="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.2.2.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml">)</mo></mrow><mrow id="S3.Ex4.m1.5.5.4.1.1.3" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml"><mo id="S3.Ex4.m1.5.5.4.1.1.3.1" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml">(</mo><mi id="S3.Ex4.m1.5.5.4.1.1.1" mathsize="90%" xref="S3.Ex4.m1.5.5.4.1.1.1.cmml">k</mi><mo id="S3.Ex4.m1.5.5.4.1.1.3.2" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml">)</mo></mrow></msup></mrow><mo id="S3.Ex4.m1.7.7.6.3.1.1.1.1" maxsize="90%" minsize="90%" stretchy="true" symmetric="true" xref="S3.Ex4.m1.7.7.6.3.1.1.1.1.cmml">/</mo><msub id="S3.Ex4.m1.7.7.6.3.1.1.1.3" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3.cmml"><mi id="S3.Ex4.m1.7.7.6.3.1.1.1.3.2" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3.2.cmml">τ</mi><mi id="S3.Ex4.m1.7.7.6.3.1.1.1.3.3" mathsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3.3.cmml">s</mi></msub></mrow><mo id="S3.Ex4.m1.7.7.6.3.1.1.3" maxsize="90%" minsize="90%" xref="S3.Ex4.m1.7.7.6.3.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S3.Ex4.m1.9.9.1.2" mathsize="90%" xref="S3.Ex4.m1.9.9.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex4.m1.9b"><apply id="S3.Ex4.m1.9.9.1.1.cmml" xref="S3.Ex4.m1.9.9.1"><eq id="S3.Ex4.m1.9.9.1.1.1.cmml" xref="S3.Ex4.m1.9.9.1.1.1"></eq><apply id="S3.Ex4.m1.9.9.1.1.2.cmml" xref="S3.Ex4.m1.9.9.1.1.2"><times id="S3.Ex4.m1.9.9.1.1.2.1.cmml" xref="S3.Ex4.m1.9.9.1.1.2.1"></times><apply id="S3.Ex4.m1.9.9.1.1.2.2.cmml" xref="S3.Ex4.m1.9.9.1.1.2.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.9.9.1.1.2.2.1.cmml" xref="S3.Ex4.m1.9.9.1.1.2.2">subscript</csymbol><ci id="S3.Ex4.m1.9.9.1.1.2.2.2.cmml" xref="S3.Ex4.m1.9.9.1.1.2.2.2">𝑃</ci><ci id="S3.Ex4.m1.9.9.1.1.2.2.3.cmml" xref="S3.Ex4.m1.9.9.1.1.2.2.3">𝑠</ci></apply><apply id="S3.Ex4.m1.9.9.1.1.2.3.cmml" xref="S3.Ex4.m1.9.9.1.1.2.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.9.9.1.1.2.3.1.cmml" xref="S3.Ex4.m1.9.9.1.1.2.3">superscript</csymbol><ci id="S3.Ex4.m1.8.8.cmml" xref="S3.Ex4.m1.8.8">𝑥</ci><ci id="S3.Ex4.m1.1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1.1">𝑖</ci></apply></apply><apply id="S3.Ex4.m1.7.7.cmml" xref="S3.Ex4.m1.7.7"><divide id="S3.Ex4.m1.7.7.7.cmml" xref="S3.Ex4.m1.7.7"></divide><apply id="S3.Ex4.m1.4.4.3.cmml" xref="S3.Ex4.m1.4.4.3"><times id="S3.Ex4.m1.4.4.3.4.cmml" xref="S3.Ex4.m1.4.4.3.4"></times><ci id="S3.Ex4.m1.4.4.3.5.cmml" xref="S3.Ex4.m1.4.4.3.5">𝑒</ci><ci id="S3.Ex4.m1.4.4.3.6.cmml" xref="S3.Ex4.m1.4.4.3.6">𝑥</ci><ci id="S3.Ex4.m1.4.4.3.7.cmml" xref="S3.Ex4.m1.4.4.3.7">𝑝</ci><apply id="S3.Ex4.m1.4.4.3.3.1.1.cmml" xref="S3.Ex4.m1.4.4.3.3.1"><divide id="S3.Ex4.m1.4.4.3.3.1.1.1.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.1"></divide><apply id="S3.Ex4.m1.4.4.3.3.1.1.2.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2"><times id="S3.Ex4.m1.4.4.3.3.1.1.2.1.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.1"></times><apply id="S3.Ex4.m1.4.4.3.3.1.1.2.2.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.4.4.3.3.1.1.2.2.1.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2">subscript</csymbol><ci id="S3.Ex4.m1.4.4.3.3.1.1.2.2.2.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2.2">𝑓</ci><ci id="S3.Ex4.m1.4.4.3.3.1.1.2.2.3.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.2.3">𝜃</ci></apply><apply id="S3.Ex4.m1.4.4.3.3.1.1.2.3.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.4.4.3.3.1.1.2.3.1.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.2.3">superscript</csymbol><ci id="S3.Ex4.m1.3.3.2.2.cmml" xref="S3.Ex4.m1.3.3.2.2">𝑥</ci><ci id="S3.Ex4.m1.2.2.1.1.1.1.cmml" xref="S3.Ex4.m1.2.2.1.1.1.1">𝑖</ci></apply></apply><apply id="S3.Ex4.m1.4.4.3.3.1.1.3.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.4.4.3.3.1.1.3.1.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.3">subscript</csymbol><ci id="S3.Ex4.m1.4.4.3.3.1.1.3.2.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.3.2">𝜏</ci><ci id="S3.Ex4.m1.4.4.3.3.1.1.3.3.cmml" xref="S3.Ex4.m1.4.4.3.3.1.1.3.3">𝑠</ci></apply></apply></apply><apply id="S3.Ex4.m1.7.7.6.cmml" xref="S3.Ex4.m1.7.7.6"><apply id="S3.Ex4.m1.7.7.6.4.cmml" xref="S3.Ex4.m1.7.7.6.4"><csymbol cd="ambiguous" id="S3.Ex4.m1.7.7.6.4.1.cmml" xref="S3.Ex4.m1.7.7.6.4">superscript</csymbol><apply id="S3.Ex4.m1.7.7.6.4.2.cmml" xref="S3.Ex4.m1.7.7.6.4"><csymbol cd="ambiguous" id="S3.Ex4.m1.7.7.6.4.2.1.cmml" xref="S3.Ex4.m1.7.7.6.4">subscript</csymbol><sum id="S3.Ex4.m1.7.7.6.4.2.2.cmml" xref="S3.Ex4.m1.7.7.6.4.2.2"></sum><apply id="S3.Ex4.m1.7.7.6.4.2.3.cmml" xref="S3.Ex4.m1.7.7.6.4.2.3"><eq id="S3.Ex4.m1.7.7.6.4.2.3.1.cmml" xref="S3.Ex4.m1.7.7.6.4.2.3.1"></eq><ci id="S3.Ex4.m1.7.7.6.4.2.3.2.cmml" xref="S3.Ex4.m1.7.7.6.4.2.3.2">𝑘</ci><cn id="S3.Ex4.m1.7.7.6.4.2.3.3.cmml" type="integer" xref="S3.Ex4.m1.7.7.6.4.2.3.3">1</cn></apply></apply><ci id="S3.Ex4.m1.7.7.6.4.3.cmml" xref="S3.Ex4.m1.7.7.6.4.3">𝐾</ci></apply><apply id="S3.Ex4.m1.7.7.6.3.cmml" xref="S3.Ex4.m1.7.7.6.3"><times id="S3.Ex4.m1.7.7.6.3.2.cmml" xref="S3.Ex4.m1.7.7.6.3.2"></times><ci id="S3.Ex4.m1.7.7.6.3.3.cmml" xref="S3.Ex4.m1.7.7.6.3.3">𝑒</ci><ci id="S3.Ex4.m1.7.7.6.3.4.cmml" xref="S3.Ex4.m1.7.7.6.3.4">𝑥</ci><ci id="S3.Ex4.m1.7.7.6.3.5.cmml" xref="S3.Ex4.m1.7.7.6.3.5">𝑝</ci><apply id="S3.Ex4.m1.7.7.6.3.1.1.1.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1"><divide id="S3.Ex4.m1.7.7.6.3.1.1.1.1.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.1"></divide><apply id="S3.Ex4.m1.7.7.6.3.1.1.1.2.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2"><times id="S3.Ex4.m1.7.7.6.3.1.1.1.2.1.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.1"></times><apply id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.1.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2">subscript</csymbol><ci id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.2.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.2">𝑓</ci><ci id="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.3.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.2.3">𝜃</ci></apply><apply id="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.7.7.6.3.1.1.1.2.3.1.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.2.3">superscript</csymbol><ci id="S3.Ex4.m1.6.6.5.2.cmml" xref="S3.Ex4.m1.6.6.5.2">𝑥</ci><ci id="S3.Ex4.m1.5.5.4.1.1.1.cmml" xref="S3.Ex4.m1.5.5.4.1.1.1">𝑘</ci></apply></apply><apply id="S3.Ex4.m1.7.7.6.3.1.1.1.3.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.7.7.6.3.1.1.1.3.1.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3">subscript</csymbol><ci id="S3.Ex4.m1.7.7.6.3.1.1.1.3.2.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3.2">𝜏</ci><ci id="S3.Ex4.m1.7.7.6.3.1.1.1.3.3.cmml" xref="S3.Ex4.m1.7.7.6.3.1.1.1.3.3">𝑠</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex4.m1.9c">P_{s}(x)^{(i)}=\frac{exp(f_{\theta}(x)^{(i)}/\tau_{s})}{\sum_{k=1}^{K}exp(f_{%
\theta}(x)^{(k)}/\tau_{s})},</annotation><annotation encoding="application/x-llamapun" id="S3.Ex4.m1.9d">italic_P start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_x ) start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT = divide start_ARG italic_e italic_x italic_p ( italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT / italic_τ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT italic_e italic_x italic_p ( italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) start_POSTSUPERSCRIPT ( italic_k ) end_POSTSUPERSCRIPT / italic_τ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p5">
<p class="ltx_p" id="S3.SS2.SSS2.p5.6"><span class="ltx_text" id="S3.SS2.SSS2.p5.6.1" style="font-size:90%;">where </span><math alttext="f_{\theta}(x)=h_{\theta}(g_{\theta}(x))" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.1.m1.3"><semantics id="S3.SS2.SSS2.p5.1.m1.3a"><mrow id="S3.SS2.SSS2.p5.1.m1.3.3" xref="S3.SS2.SSS2.p5.1.m1.3.3.cmml"><mrow id="S3.SS2.SSS2.p5.1.m1.3.3.3" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.cmml"><msub id="S3.SS2.SSS2.p5.1.m1.3.3.3.2" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2.cmml"><mi id="S3.SS2.SSS2.p5.1.m1.3.3.3.2.2" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2.2.cmml">f</mi><mi id="S3.SS2.SSS2.p5.1.m1.3.3.3.2.3" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2.3.cmml">θ</mi></msub><mo id="S3.SS2.SSS2.p5.1.m1.3.3.3.1" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.1.cmml">⁢</mo><mrow id="S3.SS2.SSS2.p5.1.m1.3.3.3.3.2" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.cmml"><mo id="S3.SS2.SSS2.p5.1.m1.3.3.3.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.cmml">(</mo><mi id="S3.SS2.SSS2.p5.1.m1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.1.1.cmml">x</mi><mo id="S3.SS2.SSS2.p5.1.m1.3.3.3.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS2.p5.1.m1.3.3.2" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.2.cmml">=</mo><mrow id="S3.SS2.SSS2.p5.1.m1.3.3.1" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.cmml"><msub id="S3.SS2.SSS2.p5.1.m1.3.3.1.3" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3.cmml"><mi id="S3.SS2.SSS2.p5.1.m1.3.3.1.3.2" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3.2.cmml">h</mi><mi id="S3.SS2.SSS2.p5.1.m1.3.3.1.3.3" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3.3.cmml">θ</mi></msub><mo id="S3.SS2.SSS2.p5.1.m1.3.3.1.2" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml"><mo id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml"><msub id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.2" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.2.cmml">g</mi><mi id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.3" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.3.cmml">θ</mi></msub><mo id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.1" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.3.2" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml"><mo id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S3.SS2.SSS2.p5.1.m1.2.2" mathsize="90%" xref="S3.SS2.SSS2.p5.1.m1.2.2.cmml">x</mi><mo id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.1.m1.3b"><apply id="S3.SS2.SSS2.p5.1.m1.3.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3"><eq id="S3.SS2.SSS2.p5.1.m1.3.3.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.2"></eq><apply id="S3.SS2.SSS2.p5.1.m1.3.3.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.3"><times id="S3.SS2.SSS2.p5.1.m1.3.3.3.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.1"></times><apply id="S3.SS2.SSS2.p5.1.m1.3.3.3.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.1.m1.3.3.3.2.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2">subscript</csymbol><ci id="S3.SS2.SSS2.p5.1.m1.3.3.3.2.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2.2">𝑓</ci><ci id="S3.SS2.SSS2.p5.1.m1.3.3.3.2.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.3.2.3">𝜃</ci></apply><ci id="S3.SS2.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.1.1">𝑥</ci></apply><apply id="S3.SS2.SSS2.p5.1.m1.3.3.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1"><times id="S3.SS2.SSS2.p5.1.m1.3.3.1.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.2"></times><apply id="S3.SS2.SSS2.p5.1.m1.3.3.1.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.1.m1.3.3.1.3.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p5.1.m1.3.3.1.3.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3.2">ℎ</ci><ci id="S3.SS2.SSS2.p5.1.m1.3.3.1.3.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.3.3">𝜃</ci></apply><apply id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1"><times id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.1"></times><apply id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.2">𝑔</ci><ci id="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS2.p5.1.m1.3.3.1.1.1.1.2.3">𝜃</ci></apply><ci id="S3.SS2.SSS2.p5.1.m1.2.2.cmml" xref="S3.SS2.SSS2.p5.1.m1.2.2">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.1.m1.3c">f_{\theta}(x)=h_{\theta}(g_{\theta}(x))</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p5.1.m1.3d">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) = italic_h start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) )</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p5.6.2" style="font-size:90%;">. </span><math alttext="K" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.2.m2.1"><semantics id="S3.SS2.SSS2.p5.2.m2.1a"><mi id="S3.SS2.SSS2.p5.2.m2.1.1" mathsize="90%" xref="S3.SS2.SSS2.p5.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.2.m2.1b"><ci id="S3.SS2.SSS2.p5.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p5.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p5.2.m2.1d">italic_K</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p5.6.3" style="font-size:90%;"> is the output dimension of </span><math alttext="h" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.3.m3.1"><semantics id="S3.SS2.SSS2.p5.3.m3.1a"><mi id="S3.SS2.SSS2.p5.3.m3.1.1" mathsize="90%" xref="S3.SS2.SSS2.p5.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.3.m3.1b"><ci id="S3.SS2.SSS2.p5.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p5.3.m3.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.3.m3.1c">h</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p5.3.m3.1d">italic_h</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p5.6.4" style="font-size:90%;">, and </span><math alttext="\tau_{s}&gt;0" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.4.m4.1"><semantics id="S3.SS2.SSS2.p5.4.m4.1a"><mrow id="S3.SS2.SSS2.p5.4.m4.1.1" xref="S3.SS2.SSS2.p5.4.m4.1.1.cmml"><msub id="S3.SS2.SSS2.p5.4.m4.1.1.2" xref="S3.SS2.SSS2.p5.4.m4.1.1.2.cmml"><mi id="S3.SS2.SSS2.p5.4.m4.1.1.2.2" mathsize="90%" xref="S3.SS2.SSS2.p5.4.m4.1.1.2.2.cmml">τ</mi><mi id="S3.SS2.SSS2.p5.4.m4.1.1.2.3" mathsize="90%" xref="S3.SS2.SSS2.p5.4.m4.1.1.2.3.cmml">s</mi></msub><mo id="S3.SS2.SSS2.p5.4.m4.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p5.4.m4.1.1.1.cmml">&gt;</mo><mn id="S3.SS2.SSS2.p5.4.m4.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p5.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.4.m4.1b"><apply id="S3.SS2.SSS2.p5.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1"><gt id="S3.SS2.SSS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1.1"></gt><apply id="S3.SS2.SSS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p5.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1.2.2">𝜏</ci><ci id="S3.SS2.SSS2.p5.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS2.p5.4.m4.1.1.2.3">𝑠</ci></apply><cn id="S3.SS2.SSS2.p5.4.m4.1.1.3.cmml" type="integer" xref="S3.SS2.SSS2.p5.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.4.m4.1c">\tau_{s}&gt;0</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p5.4.m4.1d">italic_τ start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT &gt; 0</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p5.6.5" style="font-size:90%;"> is a temperature parameter. A similar formula holds for the teacher counterpart with </span><math alttext="P_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.5.m5.1"><semantics id="S3.SS2.SSS2.p5.5.m5.1a"><msub id="S3.SS2.SSS2.p5.5.m5.1.1" xref="S3.SS2.SSS2.p5.5.m5.1.1.cmml"><mi id="S3.SS2.SSS2.p5.5.m5.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p5.5.m5.1.1.2.cmml">P</mi><mi id="S3.SS2.SSS2.p5.5.m5.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p5.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.5.m5.1b"><apply id="S3.SS2.SSS2.p5.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p5.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p5.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p5.5.m5.1.1.2">𝑃</ci><ci id="S3.SS2.SSS2.p5.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p5.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.5.m5.1c">P_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p5.5.m5.1d">italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p5.6.6" style="font-size:90%;"> and </span><math alttext="\tau_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p5.6.m6.1"><semantics id="S3.SS2.SSS2.p5.6.m6.1a"><msub id="S3.SS2.SSS2.p5.6.m6.1.1" xref="S3.SS2.SSS2.p5.6.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p5.6.m6.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p5.6.m6.1.1.2.cmml">τ</mi><mi id="S3.SS2.SSS2.p5.6.m6.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p5.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p5.6.m6.1b"><apply id="S3.SS2.SSS2.p5.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p5.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p5.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p5.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p5.6.m6.1.1.2">𝜏</ci><ci id="S3.SS2.SSS2.p5.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p5.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p5.6.m6.1c">\tau_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p5.6.m6.1d">italic_τ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p5.6.7" style="font-size:90%;">. The usage of a scaled softmax allows the sharpening of the output distribution (especially for the teacher) to avoid model collapse in practice </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p5.6.8.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p5.6.9.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S3.SS2.SSS2.p5.6.10.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p5.6.11" style="font-size:90%;">. Additionally, we adhere to the centering methodology presented in DINO to further avoid model collapse and reduce large batch size dependency. Detailed descriptions of the heads are provided in Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1.SS3" style="font-size:90%;" title="A.3 Projection Head ‣ Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">A.3</span></a><span class="ltx_text" id="S3.SS2.SSS2.p5.6.12" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p6">
<p class="ltx_p" id="S3.SS2.SSS2.p6.7"><span class="ltx_text" id="S3.SS2.SSS2.p6.7.1" style="font-size:90%;">The intended revealing of unmasked original image information is effectively achieved through FOLK’s teacher-student design. During pre-training, the teacher model sees naturally looking images, which better align with those encountered during the fine-tuning stage, thereby enhancing fine-tuning efficiency, particularly in few-shot learning scenarios. On the other hand, the student model only observes masked views but is guided by the teacher model using the following distillation loss. Both the student and teacher models </span><math alttext="g_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.1.m1.1"><semantics id="S3.SS2.SSS2.p6.1.m1.1a"><msub id="S3.SS2.SSS2.p6.1.m1.1.1" xref="S3.SS2.SSS2.p6.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p6.1.m1.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p6.1.m1.1.1.2.cmml">g</mi><mi id="S3.SS2.SSS2.p6.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.1.m1.1b"><apply id="S3.SS2.SSS2.p6.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p6.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1.2">𝑔</ci><ci id="S3.SS2.SSS2.p6.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p6.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.1.m1.1c">g_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.1.m1.1d">italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.2" style="font-size:90%;"> and </span><math alttext="g_{\phi}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.2.m2.1"><semantics id="S3.SS2.SSS2.p6.2.m2.1a"><msub id="S3.SS2.SSS2.p6.2.m2.1.1" xref="S3.SS2.SSS2.p6.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p6.2.m2.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p6.2.m2.1.1.2.cmml">g</mi><mi id="S3.SS2.SSS2.p6.2.m2.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.2.m2.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.2.m2.1b"><apply id="S3.SS2.SSS2.p6.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p6.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p6.2.m2.1.1.2">𝑔</ci><ci id="S3.SS2.SSS2.p6.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p6.2.m2.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.2.m2.1c">g_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.2.m2.1d">italic_g start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.3" style="font-size:90%;">, with their heads </span><math alttext="h_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.3.m3.1"><semantics id="S3.SS2.SSS2.p6.3.m3.1a"><msub id="S3.SS2.SSS2.p6.3.m3.1.1" xref="S3.SS2.SSS2.p6.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p6.3.m3.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p6.3.m3.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS2.p6.3.m3.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.3.m3.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.3.m3.1b"><apply id="S3.SS2.SSS2.p6.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p6.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p6.3.m3.1.1.2">ℎ</ci><ci id="S3.SS2.SSS2.p6.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p6.3.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.3.m3.1c">h_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.3.m3.1d">italic_h start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.4" style="font-size:90%;"> and </span><math alttext="h_{\phi}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.4.m4.1"><semantics id="S3.SS2.SSS2.p6.4.m4.1a"><msub id="S3.SS2.SSS2.p6.4.m4.1.1" xref="S3.SS2.SSS2.p6.4.m4.1.1.cmml"><mi id="S3.SS2.SSS2.p6.4.m4.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p6.4.m4.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS2.p6.4.m4.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.4.m4.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.4.m4.1b"><apply id="S3.SS2.SSS2.p6.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p6.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p6.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p6.4.m4.1.1.2">ℎ</ci><ci id="S3.SS2.SSS2.p6.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p6.4.m4.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.4.m4.1c">h_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.4.m4.1d">italic_h start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.5" style="font-size:90%;">, share the same architecture and initialization but have distinct parameters during training. Only the student model </span><math alttext="g_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.5.m5.1"><semantics id="S3.SS2.SSS2.p6.5.m5.1a"><msub id="S3.SS2.SSS2.p6.5.m5.1.1" xref="S3.SS2.SSS2.p6.5.m5.1.1.cmml"><mi id="S3.SS2.SSS2.p6.5.m5.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p6.5.m5.1.1.2.cmml">g</mi><mi id="S3.SS2.SSS2.p6.5.m5.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.5.m5.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.5.m5.1b"><apply id="S3.SS2.SSS2.p6.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p6.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p6.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p6.5.m5.1.1.2">𝑔</ci><ci id="S3.SS2.SSS2.p6.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p6.5.m5.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.5.m5.1c">g_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.5.m5.1d">italic_g start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.6" style="font-size:90%;"> and its both heads </span><math alttext="h_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.6.m6.1"><semantics id="S3.SS2.SSS2.p6.6.m6.1a"><msub id="S3.SS2.SSS2.p6.6.m6.1.1" xref="S3.SS2.SSS2.p6.6.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p6.6.m6.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p6.6.m6.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS2.p6.6.m6.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.6.m6.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.6.m6.1b"><apply id="S3.SS2.SSS2.p6.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p6.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p6.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p6.6.m6.1.1.2">ℎ</ci><ci id="S3.SS2.SSS2.p6.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p6.6.m6.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.6.m6.1c">h_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.6.m6.1d">italic_h start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.7" style="font-size:90%;"> and </span><math alttext="\hat{h}_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p6.7.m7.1"><semantics id="S3.SS2.SSS2.p6.7.m7.1a"><msub id="S3.SS2.SSS2.p6.7.m7.1.1" xref="S3.SS2.SSS2.p6.7.m7.1.1.cmml"><mover accent="true" id="S3.SS2.SSS2.p6.7.m7.1.1.2" xref="S3.SS2.SSS2.p6.7.m7.1.1.2.cmml"><mi id="S3.SS2.SSS2.p6.7.m7.1.1.2.2" mathsize="90%" xref="S3.SS2.SSS2.p6.7.m7.1.1.2.2.cmml">h</mi><mo id="S3.SS2.SSS2.p6.7.m7.1.1.2.1" mathsize="90%" xref="S3.SS2.SSS2.p6.7.m7.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.SSS2.p6.7.m7.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p6.7.m7.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p6.7.m7.1b"><apply id="S3.SS2.SSS2.p6.7.m7.1.1.cmml" xref="S3.SS2.SSS2.p6.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p6.7.m7.1.1.1.cmml" xref="S3.SS2.SSS2.p6.7.m7.1.1">subscript</csymbol><apply id="S3.SS2.SSS2.p6.7.m7.1.1.2.cmml" xref="S3.SS2.SSS2.p6.7.m7.1.1.2"><ci id="S3.SS2.SSS2.p6.7.m7.1.1.2.1.cmml" xref="S3.SS2.SSS2.p6.7.m7.1.1.2.1">^</ci><ci id="S3.SS2.SSS2.p6.7.m7.1.1.2.2.cmml" xref="S3.SS2.SSS2.p6.7.m7.1.1.2.2">ℎ</ci></apply><ci id="S3.SS2.SSS2.p6.7.m7.1.1.3.cmml" xref="S3.SS2.SSS2.p6.7.m7.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p6.7.m7.1c">\hat{h}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p6.7.m7.1d">over^ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p6.7.8" style="font-size:90%;"> are updated by the loss back-propagation, while the teacher parameters are periodically updated with an exponential moving average (EMA) of the corresponding student parameters.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p7">
<p class="ltx_p" id="S3.SS2.SSS2.p7.1"><span class="ltx_text" id="S3.SS2.SSS2.p7.1.1" style="font-size:90%;">A distillation loss is employed to enforce the less-informed student model to emulate the more knowledgeable teacher model who perceives the original views. For a single input image </span><math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p7.1.m1.1"><semantics id="S3.SS2.SSS2.p7.1.m1.1a"><mi id="S3.SS2.SSS2.p7.1.m1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p7.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p7.1.m1.1b"><ci id="S3.SS2.SSS2.p7.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p7.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p7.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p7.1.m1.1d">italic_x</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p7.1.2" style="font-size:90%;">, this loss can be written as:</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p8">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{dis}}=-[P_{t}(u)\log\left(P_{s}(\tilde{v})\right)+P_{t}(v)%
\log\left(P_{s}(\tilde{u})\right)]." class="ltx_Math" display="block" id="S3.Ex5.m1.7"><semantics id="S3.Ex5.m1.7a"><mrow id="S3.Ex5.m1.7.7.1" xref="S3.Ex5.m1.7.7.1.1.cmml"><mrow id="S3.Ex5.m1.7.7.1.1" xref="S3.Ex5.m1.7.7.1.1.cmml"><msub id="S3.Ex5.m1.7.7.1.1.3" xref="S3.Ex5.m1.7.7.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex5.m1.7.7.1.1.3.2" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.3.2.cmml">ℒ</mi><mtext id="S3.Ex5.m1.7.7.1.1.3.3" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.3.3a.cmml">dis</mtext></msub><mo id="S3.Ex5.m1.7.7.1.1.2" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.2.cmml">=</mo><mrow id="S3.Ex5.m1.7.7.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1a" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.cmml">−</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.2.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.cmml"><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.cmml"><msub id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.2" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.2.cmml">P</mi><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.3" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.4.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.4.2.1" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.Ex5.m1.1.1" mathsize="90%" xref="S3.Ex5.m1.1.1.cmml">u</mi><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.4.2.2" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.2a" lspace="0.167em" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex5.m1.3.3" mathsize="90%" xref="S3.Ex5.m1.3.3.cmml">log</mi><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1a" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.2" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">P</mi><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.3" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">s</mi></msub><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex5.m1.2.2.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.2.2.cmml">(</mo><mover accent="true" id="S3.Ex5.m1.2.2" xref="S3.Ex5.m1.2.2.cmml"><mi id="S3.Ex5.m1.2.2.2" mathsize="90%" xref="S3.Ex5.m1.2.2.2.cmml">v</mi><mo id="S3.Ex5.m1.2.2.1" mathsize="90%" xref="S3.Ex5.m1.2.2.1.cmml">~</mo></mover><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.3" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.3.cmml">+</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.cmml"><msub id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.cmml"><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.2" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.2.cmml">P</mi><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.3" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.3.cmml">t</mi></msub><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.4.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.4.2.1" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.Ex5.m1.4.4" mathsize="90%" xref="S3.Ex5.m1.4.4.cmml">v</mi><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.4.2.2" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.cmml">)</mo></mrow><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.2a" lspace="0.167em" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.2.cmml"><mi id="S3.Ex5.m1.6.6" mathsize="90%" xref="S3.Ex5.m1.6.6.cmml">log</mi><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1a" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.2.cmml">⁡</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.2.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.2.cmml">(</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.cmml"><msub id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.cmml"><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.2" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.2.cmml">P</mi><mi id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.3" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.3.cmml">s</mi></msub><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.1" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.3.2" xref="S3.Ex5.m1.5.5.cmml"><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.3.2.1" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.5.5.cmml">(</mo><mover accent="true" id="S3.Ex5.m1.5.5" xref="S3.Ex5.m1.5.5.cmml"><mi id="S3.Ex5.m1.5.5.2" mathsize="90%" xref="S3.Ex5.m1.5.5.2.cmml">u</mi><mo id="S3.Ex5.m1.5.5.1" mathsize="90%" xref="S3.Ex5.m1.5.5.1.cmml">~</mo></mover><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.3.2.2" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.5.5.cmml">)</mo></mrow></mrow><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.3" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.Ex5.m1.7.7.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.Ex5.m1.7.7.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S3.Ex5.m1.7.7.1.2" lspace="0em" mathsize="90%" xref="S3.Ex5.m1.7.7.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex5.m1.7b"><apply id="S3.Ex5.m1.7.7.1.1.cmml" xref="S3.Ex5.m1.7.7.1"><eq id="S3.Ex5.m1.7.7.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.2"></eq><apply id="S3.Ex5.m1.7.7.1.1.3.cmml" xref="S3.Ex5.m1.7.7.1.1.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.7.7.1.1.3.1.cmml" xref="S3.Ex5.m1.7.7.1.1.3">subscript</csymbol><ci id="S3.Ex5.m1.7.7.1.1.3.2.cmml" xref="S3.Ex5.m1.7.7.1.1.3.2">ℒ</ci><ci id="S3.Ex5.m1.7.7.1.1.3.3a.cmml" xref="S3.Ex5.m1.7.7.1.1.3.3"><mtext id="S3.Ex5.m1.7.7.1.1.3.3.cmml" mathsize="63%" xref="S3.Ex5.m1.7.7.1.1.3.3">dis</mtext></ci></apply><apply id="S3.Ex5.m1.7.7.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1"><minus id="S3.Ex5.m1.7.7.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1"></minus><apply id="S3.Ex5.m1.7.7.1.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex5.m1.7.7.1.1.1.1.2.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1"><plus id="S3.Ex5.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.3"></plus><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1"><times id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.2"></times><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.2">𝑃</ci><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><ci id="S3.Ex5.m1.1.1.cmml" xref="S3.Ex5.m1.1.1">𝑢</ci><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1"><log id="S3.Ex5.m1.3.3.cmml" xref="S3.Ex5.m1.3.3"></log><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑃</ci><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑠</ci></apply><apply id="S3.Ex5.m1.2.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.Ex5.m1.2.2.1.cmml" xref="S3.Ex5.m1.2.2.1">~</ci><ci id="S3.Ex5.m1.2.2.2.cmml" xref="S3.Ex5.m1.2.2.2">𝑣</ci></apply></apply></apply></apply><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2"><times id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.2"></times><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.2">𝑃</ci><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.3.3">𝑡</ci></apply><ci id="S3.Ex5.m1.4.4.cmml" xref="S3.Ex5.m1.4.4">𝑣</ci><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1"><log id="S3.Ex5.m1.6.6.cmml" xref="S3.Ex5.m1.6.6"></log><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1"><times id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.1"></times><apply id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.1.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.2.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.2">𝑃</ci><ci id="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.3.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.2.3">𝑠</ci></apply><apply id="S3.Ex5.m1.5.5.cmml" xref="S3.Ex5.m1.7.7.1.1.1.1.1.1.2.1.1.1.1.3.2"><ci id="S3.Ex5.m1.5.5.1.cmml" xref="S3.Ex5.m1.5.5.1">~</ci><ci id="S3.Ex5.m1.5.5.2.cmml" xref="S3.Ex5.m1.5.5.2">𝑢</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex5.m1.7c">\mathcal{L}_{\text{dis}}=-[P_{t}(u)\log\left(P_{s}(\tilde{v})\right)+P_{t}(v)%
\log\left(P_{s}(\tilde{u})\right)].</annotation><annotation encoding="application/x-llamapun" id="S3.Ex5.m1.7d">caligraphic_L start_POSTSUBSCRIPT dis end_POSTSUBSCRIPT = - [ italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_u ) roman_log ( italic_P start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( over~ start_ARG italic_v end_ARG ) ) + italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_v ) roman_log ( italic_P start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( over~ start_ARG italic_u end_ARG ) ) ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p9">
<p class="ltx_p" id="S3.SS2.SSS2.p9.6"><span class="ltx_text" id="S3.SS2.SSS2.p9.6.1" style="font-size:90%;">where </span><math alttext="u,v" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p9.1.m1.2"><semantics id="S3.SS2.SSS2.p9.1.m1.2a"><mrow id="S3.SS2.SSS2.p9.1.m1.2.3.2" xref="S3.SS2.SSS2.p9.1.m1.2.3.1.cmml"><mi id="S3.SS2.SSS2.p9.1.m1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p9.1.m1.1.1.cmml">u</mi><mo id="S3.SS2.SSS2.p9.1.m1.2.3.2.1" mathsize="90%" xref="S3.SS2.SSS2.p9.1.m1.2.3.1.cmml">,</mo><mi id="S3.SS2.SSS2.p9.1.m1.2.2" mathsize="90%" xref="S3.SS2.SSS2.p9.1.m1.2.2.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p9.1.m1.2b"><list id="S3.SS2.SSS2.p9.1.m1.2.3.1.cmml" xref="S3.SS2.SSS2.p9.1.m1.2.3.2"><ci id="S3.SS2.SSS2.p9.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p9.1.m1.1.1">𝑢</ci><ci id="S3.SS2.SSS2.p9.1.m1.2.2.cmml" xref="S3.SS2.SSS2.p9.1.m1.2.2">𝑣</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p9.1.m1.2c">u,v</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p9.1.m1.2d">italic_u , italic_v</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p9.6.2" style="font-size:90%;"> are two different views of </span><math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p9.2.m2.1"><semantics id="S3.SS2.SSS2.p9.2.m2.1a"><mi id="S3.SS2.SSS2.p9.2.m2.1.1" mathsize="90%" xref="S3.SS2.SSS2.p9.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p9.2.m2.1b"><ci id="S3.SS2.SSS2.p9.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p9.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p9.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p9.2.m2.1d">italic_x</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p9.6.3" style="font-size:90%;">, and </span><math alttext="\tilde{u},\tilde{v}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p9.3.m3.2"><semantics id="S3.SS2.SSS2.p9.3.m3.2a"><mrow id="S3.SS2.SSS2.p9.3.m3.2.3.2" xref="S3.SS2.SSS2.p9.3.m3.2.3.1.cmml"><mover accent="true" id="S3.SS2.SSS2.p9.3.m3.1.1" xref="S3.SS2.SSS2.p9.3.m3.1.1.cmml"><mi id="S3.SS2.SSS2.p9.3.m3.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p9.3.m3.1.1.2.cmml">u</mi><mo id="S3.SS2.SSS2.p9.3.m3.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p9.3.m3.1.1.1.cmml">~</mo></mover><mo id="S3.SS2.SSS2.p9.3.m3.2.3.2.1" mathsize="90%" xref="S3.SS2.SSS2.p9.3.m3.2.3.1.cmml">,</mo><mover accent="true" id="S3.SS2.SSS2.p9.3.m3.2.2" xref="S3.SS2.SSS2.p9.3.m3.2.2.cmml"><mi id="S3.SS2.SSS2.p9.3.m3.2.2.2" mathsize="90%" xref="S3.SS2.SSS2.p9.3.m3.2.2.2.cmml">v</mi><mo id="S3.SS2.SSS2.p9.3.m3.2.2.1" mathsize="90%" xref="S3.SS2.SSS2.p9.3.m3.2.2.1.cmml">~</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p9.3.m3.2b"><list id="S3.SS2.SSS2.p9.3.m3.2.3.1.cmml" xref="S3.SS2.SSS2.p9.3.m3.2.3.2"><apply id="S3.SS2.SSS2.p9.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p9.3.m3.1.1"><ci id="S3.SS2.SSS2.p9.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p9.3.m3.1.1.1">~</ci><ci id="S3.SS2.SSS2.p9.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p9.3.m3.1.1.2">𝑢</ci></apply><apply id="S3.SS2.SSS2.p9.3.m3.2.2.cmml" xref="S3.SS2.SSS2.p9.3.m3.2.2"><ci id="S3.SS2.SSS2.p9.3.m3.2.2.1.cmml" xref="S3.SS2.SSS2.p9.3.m3.2.2.1">~</ci><ci id="S3.SS2.SSS2.p9.3.m3.2.2.2.cmml" xref="S3.SS2.SSS2.p9.3.m3.2.2.2">𝑣</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p9.3.m3.2c">\tilde{u},\tilde{v}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p9.3.m3.2d">over~ start_ARG italic_u end_ARG , over~ start_ARG italic_v end_ARG</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p9.6.4" style="font-size:90%;"> are the corresponding frequency-masked views. </span><math alttext="P_{s}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p9.4.m4.1"><semantics id="S3.SS2.SSS2.p9.4.m4.1a"><msub id="S3.SS2.SSS2.p9.4.m4.1.1" xref="S3.SS2.SSS2.p9.4.m4.1.1.cmml"><mi id="S3.SS2.SSS2.p9.4.m4.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p9.4.m4.1.1.2.cmml">P</mi><mi id="S3.SS2.SSS2.p9.4.m4.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p9.4.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p9.4.m4.1b"><apply id="S3.SS2.SSS2.p9.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p9.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p9.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p9.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p9.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p9.4.m4.1.1.2">𝑃</ci><ci id="S3.SS2.SSS2.p9.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p9.4.m4.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p9.4.m4.1c">P_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p9.4.m4.1d">italic_P start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p9.6.5" style="font-size:90%;"> and </span><math alttext="P_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p9.5.m5.1"><semantics id="S3.SS2.SSS2.p9.5.m5.1a"><msub id="S3.SS2.SSS2.p9.5.m5.1.1" xref="S3.SS2.SSS2.p9.5.m5.1.1.cmml"><mi id="S3.SS2.SSS2.p9.5.m5.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p9.5.m5.1.1.2.cmml">P</mi><mi id="S3.SS2.SSS2.p9.5.m5.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p9.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p9.5.m5.1b"><apply id="S3.SS2.SSS2.p9.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p9.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p9.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p9.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p9.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p9.5.m5.1.1.2">𝑃</ci><ci id="S3.SS2.SSS2.p9.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p9.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p9.5.m5.1c">P_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p9.5.m5.1d">italic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p9.6.6" style="font-size:90%;"> are the student and teacher output probability distributions introduced in Eq. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.Ex4" style="font-size:90%;" title="In 3.2.2 Making Backbone Familiar with Natural Images ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S3.SS2.SSS2.p9.6.7" style="font-size:90%;">. The EMA update to the teacher is then ruled by </span><math alttext="\phi\leftarrow\lambda\phi+(1-\lambda)\theta" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p9.6.m6.1"><semantics id="S3.SS2.SSS2.p9.6.m6.1a"><mrow id="S3.SS2.SSS2.p9.6.m6.1.1" xref="S3.SS2.SSS2.p9.6.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p9.6.m6.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.3.cmml">ϕ</mi><mo id="S3.SS2.SSS2.p9.6.m6.1.1.2" mathsize="90%" stretchy="false" xref="S3.SS2.SSS2.p9.6.m6.1.1.2.cmml">←</mo><mrow id="S3.SS2.SSS2.p9.6.m6.1.1.1" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.cmml"><mrow id="S3.SS2.SSS2.p9.6.m6.1.1.1.3" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.cmml"><mi id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.2" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.2.cmml">λ</mi><mo id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.1" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.3" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.3.cmml">ϕ</mi></mrow><mo id="S3.SS2.SSS2.p9.6.m6.1.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.2.cmml">+</mo><mrow id="S3.SS2.SSS2.p9.6.m6.1.1.1.1" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.cmml"><mrow id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.cmml"><mn id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.1" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.2" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.2.cmml">⁢</mo><mi id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.3.cmml">θ</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p9.6.m6.1b"><apply id="S3.SS2.SSS2.p9.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1"><ci id="S3.SS2.SSS2.p9.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.2">←</ci><ci id="S3.SS2.SSS2.p9.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.3">italic-ϕ</ci><apply id="S3.SS2.SSS2.p9.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1"><plus id="S3.SS2.SSS2.p9.6.m6.1.1.1.2.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.2"></plus><apply id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3"><times id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.1.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.1"></times><ci id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.2.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.2">𝜆</ci><ci id="S3.SS2.SSS2.p9.6.m6.1.1.1.3.3.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.3.3">italic-ϕ</ci></apply><apply id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1"><times id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.2"></times><apply id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1"><minus id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.1"></minus><cn id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.2">1</cn><ci id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.1.1.1.3">𝜆</ci></apply><ci id="S3.SS2.SSS2.p9.6.m6.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p9.6.m6.1.1.1.1.3">𝜃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p9.6.m6.1c">\phi\leftarrow\lambda\phi+(1-\lambda)\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p9.6.m6.1d">italic_ϕ ← italic_λ italic_ϕ + ( 1 - italic_λ ) italic_θ</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p9.6.8" style="font-size:90%;">, ensuring a gradual integration of knowledge over time.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p10">
<p class="ltx_p" id="S3.SS2.SSS2.p10.1"><span class="ltx_text" id="S3.SS2.SSS2.p10.1.1" style="font-size:90%;">Note that, same as MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p10.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p10.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S3.SS2.SSS2.p10.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p10.1.5" style="font-size:90%;">, FOLK features compatibility with both ViT and CNN-based architectures. Illustrated in Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.2.2 Making Backbone Familiar with Natural Images ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS2.SSS2.p10.1.6" style="font-size:90%;">, when using a ViT-based model as the student (and teacher), the patch tokens out of the final encoder layer are fed into the MFM head, whereas the class token </span><math alttext="[CLS]" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p10.1.m1.1"><semantics id="S3.SS2.SSS2.p10.1.m1.1a"><mrow id="S3.SS2.SSS2.p10.1.m1.1.1.1" xref="S3.SS2.SSS2.p10.1.m1.1.1.2.cmml"><mo id="S3.SS2.SSS2.p10.1.m1.1.1.1.2" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p10.1.m1.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.SSS2.p10.1.m1.1.1.1.1" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.2" mathsize="90%" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.2.cmml">C</mi><mo id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.1" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.3" mathsize="90%" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.3.cmml">L</mi><mo id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.1a" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.4" mathsize="90%" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.4.cmml">S</mi></mrow><mo id="S3.SS2.SSS2.p10.1.m1.1.1.1.3" maxsize="90%" minsize="90%" xref="S3.SS2.SSS2.p10.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p10.1.m1.1b"><apply id="S3.SS2.SSS2.p10.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS2.p10.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1"><times id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.1"></times><ci id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.3">𝐿</ci><ci id="S3.SS2.SSS2.p10.1.m1.1.1.1.1.4.cmml" xref="S3.SS2.SSS2.p10.1.m1.1.1.1.1.4">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p10.1.m1.1c">[CLS]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p10.1.m1.1d">[ italic_C italic_L italic_S ]</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS2.p10.1.7" style="font-size:90%;"> is directed to the student (and teacher) head. Conversely, when using a CNN-based model, the framework utilizes the final feature maps out of the CNN encoder as the input for the MFM head. An average-pooled feature map from the original feature maps will serve as the input to the student (and teacher) head. We provide experiments and results using a CNN model (i.e. ResNet-50 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S3.SS2.SSS2.p10.1.8.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S3.SS2.SSS2.p10.1.9.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a><span class="ltx_text" id="S3.SS2.SSS2.p10.1.10.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S3.SS2.SSS2.p10.1.11" style="font-size:90%;">) in Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS1" style="font-size:90%;" title="B.1 Image Classification - CNN Base Modal ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">B.1</span></a><span class="ltx_text" id="S3.SS2.SSS2.p10.1.12" style="font-size:90%;">. Hence, FOLK facilitates a consistent approach across different architectural paradigms.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Comprehensive Loss Calculation</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1"><span class="ltx_text" id="S3.SS2.SSS3.p1.1.1" style="font-size:90%;">Finally, a comprehensive loss can be derived by integrating the two primary loss components:</span></p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{tot}}=\alpha\cdot\mathcal{L}_{\text{dis}}+\mathcal{L}_{%
\text{MFM}}." class="ltx_Math" display="block" id="S3.Ex6.m1.1"><semantics id="S3.Ex6.m1.1a"><mrow id="S3.Ex6.m1.1.1.1" xref="S3.Ex6.m1.1.1.1.1.cmml"><mrow id="S3.Ex6.m1.1.1.1.1" xref="S3.Ex6.m1.1.1.1.1.cmml"><msub id="S3.Ex6.m1.1.1.1.1.2" xref="S3.Ex6.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex6.m1.1.1.1.1.2.2" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.2.2.cmml">ℒ</mi><mtext id="S3.Ex6.m1.1.1.1.1.2.3" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.2.3a.cmml">tot</mtext></msub><mo id="S3.Ex6.m1.1.1.1.1.1" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.Ex6.m1.1.1.1.1.3" xref="S3.Ex6.m1.1.1.1.1.3.cmml"><mrow id="S3.Ex6.m1.1.1.1.1.3.2" xref="S3.Ex6.m1.1.1.1.1.3.2.cmml"><mi id="S3.Ex6.m1.1.1.1.1.3.2.2" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.3.2.2.cmml">α</mi><mo id="S3.Ex6.m1.1.1.1.1.3.2.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.Ex6.m1.1.1.1.1.3.2.1.cmml">⋅</mo><msub id="S3.Ex6.m1.1.1.1.1.3.2.3" xref="S3.Ex6.m1.1.1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex6.m1.1.1.1.1.3.2.3.2" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.3.2.3.2.cmml">ℒ</mi><mtext id="S3.Ex6.m1.1.1.1.1.3.2.3.3" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.3.2.3.3a.cmml">dis</mtext></msub></mrow><mo id="S3.Ex6.m1.1.1.1.1.3.1" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.Ex6.m1.1.1.1.1.3.3" xref="S3.Ex6.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex6.m1.1.1.1.1.3.3.2" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.3.3.2.cmml">ℒ</mi><mtext id="S3.Ex6.m1.1.1.1.1.3.3.3" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.3.3.3a.cmml">MFM</mtext></msub></mrow></mrow><mo id="S3.Ex6.m1.1.1.1.2" lspace="0em" mathsize="90%" xref="S3.Ex6.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex6.m1.1b"><apply id="S3.Ex6.m1.1.1.1.1.cmml" xref="S3.Ex6.m1.1.1.1"><eq id="S3.Ex6.m1.1.1.1.1.1.cmml" xref="S3.Ex6.m1.1.1.1.1.1"></eq><apply id="S3.Ex6.m1.1.1.1.1.2.cmml" xref="S3.Ex6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.1.1.2.1.cmml" xref="S3.Ex6.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex6.m1.1.1.1.1.2.2.cmml" xref="S3.Ex6.m1.1.1.1.1.2.2">ℒ</ci><ci id="S3.Ex6.m1.1.1.1.1.2.3a.cmml" xref="S3.Ex6.m1.1.1.1.1.2.3"><mtext id="S3.Ex6.m1.1.1.1.1.2.3.cmml" mathsize="63%" xref="S3.Ex6.m1.1.1.1.1.2.3">tot</mtext></ci></apply><apply id="S3.Ex6.m1.1.1.1.1.3.cmml" xref="S3.Ex6.m1.1.1.1.1.3"><plus id="S3.Ex6.m1.1.1.1.1.3.1.cmml" xref="S3.Ex6.m1.1.1.1.1.3.1"></plus><apply id="S3.Ex6.m1.1.1.1.1.3.2.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2"><ci id="S3.Ex6.m1.1.1.1.1.3.2.1.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2.1">⋅</ci><ci id="S3.Ex6.m1.1.1.1.1.3.2.2.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2.2">𝛼</ci><apply id="S3.Ex6.m1.1.1.1.1.3.2.3.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.Ex6.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2.3.2">ℒ</ci><ci id="S3.Ex6.m1.1.1.1.1.3.2.3.3a.cmml" xref="S3.Ex6.m1.1.1.1.1.3.2.3.3"><mtext id="S3.Ex6.m1.1.1.1.1.3.2.3.3.cmml" mathsize="63%" xref="S3.Ex6.m1.1.1.1.1.3.2.3.3">dis</mtext></ci></apply></apply><apply id="S3.Ex6.m1.1.1.1.1.3.3.cmml" xref="S3.Ex6.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.1.1.3.3.1.cmml" xref="S3.Ex6.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.Ex6.m1.1.1.1.1.3.3.2.cmml" xref="S3.Ex6.m1.1.1.1.1.3.3.2">ℒ</ci><ci id="S3.Ex6.m1.1.1.1.1.3.3.3a.cmml" xref="S3.Ex6.m1.1.1.1.1.3.3.3"><mtext id="S3.Ex6.m1.1.1.1.1.3.3.3.cmml" mathsize="63%" xref="S3.Ex6.m1.1.1.1.1.3.3.3">MFM</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex6.m1.1c">\mathcal{L}_{\text{tot}}=\alpha\cdot\mathcal{L}_{\text{dis}}+\mathcal{L}_{%
\text{MFM}}.</annotation><annotation encoding="application/x-llamapun" id="S3.Ex6.m1.1d">caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT = italic_α ⋅ caligraphic_L start_POSTSUBSCRIPT dis end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT MFM end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.6"><span class="ltx_text" id="S3.SS2.SSS3.p3.6.1" style="font-size:90%;">where a hyperparameter </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.1.m1.1"><semantics id="S3.SS2.SSS3.p3.1.m1.1a"><mi id="S3.SS2.SSS3.p3.1.m1.1.1" mathsize="90%" xref="S3.SS2.SSS3.p3.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.1.m1.1b"><ci id="S3.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.1.m1.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS3.p3.6.2" style="font-size:90%;"> controls the weights between two loss terms, which is set as </span><math alttext="1" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.2.m2.1"><semantics id="S3.SS2.SSS3.p3.2.m2.1a"><mn id="S3.SS2.SSS3.p3.2.m2.1.1" mathsize="90%" xref="S3.SS2.SSS3.p3.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.2.m2.1b"><cn id="S3.SS2.SSS3.p3.2.m2.1.1.cmml" type="integer" xref="S3.SS2.SSS3.p3.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.2.m2.1d">1</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS3.p3.6.3" style="font-size:90%;"> in our experiments, unless stated otherwise. Note that for a single input image, </span><math alttext="\mathcal{L}_{\text{MFM}}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.3.m3.1"><semantics id="S3.SS2.SSS3.p3.3.m3.1a"><msub id="S3.SS2.SSS3.p3.3.m3.1.1" xref="S3.SS2.SSS3.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS3.p3.3.m3.1.1.2" mathsize="90%" xref="S3.SS2.SSS3.p3.3.m3.1.1.2.cmml">ℒ</mi><mtext id="S3.SS2.SSS3.p3.3.m3.1.1.3" mathsize="90%" xref="S3.SS2.SSS3.p3.3.m3.1.1.3a.cmml">MFM</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.3.m3.1b"><apply id="S3.SS2.SSS3.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.2">ℒ</ci><ci id="S3.SS2.SSS3.p3.3.m3.1.1.3a.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3"><mtext id="S3.SS2.SSS3.p3.3.m3.1.1.3.cmml" mathsize="63%" xref="S3.SS2.SSS3.p3.3.m3.1.1.3">MFM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.3.m3.1c">\mathcal{L}_{\text{MFM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT MFM end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS3.p3.6.4" style="font-size:90%;"> takes an average over two terms for the two different views. This comprehensive loss facilitates the simultaneous model learning on the two tasks introduced above, the masked frequencies reconstruction (through </span><math alttext="\mathcal{L}_{\text{MFM}}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.4.m4.1"><semantics id="S3.SS2.SSS3.p3.4.m4.1a"><msub id="S3.SS2.SSS3.p3.4.m4.1.1" xref="S3.SS2.SSS3.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS3.p3.4.m4.1.1.2" mathsize="90%" xref="S3.SS2.SSS3.p3.4.m4.1.1.2.cmml">ℒ</mi><mtext id="S3.SS2.SSS3.p3.4.m4.1.1.3" mathsize="90%" xref="S3.SS2.SSS3.p3.4.m4.1.1.3a.cmml">MFM</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.4.m4.1b"><apply id="S3.SS2.SSS3.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p3.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.2">ℒ</ci><ci id="S3.SS2.SSS3.p3.4.m4.1.1.3a.cmml" xref="S3.SS2.SSS3.p3.4.m4.1.1.3"><mtext id="S3.SS2.SSS3.p3.4.m4.1.1.3.cmml" mathsize="63%" xref="S3.SS2.SSS3.p3.4.m4.1.1.3">MFM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.4.m4.1c">\mathcal{L}_{\text{MFM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT MFM end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS3.p3.6.5" style="font-size:90%;">) and original image feature reconstruction with self-distillation (through </span><math alttext="\mathcal{L}_{\text{dis}}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.5.m5.1"><semantics id="S3.SS2.SSS3.p3.5.m5.1a"><msub id="S3.SS2.SSS3.p3.5.m5.1.1" xref="S3.SS2.SSS3.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS3.p3.5.m5.1.1.2" mathsize="90%" xref="S3.SS2.SSS3.p3.5.m5.1.1.2.cmml">ℒ</mi><mtext id="S3.SS2.SSS3.p3.5.m5.1.1.3" mathsize="90%" xref="S3.SS2.SSS3.p3.5.m5.1.1.3a.cmml">dis</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.5.m5.1b"><apply id="S3.SS2.SSS3.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.5.m5.1.1.1.cmml" xref="S3.SS2.SSS3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p3.5.m5.1.1.2.cmml" xref="S3.SS2.SSS3.p3.5.m5.1.1.2">ℒ</ci><ci id="S3.SS2.SSS3.p3.5.m5.1.1.3a.cmml" xref="S3.SS2.SSS3.p3.5.m5.1.1.3"><mtext id="S3.SS2.SSS3.p3.5.m5.1.1.3.cmml" mathsize="63%" xref="S3.SS2.SSS3.p3.5.m5.1.1.3">dis</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.5.m5.1c">\mathcal{L}_{\text{dis}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.5.m5.1d">caligraphic_L start_POSTSUBSCRIPT dis end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS3.p3.6.6" style="font-size:90%;">). Furthermore, an ablation study for different choices of the hyperparameter </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.6.m6.1"><semantics id="S3.SS2.SSS3.p3.6.m6.1a"><mi id="S3.SS2.SSS3.p3.6.m6.1.1" mathsize="90%" xref="S3.SS2.SSS3.p3.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.6.m6.1b"><ci id="S3.SS2.SSS3.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS3.p3.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.6.m6.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.6.m6.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S3.SS2.SSS3.p3.6.7" style="font-size:90%;"> is provided in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS4" style="font-size:90%;" title="4.2.4 Ablation Study ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4.2.4</span></a><span class="ltx_text" id="S3.SS2.SSS3.p3.6.8" style="font-size:90%;">.</span></p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Setup</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text" id="S4.SS1.p1.1.1" style="font-size:90%;">In this study, we employ two well-established model architectures as the foundation for our experiments: the ViT-Small (ViT-S/16) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Dosovitskiy et al.</span><span class="ltx_text" id="S4.SS1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S4.SS1.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p1.1.5" style="font-size:90%;"> and the ResNet-50 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S4.SS1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a><span class="ltx_text" id="S4.SS1.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p1.1.9" style="font-size:90%;">. These models are chosen for their proven effectiveness and versatility, showing the power of our model with different types of model architecture. We adopt the ImageNet-1K training dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p1.1.10.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Deng et al.</span><span class="ltx_text" id="S4.SS1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">2009</span></a><span class="ltx_text" id="S4.SS1.p1.1.12.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p1.1.13" style="font-size:90%;"> without labels for pre-training our self-supervised learning approach.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text" id="S4.SS1.p2.1.1" style="font-size:90%;">Our model’s performance is evaluated across two critical areas: image classification and semantic segmentation. For image classification, we continue to leverage the ImageNet-1K dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p2.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Deng et al.</span><span class="ltx_text" id="S4.SS1.p2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">2009</span></a><span class="ltx_text" id="S4.SS1.p2.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p2.1.5" style="font-size:90%;"> to assess the generalizability and effectiveness of the learned features. In contrast, for semantic segmentation, we utilize the ADE20K dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS1.p2.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S4.SS1.p2.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib70" title=""><span class="ltx_text" style="font-size:90%;">2017</span></a><span class="ltx_text" id="S4.SS1.p2.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS1.p2.1.9" style="font-size:90%;">, a standard benchmark in scene parsing and segmentation tasks. This bifurcated approach to evaluation ensures a thorough analysis of the models’ capabilities in varied contexts. Our computational infrastructure supports these extensive experiments, consisting of four nodes, each of which has four NVIDIA A100 80GB GPUs, in total 16 GPUs. Please see Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A1" style="font-size:90%;" title="Appendix A Implementation Details ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">A</span></a><span class="ltx_text" id="S4.SS1.p2.1.10" style="font-size:90%;"> for implementation details. Also, see Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS4" style="font-size:90%;" title="B.4 Efficiency Analysis ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">B.4</span></a><span class="ltx_text" id="S4.SS1.p2.1.11" style="font-size:90%;"> for GPU usage.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Analysis</h3>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Image Classification</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1"><span class="ltx_text" id="S4.SS2.SSS1.p1.1.1" style="font-size:90%;">In this section, we focus on the fine-tuning capabilities of different vision pre-training techniques, using the ViT-S/16 encoder on the ImageNet-1K dataset. The motivation behind this analysis stems from the need to understand how different SSL strategies, which range from traditional methods to novel approaches like the FOLK method introduced here, perform under uniform testing conditions with the well-established ImageNet benchmark dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.SSS1.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Deng et al.</span><span class="ltx_text" id="S4.SS2.SSS1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">2009</span></a><span class="ltx_text" id="S4.SS2.SSS1.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.SSS1.p1.1.5" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.2.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.1.1.1" style="font-size:90%;">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.1.2.1" style="font-size:90%;">Ref</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.3.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.1.3.1" style="font-size:90%;">Data</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.3.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.1.4.1" style="font-size:90%;">Epoch</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.3.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.1.5.1" style="font-size:90%;">Token</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.3.1.6"><span class="ltx_text ltx_font_bold" id="S4.T1.2.3.1.6.1" style="font-size:90%;">ViT-S</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.4.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.4.2.1"><span class="ltx_text" id="S4.T1.2.4.2.1.1" style="font-size:90%;">Scratch</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.4.2.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.4.2.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Touvron et al.</span><span class="ltx_text" id="S4.T1.2.4.2.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib57" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S4.T1.2.4.2.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.4.2.3"><span class="ltx_text" id="S4.T1.2.4.2.3.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.4.2.4"><span class="ltx_text" id="S4.T1.2.4.2.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.4.2.5"><span class="ltx_text" id="S4.T1.2.4.2.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.4.2.6"><span class="ltx_text" id="S4.T1.2.4.2.6.1" style="font-size:90%;">79.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.5.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.5.3.1"><span class="ltx_text" id="S4.T1.2.5.3.1.1" style="font-size:90%;">MAE</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.5.3.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.5.3.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="S4.T1.2.5.3.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">2022a</span></a><span class="ltx_text" id="S4.T1.2.5.3.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.5.3.3"><span class="ltx_text" id="S4.T1.2.5.3.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.5.3.4"><span class="ltx_text" id="S4.T1.2.5.3.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.5.3.5"><span class="ltx_text" id="S4.T1.2.5.3.5.1" style="font-size:90%;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.5.3.6"><span class="ltx_text" id="S4.T1.2.5.3.6.1" style="font-size:90%;">80.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.6.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.6.4.1"><span class="ltx_text" id="S4.T1.2.6.4.1.1" style="font-size:90%;">SimMIM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.6.4.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.6.4.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S4.T1.2.6.4.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T1.2.6.4.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.6.4.3"><span class="ltx_text" id="S4.T1.2.6.4.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.6.4.4"><span class="ltx_text" id="S4.T1.2.6.4.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.6.4.5"><span class="ltx_text" id="S4.T1.2.6.4.5.1" style="font-size:90%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.6.4.6"><span class="ltx_text" id="S4.T1.2.6.4.6.1" style="font-size:90%;">80.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.7.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.7.5.1"><span class="ltx_text" id="S4.T1.2.7.5.1.1" style="font-size:90%;">iBOT</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.7.5.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.7.5.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S4.T1.2.7.5.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T1.2.7.5.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.7.5.3"><span class="ltx_text" id="S4.T1.2.7.5.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.7.5.4"><span class="ltx_text" id="S4.T1.2.7.5.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.7.5.5"><span class="ltx_text" id="S4.T1.2.7.5.5.1" style="font-size:90%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.7.5.6"><span class="ltx_text" id="S4.T1.2.7.5.6.1" style="font-size:90%;">81.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.8.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.8.6.1" rowspan="2"><span class="ltx_text" id="S4.T1.2.8.6.1.1" style="font-size:90%;">BEiT</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.8.6.2" rowspan="2"><span class="ltx_text" id="S4.T1.2.8.6.2.1" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bao et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.8.6.3"><span class="ltx_text" id="S4.T1.2.8.6.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.8.6.4" rowspan="2"><span class="ltx_text" id="S4.T1.2.8.6.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.8.6.5" rowspan="2"><span class="ltx_text" id="S4.T1.2.8.6.5.1" style="font-size:90%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.8.6.6" rowspan="2"><span class="ltx_text" id="S4.T1.2.8.6.6.1" style="font-size:90%;">81.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.9.7">
<td class="ltx_td ltx_align_center" id="S4.T1.2.9.7.1"><span class="ltx_text" id="S4.T1.2.9.7.1.1" style="font-size:90%;">+ DALL-E</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.10.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.10.8.1"><span class="ltx_text" id="S4.T1.2.10.8.1.1" style="font-size:90%;">AttMask</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.10.8.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.10.8.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S4.T1.2.10.8.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T1.2.10.8.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.10.8.3"><span class="ltx_text" id="S4.T1.2.10.8.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.10.8.4"><span class="ltx_text" id="S4.T1.2.10.8.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.10.8.5"><span class="ltx_text" id="S4.T1.2.10.8.5.1" style="font-size:90%;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.10.8.6"><span class="ltx_text" id="S4.T1.2.10.8.6.1" style="font-size:90%;">81.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.11.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.11.9.1"><span class="ltx_text" id="S4.T1.2.11.9.1.1" style="font-size:90%;">MoCo V3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.11.9.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.11.9.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Ci et al.</span><span class="ltx_text" id="S4.T1.2.11.9.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T1.2.11.9.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.11.9.3"><span class="ltx_text" id="S4.T1.2.11.9.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.11.9.4"><span class="ltx_text" id="S4.T1.2.11.9.4.1" style="font-size:90%;">600</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.11.9.5"><span class="ltx_text" id="S4.T1.2.11.9.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.11.9.6"><span class="ltx_text" id="S4.T1.2.11.9.6.1" style="font-size:90%;">81.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.12.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.12.10.1"><span class="ltx_text" id="S4.T1.2.12.10.1.1" style="font-size:90%;">DINO</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.12.10.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.12.10.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="S4.T1.2.12.10.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S4.T1.2.12.10.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.12.10.3"><span class="ltx_text" id="S4.T1.2.12.10.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.12.10.4"><span class="ltx_text" id="S4.T1.2.12.10.4.1" style="font-size:90%;">1600</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.12.10.5"><span class="ltx_text" id="S4.T1.2.12.10.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.12.10.6"><span class="ltx_text" id="S4.T1.2.12.10.6.1" style="font-size:90%;">81.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.13.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.13.11.1"><span class="ltx_text" id="S4.T1.2.13.11.1.1" style="font-size:90%;">MFM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.13.11.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.2.13.11.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S4.T1.2.13.11.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.T1.2.13.11.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.13.11.3"><span class="ltx_text" id="S4.T1.2.13.11.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.13.11.4"><span class="ltx_text" id="S4.T1.2.13.11.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.13.11.5"><span class="ltx_text" id="S4.T1.2.13.11.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.13.11.6">
<span class="ltx_ERROR undefined" id="S4.T1.2.13.11.6.1">\ul</span><span class="ltx_text" id="S4.T1.2.13.11.6.2" style="font-size:90%;">81.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1">
<span class="ltx_text" id="S4.T1.1.1.1.1" style="font-size:90%;">MFM</span><sup class="ltx_sup" id="S4.T1.1.1.1.2"><span class="ltx_text" id="S4.T1.1.1.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T1.1.1.2.1.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S4.T1.1.1.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.T1.1.1.2.3.3" style="font-size:90%;">)</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3"><span class="ltx_text" id="S4.T1.1.1.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4"><span class="ltx_text" id="S4.T1.1.1.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5"><span class="ltx_text" id="S4.T1.1.1.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6"><span class="ltx_text" id="S4.T1.1.1.6.1" style="font-size:90%;">81.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.14.12">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.14.12.1"><span class="ltx_text" id="S4.T1.2.14.12.1.1" style="font-size:90%;">MFM</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.14.12.2" rowspan="2"><span class="ltx_text" id="S4.T1.2.14.12.2.1" style="font-size:90%;"><cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xie et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite></span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.14.12.3" rowspan="2"><span class="ltx_text" id="S4.T1.2.14.12.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.14.12.4" rowspan="2"><span class="ltx_text" id="S4.T1.2.14.12.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.14.12.5" rowspan="2"><span class="ltx_text" id="S4.T1.2.14.12.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.2.14.12.6" rowspan="2"><span class="ltx_text" id="S4.T1.2.14.12.6.1" style="font-size:90%;">81.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.2.1">
<span class="ltx_text" id="S4.T1.2.2.1.1" style="font-size:90%;">+ R/Com</span><sup class="ltx_sup" id="S4.T1.2.2.1.2"><span class="ltx_text" id="S4.T1.2.2.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.15.13">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.15.13.1"><span class="ltx_text ltx_font_bold" id="S4.T1.2.15.13.1.1" style="font-size:90%;">FOLK</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.15.13.2"><span class="ltx_text" id="S4.T1.2.15.13.2.1" style="font-size:90%;">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.15.13.3"><span class="ltx_text" id="S4.T1.2.15.13.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.15.13.4"><span class="ltx_text" id="S4.T1.2.15.13.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.15.13.5"><span class="ltx_text" id="S4.T1.2.15.13.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.15.13.6">
<span class="ltx_ERROR undefined" id="S4.T1.2.15.13.6.1">\ul</span><span class="ltx_text" id="S4.T1.2.15.13.6.2" style="font-size:90%;">81.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.16.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.2.16.14.1"><span class="ltx_text ltx_font_bold" id="S4.T1.2.16.14.1.1" style="font-size:90%;">FOLK</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.2.16.14.2"><span class="ltx_text" id="S4.T1.2.16.14.2.1" style="font-size:90%;">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.2.16.14.3"><span class="ltx_text" id="S4.T1.2.16.14.3.1" style="font-size:90%;">ImageNet-1K</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.2.16.14.4"><span class="ltx_text" id="S4.T1.2.16.14.4.1" style="font-size:90%;">800</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.2.16.14.5"><span class="ltx_text" id="S4.T1.2.16.14.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.2.16.14.6"><span class="ltx_text ltx_font_bold" id="S4.T1.2.16.14.6.1" style="font-size:90%;">82.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Top-1 results of fine-tuning self-supervised approaches utilizing ViT-S/16 as an encoder for ImageNet-1K. All recorded data were resized to images of size <math alttext="224\times 224" class="ltx_Math" display="inline" id="S4.T1.7.m1.1"><semantics id="S4.T1.7.m1.1b"><mrow id="S4.T1.7.m1.1.1" xref="S4.T1.7.m1.1.1.cmml"><mn id="S4.T1.7.m1.1.1.2" xref="S4.T1.7.m1.1.1.2.cmml">224</mn><mo id="S4.T1.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.T1.7.m1.1.1.1.cmml">×</mo><mn id="S4.T1.7.m1.1.1.3" xref="S4.T1.7.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.m1.1c"><apply id="S4.T1.7.m1.1.1.cmml" xref="S4.T1.7.m1.1.1"><times id="S4.T1.7.m1.1.1.1.cmml" xref="S4.T1.7.m1.1.1.1"></times><cn id="S4.T1.7.m1.1.1.2.cmml" type="integer" xref="S4.T1.7.m1.1.1.2">224</cn><cn id="S4.T1.7.m1.1.1.3.cmml" type="integer" xref="S4.T1.7.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.m1.1d">224\times 224</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.m1.1e">224 × 224</annotation></semantics></math>. Data means the pre-training dataset, and token means methods that need a masked token. <sup class="ltx_sup" id="S4.T1.19.1">∗</sup>Our reproduced results with MFM official code through a pre-training phase of <math alttext="300" class="ltx_Math" display="inline" id="S4.T1.9.m3.1"><semantics id="S4.T1.9.m3.1b"><mn id="S4.T1.9.m3.1.1" xref="S4.T1.9.m3.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.T1.9.m3.1c"><cn id="S4.T1.9.m3.1.1.cmml" type="integer" xref="S4.T1.9.m3.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.m3.1d">300</annotation><annotation encoding="application/x-llamapun" id="S4.T1.9.m3.1e">300</annotation></semantics></math> epochs followed by <math alttext="200" class="ltx_Math" display="inline" id="S4.T1.10.m4.1"><semantics id="S4.T1.10.m4.1b"><mn id="S4.T1.10.m4.1.1" xref="S4.T1.10.m4.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S4.T1.10.m4.1c"><cn id="S4.T1.10.m4.1.1.cmml" type="integer" xref="S4.T1.10.m4.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.m4.1d">200</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.m4.1e">200</annotation></semantics></math> epochs of full fine-tuning. Also, MFM + R/Com means using the MFM approach with our proposed filters, instead of its original low/high-pass filters.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.3"><span class="ltx_text" id="S4.SS2.SSS1.p2.3.1" style="font-size:90%;">In Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.T1" style="font-size:90%;" title="Table 1 ‣ 4.2.1 Image Classification ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S4.SS2.SSS1.p2.3.2" style="font-size:90%;">, notably, the traditional training from scratch method achieves a baseline accuracy of </span><math alttext="79.9\%" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.1.m1.1"><semantics id="S4.SS2.SSS1.p2.1.m1.1a"><mrow id="S4.SS2.SSS1.p2.1.m1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.cmml"><mn id="S4.SS2.SSS1.p2.1.m1.1.1.2" mathsize="90%" xref="S4.SS2.SSS1.p2.1.m1.1.1.2.cmml">79.9</mn><mo id="S4.SS2.SSS1.p2.1.m1.1.1.1" mathsize="90%" xref="S4.SS2.SSS1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.1.m1.1b"><apply id="S4.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1.1">percent</csymbol><cn id="S4.SS2.SSS1.p2.1.m1.1.1.2.cmml" type="float" xref="S4.SS2.SSS1.p2.1.m1.1.1.2">79.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.1.m1.1c">79.9\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.1.m1.1d">79.9 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p2.3.3" style="font-size:90%;">, which sets the stage for evaluating the added value of SSL strategies. Models employing masked token (i.e. image patch) strategies, such as MAE, SimMIM, BEiT, and AttMask, show a notable improvement over the baseline, with accuracies ranging from </span><math alttext="80.6\%" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.2.m2.1"><semantics id="S4.SS2.SSS1.p2.2.m2.1a"><mrow id="S4.SS2.SSS1.p2.2.m2.1.1" xref="S4.SS2.SSS1.p2.2.m2.1.1.cmml"><mn id="S4.SS2.SSS1.p2.2.m2.1.1.2" mathsize="90%" xref="S4.SS2.SSS1.p2.2.m2.1.1.2.cmml">80.6</mn><mo id="S4.SS2.SSS1.p2.2.m2.1.1.1" mathsize="90%" xref="S4.SS2.SSS1.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.2.m2.1b"><apply id="S4.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS1.p2.2.m2.1.1.1">percent</csymbol><cn id="S4.SS2.SSS1.p2.2.m2.1.1.2.cmml" type="float" xref="S4.SS2.SSS1.p2.2.m2.1.1.2">80.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.2.m2.1c">80.6\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.2.m2.1d">80.6 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p2.3.4" style="font-size:90%;"> to </span><math alttext="81.3\%" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.3.m3.1"><semantics id="S4.SS2.SSS1.p2.3.m3.1a"><mrow id="S4.SS2.SSS1.p2.3.m3.1.1" xref="S4.SS2.SSS1.p2.3.m3.1.1.cmml"><mn id="S4.SS2.SSS1.p2.3.m3.1.1.2" mathsize="90%" xref="S4.SS2.SSS1.p2.3.m3.1.1.2.cmml">81.3</mn><mo id="S4.SS2.SSS1.p2.3.m3.1.1.1" mathsize="90%" xref="S4.SS2.SSS1.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.3.m3.1b"><apply id="S4.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.SSS1.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS1.p2.3.m3.1.1.1">percent</csymbol><cn id="S4.SS2.SSS1.p2.3.m3.1.1.2.cmml" type="float" xref="S4.SS2.SSS1.p2.3.m3.1.1.2">81.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.3.m3.1c">81.3\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.3.m3.1d">81.3 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p2.3.5" style="font-size:90%;">. This highlights the potential benefits of using masked tokens in training to boost model performance. However, these methods only work with image token-based models, such as ViTs.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.5"><span class="ltx_text" id="S4.SS2.SSS1.p3.5.1" style="font-size:90%;">In contrast, the FOLK method demonstrates a compelling advancement in vision SSL without the need for token masking or additional datasets, like DALL-E </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.SSS1.p3.5.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Ramesh et al.</span><span class="ltx_text" id="S4.SS2.SSS1.p3.5.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="S4.SS2.SSS1.p3.5.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.SSS1.p3.5.5" style="font-size:90%;"> used in the BEiT model. The standard FOLK approach reaches an accuracy of </span><math alttext="81.6\%" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p3.1.m1.1"><semantics id="S4.SS2.SSS1.p3.1.m1.1a"><mrow id="S4.SS2.SSS1.p3.1.m1.1.1" xref="S4.SS2.SSS1.p3.1.m1.1.1.cmml"><mn id="S4.SS2.SSS1.p3.1.m1.1.1.2" mathsize="90%" xref="S4.SS2.SSS1.p3.1.m1.1.1.2.cmml">81.6</mn><mo id="S4.SS2.SSS1.p3.1.m1.1.1.1" mathsize="90%" xref="S4.SS2.SSS1.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p3.1.m1.1b"><apply id="S4.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p3.1.m1.1.1.1">percent</csymbol><cn id="S4.SS2.SSS1.p3.1.m1.1.1.2.cmml" type="float" xref="S4.SS2.SSS1.p3.1.m1.1.1.2">81.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p3.1.m1.1c">81.6\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p3.1.m1.1d">81.6 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p3.5.6" style="font-size:90%;"> with </span><math alttext="300" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p3.2.m2.1"><semantics id="S4.SS2.SSS1.p3.2.m2.1a"><mn id="S4.SS2.SSS1.p3.2.m2.1.1" mathsize="90%" xref="S4.SS2.SSS1.p3.2.m2.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p3.2.m2.1b"><cn id="S4.SS2.SSS1.p3.2.m2.1.1.cmml" type="integer" xref="S4.SS2.SSS1.p3.2.m2.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p3.2.m2.1c">300</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p3.2.m2.1d">300</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p3.5.7" style="font-size:90%;"> epochs pre-training, matching the highest performance of other models trained under similar conditions but with more epochs, i.e. MoCo V3 and DINO with </span><math alttext="600" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p3.3.m3.1"><semantics id="S4.SS2.SSS1.p3.3.m3.1a"><mn id="S4.SS2.SSS1.p3.3.m3.1.1" mathsize="90%" xref="S4.SS2.SSS1.p3.3.m3.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p3.3.m3.1b"><cn id="S4.SS2.SSS1.p3.3.m3.1.1.cmml" type="integer" xref="S4.SS2.SSS1.p3.3.m3.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p3.3.m3.1c">600</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p3.3.m3.1d">600</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p3.5.8" style="font-size:90%;"> and </span><math alttext="1600" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p3.4.m4.1"><semantics id="S4.SS2.SSS1.p3.4.m4.1a"><mn id="S4.SS2.SSS1.p3.4.m4.1.1" mathsize="90%" xref="S4.SS2.SSS1.p3.4.m4.1.1.cmml">1600</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p3.4.m4.1b"><cn id="S4.SS2.SSS1.p3.4.m4.1.1.cmml" type="integer" xref="S4.SS2.SSS1.p3.4.m4.1.1">1600</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p3.4.m4.1c">1600</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p3.4.m4.1d">1600</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p3.5.9" style="font-size:90%;"> epochs, respectively. Its performance is further improved to </span><math alttext="82.1\%" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p3.5.m5.1"><semantics id="S4.SS2.SSS1.p3.5.m5.1a"><mrow id="S4.SS2.SSS1.p3.5.m5.1.1" xref="S4.SS2.SSS1.p3.5.m5.1.1.cmml"><mn id="S4.SS2.SSS1.p3.5.m5.1.1.2" mathsize="90%" xref="S4.SS2.SSS1.p3.5.m5.1.1.2.cmml">82.1</mn><mo id="S4.SS2.SSS1.p3.5.m5.1.1.1" mathsize="90%" xref="S4.SS2.SSS1.p3.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p3.5.m5.1b"><apply id="S4.SS2.SSS1.p3.5.m5.1.1.cmml" xref="S4.SS2.SSS1.p3.5.m5.1.1"><csymbol cd="latexml" id="S4.SS2.SSS1.p3.5.m5.1.1.1.cmml" xref="S4.SS2.SSS1.p3.5.m5.1.1.1">percent</csymbol><cn id="S4.SS2.SSS1.p3.5.m5.1.1.2.cmml" type="float" xref="S4.SS2.SSS1.p3.5.m5.1.1.2">82.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p3.5.m5.1c">82.1\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p3.5.m5.1d">82.1 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS1.p3.5.10" style="font-size:90%;"> when extended to 800 epochs pre-training, surpassing all other methods with a notable margin. This showcases FOLK’s superior capability, suggesting that its method of integrating learning from dual inputs—filtered and original images—significantly enhances learning efficiency and model efficacy. Furthermore, we provide a qualitative analysis with visualizations of our proposed filters on example images, along with the model predictions for the pretext task, which further demonstrate a successful pre-training achieved by FOLK. This is detailed in Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3" style="font-size:90%;" title="Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">C</span></a><span class="ltx_text" id="S4.SS2.SSS1.p3.5.11" style="font-size:90%;">.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Few Shot Learning</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1"><span class="ltx_text" id="S4.SS2.SSS2.p1.1.1" style="font-size:90%;">Our few-shot learning experiment’s motivation lies in demonstrating the robustness and efficiency of our FOLK framework compared to other pre-training methodologies, especially in scenarios characterized by limited data availability. In this context, we particularly challenge the efficacy of the FOLK model against the MFM approach and others under the premise that showing original images (solving the second weakness of MFM by applying KD) significantly enhances performance on few-shot learning tasks.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1"><span class="ltx_text" id="S4.SS2.SSS2.p2.1.1" style="font-size:90%;">In this experiment, we aim to highlight FOLK’s superior adaptability and efficiency by fine-tuning pre-trained models using only </span><math alttext="10\%" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p2.1.m1.1"><semantics id="S4.SS2.SSS2.p2.1.m1.1a"><mrow id="S4.SS2.SSS2.p2.1.m1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.cmml"><mn id="S4.SS2.SSS2.p2.1.m1.1.1.2" mathsize="90%" xref="S4.SS2.SSS2.p2.1.m1.1.1.2.cmml">10</mn><mo id="S4.SS2.SSS2.p2.1.m1.1.1.1" mathsize="90%" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.1b"><apply id="S4.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1">percent</csymbol><cn id="S4.SS2.SSS2.p2.1.m1.1.1.2.cmml" type="integer" xref="S4.SS2.SSS2.p2.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.1c">10\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p2.1.m1.1d">10 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS2.p2.1.2" style="font-size:90%;"> of the ImageNet-1K dataset over 200 epochs. This setup allows us to critically assess the influence of learning rate adjustments on performance under sparse data conditions. We explore variations in base learning rates and warm-up periods using a cosine learning rate strategy for optimization </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.SSS2.p2.1.3.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Gotmare et al.</span><span class="ltx_text" id="S4.SS2.SSS2.p2.1.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="S4.SS2.SSS2.p2.1.5.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.SSS2.p2.1.6" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.6.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T2.6.1.1.1.1" style="font-size:90%;">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.6.1.1.2.1" style="font-size:90%;">Base LR = 2e-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.1.1.3.1" style="font-size:90%;">Base LR = 2e-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.6.1.1.4.1" style="font-size:90%;">Base LR = 2e-3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.1.1.5" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T2.6.1.1.5.1" style="font-size:90%;">AVG</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.6.2.2.1.1" style="font-size:90%;">Warm Up = 0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T2.6.2.2.2.1" style="font-size:90%;">Warm Up = 100</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.2.2.3.1" style="font-size:90%;">Warm Up = 5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.3.3.1"><span class="ltx_text" id="S4.T2.6.3.3.1.1" style="font-size:90%;">iBOT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.3.3.2"><span class="ltx_text" id="S4.T2.6.3.3.2.1" style="font-size:90%;">64.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.3.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.3.3.3.1" style="font-size:90%;">71.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.3.3.4"><span class="ltx_text" id="S4.T2.6.3.3.4.1" style="font-size:90%;">2.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.3.3.5"><span class="ltx_text" id="S4.T2.6.3.3.5.1" style="font-size:90%;">45.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.4.4.1"><span class="ltx_text" id="S4.T2.6.4.4.1.1" style="font-size:90%;">AttMask</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.4.4.2">
<span class="ltx_ERROR undefined" id="S4.T2.6.4.4.2.1">\ul</span><span class="ltx_text" id="S4.T2.6.4.4.2.2" style="font-size:90%;">69.8</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.4.4.3">
<span class="ltx_ERROR undefined" id="S4.T2.6.4.4.3.1">\ul</span><span class="ltx_text" id="S4.T2.6.4.4.3.2" style="font-size:90%;">71.0</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.4.4.4"><span class="ltx_text" id="S4.T2.6.4.4.4.1" style="font-size:90%;">31.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.4.4.5"><span class="ltx_text" id="S4.T2.6.4.4.5.1" style="font-size:90%;">57.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.5.5.1"><span class="ltx_text" id="S4.T2.6.5.5.1.1" style="font-size:90%;">MFM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.5.5.2"><span class="ltx_text" id="S4.T2.6.5.5.2.1" style="font-size:90%;">57.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.5.5.3"><span class="ltx_text" id="S4.T2.6.5.5.3.1" style="font-size:90%;">58.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.5.5.4"><span class="ltx_text" id="S4.T2.6.5.5.4.1" style="font-size:90%;">41.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.5.5.5"><span class="ltx_text" id="S4.T2.6.5.5.5.1" style="font-size:90%;">52.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.6.1"><span class="ltx_text" id="S4.T2.6.6.6.1.1" style="font-size:90%;">MFM + Com/RCom</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.6.2"><span class="ltx_text" id="S4.T2.6.6.6.2.1" style="font-size:90%;">66.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.6.3"><span class="ltx_text" id="S4.T2.6.6.6.3.1" style="font-size:90%;">63.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.6.4">
<span class="ltx_ERROR undefined" id="S4.T2.6.6.6.4.1">\ul</span><span class="ltx_text" id="S4.T2.6.6.6.4.2" style="font-size:90%;">59.9</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.6.5">
<span class="ltx_ERROR undefined" id="S4.T2.6.6.6.5.1">\ul</span><span class="ltx_text" id="S4.T2.6.6.6.5.2" style="font-size:90%;">63.4</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.7.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.6.7.7.1"><span class="ltx_text ltx_font_bold" id="S4.T2.6.7.7.1.1" style="font-size:90%;">FOLK</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.6.7.7.2"><span class="ltx_text ltx_font_bold" id="S4.T2.6.7.7.2.1" style="font-size:90%;">71.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.6.7.7.3"><span class="ltx_text" id="S4.T2.6.7.7.3.1" style="font-size:90%;">68.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.6.7.7.4"><span class="ltx_text ltx_font_bold" id="S4.T2.6.7.7.4.1" style="font-size:90%;">62.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.6.7.7.5.1" style="font-size:90%;">67.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of few-shot learning that fine-tunes the pre-trained ViT-S with different approaches for <math alttext="200" class="ltx_Math" display="inline" id="S4.T2.3.m1.1"><semantics id="S4.T2.3.m1.1b"><mn id="S4.T2.3.m1.1.1" xref="S4.T2.3.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S4.T2.3.m1.1c"><cn id="S4.T2.3.m1.1.1.cmml" type="integer" xref="S4.T2.3.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.m1.1d">200</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.m1.1e">200</annotation></semantics></math> epoch with <math alttext="10\%" class="ltx_Math" display="inline" id="S4.T2.4.m2.1"><semantics id="S4.T2.4.m2.1b"><mrow id="S4.T2.4.m2.1.1" xref="S4.T2.4.m2.1.1.cmml"><mn id="S4.T2.4.m2.1.1.2" xref="S4.T2.4.m2.1.1.2.cmml">10</mn><mo id="S4.T2.4.m2.1.1.1" xref="S4.T2.4.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.m2.1c"><apply id="S4.T2.4.m2.1.1.cmml" xref="S4.T2.4.m2.1.1"><csymbol cd="latexml" id="S4.T2.4.m2.1.1.1.cmml" xref="S4.T2.4.m2.1.1.1">percent</csymbol><cn id="S4.T2.4.m2.1.1.2.cmml" type="integer" xref="S4.T2.4.m2.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.m2.1d">10\%</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.m2.1e">10 %</annotation></semantics></math> of labeled data from ImageNet-1k. Base LR means the peak value of the learning rate, and Warm Up refers to the initial epochs during which the learning rate increases from 0 to the predefined Base LR. After reaching the Base LR, the learning rate then decreases according to a cosine function, from the Base LR back down to 0. AVG: average.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1"><span class="ltx_text" id="S4.SS2.SSS2.p3.1.1" style="font-size:90%;">Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.T2" style="font-size:90%;" title="Table 2 ‣ 4.2.2 Few Shot Learning ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S4.SS2.SSS2.p3.1.2" style="font-size:90%;"> demonstrates the potential of our approach to effectively leverage small datasets, making it especially relevant for applications where data is scarce. The MFM model does not perform well with limited data in downstream tasks assumably because, during the pretext task, MFM does not see the original image without augmentation. And this limitation has been addressed in our proposed FOLK method, owing to the self-distillation design. FOLK is more robust in different training settings compared to other methods.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Semantic Segmentation</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1"><span class="ltx_text" id="S4.SS2.SSS3.p1.1.1" style="font-size:90%;">Semantic segmentation is a typical downstream task in the vision domain, where a classification needs to be performed on each pixel individually. We evaluated FOLK and compared it with several alternative SSL approaches on this task, using the ADE20K dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.SSS3.p1.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S4.SS2.SSS3.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib70" title=""><span class="ltx_text" style="font-size:90%;">2017</span></a><span class="ltx_text" id="S4.SS2.SSS3.p1.1.4.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.SSS3.p1.1.5" style="font-size:90%;"> and incorporating a task layer from UPerNet as described by </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.SSS3.p1.1.6.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xiao et al.</span><span class="ltx_text" id="S4.SS2.SSS3.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib61" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a><span class="ltx_text" id="S4.SS2.SSS3.p1.1.8.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.SSS3.p1.1.9" style="font-size:90%;"> to the SSL pre-trained encoder. The whole model was fine-tuned over 160k iterations, handling images at a resolution of </span><math alttext="512\times 512" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p1.1.m1.1"><semantics id="S4.SS2.SSS3.p1.1.m1.1a"><mrow id="S4.SS2.SSS3.p1.1.m1.1.1" xref="S4.SS2.SSS3.p1.1.m1.1.1.cmml"><mn id="S4.SS2.SSS3.p1.1.m1.1.1.2" mathsize="90%" xref="S4.SS2.SSS3.p1.1.m1.1.1.2.cmml">512</mn><mo id="S4.SS2.SSS3.p1.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S4.SS2.SSS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS2.SSS3.p1.1.m1.1.1.3" mathsize="90%" xref="S4.SS2.SSS3.p1.1.m1.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.1.m1.1b"><apply id="S4.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1"><times id="S4.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1.1"></times><cn id="S4.SS2.SSS3.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS2.SSS3.p1.1.m1.1.1.2">512</cn><cn id="S4.SS2.SSS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.SSS3.p1.1.m1.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.1.m1.1c">512\times 512</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p1.1.m1.1d">512 × 512</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p1.1.10" style="font-size:90%;">, following the methodology established by iBOT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.SS2.SSS3.p1.1.11.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S4.SS2.SSS3.p1.1.12.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.SS2.SSS3.p1.1.13.3" style="font-size:90%;">)</span></cite><span class="ltx_text" id="S4.SS2.SSS3.p1.1.14" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T3.5.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.5.6.1.1.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.6.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.6.1.2.1" style="font-size:90%;">mIoU</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T3.1.1.1">
<span class="ltx_text" id="S4.T3.1.1.1.1" style="font-size:90%;">Supervised Learning</span><sup class="ltx_sup" id="S4.T3.1.1.1.2"><span class="ltx_text" id="S4.T3.1.1.1.2.1" style="font-size:90%;">∙</span></sup><span class="ltx_text" id="S4.T3.1.1.1.3" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T3.1.1.1.4.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S4.T3.1.1.1.5.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T3.1.1.1.6.3" style="font-size:90%;">)</span></cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2"><span class="ltx_text" id="S4.T3.1.1.2.1" style="font-size:90%;">44.5</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.5.7.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T3.5.7.2.1">
<span class="ltx_text" id="S4.T3.5.7.2.1.1" style="font-size:90%;">iBOT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T3.5.7.2.1.2.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="S4.T3.5.7.2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T3.5.7.2.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.5.7.2.2">
<span class="ltx_ERROR undefined" id="S4.T3.5.7.2.2.1">\ul</span><span class="ltx_text" id="S4.T3.5.7.2.2.2" style="font-size:90%;">45.4</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.2.2.1">
<span class="ltx_text" id="S4.T3.2.2.1.1" style="font-size:90%;">iBOT</span><math alttext="+" class="ltx_Math" display="inline" id="S4.T3.2.2.1.m1.1"><semantics id="S4.T3.2.2.1.m1.1a"><mo id="S4.T3.2.2.1.m1.1.1" mathsize="90%" xref="S4.T3.2.2.1.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><plus id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">+</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.1.m1.1d">+</annotation></semantics></math><span class="ltx_text" id="S4.T3.2.2.1.2" style="font-size:90%;">AttMask </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T3.2.2.1.3.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="S4.T3.2.2.1.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="S4.T3.2.2.1.5.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.2.2"><span class="ltx_text" id="S4.T3.2.2.2.1" style="font-size:90%;">45.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.3.3.1">
<span class="ltx_text" id="S4.T3.3.3.1.1" style="font-size:90%;">MFM</span><sup class="ltx_sup" id="S4.T3.3.3.1.2"><span class="ltx_text" id="S4.T3.3.3.1.2.1" style="font-size:90%;">∗</span></sup><span class="ltx_text" id="S4.T3.3.3.1.3" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T3.3.3.1.4.1" style="font-size:90%;">(</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="S4.T3.3.3.1.5.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="S4.T3.3.3.1.6.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.3.3.2"><span class="ltx_text" id="S4.T3.3.3.2.1" style="font-size:90%;">44.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T3.4.4.1"><span class="ltx_text ltx_font_bold" id="S4.T3.4.4.1.1" style="font-size:90%;">FOLK<sup class="ltx_sup" id="S4.T3.4.4.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S4.T3.4.4.1.1.1.1">†</span></sup></span></th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.4.2"><span class="ltx_text" id="S4.T3.4.4.2.1" style="font-size:90%;">45.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T3.5.5.1"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.1.1" style="font-size:90%;">FOLK<sup class="ltx_sup" id="S4.T3.5.5.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S4.T3.5.5.1.1.1.1">‡</span></sup></span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.5.5.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.5.2.1" style="font-size:90%;">45.5</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>The full fine-tuning ViT-S/16 model for semantic segmentation task with ADE20K dataset. <sup class="ltx_sup" id="S4.T3.25.1">∙</sup> Supervised Learning result taken from iBOT paper. <sup class="ltx_sup" id="S4.T3.26.2">∗</sup> We produced MFM results with their official code. FOLK was pre-trained with <sup class="ltx_sup" id="S4.T3.27.3"><span class="ltx_text ltx_font_italic" id="S4.T3.27.3.1">†</span></sup> 300 and <sup class="ltx_sup" id="S4.T3.28.4"><span class="ltx_text ltx_font_italic" id="S4.T3.28.4.1">‡</span></sup> 800 epochs.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS3.p2">
<p class="ltx_p" id="S4.SS2.SSS3.p2.6"><span class="ltx_text" id="S4.SS2.SSS3.p2.6.1" style="font-size:90%;">Results of this fine-tuning effort for the semantic segmentation task on the ADE20K dataset are shown in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.T3" style="font-size:90%;" title="Table 3 ‣ 4.2.3 Semantic Segmentation ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S4.SS2.SSS3.p2.6.2" style="font-size:90%;">. It presents a comparative analysis of different methodologies: Supervised Learning, iBOT, iBOT with Attention Mask (AttMask), MFM, and our FOLK model at different pre-training epochs (</span><math alttext="300" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p2.1.m1.1"><semantics id="S4.SS2.SSS3.p2.1.m1.1a"><mn id="S4.SS2.SSS3.p2.1.m1.1.1" mathsize="90%" xref="S4.SS2.SSS3.p2.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.1.m1.1b"><cn id="S4.SS2.SSS3.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p2.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.1.m1.1c">300</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p2.1.m1.1d">300</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p2.6.3" style="font-size:90%;"> and </span><math alttext="800" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p2.2.m2.1"><semantics id="S4.SS2.SSS3.p2.2.m2.1a"><mn id="S4.SS2.SSS3.p2.2.m2.1.1" mathsize="90%" xref="S4.SS2.SSS3.p2.2.m2.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.2.m2.1b"><cn id="S4.SS2.SSS3.p2.2.m2.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p2.2.m2.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.2.m2.1c">800</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p2.2.m2.1d">800</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p2.6.4" style="font-size:90%;"> epochs). Notably, the FOLK model with </span><math alttext="800" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p2.3.m3.1"><semantics id="S4.SS2.SSS3.p2.3.m3.1a"><mn id="S4.SS2.SSS3.p2.3.m3.1.1" mathsize="90%" xref="S4.SS2.SSS3.p2.3.m3.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.3.m3.1b"><cn id="S4.SS2.SSS3.p2.3.m3.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p2.3.m3.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.3.m3.1c">800</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p2.3.m3.1d">800</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p2.6.5" style="font-size:90%;"> epochs of pre-training achieves the highest mIoU at </span><math alttext="45.5" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p2.4.m4.1"><semantics id="S4.SS2.SSS3.p2.4.m4.1a"><mn id="S4.SS2.SSS3.p2.4.m4.1.1" mathsize="90%" xref="S4.SS2.SSS3.p2.4.m4.1.1.cmml">45.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.4.m4.1b"><cn id="S4.SS2.SSS3.p2.4.m4.1.1.cmml" type="float" xref="S4.SS2.SSS3.p2.4.m4.1.1">45.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.4.m4.1c">45.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p2.4.m4.1d">45.5</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p2.6.6" style="font-size:90%;">, slightly surpassing the iBOT’s </span><math alttext="45.4" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p2.5.m5.1"><semantics id="S4.SS2.SSS3.p2.5.m5.1a"><mn id="S4.SS2.SSS3.p2.5.m5.1.1" mathsize="90%" xref="S4.SS2.SSS3.p2.5.m5.1.1.cmml">45.4</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.5.m5.1b"><cn id="S4.SS2.SSS3.p2.5.m5.1.1.cmml" type="float" xref="S4.SS2.SSS3.p2.5.m5.1.1">45.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.5.m5.1c">45.4</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p2.5.m5.1d">45.4</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p2.6.7" style="font-size:90%;"> mIoU. This indicates a successful adaptation of the FOLK methodology, showing not only an improvement over the MFM results but also demonstrating that extended pre-training can lead to marginal yet significant performance gains. Furthermore, even at </span><math alttext="300" class="ltx_Math" display="inline" id="S4.SS2.SSS3.p2.6.m6.1"><semantics id="S4.SS2.SSS3.p2.6.m6.1a"><mn id="S4.SS2.SSS3.p2.6.m6.1.1" mathsize="90%" xref="S4.SS2.SSS3.p2.6.m6.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p2.6.m6.1b"><cn id="S4.SS2.SSS3.p2.6.m6.1.1.cmml" type="integer" xref="S4.SS2.SSS3.p2.6.m6.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p2.6.m6.1c">300</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS3.p2.6.m6.1d">300</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS3.p2.6.8" style="font-size:90%;"> pre-training epochs, FOLK performs comparably to other advanced methods, highlighting its efficacy in leveraging the dataset and architecture for semantic segmentation tasks.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Ablation Study</h4>
<div class="ltx_para" id="S4.SS2.SSS4.p1">
<p class="ltx_p" id="S4.SS2.SSS4.p1.12"><span class="ltx_text" id="S4.SS2.SSS4.p1.12.1" style="font-size:90%;">We explore the optimal weight values for </span><math alttext="\mathcal{L}_{\text{tot}}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.1.m1.1"><semantics id="S4.SS2.SSS4.p1.1.m1.1a"><msub id="S4.SS2.SSS4.p1.1.m1.1.1" xref="S4.SS2.SSS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS4.p1.1.m1.1.1.2" mathsize="90%" xref="S4.SS2.SSS4.p1.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S4.SS2.SSS4.p1.1.m1.1.1.3" mathsize="90%" xref="S4.SS2.SSS4.p1.1.m1.1.1.3a.cmml">tot</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.1.m1.1b"><apply id="S4.SS2.SSS4.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS4.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1.2">ℒ</ci><ci id="S4.SS2.SSS4.p1.1.m1.1.1.3a.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1.3"><mtext id="S4.SS2.SSS4.p1.1.m1.1.1.3.cmml" mathsize="63%" xref="S4.SS2.SSS4.p1.1.m1.1.1.3">tot</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.1.m1.1c">\mathcal{L}_{\text{tot}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.2" style="font-size:90%;">, introduced in Eq. </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.Ex6" style="font-size:90%;" title="In 3.2.3 Comprehensive Loss Calculation ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="S4.SS2.SSS4.p1.12.3" style="font-size:90%;">. Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.T4" style="font-size:90%;" title="Table 4 ‣ 4.2.4 Ablation Study ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S4.SS2.SSS4.p1.12.4" style="font-size:90%;"> provides an insight into how variations in the parameter </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.2.m2.1"><semantics id="S4.SS2.SSS4.p1.2.m2.1a"><mi id="S4.SS2.SSS4.p1.2.m2.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.2.m2.1b"><ci id="S4.SS2.SSS4.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.2.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.2.m2.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.5" style="font-size:90%;"> influence the Top 1 Accuracy of a ViT-S/16 model employing the FOLK methodology. As </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.3.m3.1"><semantics id="S4.SS2.SSS4.p1.3.m3.1a"><mi id="S4.SS2.SSS4.p1.3.m3.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.3.m3.1b"><ci id="S4.SS2.SSS4.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p1.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.3.m3.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.6" style="font-size:90%;"> is adjusted from </span><math alttext="4" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.4.m4.1"><semantics id="S4.SS2.SSS4.p1.4.m4.1a"><mn id="S4.SS2.SSS4.p1.4.m4.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.4.m4.1b"><cn id="S4.SS2.SSS4.p1.4.m4.1.1.cmml" type="integer" xref="S4.SS2.SSS4.p1.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.4.m4.1c">4</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.4.m4.1d">4</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.7" style="font-size:90%;"> down to </span><math alttext="0.05" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.5.m5.1"><semantics id="S4.SS2.SSS4.p1.5.m5.1a"><mn id="S4.SS2.SSS4.p1.5.m5.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.5.m5.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.5.m5.1b"><cn id="S4.SS2.SSS4.p1.5.m5.1.1.cmml" type="float" xref="S4.SS2.SSS4.p1.5.m5.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.5.m5.1c">0.05</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.5.m5.1d">0.05</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.8" style="font-size:90%;">, a clear trend is observed where the model’s accuracy improves notably when </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.6.m6.1"><semantics id="S4.SS2.SSS4.p1.6.m6.1a"><mi id="S4.SS2.SSS4.p1.6.m6.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.6.m6.1b"><ci id="S4.SS2.SSS4.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS4.p1.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.6.m6.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.6.m6.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.9" style="font-size:90%;"> is reduced from </span><math alttext="4" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.7.m7.1"><semantics id="S4.SS2.SSS4.p1.7.m7.1a"><mn id="S4.SS2.SSS4.p1.7.m7.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.7.m7.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.7.m7.1b"><cn id="S4.SS2.SSS4.p1.7.m7.1.1.cmml" type="integer" xref="S4.SS2.SSS4.p1.7.m7.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.7.m7.1c">4</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.7.m7.1d">4</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.10" style="font-size:90%;"> to </span><math alttext="1" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.8.m8.1"><semantics id="S4.SS2.SSS4.p1.8.m8.1a"><mn id="S4.SS2.SSS4.p1.8.m8.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.8.m8.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.8.m8.1b"><cn id="S4.SS2.SSS4.p1.8.m8.1.1.cmml" type="integer" xref="S4.SS2.SSS4.p1.8.m8.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.8.m8.1c">1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.8.m8.1d">1</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.11" style="font-size:90%;">, peaking at an accuracy of </span><math alttext="81.6\%" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.9.m9.1"><semantics id="S4.SS2.SSS4.p1.9.m9.1a"><mrow id="S4.SS2.SSS4.p1.9.m9.1.1" xref="S4.SS2.SSS4.p1.9.m9.1.1.cmml"><mn id="S4.SS2.SSS4.p1.9.m9.1.1.2" mathsize="90%" xref="S4.SS2.SSS4.p1.9.m9.1.1.2.cmml">81.6</mn><mo id="S4.SS2.SSS4.p1.9.m9.1.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.9.m9.1b"><apply id="S4.SS2.SSS4.p1.9.m9.1.1.cmml" xref="S4.SS2.SSS4.p1.9.m9.1.1"><csymbol cd="latexml" id="S4.SS2.SSS4.p1.9.m9.1.1.1.cmml" xref="S4.SS2.SSS4.p1.9.m9.1.1.1">percent</csymbol><cn id="S4.SS2.SSS4.p1.9.m9.1.1.2.cmml" type="float" xref="S4.SS2.SSS4.p1.9.m9.1.1.2">81.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.9.m9.1c">81.6\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.9.m9.1d">81.6 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.12" style="font-size:90%;"> at </span><math alttext="\alpha=1" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.10.m10.1"><semantics id="S4.SS2.SSS4.p1.10.m10.1a"><mrow id="S4.SS2.SSS4.p1.10.m10.1.1" xref="S4.SS2.SSS4.p1.10.m10.1.1.cmml"><mi id="S4.SS2.SSS4.p1.10.m10.1.1.2" mathsize="90%" xref="S4.SS2.SSS4.p1.10.m10.1.1.2.cmml">α</mi><mo id="S4.SS2.SSS4.p1.10.m10.1.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.10.m10.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS4.p1.10.m10.1.1.3" mathsize="90%" xref="S4.SS2.SSS4.p1.10.m10.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.10.m10.1b"><apply id="S4.SS2.SSS4.p1.10.m10.1.1.cmml" xref="S4.SS2.SSS4.p1.10.m10.1.1"><eq id="S4.SS2.SSS4.p1.10.m10.1.1.1.cmml" xref="S4.SS2.SSS4.p1.10.m10.1.1.1"></eq><ci id="S4.SS2.SSS4.p1.10.m10.1.1.2.cmml" xref="S4.SS2.SSS4.p1.10.m10.1.1.2">𝛼</ci><cn id="S4.SS2.SSS4.p1.10.m10.1.1.3.cmml" type="integer" xref="S4.SS2.SSS4.p1.10.m10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.10.m10.1c">\alpha=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.10.m10.1d">italic_α = 1</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.13" style="font-size:90%;">. This suggests that a lower </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.11.m11.1"><semantics id="S4.SS2.SSS4.p1.11.m11.1a"><mi id="S4.SS2.SSS4.p1.11.m11.1.1" mathsize="90%" xref="S4.SS2.SSS4.p1.11.m11.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.11.m11.1b"><ci id="S4.SS2.SSS4.p1.11.m11.1.1.cmml" xref="S4.SS2.SSS4.p1.11.m11.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.11.m11.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.11.m11.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.14" style="font-size:90%;"> enhances the model’s performance, potentially indicating an optimal configuration of the loss function </span><math alttext="\mathcal{L}_{\text{tot}}" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p1.12.m12.1"><semantics id="S4.SS2.SSS4.p1.12.m12.1a"><msub id="S4.SS2.SSS4.p1.12.m12.1.1" xref="S4.SS2.SSS4.p1.12.m12.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS4.p1.12.m12.1.1.2" mathsize="90%" xref="S4.SS2.SSS4.p1.12.m12.1.1.2.cmml">ℒ</mi><mtext id="S4.SS2.SSS4.p1.12.m12.1.1.3" mathsize="90%" xref="S4.SS2.SSS4.p1.12.m12.1.1.3a.cmml">tot</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.12.m12.1b"><apply id="S4.SS2.SSS4.p1.12.m12.1.1.cmml" xref="S4.SS2.SSS4.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p1.12.m12.1.1.1.cmml" xref="S4.SS2.SSS4.p1.12.m12.1.1">subscript</csymbol><ci id="S4.SS2.SSS4.p1.12.m12.1.1.2.cmml" xref="S4.SS2.SSS4.p1.12.m12.1.1.2">ℒ</ci><ci id="S4.SS2.SSS4.p1.12.m12.1.1.3a.cmml" xref="S4.SS2.SSS4.p1.12.m12.1.1.3"><mtext id="S4.SS2.SSS4.p1.12.m12.1.1.3.cmml" mathsize="63%" xref="S4.SS2.SSS4.p1.12.m12.1.1.3">tot</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.12.m12.1c">\mathcal{L}_{\text{tot}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p1.12.m12.1d">caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p1.12.15" style="font-size:90%;"> at this point.</span></p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p2">
<p class="ltx_p" id="S4.SS2.SSS4.p2.7"><span class="ltx_text" id="S4.SS2.SSS4.p2.7.1" style="font-size:90%;">Further adjustments of </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.1.m1.1"><semantics id="S4.SS2.SSS4.p2.1.m1.1a"><mi id="S4.SS2.SSS4.p2.1.m1.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.1.m1.1b"><ci id="S4.SS2.SSS4.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.1.m1.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.2" style="font-size:90%;"> beyond this optimal point (decreasing it to </span><math alttext="0.1" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.2.m2.1"><semantics id="S4.SS2.SSS4.p2.2.m2.1a"><mn id="S4.SS2.SSS4.p2.2.m2.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.2.m2.1b"><cn id="S4.SS2.SSS4.p2.2.m2.1.1.cmml" type="float" xref="S4.SS2.SSS4.p2.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.2.m2.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.2.m2.1d">0.1</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.3" style="font-size:90%;"> and </span><math alttext="0.05" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.3.m3.1"><semantics id="S4.SS2.SSS4.p2.3.m3.1a"><mn id="S4.SS2.SSS4.p2.3.m3.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.3.m3.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.3.m3.1b"><cn id="S4.SS2.SSS4.p2.3.m3.1.1.cmml" type="float" xref="S4.SS2.SSS4.p2.3.m3.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.3.m3.1c">0.05</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.3.m3.1d">0.05</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.4" style="font-size:90%;">) result in a slight decrease in accuracy to </span><math alttext="81.4\%" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.4.m4.1"><semantics id="S4.SS2.SSS4.p2.4.m4.1a"><mrow id="S4.SS2.SSS4.p2.4.m4.1.1" xref="S4.SS2.SSS4.p2.4.m4.1.1.cmml"><mn id="S4.SS2.SSS4.p2.4.m4.1.1.2" mathsize="90%" xref="S4.SS2.SSS4.p2.4.m4.1.1.2.cmml">81.4</mn><mo id="S4.SS2.SSS4.p2.4.m4.1.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.4.m4.1b"><apply id="S4.SS2.SSS4.p2.4.m4.1.1.cmml" xref="S4.SS2.SSS4.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS2.SSS4.p2.4.m4.1.1.1.cmml" xref="S4.SS2.SSS4.p2.4.m4.1.1.1">percent</csymbol><cn id="S4.SS2.SSS4.p2.4.m4.1.1.2.cmml" type="float" xref="S4.SS2.SSS4.p2.4.m4.1.1.2">81.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.4.m4.1c">81.4\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.4.m4.1d">81.4 %</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.5" style="font-size:90%;">, indicating a plateau. This stability around lower </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.5.m5.1"><semantics id="S4.SS2.SSS4.p2.5.m5.1a"><mi id="S4.SS2.SSS4.p2.5.m5.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.5.m5.1b"><ci id="S4.SS2.SSS4.p2.5.m5.1.1.cmml" xref="S4.SS2.SSS4.p2.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.5.m5.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.5.m5.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.6" style="font-size:90%;"> values implies that while </span><math alttext="\alpha=1" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.6.m6.1"><semantics id="S4.SS2.SSS4.p2.6.m6.1a"><mrow id="S4.SS2.SSS4.p2.6.m6.1.1" xref="S4.SS2.SSS4.p2.6.m6.1.1.cmml"><mi id="S4.SS2.SSS4.p2.6.m6.1.1.2" mathsize="90%" xref="S4.SS2.SSS4.p2.6.m6.1.1.2.cmml">α</mi><mo id="S4.SS2.SSS4.p2.6.m6.1.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS4.p2.6.m6.1.1.3" mathsize="90%" xref="S4.SS2.SSS4.p2.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.6.m6.1b"><apply id="S4.SS2.SSS4.p2.6.m6.1.1.cmml" xref="S4.SS2.SSS4.p2.6.m6.1.1"><eq id="S4.SS2.SSS4.p2.6.m6.1.1.1.cmml" xref="S4.SS2.SSS4.p2.6.m6.1.1.1"></eq><ci id="S4.SS2.SSS4.p2.6.m6.1.1.2.cmml" xref="S4.SS2.SSS4.p2.6.m6.1.1.2">𝛼</ci><cn id="S4.SS2.SSS4.p2.6.m6.1.1.3.cmml" type="integer" xref="S4.SS2.SSS4.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.6.m6.1c">\alpha=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.6.m6.1d">italic_α = 1</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.7" style="font-size:90%;"> is optimal, the model’s performance does not degrade significantly with minor deviations from this value. The findings suggest that </span><math alttext="\alpha" class="ltx_Math" display="inline" id="S4.SS2.SSS4.p2.7.m7.1"><semantics id="S4.SS2.SSS4.p2.7.m7.1a"><mi id="S4.SS2.SSS4.p2.7.m7.1.1" mathsize="90%" xref="S4.SS2.SSS4.p2.7.m7.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p2.7.m7.1b"><ci id="S4.SS2.SSS4.p2.7.m7.1.1.cmml" xref="S4.SS2.SSS4.p2.7.m7.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p2.7.m7.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS4.p2.7.m7.1d">italic_α</annotation></semantics></math><span class="ltx_text" id="S4.SS2.SSS4.p2.7.8" style="font-size:90%;"> critically influences the learning dynamics or loss function weighting, making its precise tuning essential for achieving the best performance from the ViT-S/16 model in the FOLK framework.</span></p>
</div>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T4.6.6.7.1" style="font-size:90%;">Param</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.1.1.1"><math alttext="\alpha=4" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.m1.1a"><mrow id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.m1.1.1.2" mathsize="90%" xref="S4.T4.1.1.1.m1.1.1.2.cmml">α</mi><mo id="S4.T4.1.1.1.m1.1.1.1" mathsize="90%" xref="S4.T4.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T4.1.1.1.m1.1.1.3" mathsize="90%" xref="S4.T4.1.1.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><eq id="S4.T4.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1.1"></eq><ci id="S4.T4.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.m1.1.1.2">𝛼</ci><cn id="S4.T4.1.1.1.m1.1.1.3.cmml" type="integer" xref="S4.T4.1.1.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">\alpha=4</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.m1.1d">italic_α = 4</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.2.2.2"><math alttext="\alpha=3" class="ltx_Math" display="inline" id="S4.T4.2.2.2.m1.1"><semantics id="S4.T4.2.2.2.m1.1a"><mrow id="S4.T4.2.2.2.m1.1.1" xref="S4.T4.2.2.2.m1.1.1.cmml"><mi id="S4.T4.2.2.2.m1.1.1.2" mathsize="90%" xref="S4.T4.2.2.2.m1.1.1.2.cmml">α</mi><mo id="S4.T4.2.2.2.m1.1.1.1" mathsize="90%" xref="S4.T4.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T4.2.2.2.m1.1.1.3" mathsize="90%" xref="S4.T4.2.2.2.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b"><apply id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1"><eq id="S4.T4.2.2.2.m1.1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1.1"></eq><ci id="S4.T4.2.2.2.m1.1.1.2.cmml" xref="S4.T4.2.2.2.m1.1.1.2">𝛼</ci><cn id="S4.T4.2.2.2.m1.1.1.3.cmml" type="integer" xref="S4.T4.2.2.2.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">\alpha=3</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.m1.1d">italic_α = 3</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.3.3.3"><math alttext="\alpha=2" class="ltx_Math" display="inline" id="S4.T4.3.3.3.m1.1"><semantics id="S4.T4.3.3.3.m1.1a"><mrow id="S4.T4.3.3.3.m1.1.1" xref="S4.T4.3.3.3.m1.1.1.cmml"><mi id="S4.T4.3.3.3.m1.1.1.2" mathsize="90%" xref="S4.T4.3.3.3.m1.1.1.2.cmml">α</mi><mo id="S4.T4.3.3.3.m1.1.1.1" mathsize="90%" xref="S4.T4.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T4.3.3.3.m1.1.1.3" mathsize="90%" xref="S4.T4.3.3.3.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.m1.1b"><apply id="S4.T4.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1"><eq id="S4.T4.3.3.3.m1.1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1.1"></eq><ci id="S4.T4.3.3.3.m1.1.1.2.cmml" xref="S4.T4.3.3.3.m1.1.1.2">𝛼</ci><cn id="S4.T4.3.3.3.m1.1.1.3.cmml" type="integer" xref="S4.T4.3.3.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.m1.1c">\alpha=2</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.m1.1d">italic_α = 2</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.4.4.4"><math alttext="\alpha=1" class="ltx_Math" display="inline" id="S4.T4.4.4.4.m1.1"><semantics id="S4.T4.4.4.4.m1.1a"><mrow id="S4.T4.4.4.4.m1.1.1" xref="S4.T4.4.4.4.m1.1.1.cmml"><mi id="S4.T4.4.4.4.m1.1.1.2" mathsize="90%" xref="S4.T4.4.4.4.m1.1.1.2.cmml">α</mi><mo id="S4.T4.4.4.4.m1.1.1.1" mathsize="90%" xref="S4.T4.4.4.4.m1.1.1.1.cmml">=</mo><mn id="S4.T4.4.4.4.m1.1.1.3" mathsize="90%" xref="S4.T4.4.4.4.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.m1.1b"><apply id="S4.T4.4.4.4.m1.1.1.cmml" xref="S4.T4.4.4.4.m1.1.1"><eq id="S4.T4.4.4.4.m1.1.1.1.cmml" xref="S4.T4.4.4.4.m1.1.1.1"></eq><ci id="S4.T4.4.4.4.m1.1.1.2.cmml" xref="S4.T4.4.4.4.m1.1.1.2">𝛼</ci><cn id="S4.T4.4.4.4.m1.1.1.3.cmml" type="integer" xref="S4.T4.4.4.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.m1.1c">\alpha=1</annotation><annotation encoding="application/x-llamapun" id="S4.T4.4.4.4.m1.1d">italic_α = 1</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T4.5.5.5"><math alttext="\alpha=0.1" class="ltx_Math" display="inline" id="S4.T4.5.5.5.m1.1"><semantics id="S4.T4.5.5.5.m1.1a"><mrow id="S4.T4.5.5.5.m1.1.1" xref="S4.T4.5.5.5.m1.1.1.cmml"><mi id="S4.T4.5.5.5.m1.1.1.2" mathsize="90%" xref="S4.T4.5.5.5.m1.1.1.2.cmml">α</mi><mo id="S4.T4.5.5.5.m1.1.1.1" mathsize="90%" xref="S4.T4.5.5.5.m1.1.1.1.cmml">=</mo><mn id="S4.T4.5.5.5.m1.1.1.3" mathsize="90%" xref="S4.T4.5.5.5.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.m1.1b"><apply id="S4.T4.5.5.5.m1.1.1.cmml" xref="S4.T4.5.5.5.m1.1.1"><eq id="S4.T4.5.5.5.m1.1.1.1.cmml" xref="S4.T4.5.5.5.m1.1.1.1"></eq><ci id="S4.T4.5.5.5.m1.1.1.2.cmml" xref="S4.T4.5.5.5.m1.1.1.2">𝛼</ci><cn id="S4.T4.5.5.5.m1.1.1.3.cmml" type="float" xref="S4.T4.5.5.5.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.m1.1c">\alpha=0.1</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.5.5.m1.1d">italic_α = 0.1</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.6.6.6"><math alttext="\alpha=0.05" class="ltx_Math" display="inline" id="S4.T4.6.6.6.m1.1"><semantics id="S4.T4.6.6.6.m1.1a"><mrow id="S4.T4.6.6.6.m1.1.1" xref="S4.T4.6.6.6.m1.1.1.cmml"><mi id="S4.T4.6.6.6.m1.1.1.2" mathsize="90%" xref="S4.T4.6.6.6.m1.1.1.2.cmml">α</mi><mo id="S4.T4.6.6.6.m1.1.1.1" mathsize="90%" xref="S4.T4.6.6.6.m1.1.1.1.cmml">=</mo><mn id="S4.T4.6.6.6.m1.1.1.3" mathsize="90%" xref="S4.T4.6.6.6.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.m1.1b"><apply id="S4.T4.6.6.6.m1.1.1.cmml" xref="S4.T4.6.6.6.m1.1.1"><eq id="S4.T4.6.6.6.m1.1.1.1.cmml" xref="S4.T4.6.6.6.m1.1.1.1"></eq><ci id="S4.T4.6.6.6.m1.1.1.2.cmml" xref="S4.T4.6.6.6.m1.1.1.2">𝛼</ci><cn id="S4.T4.6.6.6.m1.1.1.3.cmml" type="float" xref="S4.T4.6.6.6.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.m1.1c">\alpha=0.05</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.6.6.m1.1d">italic_α = 0.05</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.6.7.1">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.6.7.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.6.7.1.1.1" style="font-size:90%;">Acc</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.6.7.1.2"><span class="ltx_text" id="S4.T4.6.7.1.2.1" style="font-size:90%;">80.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.6.7.1.3"><span class="ltx_text" id="S4.T4.6.7.1.3.1" style="font-size:90%;">80.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.6.7.1.4"><span class="ltx_text" id="S4.T4.6.7.1.4.1" style="font-size:90%;">81.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.6.7.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.6.7.1.5.1" style="font-size:90%;">81.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T4.6.7.1.6">
<span class="ltx_text" id="S4.T4.6.7.1.6.1" style="font-size:90%;"></span><span class="ltx_ERROR undefined" id="S4.T4.6.7.1.6.2">\ul</span><span class="ltx_text" id="S4.T4.6.7.1.6.3" style="font-size:90%;">81.4</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.6.7.1.7">
<span class="ltx_text" id="S4.T4.6.7.1.7.1" style="font-size:90%;"></span><span class="ltx_ERROR undefined" id="S4.T4.6.7.1.7.2">\ul</span><span class="ltx_text" id="S4.T4.6.7.1.7.3" style="font-size:90%;">81.4</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Effect of <math alttext="\alpha" class="ltx_Math" display="inline" id="S4.T4.9.m1.1"><semantics id="S4.T4.9.m1.1b"><mi id="S4.T4.9.m1.1.1" xref="S4.T4.9.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.T4.9.m1.1c"><ci id="S4.T4.9.m1.1.1.cmml" xref="S4.T4.9.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.m1.1d">\alpha</annotation><annotation encoding="application/x-llamapun" id="S4.T4.9.m1.1e">italic_α</annotation></semantics></math> values in <math alttext="\mathcal{L}_{\text{tot}}" class="ltx_Math" display="inline" id="S4.T4.10.m2.1"><semantics id="S4.T4.10.m2.1b"><msub id="S4.T4.10.m2.1.1" xref="S4.T4.10.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T4.10.m2.1.1.2" xref="S4.T4.10.m2.1.1.2.cmml">ℒ</mi><mtext id="S4.T4.10.m2.1.1.3" xref="S4.T4.10.m2.1.1.3a.cmml">tot</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T4.10.m2.1c"><apply id="S4.T4.10.m2.1.1.cmml" xref="S4.T4.10.m2.1.1"><csymbol cd="ambiguous" id="S4.T4.10.m2.1.1.1.cmml" xref="S4.T4.10.m2.1.1">subscript</csymbol><ci id="S4.T4.10.m2.1.1.2.cmml" xref="S4.T4.10.m2.1.1.2">ℒ</ci><ci id="S4.T4.10.m2.1.1.3a.cmml" xref="S4.T4.10.m2.1.1.3"><mtext id="S4.T4.10.m2.1.1.3.cmml" mathsize="70%" xref="S4.T4.10.m2.1.1.3">tot</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.m2.1d">\mathcal{L}_{\text{tot}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.10.m2.1e">caligraphic_L start_POSTSUBSCRIPT tot end_POSTSUBSCRIPT</annotation></semantics></math> on top 1 accuracy for a ViT-S/16 model using FOLK methodology.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS4.p3">
<p class="ltx_p" id="S4.SS2.SSS4.p3.1"><span class="ltx_text" id="S4.SS2.SSS4.p3.1.1" style="font-size:90%;">In another ablation study, we examine the effects of employing various filters for frequency masking, which demonstrates the superior effectiveness of our informed filters design. This part is detailed in Appendix </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.SS3" style="font-size:90%;" title="B.3 Ablation Study - Different Filters ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">B.3</span></a><span class="ltx_text" id="S4.SS2.SSS4.p3.1.2" style="font-size:90%;">).</span></p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text" id="S5.p1.1.1" style="font-size:90%;">In this paper, we introduce the FOLK framework, a novel SSL method that addresses the limitations of previous frequency-based pre-training approaches. By integrating Fourier transform compression with self-knowledge distillation, FOLK adaptively selects frequencies for masking based on unique image responses, which allows the model to focus on more distinctive image features in the frequency domain, thereby enhancing the pre-training efficiency and model efficacy. Moreover, our dual-branch framework, which leverages both filtered and original images in pre-training, minimizes the adaptation requirements for natural-looking images in downstream tasks. Our experimental results demonstrate the effectiveness of FOLK, achieving competitive performance compared to many leading SSL methods. Notably, FOLK excels in tasks such as image classification, few-shot learning, and semantic segmentation, all while requiring fewer pre-training epochs.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.5.5.1" style="font-size:90%;">Ahn et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.7.1" style="font-size:90%;">
Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D Lawrence, and Zhenwen Dai.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.8.1" style="font-size:90%;">Variational information distillation for knowledge transfer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib1.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib1.11.3" style="font-size:90%;">, pages 9163–9171, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.4.4.1" style="font-size:90%;">Almalki and Latecki [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.6.1" style="font-size:90%;">
Amani Almalki and Longin Jan Latecki.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">Self-supervised learning with masked autoencoders for teeth segmentation from intra-oral 3d scans.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib2.9.2" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em><span class="ltx_text" id="bib.bib2.10.3" style="font-size:90%;">, pages 7820–7830, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.5.5.1" style="font-size:90%;">Bao et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.7.1" style="font-size:90%;">
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.8.1" style="font-size:90%;">Beit: Bert pre-training of image transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib3.11.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.5.5.1" style="font-size:90%;">Ben-Shaul et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.7.1" style="font-size:90%;">
Ido Ben-Shaul, Ravid Shwartz-Ziv, Tomer Galanti, Shai Dekel, and Yann LeCun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.8.1" style="font-size:90%;">Reverse engineering self-supervised learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib4.10.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.5.5.1" style="font-size:90%;">Buciluǎ et al. [2006]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">
Cristian Buciluǎ, Rich Caruana, and Alexandru Niculescu-Mizil.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.8.1" style="font-size:90%;">Model compression.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib5.10.2" style="font-size:90%;">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</em><span class="ltx_text" id="bib.bib5.11.3" style="font-size:90%;">, pages 535–541, 2006.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">Caron et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">Unsupervised learning of visual features by contrasting cluster assignments.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib6.10.2" style="font-size:90%;">, 33:9912–9924, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.5.5.1" style="font-size:90%;">Caron et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.7.1" style="font-size:90%;">
Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.8.1" style="font-size:90%;">Emerging properties in self-supervised vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span class="ltx_text" id="bib.bib7.11.3" style="font-size:90%;">, pages 9650–9660, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">Chen et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.7.1" style="font-size:90%;">
Defang Chen, Jian-Ping Mei, Yuan Zhang, Can Wang, Zhe Wang, Yan Feng, and Chun Chen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.8.1" style="font-size:90%;">Cross-layer distillation with semantic calibration.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib8.10.2" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</em><span class="ltx_text" id="bib.bib8.11.3" style="font-size:90%;">, volume 35, pages 7028–7036, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.5.5.1" style="font-size:90%;">Chen et al. [2020a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.7.1" style="font-size:90%;">
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.8.1" style="font-size:90%;">Generative pretraining from pixels.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib9.11.3" style="font-size:90%;">, pages 1691–1703. PMLR, 2020a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.5.5.1" style="font-size:90%;">Chen et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.7.1" style="font-size:90%;">
Mengzhao Chen, Mingbao Lin, Ke Li, Yunhang Shen, Yongjian Wu, Fei Chao, and Rongrong Ji.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.8.1" style="font-size:90%;">Cf-vit: A general coarse-to-fine method for vision transformer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib10.10.2" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</em><span class="ltx_text" id="bib.bib10.11.3" style="font-size:90%;">, volume 37, pages 7042–7052, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">Chen et al. [2020b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.7.1" style="font-size:90%;">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.8.1" style="font-size:90%;">A simple framework for contrastive learning of visual representations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib11.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib11.11.3" style="font-size:90%;">, pages 1597–1607. PMLR, 2020b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">Chen et al. [2020c]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E Hinton.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">Big self-supervised models are strong semi-supervised learners.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib12.10.2" style="font-size:90%;">, 33:22243–22255, 2020c.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.4.4.1" style="font-size:90%;">Chen and He [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.6.1" style="font-size:90%;">
Xinlei Chen and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">Exploring simple siamese representation learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.9.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib13.10.3" style="font-size:90%;">, pages 15750–15758, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">Chen et al. [2020d]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.7.1" style="font-size:90%;">
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.8.1" style="font-size:90%;">Improved baselines with momentum contrastive learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.9.1" style="font-size:90%;">arXiv preprint arXiv:2003.04297</em><span class="ltx_text" id="bib.bib14.10.2" style="font-size:90%;">, 2020d.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">Chong et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.7.1" style="font-size:90%;">
Dading Chong, Helin Wang, Peilin Zhou, and Qingcheng Zeng.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.8.1" style="font-size:90%;">Masked spectrogram prediction for self-supervised audio pre-training.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib15.10.2" style="font-size:90%;">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em><span class="ltx_text" id="bib.bib15.11.3" style="font-size:90%;">, pages 1–5. IEEE, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.5.5.1" style="font-size:90%;">Ci et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">
Yuanzheng Ci, Chen Lin, Lei Bai, and Wanli Ouyang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">Fast-moco: Boost momentum-based contrastive learning with combinatorial patches.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.10.2" style="font-size:90%;">European Conference on Computer Vision</em><span class="ltx_text" id="bib.bib16.11.3" style="font-size:90%;">, pages 290–306. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">Clark et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.7.1" style="font-size:90%;">
Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D Manning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.8.1" style="font-size:90%;">Electra: Pre-training text encoders as discriminators rather than generators.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.9.1" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib17.10.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.5.5.1" style="font-size:90%;">Cubuk et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">
Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.8.1" style="font-size:90%;">Randaugment: Practical automated data augmentation with a reduced search space.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib18.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops</em><span class="ltx_text" id="bib.bib18.11.3" style="font-size:90%;">, pages 702–703, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.5.5.1" style="font-size:90%;">Deng et al. [2009]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.8.1" style="font-size:90%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib19.10.2" style="font-size:90%;">2009 IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib19.11.3" style="font-size:90%;">, pages 248–255. Ieee, 2009.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">Devlin et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">Bert: Pre-training of deep bidirectional transformers for language understanding.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.9.1" style="font-size:90%;">arXiv preprint arXiv:1810.04805</em><span class="ltx_text" id="bib.bib20.10.2" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.5.5.1" style="font-size:90%;">Dosovitskiy et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.7.1" style="font-size:90%;">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.8.1" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at scale.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib21.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib21.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.5.5.1" style="font-size:90%;">Fang et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.7.1" style="font-size:90%;">
Yuxin Fang, Li Dong, Hangbo Bao, Xinggang Wang, and Furu Wei.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.8.1" style="font-size:90%;">Corrupted image modeling for self-supervised visual pre-training.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.10.2" style="font-size:90%;">The Eleventh International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib22.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.5.5.1" style="font-size:90%;">Fang et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.7.1" style="font-size:90%;">
Zhiyuan Fang, Jianfeng Wang, Lijuan Wang, Lei Zhang, Yezhou Yang, and Zicheng Liu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.8.1" style="font-size:90%;">Seed: Self-supervised distillation for visual representation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib23.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib23.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">Gidaris et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">Unsupervised representation learning by predicting image rotations.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib24.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib24.11.3" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">Gotmare et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">A closer look at deep learning heuristics: Learning rate restarts, warmup and distillation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib25.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib25.11.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">Grill et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">Bootstrap your own latent-a new approach to self-supervised learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib26.10.2" style="font-size:90%;">, 33:21271–21284, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">He et al. [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.7.1" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.8.1" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib27.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib27.11.3" style="font-size:90%;">, pages 770–778, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">He et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">Momentum contrast for unsupervised visual representation learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib28.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib28.11.3" style="font-size:90%;">, pages 9729–9738, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.5.5.1" style="font-size:90%;">He et al. [2022a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.8.1" style="font-size:90%;">Masked autoencoders are scalable vision learners.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib29.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib29.11.3" style="font-size:90%;">, pages 16000–16009, 2022a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">He et al. [2022b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.7.1" style="font-size:90%;">
Ruifei He, Shuyang Sun, Jihan Yang, Song Bai, and Xiaojuan Qi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.8.1" style="font-size:90%;">Knowledge distillation as efficient pre-training: Faster convergence, higher data-efficiency, and better transferability.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib30.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib30.11.3" style="font-size:90%;">, pages 9161–9171, 2022b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">Hinton et al. [2015]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.7.1" style="font-size:90%;">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.8.1" style="font-size:90%;">Distilling the knowledge in a neural network.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.9.1" style="font-size:90%;">arXiv preprint arXiv:1503.02531</em><span class="ltx_text" id="bib.bib31.10.2" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">Kakogeorgiou et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.7.1" style="font-size:90%;">
Ioannis Kakogeorgiou, Spyros Gidaris, Bill Psomas, Yannis Avrithis, Andrei Bursuc, Konstantinos Karantzalos, and Nikos Komodakis.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.8.1" style="font-size:90%;">What to hide from your students: Attention-guided masked image modeling.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib32.10.2" style="font-size:90%;">European Conference on Computer Vision</em><span class="ltx_text" id="bib.bib32.11.3" style="font-size:90%;">, pages 300–318. Springer, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.5.5.1" style="font-size:90%;">Kamarainen et al. [2006]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.7.1" style="font-size:90%;">
J-K Kamarainen, Ville Kyrki, and Heikki Kalviainen.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.8.1" style="font-size:90%;">Invariance properties of gabor filter-based features-overview and applications.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.9.1" style="font-size:90%;">IEEE Transactions on image processing</em><span class="ltx_text" id="bib.bib33.10.2" style="font-size:90%;">, 15(5):1088–1099, 2006.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.5.5.1" style="font-size:90%;">Li et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.7.1" style="font-size:90%;">
Wei Li, Jiahao Xie, and Chen Change Loy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.8.1" style="font-size:90%;">Correlational image modeling for self-supervised visual pre-training.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib34.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib34.11.3" style="font-size:90%;">, pages 15105–15115, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.4.4.1" style="font-size:90%;">Li and Arora [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.6.1" style="font-size:90%;">
Zhiyuan Li and Sanjeev Arora.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">An exponential learning rate schedule for deep learning.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib35.9.2" style="font-size:90%;">8th International Conference on Learning Representations, ICLR 2020</em><span class="ltx_text" id="bib.bib35.10.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.5.5.1" style="font-size:90%;">Liu et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.7.1" style="font-size:90%;">
Ran Liu, Ellen L Zippi, Hadi Pouransari, Chris Sandino, Jingping Nie, Hanlin Goh, Erdrin Azemi, and Ali Moin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.8.1" style="font-size:90%;">Frequency-aware masked autoencoders for multimodal pretraining on biosignals.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.9.1" style="font-size:90%;">arXiv preprint arXiv:2309.05927</em><span class="ltx_text" id="bib.bib36.10.2" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.5.5.1" style="font-size:90%;">Liu et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.7.1" style="font-size:90%;">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.8.1" style="font-size:90%;">Roberta: A robustly optimized bert pretraining approach.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.9.1" style="font-size:90%;">arXiv preprint arXiv:1907.11692</em><span class="ltx_text" id="bib.bib37.10.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.4.4.1" style="font-size:90%;">Loshchilov and Hutter [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.6.1" style="font-size:90%;">
Ilya Loshchilov and Frank Hutter.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.7.1" style="font-size:90%;">Decoupled weight decay regularization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib38.9.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib38.10.3" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.5.5.1" style="font-size:90%;">Monsefi et al. [2024a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.7.1" style="font-size:90%;">
Amin Karimi Monsefi, Payam Karisani, Mengxi Zhou, Stacey Choi, Nathan Doble, Heng Ji, Srinivasan Parthasarathy, and Rajiv Ramnath.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.8.1" style="font-size:90%;">Masked logonet: Fast and accurate 3d image analysis for medical domain.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.9.1" style="font-size:90%;">arXiv preprint arXiv:2402.06190</em><span class="ltx_text" id="bib.bib39.10.2" style="font-size:90%;">, 2024a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.5.5.1" style="font-size:90%;">Monsefi et al. [2024b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.7.1" style="font-size:90%;">
Amin Karimi Monsefi, Kishore Prakash Sailaja, Ali Alilooee, Ser-Nam Lim, and Rajiv Ramnath.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.8.1" style="font-size:90%;">Detailclip: Detail-oriented clip for fine-grained tasks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.9.1" style="font-size:90%;">arXiv preprint arXiv:2409.06809</em><span class="ltx_text" id="bib.bib40.10.2" style="font-size:90%;">, 2024b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.4.4.1" style="font-size:90%;">Navard and Yilmaz [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.6.1" style="font-size:90%;">
Pouyan Navard and Alper Yilmaz.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.7.1" style="font-size:90%;">A probabilistic-based drift correction module for visual inertial slams.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.8.1" style="font-size:90%;">arXiv preprint arXiv:2404.10140</em><span class="ltx_text" id="bib.bib41.9.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.4.4.1" style="font-size:90%;">Noroozi and Favaro [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.6.1" style="font-size:90%;">
Mehdi Noroozi and Paolo Favaro.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.7.1" style="font-size:90%;">Unsupervised learning of visual representations by solving jigsaw puzzles.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.8.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib42.9.2" style="font-size:90%;">European conference on computer vision</em><span class="ltx_text" id="bib.bib42.10.3" style="font-size:90%;">, pages 69–84. Springer, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.5.5.1" style="font-size:90%;">Oord et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.7.1" style="font-size:90%;">
Aaron van den Oord, Yazhe Li, and Oriol Vinyals.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.8.1" style="font-size:90%;">Representation learning with contrastive predictive coding.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.9.1" style="font-size:90%;">arXiv preprint arXiv:1807.03748</em><span class="ltx_text" id="bib.bib43.10.2" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.4.4.1" style="font-size:90%;">Oppenheim and Lim [1981]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.6.1" style="font-size:90%;">
Alan V Oppenheim and Jae S Lim.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.7.1" style="font-size:90%;">The importance of phase in signals.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.8.1" style="font-size:90%;">Proceedings of the IEEE</em><span class="ltx_text" id="bib.bib44.9.2" style="font-size:90%;">, 69(5):529–541, 1981.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.5.5.1" style="font-size:90%;">Oquab et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.7.1" style="font-size:90%;">
Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy V Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel HAZIZA, Francisco Massa, Alaaeldin El-Nouby, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.8.1" style="font-size:90%;">Dinov2: Learning robust visual features without supervision.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.9.1" style="font-size:90%;">Transactions on Machine Learning Research</em><span class="ltx_text" id="bib.bib45.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.5.5.1" style="font-size:90%;">Paszke et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.7.1" style="font-size:90%;">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.8.1" style="font-size:90%;">Pytorch: An imperative style, high-performance deep learning library.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib46.10.2" style="font-size:90%;">, 32, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.5.5.1" style="font-size:90%;">Perera et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.7.1" style="font-size:90%;">
Shehan Perera, Pouyan Navard, and Alper Yilmaz.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.8.1" style="font-size:90%;">Segformer3d: an efficient transformer for 3d medical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib47.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib47.11.3" style="font-size:90%;">, pages 4981–4988, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.4.4.1" style="font-size:90%;">Piotrowski and Campbell [1982]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.6.1" style="font-size:90%;">
Leon N Piotrowski and Fergus W Campbell.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.7.1" style="font-size:90%;">A demonstration of the visual importance and flexibility of spatial-frequency amplitude and phase.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.8.1" style="font-size:90%;">Perception</em><span class="ltx_text" id="bib.bib48.9.2" style="font-size:90%;">, 11(3):337–346, 1982.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.5.5.1" style="font-size:90%;">Pratt et al. [1969]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.7.1" style="font-size:90%;">
William K Pratt, Julius Kane, and Harry C Andrews.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.8.1" style="font-size:90%;">Hadamard transform image coding.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.9.1" style="font-size:90%;">Proceedings of the IEEE</em><span class="ltx_text" id="bib.bib49.10.2" style="font-size:90%;">, 57(1):58–68, 1969.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib50.5.5.1" style="font-size:90%;">Ramesh et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.7.1" style="font-size:90%;">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.8.1" style="font-size:90%;">Zero-shot text-to-image generation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib50.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib50.11.3" style="font-size:90%;">, pages 8821–8831. Pmlr, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib51.5.5.1" style="font-size:90%;">Romero et al. [2014]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.7.1" style="font-size:90%;">
Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.8.1" style="font-size:90%;">Fitnets: Hints for thin deep nets.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.9.1" style="font-size:90%;">arXiv preprint arXiv:1412.6550</em><span class="ltx_text" id="bib.bib51.10.2" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib52.5.5.1" style="font-size:90%;">Su et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.7.1" style="font-size:90%;">
Qing Su, Anton Netchaev, Hai Li, and Shihao Ji.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.8.1" style="font-size:90%;">Flsl: Feature-level self-supervised learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib52.10.2" style="font-size:90%;">, 36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib53.5.5.1" style="font-size:90%;">Szegedy et al. [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.7.1" style="font-size:90%;">
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.8.1" style="font-size:90%;">Rethinking the inception architecture for computer vision.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib53.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib53.11.3" style="font-size:90%;">, pages 2818–2826, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib54.4.4.1" style="font-size:90%;">Tarvainen and Valpola [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.6.1" style="font-size:90%;">
Antti Tarvainen and Harri Valpola.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.7.1" style="font-size:90%;">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.8.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib54.9.2" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib55.5.5.1" style="font-size:90%;">Tian et al. [2020a]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.7.1" style="font-size:90%;">
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.8.1" style="font-size:90%;">Contrastive representation distillation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib55.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib55.11.3" style="font-size:90%;">, 2020a.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib56.5.5.1" style="font-size:90%;">Tian et al. [2020b]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.7.1" style="font-size:90%;">
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and Phillip Isola.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.8.1" style="font-size:90%;">What makes for good views for contrastive learning?
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.9.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib56.10.2" style="font-size:90%;">, 33:6827–6839, 2020b.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib57.5.5.1" style="font-size:90%;">Touvron et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.7.1" style="font-size:90%;">
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Hervé Jégou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.8.1" style="font-size:90%;">Training data-efficient image transformers &amp; distillation through attention.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib57.10.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib57.11.3" style="font-size:90%;">, pages 10347–10357. PMLR, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib58.5.5.1" style="font-size:90%;">Wang et al. [2020]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.7.1" style="font-size:90%;">
Yulin Wang, Kangchen Lv, Rui Huang, Shiji Song, Le Yang, and Gao Huang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.8.1" style="font-size:90%;">Glance and focus: a dynamic approach to reducing spatial redundancy in image classification.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.9.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib58.10.2" style="font-size:90%;">, 33:2432–2444, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib59.5.5.1" style="font-size:90%;">Wei et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.7.1" style="font-size:90%;">
Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, and Christoph Feichtenhofer.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.8.1" style="font-size:90%;">Masked feature prediction for self-supervised visual pre-training.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib59.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib59.11.3" style="font-size:90%;">, pages 14668–14678, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib60.5.5.1" style="font-size:90%;">Wightman et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.7.1" style="font-size:90%;">
Ross Wightman, Hugo Touvron, and Herve Jegou.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.8.1" style="font-size:90%;">Resnet strikes back: An improved training procedure in timm.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib60.10.2" style="font-size:90%;">NeurIPS 2021 Workshop on ImageNet: Past, Present, and Future</em><span class="ltx_text" id="bib.bib60.11.3" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib61.5.5.1" style="font-size:90%;">Xiao et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.7.1" style="font-size:90%;">
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.8.1" style="font-size:90%;">Unified perceptual parsing for scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib61.10.2" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</em><span class="ltx_text" id="bib.bib61.11.3" style="font-size:90%;">, pages 418–434, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib62.5.5.1" style="font-size:90%;">Xie et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.7.1" style="font-size:90%;">
Jiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew-Soon Ong, and Chen Change Loy.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.8.1" style="font-size:90%;">Masked frequency modeling for self-supervised visual pre-training.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib62.10.2" style="font-size:90%;">The Eleventh International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib62.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib63.5.5.1" style="font-size:90%;">Xie et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.7.1" style="font-size:90%;">
Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, and Han Hu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.8.1" style="font-size:90%;">Simmim: A simple framework for masked image modeling.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib63.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span class="ltx_text" id="bib.bib63.11.3" style="font-size:90%;">, pages 9653–9663, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib64.5.5.1" style="font-size:90%;">Yi et al. [2023]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.7.1" style="font-size:90%;">
Kun Yi, Yixiao Ge, Xiaotong Li, Shusheng Yang, Dian Li, Jianping Wu, Ying Shan, and Xiaohu Qie.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.8.1" style="font-size:90%;">Masked image modeling with denoising contrast.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib64.10.2" style="font-size:90%;">The Eleventh International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib64.11.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib65.5.5.1" style="font-size:90%;">Yun et al. [2019]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.7.1" style="font-size:90%;">
Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.8.1" style="font-size:90%;">Cutmix: Regularization strategy to train strong classifiers with localizable features.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib65.10.2" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span class="ltx_text" id="bib.bib65.11.3" style="font-size:90%;">, pages 6023–6032, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib66.5.5.1" style="font-size:90%;">Zhang et al. [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.7.1" style="font-size:90%;">
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.8.1" style="font-size:90%;">mixup: Beyond empirical risk minimization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib66.10.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib66.11.3" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib67.5.5.1" style="font-size:90%;">Zhang et al. [2016]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.7.1" style="font-size:90%;">
Richard Zhang, Phillip Isola, and Alexei A Efros.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.8.1" style="font-size:90%;">Colorful image colorization.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib67.10.2" style="font-size:90%;">Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III 14</em><span class="ltx_text" id="bib.bib67.11.3" style="font-size:90%;">, pages 649–666. Springer, 2016.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib68.4.4.1" style="font-size:90%;">Zhang and Sabuncu [2018]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.6.1" style="font-size:90%;">
Zhilu Zhang and Mert Sabuncu.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.7.1" style="font-size:90%;">Generalized cross entropy loss for training deep neural networks with noisy labels.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.8.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib68.9.2" style="font-size:90%;">, 31, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib69.5.5.1" style="font-size:90%;">Zheng et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.7.1" style="font-size:90%;">
Tianyi Zheng, Bo Li, Shuang Wu, Ben Wan, Guodong Mu, Shice Liu, Shouhong Ding, and Jia Wang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.8.1" style="font-size:90%;">Mfae: Masked frequency autoencoders for domain generalization face anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.9.1" style="font-size:90%;">IEEE Transactions on Information Forensics and Security</em><span class="ltx_text" id="bib.bib69.10.2" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib70.5.5.1" style="font-size:90%;">Zhou et al. [2017]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.7.1" style="font-size:90%;">
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.8.1" style="font-size:90%;">Scene parsing through ade20k dataset.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.9.1" style="font-size:90%;">In </span><em class="ltx_emph ltx_font_italic" id="bib.bib70.10.2" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib70.11.3" style="font-size:90%;">, pages 633–641, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib71.5.5.1" style="font-size:90%;">Zhou et al. [2021]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.7.1" style="font-size:90%;">
Helong Zhou, Liangchen Song, Jiajie Chen, Ye Zhou, Guoli Wang, Junsong Yuan, and Qian Zhang.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.8.1" style="font-size:90%;">Rethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.9.1" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib71.10.2" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib72.5.5.1" style="font-size:90%;">Zhou et al. [2022]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.7.1" style="font-size:90%;">
Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.8.1" style="font-size:90%;">ibot: Image bert pre-training with online tokenizer.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.9.1" style="font-size:90%;">International Conference on Learning Representations (ICLR)</em><span class="ltx_text" id="bib.bib72.10.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib73.5.5.1" style="font-size:90%;">Zhou et al. [2024]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.7.1" style="font-size:90%;">
Mengxi Zhou, Yue Zhang, Amin Karimi Monsefi, Stacey S Choi, Nathan Doble, Srinivasan Parthasarathy, and Rajiv Ramnath.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.8.1" style="font-size:90%;">Reducing manual labeling requirements and improved retinal ganglion cell identification in 3d ao-oct volumes using semi-supervised learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.9.1" style="font-size:90%;">Biomedical Optics Express</em><span class="ltx_text" id="bib.bib73.10.2" style="font-size:90%;">, 15(8):4540–4556, 2024.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1" lang="en">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">Appendix</h2>
<div class="ltx_para" id="Ax1.p1">
<p class="ltx_p" id="Ax1.p1.1"><span class="ltx_text" id="Ax1.p1.1.1" style="font-size:90%;">The following sections present a comprehensive overview of the FOLK implementation, detailing both the pre-training and fine-tuning phases. We also provide extensive experimental analyses, including performance evaluations on CNN-based model image classification, few-shot learning, and method efficiency analysis. Additionally, we will showcase visualizations of our designed informed filters for various input images, as well as the outputs generated by our pre-trained model on the pretext task, further demonstrating the effectiveness of our approach.</span></p>
</div>
</section>
<section class="ltx_appendix" id="A1" lang="en">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1"><span class="ltx_text" id="A1.p1.1.1" style="font-size:90%;">Throughout our experimental investigations, we adopted the methodologies prescribed by the iBOT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.p1.1.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="A1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A1.p1.1.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.p1.1.5" style="font-size:90%;"> and MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.p1.1.6.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A1.p1.1.8.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.p1.1.9" style="font-size:90%;"> frameworks. In a multi-GPU training circumstance, the learning rate adjustment is vital for optimizing the model’s learning efficiency. The formulation used to compute the scaled learning rate is delineated below:</span></p>
</div>
<div class="ltx_para" id="A1.p2">
<table class="ltx_equation ltx_eqn_table" id="A1.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="ScaledLR=BaseLR\cdot BatchSize\cdot\left(\frac{WorldSize}{512}\right)" class="ltx_Math" display="block" id="A1.E1.m1.1"><semantics id="A1.E1.m1.1a"><mrow id="A1.E1.m1.1.2" xref="A1.E1.m1.1.2.cmml"><mrow id="A1.E1.m1.1.2.2" xref="A1.E1.m1.1.2.2.cmml"><mi id="A1.E1.m1.1.2.2.2" mathsize="90%" xref="A1.E1.m1.1.2.2.2.cmml">S</mi><mo id="A1.E1.m1.1.2.2.1" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.3" mathsize="90%" xref="A1.E1.m1.1.2.2.3.cmml">c</mi><mo id="A1.E1.m1.1.2.2.1a" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.4" mathsize="90%" xref="A1.E1.m1.1.2.2.4.cmml">a</mi><mo id="A1.E1.m1.1.2.2.1b" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.5" mathsize="90%" xref="A1.E1.m1.1.2.2.5.cmml">l</mi><mo id="A1.E1.m1.1.2.2.1c" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.6" mathsize="90%" xref="A1.E1.m1.1.2.2.6.cmml">e</mi><mo id="A1.E1.m1.1.2.2.1d" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.7" mathsize="90%" xref="A1.E1.m1.1.2.2.7.cmml">d</mi><mo id="A1.E1.m1.1.2.2.1e" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.8" mathsize="90%" xref="A1.E1.m1.1.2.2.8.cmml">L</mi><mo id="A1.E1.m1.1.2.2.1f" xref="A1.E1.m1.1.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.2.9" mathsize="90%" xref="A1.E1.m1.1.2.2.9.cmml">R</mi></mrow><mo id="A1.E1.m1.1.2.1" mathsize="90%" xref="A1.E1.m1.1.2.1.cmml">=</mo><mrow id="A1.E1.m1.1.2.3" xref="A1.E1.m1.1.2.3.cmml"><mrow id="A1.E1.m1.1.2.3.2" xref="A1.E1.m1.1.2.3.2.cmml"><mrow id="A1.E1.m1.1.2.3.2.2" xref="A1.E1.m1.1.2.3.2.2.cmml"><mrow id="A1.E1.m1.1.2.3.2.2.2" xref="A1.E1.m1.1.2.3.2.2.2.cmml"><mi id="A1.E1.m1.1.2.3.2.2.2.2" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.2.2.cmml">B</mi><mo id="A1.E1.m1.1.2.3.2.2.2.1" xref="A1.E1.m1.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.2.2.3" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.2.3.cmml">a</mi><mo id="A1.E1.m1.1.2.3.2.2.2.1a" xref="A1.E1.m1.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.2.2.4" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.2.4.cmml">s</mi><mo id="A1.E1.m1.1.2.3.2.2.2.1b" xref="A1.E1.m1.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.2.2.5" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.2.5.cmml">e</mi><mo id="A1.E1.m1.1.2.3.2.2.2.1c" xref="A1.E1.m1.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.2.2.6" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.2.6.cmml">L</mi><mo id="A1.E1.m1.1.2.3.2.2.2.1d" xref="A1.E1.m1.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.2.2.7" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.2.7.cmml">R</mi></mrow><mo id="A1.E1.m1.1.2.3.2.2.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="A1.E1.m1.1.2.3.2.2.1.cmml">⋅</mo><mi id="A1.E1.m1.1.2.3.2.2.3" mathsize="90%" xref="A1.E1.m1.1.2.3.2.2.3.cmml">B</mi></mrow><mo id="A1.E1.m1.1.2.3.2.1" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.3" mathsize="90%" xref="A1.E1.m1.1.2.3.2.3.cmml">a</mi><mo id="A1.E1.m1.1.2.3.2.1a" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.4" mathsize="90%" xref="A1.E1.m1.1.2.3.2.4.cmml">t</mi><mo id="A1.E1.m1.1.2.3.2.1b" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.5" mathsize="90%" xref="A1.E1.m1.1.2.3.2.5.cmml">c</mi><mo id="A1.E1.m1.1.2.3.2.1c" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.6" mathsize="90%" xref="A1.E1.m1.1.2.3.2.6.cmml">h</mi><mo id="A1.E1.m1.1.2.3.2.1d" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.7" mathsize="90%" xref="A1.E1.m1.1.2.3.2.7.cmml">S</mi><mo id="A1.E1.m1.1.2.3.2.1e" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.8" mathsize="90%" xref="A1.E1.m1.1.2.3.2.8.cmml">i</mi><mo id="A1.E1.m1.1.2.3.2.1f" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.9" mathsize="90%" xref="A1.E1.m1.1.2.3.2.9.cmml">z</mi><mo id="A1.E1.m1.1.2.3.2.1g" xref="A1.E1.m1.1.2.3.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.2.3.2.10" mathsize="90%" xref="A1.E1.m1.1.2.3.2.10.cmml">e</mi></mrow><mo id="A1.E1.m1.1.2.3.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="A1.E1.m1.1.2.3.1.cmml">⋅</mo><mrow id="A1.E1.m1.1.2.3.3.2" xref="A1.E1.m1.1.1.cmml"><mo id="A1.E1.m1.1.2.3.3.2.1" xref="A1.E1.m1.1.1.cmml">(</mo><mfrac id="A1.E1.m1.1.1" xref="A1.E1.m1.1.1.cmml"><mrow id="A1.E1.m1.1.1.2" xref="A1.E1.m1.1.1.2.cmml"><mi id="A1.E1.m1.1.1.2.2" mathsize="90%" xref="A1.E1.m1.1.1.2.2.cmml">W</mi><mo id="A1.E1.m1.1.1.2.1" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.3" mathsize="90%" xref="A1.E1.m1.1.1.2.3.cmml">o</mi><mo id="A1.E1.m1.1.1.2.1a" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.4" mathsize="90%" xref="A1.E1.m1.1.1.2.4.cmml">r</mi><mo id="A1.E1.m1.1.1.2.1b" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.5" mathsize="90%" xref="A1.E1.m1.1.1.2.5.cmml">l</mi><mo id="A1.E1.m1.1.1.2.1c" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.6" mathsize="90%" xref="A1.E1.m1.1.1.2.6.cmml">d</mi><mo id="A1.E1.m1.1.1.2.1d" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.7" mathsize="90%" xref="A1.E1.m1.1.1.2.7.cmml">S</mi><mo id="A1.E1.m1.1.1.2.1e" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.8" mathsize="90%" xref="A1.E1.m1.1.1.2.8.cmml">i</mi><mo id="A1.E1.m1.1.1.2.1f" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.9" mathsize="90%" xref="A1.E1.m1.1.1.2.9.cmml">z</mi><mo id="A1.E1.m1.1.1.2.1g" xref="A1.E1.m1.1.1.2.1.cmml">⁢</mo><mi id="A1.E1.m1.1.1.2.10" mathsize="90%" xref="A1.E1.m1.1.1.2.10.cmml">e</mi></mrow><mn id="A1.E1.m1.1.1.3" mathsize="90%" xref="A1.E1.m1.1.1.3.cmml">512</mn></mfrac><mo id="A1.E1.m1.1.2.3.3.2.2" xref="A1.E1.m1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E1.m1.1b"><apply id="A1.E1.m1.1.2.cmml" xref="A1.E1.m1.1.2"><eq id="A1.E1.m1.1.2.1.cmml" xref="A1.E1.m1.1.2.1"></eq><apply id="A1.E1.m1.1.2.2.cmml" xref="A1.E1.m1.1.2.2"><times id="A1.E1.m1.1.2.2.1.cmml" xref="A1.E1.m1.1.2.2.1"></times><ci id="A1.E1.m1.1.2.2.2.cmml" xref="A1.E1.m1.1.2.2.2">𝑆</ci><ci id="A1.E1.m1.1.2.2.3.cmml" xref="A1.E1.m1.1.2.2.3">𝑐</ci><ci id="A1.E1.m1.1.2.2.4.cmml" xref="A1.E1.m1.1.2.2.4">𝑎</ci><ci id="A1.E1.m1.1.2.2.5.cmml" xref="A1.E1.m1.1.2.2.5">𝑙</ci><ci id="A1.E1.m1.1.2.2.6.cmml" xref="A1.E1.m1.1.2.2.6">𝑒</ci><ci id="A1.E1.m1.1.2.2.7.cmml" xref="A1.E1.m1.1.2.2.7">𝑑</ci><ci id="A1.E1.m1.1.2.2.8.cmml" xref="A1.E1.m1.1.2.2.8">𝐿</ci><ci id="A1.E1.m1.1.2.2.9.cmml" xref="A1.E1.m1.1.2.2.9">𝑅</ci></apply><apply id="A1.E1.m1.1.2.3.cmml" xref="A1.E1.m1.1.2.3"><ci id="A1.E1.m1.1.2.3.1.cmml" xref="A1.E1.m1.1.2.3.1">⋅</ci><apply id="A1.E1.m1.1.2.3.2.cmml" xref="A1.E1.m1.1.2.3.2"><times id="A1.E1.m1.1.2.3.2.1.cmml" xref="A1.E1.m1.1.2.3.2.1"></times><apply id="A1.E1.m1.1.2.3.2.2.cmml" xref="A1.E1.m1.1.2.3.2.2"><ci id="A1.E1.m1.1.2.3.2.2.1.cmml" xref="A1.E1.m1.1.2.3.2.2.1">⋅</ci><apply id="A1.E1.m1.1.2.3.2.2.2.cmml" xref="A1.E1.m1.1.2.3.2.2.2"><times id="A1.E1.m1.1.2.3.2.2.2.1.cmml" xref="A1.E1.m1.1.2.3.2.2.2.1"></times><ci id="A1.E1.m1.1.2.3.2.2.2.2.cmml" xref="A1.E1.m1.1.2.3.2.2.2.2">𝐵</ci><ci id="A1.E1.m1.1.2.3.2.2.2.3.cmml" xref="A1.E1.m1.1.2.3.2.2.2.3">𝑎</ci><ci id="A1.E1.m1.1.2.3.2.2.2.4.cmml" xref="A1.E1.m1.1.2.3.2.2.2.4">𝑠</ci><ci id="A1.E1.m1.1.2.3.2.2.2.5.cmml" xref="A1.E1.m1.1.2.3.2.2.2.5">𝑒</ci><ci id="A1.E1.m1.1.2.3.2.2.2.6.cmml" xref="A1.E1.m1.1.2.3.2.2.2.6">𝐿</ci><ci id="A1.E1.m1.1.2.3.2.2.2.7.cmml" xref="A1.E1.m1.1.2.3.2.2.2.7">𝑅</ci></apply><ci id="A1.E1.m1.1.2.3.2.2.3.cmml" xref="A1.E1.m1.1.2.3.2.2.3">𝐵</ci></apply><ci id="A1.E1.m1.1.2.3.2.3.cmml" xref="A1.E1.m1.1.2.3.2.3">𝑎</ci><ci id="A1.E1.m1.1.2.3.2.4.cmml" xref="A1.E1.m1.1.2.3.2.4">𝑡</ci><ci id="A1.E1.m1.1.2.3.2.5.cmml" xref="A1.E1.m1.1.2.3.2.5">𝑐</ci><ci id="A1.E1.m1.1.2.3.2.6.cmml" xref="A1.E1.m1.1.2.3.2.6">ℎ</ci><ci id="A1.E1.m1.1.2.3.2.7.cmml" xref="A1.E1.m1.1.2.3.2.7">𝑆</ci><ci id="A1.E1.m1.1.2.3.2.8.cmml" xref="A1.E1.m1.1.2.3.2.8">𝑖</ci><ci id="A1.E1.m1.1.2.3.2.9.cmml" xref="A1.E1.m1.1.2.3.2.9">𝑧</ci><ci id="A1.E1.m1.1.2.3.2.10.cmml" xref="A1.E1.m1.1.2.3.2.10">𝑒</ci></apply><apply id="A1.E1.m1.1.1.cmml" xref="A1.E1.m1.1.2.3.3.2"><divide id="A1.E1.m1.1.1.1.cmml" xref="A1.E1.m1.1.2.3.3.2"></divide><apply id="A1.E1.m1.1.1.2.cmml" xref="A1.E1.m1.1.1.2"><times id="A1.E1.m1.1.1.2.1.cmml" xref="A1.E1.m1.1.1.2.1"></times><ci id="A1.E1.m1.1.1.2.2.cmml" xref="A1.E1.m1.1.1.2.2">𝑊</ci><ci id="A1.E1.m1.1.1.2.3.cmml" xref="A1.E1.m1.1.1.2.3">𝑜</ci><ci id="A1.E1.m1.1.1.2.4.cmml" xref="A1.E1.m1.1.1.2.4">𝑟</ci><ci id="A1.E1.m1.1.1.2.5.cmml" xref="A1.E1.m1.1.1.2.5">𝑙</ci><ci id="A1.E1.m1.1.1.2.6.cmml" xref="A1.E1.m1.1.1.2.6">𝑑</ci><ci id="A1.E1.m1.1.1.2.7.cmml" xref="A1.E1.m1.1.1.2.7">𝑆</ci><ci id="A1.E1.m1.1.1.2.8.cmml" xref="A1.E1.m1.1.1.2.8">𝑖</ci><ci id="A1.E1.m1.1.1.2.9.cmml" xref="A1.E1.m1.1.1.2.9">𝑧</ci><ci id="A1.E1.m1.1.1.2.10.cmml" xref="A1.E1.m1.1.1.2.10">𝑒</ci></apply><cn id="A1.E1.m1.1.1.3.cmml" type="integer" xref="A1.E1.m1.1.1.3">512</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E1.m1.1c">ScaledLR=BaseLR\cdot BatchSize\cdot\left(\frac{WorldSize}{512}\right)</annotation><annotation encoding="application/x-llamapun" id="A1.E1.m1.1d">italic_S italic_c italic_a italic_l italic_e italic_d italic_L italic_R = italic_B italic_a italic_s italic_e italic_L italic_R ⋅ italic_B italic_a italic_t italic_c italic_h italic_S italic_i italic_z italic_e ⋅ ( divide start_ARG italic_W italic_o italic_r italic_l italic_d italic_S italic_i italic_z italic_e end_ARG start_ARG 512 end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A1.p3">
<p class="ltx_p" id="A1.p3.4"><span class="ltx_text" id="A1.p3.4.1" style="font-size:90%;">In this context, </span><math alttext="BaseLR" class="ltx_Math" display="inline" id="A1.p3.1.m1.1"><semantics id="A1.p3.1.m1.1a"><mrow id="A1.p3.1.m1.1.1" xref="A1.p3.1.m1.1.1.cmml"><mi id="A1.p3.1.m1.1.1.2" mathsize="90%" xref="A1.p3.1.m1.1.1.2.cmml">B</mi><mo id="A1.p3.1.m1.1.1.1" xref="A1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.p3.1.m1.1.1.3" mathsize="90%" xref="A1.p3.1.m1.1.1.3.cmml">a</mi><mo id="A1.p3.1.m1.1.1.1a" xref="A1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.p3.1.m1.1.1.4" mathsize="90%" xref="A1.p3.1.m1.1.1.4.cmml">s</mi><mo id="A1.p3.1.m1.1.1.1b" xref="A1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.p3.1.m1.1.1.5" mathsize="90%" xref="A1.p3.1.m1.1.1.5.cmml">e</mi><mo id="A1.p3.1.m1.1.1.1c" xref="A1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.p3.1.m1.1.1.6" mathsize="90%" xref="A1.p3.1.m1.1.1.6.cmml">L</mi><mo id="A1.p3.1.m1.1.1.1d" xref="A1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.p3.1.m1.1.1.7" mathsize="90%" xref="A1.p3.1.m1.1.1.7.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.p3.1.m1.1b"><apply id="A1.p3.1.m1.1.1.cmml" xref="A1.p3.1.m1.1.1"><times id="A1.p3.1.m1.1.1.1.cmml" xref="A1.p3.1.m1.1.1.1"></times><ci id="A1.p3.1.m1.1.1.2.cmml" xref="A1.p3.1.m1.1.1.2">𝐵</ci><ci id="A1.p3.1.m1.1.1.3.cmml" xref="A1.p3.1.m1.1.1.3">𝑎</ci><ci id="A1.p3.1.m1.1.1.4.cmml" xref="A1.p3.1.m1.1.1.4">𝑠</ci><ci id="A1.p3.1.m1.1.1.5.cmml" xref="A1.p3.1.m1.1.1.5">𝑒</ci><ci id="A1.p3.1.m1.1.1.6.cmml" xref="A1.p3.1.m1.1.1.6">𝐿</ci><ci id="A1.p3.1.m1.1.1.7.cmml" xref="A1.p3.1.m1.1.1.7">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.1.m1.1c">BaseLR</annotation><annotation encoding="application/x-llamapun" id="A1.p3.1.m1.1d">italic_B italic_a italic_s italic_e italic_L italic_R</annotation></semantics></math><span class="ltx_text" id="A1.p3.4.2" style="font-size:90%;"> signifies the optimal or peak learning rate identified for the model’s training process. The term </span><math alttext="BatchSize" class="ltx_Math" display="inline" id="A1.p3.2.m2.1"><semantics id="A1.p3.2.m2.1a"><mrow id="A1.p3.2.m2.1.1" xref="A1.p3.2.m2.1.1.cmml"><mi id="A1.p3.2.m2.1.1.2" mathsize="90%" xref="A1.p3.2.m2.1.1.2.cmml">B</mi><mo id="A1.p3.2.m2.1.1.1" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.3" mathsize="90%" xref="A1.p3.2.m2.1.1.3.cmml">a</mi><mo id="A1.p3.2.m2.1.1.1a" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.4" mathsize="90%" xref="A1.p3.2.m2.1.1.4.cmml">t</mi><mo id="A1.p3.2.m2.1.1.1b" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.5" mathsize="90%" xref="A1.p3.2.m2.1.1.5.cmml">c</mi><mo id="A1.p3.2.m2.1.1.1c" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.6" mathsize="90%" xref="A1.p3.2.m2.1.1.6.cmml">h</mi><mo id="A1.p3.2.m2.1.1.1d" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.7" mathsize="90%" xref="A1.p3.2.m2.1.1.7.cmml">S</mi><mo id="A1.p3.2.m2.1.1.1e" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.8" mathsize="90%" xref="A1.p3.2.m2.1.1.8.cmml">i</mi><mo id="A1.p3.2.m2.1.1.1f" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.9" mathsize="90%" xref="A1.p3.2.m2.1.1.9.cmml">z</mi><mo id="A1.p3.2.m2.1.1.1g" xref="A1.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.p3.2.m2.1.1.10" mathsize="90%" xref="A1.p3.2.m2.1.1.10.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.p3.2.m2.1b"><apply id="A1.p3.2.m2.1.1.cmml" xref="A1.p3.2.m2.1.1"><times id="A1.p3.2.m2.1.1.1.cmml" xref="A1.p3.2.m2.1.1.1"></times><ci id="A1.p3.2.m2.1.1.2.cmml" xref="A1.p3.2.m2.1.1.2">𝐵</ci><ci id="A1.p3.2.m2.1.1.3.cmml" xref="A1.p3.2.m2.1.1.3">𝑎</ci><ci id="A1.p3.2.m2.1.1.4.cmml" xref="A1.p3.2.m2.1.1.4">𝑡</ci><ci id="A1.p3.2.m2.1.1.5.cmml" xref="A1.p3.2.m2.1.1.5">𝑐</ci><ci id="A1.p3.2.m2.1.1.6.cmml" xref="A1.p3.2.m2.1.1.6">ℎ</ci><ci id="A1.p3.2.m2.1.1.7.cmml" xref="A1.p3.2.m2.1.1.7">𝑆</ci><ci id="A1.p3.2.m2.1.1.8.cmml" xref="A1.p3.2.m2.1.1.8">𝑖</ci><ci id="A1.p3.2.m2.1.1.9.cmml" xref="A1.p3.2.m2.1.1.9">𝑧</ci><ci id="A1.p3.2.m2.1.1.10.cmml" xref="A1.p3.2.m2.1.1.10">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.2.m2.1c">BatchSize</annotation><annotation encoding="application/x-llamapun" id="A1.p3.2.m2.1d">italic_B italic_a italic_t italic_c italic_h italic_S italic_i italic_z italic_e</annotation></semantics></math><span class="ltx_text" id="A1.p3.4.3" style="font-size:90%;"> refers to the number of training examples processed simultaneously by each GPU. Lastly, </span><math alttext="WorldSize" class="ltx_Math" display="inline" id="A1.p3.3.m3.1"><semantics id="A1.p3.3.m3.1a"><mrow id="A1.p3.3.m3.1.1" xref="A1.p3.3.m3.1.1.cmml"><mi id="A1.p3.3.m3.1.1.2" mathsize="90%" xref="A1.p3.3.m3.1.1.2.cmml">W</mi><mo id="A1.p3.3.m3.1.1.1" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.3" mathsize="90%" xref="A1.p3.3.m3.1.1.3.cmml">o</mi><mo id="A1.p3.3.m3.1.1.1a" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.4" mathsize="90%" xref="A1.p3.3.m3.1.1.4.cmml">r</mi><mo id="A1.p3.3.m3.1.1.1b" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.5" mathsize="90%" xref="A1.p3.3.m3.1.1.5.cmml">l</mi><mo id="A1.p3.3.m3.1.1.1c" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.6" mathsize="90%" xref="A1.p3.3.m3.1.1.6.cmml">d</mi><mo id="A1.p3.3.m3.1.1.1d" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.7" mathsize="90%" xref="A1.p3.3.m3.1.1.7.cmml">S</mi><mo id="A1.p3.3.m3.1.1.1e" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.8" mathsize="90%" xref="A1.p3.3.m3.1.1.8.cmml">i</mi><mo id="A1.p3.3.m3.1.1.1f" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.9" mathsize="90%" xref="A1.p3.3.m3.1.1.9.cmml">z</mi><mo id="A1.p3.3.m3.1.1.1g" xref="A1.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A1.p3.3.m3.1.1.10" mathsize="90%" xref="A1.p3.3.m3.1.1.10.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.p3.3.m3.1b"><apply id="A1.p3.3.m3.1.1.cmml" xref="A1.p3.3.m3.1.1"><times id="A1.p3.3.m3.1.1.1.cmml" xref="A1.p3.3.m3.1.1.1"></times><ci id="A1.p3.3.m3.1.1.2.cmml" xref="A1.p3.3.m3.1.1.2">𝑊</ci><ci id="A1.p3.3.m3.1.1.3.cmml" xref="A1.p3.3.m3.1.1.3">𝑜</ci><ci id="A1.p3.3.m3.1.1.4.cmml" xref="A1.p3.3.m3.1.1.4">𝑟</ci><ci id="A1.p3.3.m3.1.1.5.cmml" xref="A1.p3.3.m3.1.1.5">𝑙</ci><ci id="A1.p3.3.m3.1.1.6.cmml" xref="A1.p3.3.m3.1.1.6">𝑑</ci><ci id="A1.p3.3.m3.1.1.7.cmml" xref="A1.p3.3.m3.1.1.7">𝑆</ci><ci id="A1.p3.3.m3.1.1.8.cmml" xref="A1.p3.3.m3.1.1.8">𝑖</ci><ci id="A1.p3.3.m3.1.1.9.cmml" xref="A1.p3.3.m3.1.1.9">𝑧</ci><ci id="A1.p3.3.m3.1.1.10.cmml" xref="A1.p3.3.m3.1.1.10">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.3.m3.1c">WorldSize</annotation><annotation encoding="application/x-llamapun" id="A1.p3.3.m3.1d">italic_W italic_o italic_r italic_l italic_d italic_S italic_i italic_z italic_e</annotation></semantics></math><span class="ltx_text" id="A1.p3.4.4" style="font-size:90%;"> denotes the total count of GPUs employed for parallel computation. The coefficient </span><math alttext="512" class="ltx_Math" display="inline" id="A1.p3.4.m4.1"><semantics id="A1.p3.4.m4.1a"><mn id="A1.p3.4.m4.1.1" mathsize="90%" xref="A1.p3.4.m4.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A1.p3.4.m4.1b"><cn id="A1.p3.4.m4.1.1.cmml" type="integer" xref="A1.p3.4.m4.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.4.m4.1c">512</annotation><annotation encoding="application/x-llamapun" id="A1.p3.4.m4.1d">512</annotation></semantics></math><span class="ltx_text" id="A1.p3.4.5" style="font-size:90%;"> in the denominator is a normalization factor, ensuring the scaled learning rate maintains an appropriate magnitude relative to the hardware configuration. We used the PyTorch Library </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.p3.4.6.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Paszke et al.</span><span class="ltx_text" id="A1.p3.4.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="A1.p3.4.8.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.p3.4.9" style="font-size:90%;"> for our code development.</span></p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Pre-Train Stage</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1"><span class="ltx_text" id="A1.SS1.p1.1.1" style="font-size:90%;">Our pre-training procedures largely align with those outlined in the BEiT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS1.p1.1.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="A1.SS1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A1.SS1.p1.1.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS1.p1.1.5" style="font-size:90%;"> study, albeit with a few modifications. Specifically, our pre-training regime for the models incorporates simple yet effective data augmentation techniques, including random resized cropping to a resolution of </span><math alttext="224\times 224" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mrow id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml"><mn id="A1.SS1.p1.1.m1.1.1.2" mathsize="90%" xref="A1.SS1.p1.1.m1.1.1.2.cmml">224</mn><mo id="A1.SS1.p1.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="A1.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="A1.SS1.p1.1.m1.1.1.3" mathsize="90%" xref="A1.SS1.p1.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><apply id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1"><times id="A1.SS1.p1.1.m1.1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1.1"></times><cn id="A1.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="A1.SS1.p1.1.m1.1.1.2">224</cn><cn id="A1.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="A1.SS1.p1.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">224\times 224</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">224 × 224</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p1.1.6" style="font-size:90%;"> pixels and image flipping.</span></p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.12"><span class="ltx_text" id="A1.SS1.p2.12.1" style="font-size:90%;">We employ the AdamW optimizer </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS1.p2.12.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Loshchilov and Hutter</span><span class="ltx_text" id="A1.SS1.p2.12.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="A1.SS1.p2.12.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS1.p2.12.5" style="font-size:90%;">, with a pre-training duration set to </span><math alttext="300" class="ltx_Math" display="inline" id="A1.SS1.p2.1.m1.1"><semantics id="A1.SS1.p2.1.m1.1a"><mn id="A1.SS1.p2.1.m1.1.1" mathsize="90%" xref="A1.SS1.p2.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.1.m1.1b"><cn id="A1.SS1.p2.1.m1.1.1.cmml" type="integer" xref="A1.SS1.p2.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.1.m1.1c">300</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.1.m1.1d">300</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.6" style="font-size:90%;"> or </span><math alttext="800" class="ltx_Math" display="inline" id="A1.SS1.p2.2.m2.1"><semantics id="A1.SS1.p2.2.m2.1a"><mn id="A1.SS1.p2.2.m2.1.1" mathsize="90%" xref="A1.SS1.p2.2.m2.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.2.m2.1b"><cn id="A1.SS1.p2.2.m2.1.1.cmml" type="integer" xref="A1.SS1.p2.2.m2.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.2.m2.1c">800</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.2.m2.1d">800</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.7" style="font-size:90%;"> epochs, a batch size of </span><math alttext="2048" class="ltx_Math" display="inline" id="A1.SS1.p2.3.m3.1"><semantics id="A1.SS1.p2.3.m3.1a"><mn id="A1.SS1.p2.3.m3.1.1" mathsize="90%" xref="A1.SS1.p2.3.m3.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.3.m3.1b"><cn id="A1.SS1.p2.3.m3.1.1.cmml" type="integer" xref="A1.SS1.p2.3.m3.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.3.m3.1c">2048</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.3.m3.1d">2048</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.8" style="font-size:90%;">, </span><math alttext="128" class="ltx_Math" display="inline" id="A1.SS1.p2.4.m4.1"><semantics id="A1.SS1.p2.4.m4.1a"><mn id="A1.SS1.p2.4.m4.1.1" mathsize="90%" xref="A1.SS1.p2.4.m4.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.4.m4.1b"><cn id="A1.SS1.p2.4.m4.1.1.cmml" type="integer" xref="A1.SS1.p2.4.m4.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.4.m4.1c">128</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.4.m4.1d">128</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.9" style="font-size:90%;"> per GPU, and a peak learning rate of </span><math alttext="1.2\times 10^{-3}" class="ltx_Math" display="inline" id="A1.SS1.p2.5.m5.1"><semantics id="A1.SS1.p2.5.m5.1a"><mrow id="A1.SS1.p2.5.m5.1.1" xref="A1.SS1.p2.5.m5.1.1.cmml"><mn id="A1.SS1.p2.5.m5.1.1.2" mathsize="90%" xref="A1.SS1.p2.5.m5.1.1.2.cmml">1.2</mn><mo id="A1.SS1.p2.5.m5.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="A1.SS1.p2.5.m5.1.1.1.cmml">×</mo><msup id="A1.SS1.p2.5.m5.1.1.3" xref="A1.SS1.p2.5.m5.1.1.3.cmml"><mn id="A1.SS1.p2.5.m5.1.1.3.2" mathsize="90%" xref="A1.SS1.p2.5.m5.1.1.3.2.cmml">10</mn><mrow id="A1.SS1.p2.5.m5.1.1.3.3" xref="A1.SS1.p2.5.m5.1.1.3.3.cmml"><mo id="A1.SS1.p2.5.m5.1.1.3.3a" mathsize="90%" xref="A1.SS1.p2.5.m5.1.1.3.3.cmml">−</mo><mn id="A1.SS1.p2.5.m5.1.1.3.3.2" mathsize="90%" xref="A1.SS1.p2.5.m5.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.5.m5.1b"><apply id="A1.SS1.p2.5.m5.1.1.cmml" xref="A1.SS1.p2.5.m5.1.1"><times id="A1.SS1.p2.5.m5.1.1.1.cmml" xref="A1.SS1.p2.5.m5.1.1.1"></times><cn id="A1.SS1.p2.5.m5.1.1.2.cmml" type="float" xref="A1.SS1.p2.5.m5.1.1.2">1.2</cn><apply id="A1.SS1.p2.5.m5.1.1.3.cmml" xref="A1.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.p2.5.m5.1.1.3.1.cmml" xref="A1.SS1.p2.5.m5.1.1.3">superscript</csymbol><cn id="A1.SS1.p2.5.m5.1.1.3.2.cmml" type="integer" xref="A1.SS1.p2.5.m5.1.1.3.2">10</cn><apply id="A1.SS1.p2.5.m5.1.1.3.3.cmml" xref="A1.SS1.p2.5.m5.1.1.3.3"><minus id="A1.SS1.p2.5.m5.1.1.3.3.1.cmml" xref="A1.SS1.p2.5.m5.1.1.3.3"></minus><cn id="A1.SS1.p2.5.m5.1.1.3.3.2.cmml" type="integer" xref="A1.SS1.p2.5.m5.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.5.m5.1c">1.2\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.5.m5.1d">1.2 × 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.10" style="font-size:90%;">. Additional parameters include a cosine decay learning rate schedule, </span><math alttext="20" class="ltx_Math" display="inline" id="A1.SS1.p2.6.m6.1"><semantics id="A1.SS1.p2.6.m6.1a"><mn id="A1.SS1.p2.6.m6.1.1" mathsize="90%" xref="A1.SS1.p2.6.m6.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.6.m6.1b"><cn id="A1.SS1.p2.6.m6.1.1.cmml" type="integer" xref="A1.SS1.p2.6.m6.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.6.m6.1c">20</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.6.m6.1d">20</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.11" style="font-size:90%;"> warmup epochs, and a specific setting for optimizer momentum (</span><math alttext="\beta_{1}" class="ltx_Math" display="inline" id="A1.SS1.p2.7.m7.1"><semantics id="A1.SS1.p2.7.m7.1a"><msub id="A1.SS1.p2.7.m7.1.1" xref="A1.SS1.p2.7.m7.1.1.cmml"><mi id="A1.SS1.p2.7.m7.1.1.2" mathsize="90%" xref="A1.SS1.p2.7.m7.1.1.2.cmml">β</mi><mn id="A1.SS1.p2.7.m7.1.1.3" mathsize="90%" xref="A1.SS1.p2.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.7.m7.1b"><apply id="A1.SS1.p2.7.m7.1.1.cmml" xref="A1.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="A1.SS1.p2.7.m7.1.1.1.cmml" xref="A1.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="A1.SS1.p2.7.m7.1.1.2.cmml" xref="A1.SS1.p2.7.m7.1.1.2">𝛽</ci><cn id="A1.SS1.p2.7.m7.1.1.3.cmml" type="integer" xref="A1.SS1.p2.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.7.m7.1c">\beta_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.7.m7.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.12" style="font-size:90%;">, </span><math alttext="\beta_{2}" class="ltx_Math" display="inline" id="A1.SS1.p2.8.m8.1"><semantics id="A1.SS1.p2.8.m8.1a"><msub id="A1.SS1.p2.8.m8.1.1" xref="A1.SS1.p2.8.m8.1.1.cmml"><mi id="A1.SS1.p2.8.m8.1.1.2" mathsize="90%" xref="A1.SS1.p2.8.m8.1.1.2.cmml">β</mi><mn id="A1.SS1.p2.8.m8.1.1.3" mathsize="90%" xref="A1.SS1.p2.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.8.m8.1b"><apply id="A1.SS1.p2.8.m8.1.1.cmml" xref="A1.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="A1.SS1.p2.8.m8.1.1.1.cmml" xref="A1.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="A1.SS1.p2.8.m8.1.1.2.cmml" xref="A1.SS1.p2.8.m8.1.1.2">𝛽</ci><cn id="A1.SS1.p2.8.m8.1.1.3.cmml" type="integer" xref="A1.SS1.p2.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.8.m8.1c">\beta_{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.8.m8.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.13" style="font-size:90%;"> = </span><math alttext="0.9" class="ltx_Math" display="inline" id="A1.SS1.p2.9.m9.1"><semantics id="A1.SS1.p2.9.m9.1a"><mn id="A1.SS1.p2.9.m9.1.1" mathsize="90%" xref="A1.SS1.p2.9.m9.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.9.m9.1b"><cn id="A1.SS1.p2.9.m9.1.1.cmml" type="float" xref="A1.SS1.p2.9.m9.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.9.m9.1c">0.9</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.9.m9.1d">0.9</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.14" style="font-size:90%;">, </span><math alttext="0.95" class="ltx_Math" display="inline" id="A1.SS1.p2.10.m10.1"><semantics id="A1.SS1.p2.10.m10.1a"><mn id="A1.SS1.p2.10.m10.1.1" mathsize="90%" xref="A1.SS1.p2.10.m10.1.1.cmml">0.95</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.10.m10.1b"><cn id="A1.SS1.p2.10.m10.1.1.cmml" type="float" xref="A1.SS1.p2.10.m10.1.1">0.95</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.10.m10.1c">0.95</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.10.m10.1d">0.95</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.15" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS1.p2.12.16.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="A1.SS1.p2.12.17.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">2020a</span></a><span class="ltx_text" id="A1.SS1.p2.12.18.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS1.p2.12.19" style="font-size:90%;"> with a weight decay of </span><math alttext="0.05" class="ltx_Math" display="inline" id="A1.SS1.p2.11.m11.1"><semantics id="A1.SS1.p2.11.m11.1a"><mn id="A1.SS1.p2.11.m11.1.1" mathsize="90%" xref="A1.SS1.p2.11.m11.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.11.m11.1b"><cn id="A1.SS1.p2.11.m11.1.1.cmml" type="float" xref="A1.SS1.p2.11.m11.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.11.m11.1c">0.05</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.11.m11.1d">0.05</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.20" style="font-size:90%;">. Also, we used a value of </span><math alttext="3.0" class="ltx_Math" display="inline" id="A1.SS1.p2.12.m12.1"><semantics id="A1.SS1.p2.12.m12.1a"><mn id="A1.SS1.p2.12.m12.1.1" mathsize="90%" xref="A1.SS1.p2.12.m12.1.1.cmml">3.0</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.12.m12.1b"><cn id="A1.SS1.p2.12.m12.1.1.cmml" type="float" xref="A1.SS1.p2.12.m12.1.1">3.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.12.m12.1c">3.0</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.12.m12.1d">3.0</annotation></semantics></math><span class="ltx_text" id="A1.SS1.p2.12.21" style="font-size:90%;"> for gradient clipping to prevent the exploding gradient problem.</span></p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Fine-Tune Stage</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1"><span class="ltx_text" id="A1.SS2.p1.1.1" style="font-size:90%;">For the fine-tuning stage, we tried to keep most of the configuration of our FOLK the same as MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.p1.1.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A1.SS2.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A1.SS2.p1.1.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.p1.1.5" style="font-size:90%;"> for a fair comparison.</span></p>
</div>
<section class="ltx_subsubsection" id="A1.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">A.2.1 </span>Classification Task</h4>
<div class="ltx_para" id="A1.SS2.SSS1.p1">
<p class="ltx_p" id="A1.SS2.SSS1.p1.10"><span class="ltx_text" id="A1.SS2.SSS1.p1.10.1" style="font-size:90%;">We ran </span><math alttext="200" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.1.m1.1"><semantics id="A1.SS2.SSS1.p1.1.m1.1a"><mn id="A1.SS2.SSS1.p1.1.m1.1.1" mathsize="90%" xref="A1.SS2.SSS1.p1.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.1.m1.1b"><cn id="A1.SS2.SSS1.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS2.SSS1.p1.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.1.m1.1c">200</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.1.m1.1d">200</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.2" style="font-size:90%;"> epochs for fine-tuning the pre-trained model (i.e. ViT-S/16) on ImageNet-1K for image classification, employing the </span><math alttext="AdamW" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.2.m2.1"><semantics id="A1.SS2.SSS1.p1.2.m2.1a"><mrow id="A1.SS2.SSS1.p1.2.m2.1.1" xref="A1.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="A1.SS2.SSS1.p1.2.m2.1.1.2" mathsize="90%" xref="A1.SS2.SSS1.p1.2.m2.1.1.2.cmml">A</mi><mo id="A1.SS2.SSS1.p1.2.m2.1.1.1" xref="A1.SS2.SSS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS1.p1.2.m2.1.1.3" mathsize="90%" xref="A1.SS2.SSS1.p1.2.m2.1.1.3.cmml">d</mi><mo id="A1.SS2.SSS1.p1.2.m2.1.1.1a" xref="A1.SS2.SSS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS1.p1.2.m2.1.1.4" mathsize="90%" xref="A1.SS2.SSS1.p1.2.m2.1.1.4.cmml">a</mi><mo id="A1.SS2.SSS1.p1.2.m2.1.1.1b" xref="A1.SS2.SSS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS1.p1.2.m2.1.1.5" mathsize="90%" xref="A1.SS2.SSS1.p1.2.m2.1.1.5.cmml">m</mi><mo id="A1.SS2.SSS1.p1.2.m2.1.1.1c" xref="A1.SS2.SSS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS1.p1.2.m2.1.1.6" mathsize="90%" xref="A1.SS2.SSS1.p1.2.m2.1.1.6.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.2.m2.1b"><apply id="A1.SS2.SSS1.p1.2.m2.1.1.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1"><times id="A1.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1.1"></times><ci id="A1.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1.2">𝐴</ci><ci id="A1.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1.3">𝑑</ci><ci id="A1.SS2.SSS1.p1.2.m2.1.1.4.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1.4">𝑎</ci><ci id="A1.SS2.SSS1.p1.2.m2.1.1.5.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1.5">𝑚</ci><ci id="A1.SS2.SSS1.p1.2.m2.1.1.6.cmml" xref="A1.SS2.SSS1.p1.2.m2.1.1.6">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.2.m2.1c">AdamW</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.2.m2.1d">italic_A italic_d italic_a italic_m italic_W</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.3" style="font-size:90%;"> optimizer across all configurations with a weight decay of </span><math alttext="0.05" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.3.m3.1"><semantics id="A1.SS2.SSS1.p1.3.m3.1a"><mn id="A1.SS2.SSS1.p1.3.m3.1.1" mathsize="90%" xref="A1.SS2.SSS1.p1.3.m3.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.3.m3.1b"><cn id="A1.SS2.SSS1.p1.3.m3.1.1.cmml" type="float" xref="A1.SS2.SSS1.p1.3.m3.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.3.m3.1c">0.05</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.3.m3.1d">0.05</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.4" style="font-size:90%;"> and the optimizer momentum </span><math alttext="\beta_{1}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.4.m4.1"><semantics id="A1.SS2.SSS1.p1.4.m4.1a"><msub id="A1.SS2.SSS1.p1.4.m4.1.1" xref="A1.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="A1.SS2.SSS1.p1.4.m4.1.1.2" mathsize="90%" xref="A1.SS2.SSS1.p1.4.m4.1.1.2.cmml">β</mi><mn id="A1.SS2.SSS1.p1.4.m4.1.1.3" mathsize="90%" xref="A1.SS2.SSS1.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.4.m4.1b"><apply id="A1.SS2.SSS1.p1.4.m4.1.1.cmml" xref="A1.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="A1.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="A1.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="A1.SS2.SSS1.p1.4.m4.1.1.2">𝛽</ci><cn id="A1.SS2.SSS1.p1.4.m4.1.1.3.cmml" type="integer" xref="A1.SS2.SSS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.4.m4.1c">\beta_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.4.m4.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.5" style="font-size:90%;">, </span><math alttext="\beta_{2}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.5.m5.1"><semantics id="A1.SS2.SSS1.p1.5.m5.1a"><msub id="A1.SS2.SSS1.p1.5.m5.1.1" xref="A1.SS2.SSS1.p1.5.m5.1.1.cmml"><mi id="A1.SS2.SSS1.p1.5.m5.1.1.2" mathsize="90%" xref="A1.SS2.SSS1.p1.5.m5.1.1.2.cmml">β</mi><mn id="A1.SS2.SSS1.p1.5.m5.1.1.3" mathsize="90%" xref="A1.SS2.SSS1.p1.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.5.m5.1b"><apply id="A1.SS2.SSS1.p1.5.m5.1.1.cmml" xref="A1.SS2.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="A1.SS2.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="A1.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="A1.SS2.SSS1.p1.5.m5.1.1.2">𝛽</ci><cn id="A1.SS2.SSS1.p1.5.m5.1.1.3.cmml" type="integer" xref="A1.SS2.SSS1.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.5.m5.1c">\beta_{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.5.m5.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.6" style="font-size:90%;"> = </span><math alttext="0.9" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.6.m6.1"><semantics id="A1.SS2.SSS1.p1.6.m6.1a"><mn id="A1.SS2.SSS1.p1.6.m6.1.1" mathsize="90%" xref="A1.SS2.SSS1.p1.6.m6.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.6.m6.1b"><cn id="A1.SS2.SSS1.p1.6.m6.1.1.cmml" type="float" xref="A1.SS2.SSS1.p1.6.m6.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.6.m6.1c">0.9</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.6.m6.1d">0.9</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.7" style="font-size:90%;">, </span><math alttext="0.999" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.7.m7.1"><semantics id="A1.SS2.SSS1.p1.7.m7.1a"><mn id="A1.SS2.SSS1.p1.7.m7.1.1" mathsize="90%" xref="A1.SS2.SSS1.p1.7.m7.1.1.cmml">0.999</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.7.m7.1b"><cn id="A1.SS2.SSS1.p1.7.m7.1.1.cmml" type="float" xref="A1.SS2.SSS1.p1.7.m7.1.1">0.999</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.7.m7.1c">0.999</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.7.m7.1d">0.999</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.8" style="font-size:90%;">. Moreover, the approach includes a cosine decay learning rate schedule </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p1.10.9.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Li and Arora</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.10.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="A1.SS2.SSS1.p1.10.11.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p1.10.12" style="font-size:90%;">, with a layer-wise learning rate decay equal to </span><math alttext="0.8" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.8.m8.1"><semantics id="A1.SS2.SSS1.p1.8.m8.1a"><mn id="A1.SS2.SSS1.p1.8.m8.1.1" mathsize="90%" xref="A1.SS2.SSS1.p1.8.m8.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.8.m8.1b"><cn id="A1.SS2.SSS1.p1.8.m8.1.1.cmml" type="float" xref="A1.SS2.SSS1.p1.8.m8.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.8.m8.1c">0.8</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.8.m8.1d">0.8</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.13" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p1.10.14.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Bao et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a>, <span class="ltx_text" style="font-size:90%;">Clark et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="A1.SS2.SSS1.p1.10.16.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p1.10.17" style="font-size:90%;">. We also utilized advanced augmentation techniques such as Mixup </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p1.10.18.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhang et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.19.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib66" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a><span class="ltx_text" id="A1.SS2.SSS1.p1.10.20.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p1.10.21" style="font-size:90%;"> and Cutmix </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p1.10.22.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Yun et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.23.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib65" title=""><span class="ltx_text" style="font-size:90%;">2019</span></a><span class="ltx_text" id="A1.SS2.SSS1.p1.10.24.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p1.10.25" style="font-size:90%;">, as well as label smoothing and random augmentation to further improve model robustness and generalization capability </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p1.10.26.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Szegedy et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.27.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib53" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a>, <span class="ltx_text" style="font-size:90%;">Cubuk et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p1.10.27.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="A1.SS2.SSS1.p1.10.28.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p1.10.29" style="font-size:90%;">. The batch size is maintained at </span><math alttext="2048" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.9.m9.1"><semantics id="A1.SS2.SSS1.p1.9.m9.1a"><mn id="A1.SS2.SSS1.p1.9.m9.1.1" mathsize="90%" xref="A1.SS2.SSS1.p1.9.m9.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.9.m9.1b"><cn id="A1.SS2.SSS1.p1.9.m9.1.1.cmml" type="integer" xref="A1.SS2.SSS1.p1.9.m9.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.9.m9.1c">2048</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.9.m9.1d">2048</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.30" style="font-size:90%;">, with a peak learning rate set at </span><math alttext="8\times 10^{-3}" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p1.10.m10.1"><semantics id="A1.SS2.SSS1.p1.10.m10.1a"><mrow id="A1.SS2.SSS1.p1.10.m10.1.1" xref="A1.SS2.SSS1.p1.10.m10.1.1.cmml"><mn id="A1.SS2.SSS1.p1.10.m10.1.1.2" mathsize="90%" xref="A1.SS2.SSS1.p1.10.m10.1.1.2.cmml">8</mn><mo id="A1.SS2.SSS1.p1.10.m10.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="A1.SS2.SSS1.p1.10.m10.1.1.1.cmml">×</mo><msup id="A1.SS2.SSS1.p1.10.m10.1.1.3" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.cmml"><mn id="A1.SS2.SSS1.p1.10.m10.1.1.3.2" mathsize="90%" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.2.cmml">10</mn><mrow id="A1.SS2.SSS1.p1.10.m10.1.1.3.3" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.3.cmml"><mo id="A1.SS2.SSS1.p1.10.m10.1.1.3.3a" mathsize="90%" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.3.cmml">−</mo><mn id="A1.SS2.SSS1.p1.10.m10.1.1.3.3.2" mathsize="90%" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p1.10.m10.1b"><apply id="A1.SS2.SSS1.p1.10.m10.1.1.cmml" xref="A1.SS2.SSS1.p1.10.m10.1.1"><times id="A1.SS2.SSS1.p1.10.m10.1.1.1.cmml" xref="A1.SS2.SSS1.p1.10.m10.1.1.1"></times><cn id="A1.SS2.SSS1.p1.10.m10.1.1.2.cmml" type="integer" xref="A1.SS2.SSS1.p1.10.m10.1.1.2">8</cn><apply id="A1.SS2.SSS1.p1.10.m10.1.1.3.cmml" xref="A1.SS2.SSS1.p1.10.m10.1.1.3"><csymbol cd="ambiguous" id="A1.SS2.SSS1.p1.10.m10.1.1.3.1.cmml" xref="A1.SS2.SSS1.p1.10.m10.1.1.3">superscript</csymbol><cn id="A1.SS2.SSS1.p1.10.m10.1.1.3.2.cmml" type="integer" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.2">10</cn><apply id="A1.SS2.SSS1.p1.10.m10.1.1.3.3.cmml" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.3"><minus id="A1.SS2.SSS1.p1.10.m10.1.1.3.3.1.cmml" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.3"></minus><cn id="A1.SS2.SSS1.p1.10.m10.1.1.3.3.2.cmml" type="integer" xref="A1.SS2.SSS1.p1.10.m10.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p1.10.m10.1c">8\times 10^{-3}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p1.10.m10.1d">8 × 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p1.10.31" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="A1.SS2.SSS1.p2">
<p class="ltx_p" id="A1.SS2.SSS1.p2.3"><span class="ltx_text" id="A1.SS2.SSS1.p2.3.1" style="font-size:90%;">In contrast, the fine-tuning settings for the ResNet-50 model </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p2.3.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p2.3.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a><span class="ltx_text" id="A1.SS2.SSS1.p2.3.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p2.3.5" style="font-size:90%;"> generally follow the configurations suggested by </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p2.3.6.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Wightman et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p2.3.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib60" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="A1.SS2.SSS1.p2.3.8.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p2.3.9" style="font-size:90%;">, with modifications to adopt the AdamW optimizer as recommended by </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p2.3.10.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Fang et al.</span><span class="ltx_text" id="A1.SS2.SSS1.p2.3.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A1.SS2.SSS1.p2.3.12.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p2.3.13" style="font-size:90%;">. This includes a binary cross-entropy loss function </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS1.p2.3.14.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhang and Sabuncu</span><span class="ltx_text" id="A1.SS2.SSS1.p2.3.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib68" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a><span class="ltx_text" id="A1.SS2.SSS1.p2.3.16.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS1.p2.3.17" style="font-size:90%;"> and adjustments to the learning rate scheduler. The weight decay is set to </span><math alttext="0.02" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p2.1.m1.1"><semantics id="A1.SS2.SSS1.p2.1.m1.1a"><mn id="A1.SS2.SSS1.p2.1.m1.1.1" mathsize="90%" xref="A1.SS2.SSS1.p2.1.m1.1.1.cmml">0.02</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p2.1.m1.1b"><cn id="A1.SS2.SSS1.p2.1.m1.1.1.cmml" type="float" xref="A1.SS2.SSS1.p2.1.m1.1.1">0.02</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p2.1.m1.1c">0.02</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p2.1.m1.1d">0.02</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p2.3.18" style="font-size:90%;">, and the batch size is set to </span><math alttext="2048" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p2.2.m2.1"><semantics id="A1.SS2.SSS1.p2.2.m2.1a"><mn id="A1.SS2.SSS1.p2.2.m2.1.1" mathsize="90%" xref="A1.SS2.SSS1.p2.2.m2.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p2.2.m2.1b"><cn id="A1.SS2.SSS1.p2.2.m2.1.1.cmml" type="integer" xref="A1.SS2.SSS1.p2.2.m2.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p2.2.m2.1c">2048</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p2.2.m2.1d">2048</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p2.3.19" style="font-size:90%;"> to optimize performance. For ResNet-50, the fine-tuning epochs are specifically set to </span><math alttext="300" class="ltx_Math" display="inline" id="A1.SS2.SSS1.p2.3.m3.1"><semantics id="A1.SS2.SSS1.p2.3.m3.1a"><mn id="A1.SS2.SSS1.p2.3.m3.1.1" mathsize="90%" xref="A1.SS2.SSS1.p2.3.m3.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS1.p2.3.m3.1b"><cn id="A1.SS2.SSS1.p2.3.m3.1.1.cmml" type="integer" xref="A1.SS2.SSS1.p2.3.m3.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS1.p2.3.m3.1c">300</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS1.p2.3.m3.1d">300</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS1.p2.3.20" style="font-size:90%;">, with distinct configurations for repeated and random augmentation, indicating a tailored approach to maximize the model’s efficacy on the ImageNet-1K challenge.</span></p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">A.2.2 </span>Semantic Segmentation Task</h4>
<div class="ltx_para" id="A1.SS2.SSS2.p1">
<p class="ltx_p" id="A1.SS2.SSS2.p1.2"><span class="ltx_text" id="A1.SS2.SSS2.p1.2.1" style="font-size:90%;">We followed the pipeline demonstrated by the iBot </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS2.p1.2.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="A1.SS2.SSS2.p1.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A1.SS2.SSS2.p1.2.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS2.p1.2.5" style="font-size:90%;"> paper for fine-tuning the pre-trained model for semantic segmentation using the </span><math alttext="ADE20K" class="ltx_Math" display="inline" id="A1.SS2.SSS2.p1.1.m1.1"><semantics id="A1.SS2.SSS2.p1.1.m1.1a"><mrow id="A1.SS2.SSS2.p1.1.m1.1.1" xref="A1.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="A1.SS2.SSS2.p1.1.m1.1.1.2" mathsize="90%" xref="A1.SS2.SSS2.p1.1.m1.1.1.2.cmml">A</mi><mo id="A1.SS2.SSS2.p1.1.m1.1.1.1" xref="A1.SS2.SSS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS2.p1.1.m1.1.1.3" mathsize="90%" xref="A1.SS2.SSS2.p1.1.m1.1.1.3.cmml">D</mi><mo id="A1.SS2.SSS2.p1.1.m1.1.1.1a" xref="A1.SS2.SSS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS2.p1.1.m1.1.1.4" mathsize="90%" xref="A1.SS2.SSS2.p1.1.m1.1.1.4.cmml">E</mi><mo id="A1.SS2.SSS2.p1.1.m1.1.1.1b" xref="A1.SS2.SSS2.p1.1.m1.1.1.1.cmml">⁢</mo><mn id="A1.SS2.SSS2.p1.1.m1.1.1.5" mathsize="90%" xref="A1.SS2.SSS2.p1.1.m1.1.1.5.cmml">20</mn><mo id="A1.SS2.SSS2.p1.1.m1.1.1.1c" xref="A1.SS2.SSS2.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS2.p1.1.m1.1.1.6" mathsize="90%" xref="A1.SS2.SSS2.p1.1.m1.1.1.6.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS2.p1.1.m1.1b"><apply id="A1.SS2.SSS2.p1.1.m1.1.1.cmml" xref="A1.SS2.SSS2.p1.1.m1.1.1"><times id="A1.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="A1.SS2.SSS2.p1.1.m1.1.1.1"></times><ci id="A1.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="A1.SS2.SSS2.p1.1.m1.1.1.2">𝐴</ci><ci id="A1.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="A1.SS2.SSS2.p1.1.m1.1.1.3">𝐷</ci><ci id="A1.SS2.SSS2.p1.1.m1.1.1.4.cmml" xref="A1.SS2.SSS2.p1.1.m1.1.1.4">𝐸</ci><cn id="A1.SS2.SSS2.p1.1.m1.1.1.5.cmml" type="integer" xref="A1.SS2.SSS2.p1.1.m1.1.1.5">20</cn><ci id="A1.SS2.SSS2.p1.1.m1.1.1.6.cmml" xref="A1.SS2.SSS2.p1.1.m1.1.1.6">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS2.p1.1.m1.1c">ADE20K</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS2.p1.1.m1.1d">italic_A italic_D italic_E 20 italic_K</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS2.p1.2.6" style="font-size:90%;"> dataset </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS2.p1.2.7.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="A1.SS2.SSS2.p1.2.8.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib70" title=""><span class="ltx_text" style="font-size:90%;">2017</span></a><span class="ltx_text" id="A1.SS2.SSS2.p1.2.9.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS2.p1.2.10" style="font-size:90%;">. More specifically, we combined a pre-trained ViT-S/16 encoder with a UPerNet decoder </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS2.SSS2.p1.2.11.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xiao et al.</span><span class="ltx_text" id="A1.SS2.SSS2.p1.2.12.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib61" title=""><span class="ltx_text" style="font-size:90%;">2018</span></a><span class="ltx_text" id="A1.SS2.SSS2.p1.2.13.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS2.SSS2.p1.2.14" style="font-size:90%;">. The ViT-S/16 encoder extracts detailed features from images, while the UPerNet decoder specializes in semantic segmentation, translating these features into precise pixel-level classifications. This process employed the AdamW optimizer and fine-tuned for </span><math alttext="160K" class="ltx_Math" display="inline" id="A1.SS2.SSS2.p1.2.m2.1"><semantics id="A1.SS2.SSS2.p1.2.m2.1a"><mrow id="A1.SS2.SSS2.p1.2.m2.1.1" xref="A1.SS2.SSS2.p1.2.m2.1.1.cmml"><mn id="A1.SS2.SSS2.p1.2.m2.1.1.2" mathsize="90%" xref="A1.SS2.SSS2.p1.2.m2.1.1.2.cmml">160</mn><mo id="A1.SS2.SSS2.p1.2.m2.1.1.1" xref="A1.SS2.SSS2.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A1.SS2.SSS2.p1.2.m2.1.1.3" mathsize="90%" xref="A1.SS2.SSS2.p1.2.m2.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS2.p1.2.m2.1b"><apply id="A1.SS2.SSS2.p1.2.m2.1.1.cmml" xref="A1.SS2.SSS2.p1.2.m2.1.1"><times id="A1.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="A1.SS2.SSS2.p1.2.m2.1.1.1"></times><cn id="A1.SS2.SSS2.p1.2.m2.1.1.2.cmml" type="integer" xref="A1.SS2.SSS2.p1.2.m2.1.1.2">160</cn><ci id="A1.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="A1.SS2.SSS2.p1.2.m2.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS2.p1.2.m2.1c">160K</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS2.p1.2.m2.1d">160 italic_K</annotation></semantics></math><span class="ltx_text" id="A1.SS2.SSS2.p1.2.15" style="font-size:90%;"> iterations.</span></p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Projection Head</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.3"><span class="ltx_text" id="A1.SS3.p1.3.1" style="font-size:90%;">FOLK has three projection headers: one for frequency reconstruction (MFM Head, </span><math alttext="\hat{h}_{\theta}" class="ltx_Math" display="inline" id="A1.SS3.p1.1.m1.1"><semantics id="A1.SS3.p1.1.m1.1a"><msub id="A1.SS3.p1.1.m1.1.1" xref="A1.SS3.p1.1.m1.1.1.cmml"><mover accent="true" id="A1.SS3.p1.1.m1.1.1.2" xref="A1.SS3.p1.1.m1.1.1.2.cmml"><mi id="A1.SS3.p1.1.m1.1.1.2.2" mathsize="90%" xref="A1.SS3.p1.1.m1.1.1.2.2.cmml">h</mi><mo id="A1.SS3.p1.1.m1.1.1.2.1" mathsize="90%" xref="A1.SS3.p1.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="A1.SS3.p1.1.m1.1.1.3" mathsize="90%" xref="A1.SS3.p1.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.1b"><apply id="A1.SS3.p1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.1.m1.1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1">subscript</csymbol><apply id="A1.SS3.p1.1.m1.1.1.2.cmml" xref="A1.SS3.p1.1.m1.1.1.2"><ci id="A1.SS3.p1.1.m1.1.1.2.1.cmml" xref="A1.SS3.p1.1.m1.1.1.2.1">^</ci><ci id="A1.SS3.p1.1.m1.1.1.2.2.cmml" xref="A1.SS3.p1.1.m1.1.1.2.2">ℎ</ci></apply><ci id="A1.SS3.p1.1.m1.1.1.3.cmml" xref="A1.SS3.p1.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.1c">\hat{h}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p1.1.m1.1d">over^ start_ARG italic_h end_ARG start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS3.p1.3.2" style="font-size:90%;">) and two for the student (</span><math alttext="h_{\theta}" class="ltx_Math" display="inline" id="A1.SS3.p1.2.m2.1"><semantics id="A1.SS3.p1.2.m2.1a"><msub id="A1.SS3.p1.2.m2.1.1" xref="A1.SS3.p1.2.m2.1.1.cmml"><mi id="A1.SS3.p1.2.m2.1.1.2" mathsize="90%" xref="A1.SS3.p1.2.m2.1.1.2.cmml">h</mi><mi id="A1.SS3.p1.2.m2.1.1.3" mathsize="90%" xref="A1.SS3.p1.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.m2.1b"><apply id="A1.SS3.p1.2.m2.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.2.m2.1.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="A1.SS3.p1.2.m2.1.1.2.cmml" xref="A1.SS3.p1.2.m2.1.1.2">ℎ</ci><ci id="A1.SS3.p1.2.m2.1.1.3.cmml" xref="A1.SS3.p1.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.m2.1c">h_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p1.2.m2.1d">italic_h start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS3.p1.3.3" style="font-size:90%;">) and teacher (</span><math alttext="h_{\phi}" class="ltx_Math" display="inline" id="A1.SS3.p1.3.m3.1"><semantics id="A1.SS3.p1.3.m3.1a"><msub id="A1.SS3.p1.3.m3.1.1" xref="A1.SS3.p1.3.m3.1.1.cmml"><mi id="A1.SS3.p1.3.m3.1.1.2" mathsize="90%" xref="A1.SS3.p1.3.m3.1.1.2.cmml">h</mi><mi id="A1.SS3.p1.3.m3.1.1.3" mathsize="90%" xref="A1.SS3.p1.3.m3.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.3.m3.1b"><apply id="A1.SS3.p1.3.m3.1.1.cmml" xref="A1.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS3.p1.3.m3.1.1.1.cmml" xref="A1.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="A1.SS3.p1.3.m3.1.1.2.cmml" xref="A1.SS3.p1.3.m3.1.1.2">ℎ</ci><ci id="A1.SS3.p1.3.m3.1.1.3.cmml" xref="A1.SS3.p1.3.m3.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.3.m3.1c">h_{\phi}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p1.3.m3.1d">italic_h start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="A1.SS3.p1.3.4" style="font-size:90%;">) header, see Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.2.2 Making Backbone Familiar with Natural Images ‣ 3.2 FOLK Framework ‣ 3 Method ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="A1.SS3.p1.3.5" style="font-size:90%;">. We used a single linear layer for the frequency reconstruction head, similar to that in the MFM method </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS3.p1.3.6.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A1.SS3.p1.3.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A1.SS3.p1.3.8.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS3.p1.3.9" style="font-size:90%;">. However, when it came to the distillation heads (student and teacher heads), we opted for a more sophisticated architecture akin to the DINO </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS3.p1.3.10.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="A1.SS3.p1.3.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="A1.SS3.p1.3.12.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS3.p1.3.13" style="font-size:90%;"> head, albeit slightly modified. In FOLK, each head (student or teacher) comprised a 3-layer multi-layer perceptron (MLP) with a hidden dimensionality of 2048. All layers were followed by a GELU activation except the final layer. We refrained from applying batch normalization (BN), as ViT architectures, unlike standard CNNs, typically eschew BN by default. Rather than adhering to the 65536 output dimension in DINO, we followed the iBOT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A1.SS3.p1.3.14.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="A1.SS3.p1.3.15.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A1.SS3.p1.3.16.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A1.SS3.p1.3.17" style="font-size:90%;"> approach, adopting a dimensionality of 8192.</span></p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2" lang="en">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Extra Experiments</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Image Classification - CNN Base Modal</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1"><span class="ltx_text" id="A2.SS1.p1.1.1" style="font-size:90%;">One limitation of many research studies, such as iBOT </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.SS1.p1.1.2.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Zhou et al.</span><span class="ltx_text" id="A2.SS1.p1.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib72" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A2.SS1.p1.1.4.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A2.SS1.p1.1.5" style="font-size:90%;"> and AttMask </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.SS1.p1.1.6.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Kakogeorgiou et al.</span><span class="ltx_text" id="A2.SS1.p1.1.7.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A2.SS1.p1.1.8.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A2.SS1.p1.1.9" style="font-size:90%;">, is that they are only compatible with a specific type of model architecture (e.g. ViTs), but not with others (e.g. CNNs). Our approach, like MFM </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.SS1.p1.1.10.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A2.SS1.p1.1.11.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A2.SS1.p1.1.12.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A2.SS1.p1.1.13" style="font-size:90%;">, does not have this limitation and works with a wide range of encoder models.</span></p>
</div>
<div class="ltx_para" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1"><span class="ltx_text" id="A2.SS1.p2.1.1" style="font-size:90%;">Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.T5" style="font-size:90%;" title="Table 5 ‣ B.1 Image Classification - CNN Base Modal ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_text" id="A2.SS1.p2.1.2" style="font-size:90%;"> presents the ResNet-50 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.SS1.p2.1.3.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">He et al.</span><span class="ltx_text" id="A2.SS1.p2.1.4.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">2016</span></a><span class="ltx_text" id="A2.SS1.p2.1.5.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A2.SS1.p2.1.6" style="font-size:90%;"> (a CNN-based model) performance under the FOLK framework. The same FOLK pre-training strategies that have been applied to ViTs were seamlessly adopted here for CNNs. The only necessary modification to adopt CNNs is to alter the inputs to the heads: replacing patch tokens from ViTs with reshaped feature maps from CNNs, and replacing the </span><math alttext="[CLS]" class="ltx_Math" display="inline" id="A2.SS1.p2.1.m1.1"><semantics id="A2.SS1.p2.1.m1.1a"><mrow id="A2.SS1.p2.1.m1.1.1.1" xref="A2.SS1.p2.1.m1.1.1.2.cmml"><mo id="A2.SS1.p2.1.m1.1.1.1.2" maxsize="90%" minsize="90%" xref="A2.SS1.p2.1.m1.1.1.2.1.cmml">[</mo><mrow id="A2.SS1.p2.1.m1.1.1.1.1" xref="A2.SS1.p2.1.m1.1.1.1.1.cmml"><mi id="A2.SS1.p2.1.m1.1.1.1.1.2" mathsize="90%" xref="A2.SS1.p2.1.m1.1.1.1.1.2.cmml">C</mi><mo id="A2.SS1.p2.1.m1.1.1.1.1.1" xref="A2.SS1.p2.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="A2.SS1.p2.1.m1.1.1.1.1.3" mathsize="90%" xref="A2.SS1.p2.1.m1.1.1.1.1.3.cmml">L</mi><mo id="A2.SS1.p2.1.m1.1.1.1.1.1a" xref="A2.SS1.p2.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="A2.SS1.p2.1.m1.1.1.1.1.4" mathsize="90%" xref="A2.SS1.p2.1.m1.1.1.1.1.4.cmml">S</mi></mrow><mo id="A2.SS1.p2.1.m1.1.1.1.3" maxsize="90%" minsize="90%" xref="A2.SS1.p2.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.p2.1.m1.1b"><apply id="A2.SS1.p2.1.m1.1.1.2.cmml" xref="A2.SS1.p2.1.m1.1.1.1"><csymbol cd="latexml" id="A2.SS1.p2.1.m1.1.1.2.1.cmml" xref="A2.SS1.p2.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="A2.SS1.p2.1.m1.1.1.1.1.cmml" xref="A2.SS1.p2.1.m1.1.1.1.1"><times id="A2.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="A2.SS1.p2.1.m1.1.1.1.1.1"></times><ci id="A2.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="A2.SS1.p2.1.m1.1.1.1.1.2">𝐶</ci><ci id="A2.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="A2.SS1.p2.1.m1.1.1.1.1.3">𝐿</ci><ci id="A2.SS1.p2.1.m1.1.1.1.1.4.cmml" xref="A2.SS1.p2.1.m1.1.1.1.1.4">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p2.1.m1.1c">[CLS]</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p2.1.m1.1d">[ italic_C italic_L italic_S ]</annotation></semantics></math><span class="ltx_text" id="A2.SS1.p2.1.7" style="font-size:90%;"> token from ViTs with the average-pooled (and reshaped) feature map from CNNs. Our approach has demonstrated equal or superior performance to other methods with fewer epochs.</span></p>
</div>
<figure class="ltx_table" id="A2.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T5.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T5.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="A2.T5.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T5.2.1.1.1.1" style="font-size:90%;">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.2.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T5.2.1.1.2.1" style="font-size:90%;">Ref</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.2.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T5.2.1.1.3.1" style="font-size:90%;">Epoch</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T5.2.1.1.4"><span class="ltx_text ltx_font_bold" id="A2.T5.2.1.1.4.1" style="font-size:90%;">Top-1 Acc</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T5.2.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T5.2.2.1.1"><span class="ltx_text" id="A2.T5.2.2.1.1.1" style="font-size:90%;">SimSiam</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.2.2.1.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.2.1.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Chen and He</span><span class="ltx_text" id="A2.T5.2.2.1.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">2021</span></a><span class="ltx_text" id="A2.T5.2.2.1.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.2.2.1.3"><span class="ltx_text" id="A2.T5.2.2.1.3.1" style="font-size:90%;">400</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T5.2.2.1.4"><span class="ltx_text" id="A2.T5.2.2.1.4.1" style="font-size:90%;">79.1</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T5.2.3.2.1"><span class="ltx_text" id="A2.T5.2.3.2.1.1" style="font-size:90%;">MoCo v2</span></th>
<td class="ltx_td ltx_align_center" id="A2.T5.2.3.2.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.3.2.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="A2.T5.2.3.2.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">2020d</span></a><span class="ltx_text" id="A2.T5.2.3.2.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.3.2.3"><span class="ltx_text" id="A2.T5.2.3.2.3.1" style="font-size:90%;">400</span></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.3.2.4"><span class="ltx_text" id="A2.T5.2.3.2.4.1" style="font-size:90%;">79.6</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T5.2.4.3.1"><span class="ltx_text" id="A2.T5.2.4.3.1.1" style="font-size:90%;">SimCLR</span></th>
<td class="ltx_td ltx_align_center" id="A2.T5.2.4.3.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.4.3.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Chen et al.</span><span class="ltx_text" id="A2.T5.2.4.3.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">2020b</span></a><span class="ltx_text" id="A2.T5.2.4.3.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.4.3.3"><span class="ltx_text" id="A2.T5.2.4.3.3.1" style="font-size:90%;">800</span></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.4.3.4"><span class="ltx_text" id="A2.T5.2.4.3.4.1" style="font-size:90%;">79.9</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T5.2.5.4.1"><span class="ltx_text" id="A2.T5.2.5.4.1.1" style="font-size:90%;">BYOL</span></th>
<td class="ltx_td ltx_align_center" id="A2.T5.2.5.4.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.5.4.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Grill et al.</span><span class="ltx_text" id="A2.T5.2.5.4.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="A2.T5.2.5.4.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.5.4.3"><span class="ltx_text" id="A2.T5.2.5.4.3.1" style="font-size:90%;">400</span></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.5.4.4">
<span class="ltx_ERROR undefined" id="A2.T5.2.5.4.4.1">\ul</span><span class="ltx_text" id="A2.T5.2.5.4.4.2" style="font-size:90%;">80.0</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T5.2.6.5.1"><span class="ltx_text" id="A2.T5.2.6.5.1.1" style="font-size:90%;">SwAV</span></th>
<td class="ltx_td ltx_align_center" id="A2.T5.2.6.5.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.6.5.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Caron et al.</span><span class="ltx_text" id="A2.T5.2.6.5.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">2020</span></a><span class="ltx_text" id="A2.T5.2.6.5.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.6.5.3"><span class="ltx_text" id="A2.T5.2.6.5.3.1" style="font-size:90%;">600</span></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.6.5.4"><span class="ltx_text ltx_font_bold" id="A2.T5.2.6.5.4.1" style="font-size:90%;">80.1</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T5.2.7.6.1"><span class="ltx_text" id="A2.T5.2.7.6.1.1" style="font-size:90%;">MFM</span></th>
<td class="ltx_td ltx_align_center" id="A2.T5.2.7.6.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.7.6.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A2.T5.2.7.6.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A2.T5.2.7.6.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.7.6.3"><span class="ltx_text" id="A2.T5.2.7.6.3.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.7.6.4"><span class="ltx_text ltx_font_bold" id="A2.T5.2.7.6.4.1" style="font-size:90%;">80.1</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.8.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T5.2.8.7.1"><span class="ltx_text" id="A2.T5.2.8.7.1.1" style="font-size:90%;">MFM + Com/RCom</span></th>
<td class="ltx_td ltx_align_center" id="A2.T5.2.8.7.2"><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.T5.2.8.7.2.1.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A2.T5.2.8.7.2.2.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a><span class="ltx_text" id="A2.T5.2.8.7.2.3.3" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.8.7.3"><span class="ltx_text" id="A2.T5.2.8.7.3.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center" id="A2.T5.2.8.7.4"><span class="ltx_text ltx_font_bold" id="A2.T5.2.8.7.4.1" style="font-size:90%;">80.1</span></td>
</tr>
<tr class="ltx_tr" id="A2.T5.2.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A2.T5.2.9.8.1"><span class="ltx_text ltx_font_bold" id="A2.T5.2.9.8.1.1" style="font-size:90%;">FOLK</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T5.2.9.8.2"><span class="ltx_text" id="A2.T5.2.9.8.2.1" style="font-size:90%;">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T5.2.9.8.3"><span class="ltx_text" id="A2.T5.2.9.8.3.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T5.2.9.8.4"><span class="ltx_text ltx_font_bold" id="A2.T5.2.9.8.4.1" style="font-size:90%;">80.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>The top-1 full fine-tuning accuracy on ImageNet-1K for self-supervised models that utilize ResNet-50 as the encoder. This information compares our methods against others, with the results of these comparative methods being sourced from <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_text" style="font-size:90%;">Xie et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib62" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_text" style="font-size:90%;">Fang et al.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">2023</span></a>]</cite>. The highest model performance is highlighted in bold, with the second highest being underscored.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Few Shot Learning</h3>
<div class="ltx_para" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.2"><span class="ltx_text" id="A2.SS2.p1.2.1" style="font-size:90%;">In addition to the primary few-shot learning results discussed in Section </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.SS2.SSS2" style="font-size:90%;" title="4.2.2 Few Shot Learning ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4.2.2</span></a><span class="ltx_text" id="A2.SS2.p1.2.2" style="font-size:90%;">, Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.T6" style="font-size:90%;" title="Table 6 ‣ B.2 Few Shot Learning ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="A2.SS2.p1.2.3" style="font-size:90%;"> presents an extensive evaluation of few-shot learning performance. Various pre-trained models were fine-tuned using only </span><math alttext="1\%" class="ltx_Math" display="inline" id="A2.SS2.p1.1.m1.1"><semantics id="A2.SS2.p1.1.m1.1a"><mrow id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml"><mn id="A2.SS2.p1.1.m1.1.1.2" mathsize="90%" xref="A2.SS2.p1.1.m1.1.1.2.cmml">1</mn><mo id="A2.SS2.p1.1.m1.1.1.1" mathsize="90%" xref="A2.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.1b"><apply id="A2.SS2.p1.1.m1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="A2.SS2.p1.1.m1.1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1.1">percent</csymbol><cn id="A2.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="A2.SS2.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.1.m1.1d">1 %</annotation></semantics></math><span class="ltx_text" id="A2.SS2.p1.2.4" style="font-size:90%;"> of the ImageNet-1K dataset over </span><math alttext="1000" class="ltx_Math" display="inline" id="A2.SS2.p1.2.m2.1"><semantics id="A2.SS2.p1.2.m2.1a"><mn id="A2.SS2.p1.2.m2.1.1" mathsize="90%" xref="A2.SS2.p1.2.m2.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.2.m2.1b"><cn id="A2.SS2.p1.2.m2.1.1.cmml" type="integer" xref="A2.SS2.p1.2.m2.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.2.m2.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.2.m2.1d">1000</annotation></semantics></math><span class="ltx_text" id="A2.SS2.p1.2.5" style="font-size:90%;"> epochs. This setup facilitates a detailed comparison of each model’s ability to adapt to new data with minimal examples, highlighting a crucial aspect of model robustness and versatility. Furthermore, the evaluation considers three different settings for the base learning rate (LR) and warm-up periods, which are crucial hyperparameters in training deep learning models, especially under few-shot scenarios. The different configurations aim to assess each model’s robustness across varying learning rate adaptation conditions.</span></p>
</div>
<figure class="ltx_table" id="A2.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T6.6">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T6.6.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A2.T6.6.1.1.1.1" style="font-size:90%;">Method</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T6.6.1.1.2.1" style="font-size:90%;">Base LR = 2e-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T6.6.1.1.3.1" style="font-size:90%;">Base LR = 2e-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.1.1.4"><span class="ltx_text ltx_font_bold" id="A2.T6.6.1.1.4.1" style="font-size:90%;">Base LR = 2e-3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.6.1.1.5" rowspan="2"><span class="ltx_text ltx_font_bold" id="A2.T6.6.1.1.5.1" style="font-size:90%;">AVG</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.6.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.2.2.1"><span class="ltx_text ltx_font_bold" id="A2.T6.6.2.2.1.1" style="font-size:90%;">Warm Up = 0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.2.2.2"><span class="ltx_text ltx_font_bold" id="A2.T6.6.2.2.2.1" style="font-size:90%;">Warm Up = 100</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.2.2.3"><span class="ltx_text ltx_font_bold" id="A2.T6.6.2.2.3.1" style="font-size:90%;">Warm Up = 5</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.6.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.3.3.1"><span class="ltx_text" id="A2.T6.6.3.3.1.1" style="font-size:90%;">iBOT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.3.3.2"><span class="ltx_text" id="A2.T6.6.3.3.2.1" style="font-size:90%;">33.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.3.3.3">
<span class="ltx_ERROR undefined" id="A2.T6.6.3.3.3.1">\ul</span><span class="ltx_text" id="A2.T6.6.3.3.3.2" style="font-size:90%;">59.0</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.6.3.3.4"><span class="ltx_text" id="A2.T6.6.3.3.4.1" style="font-size:90%;">1.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.6.3.3.5"><span class="ltx_text" id="A2.T6.6.3.3.5.1" style="font-size:90%;">31.2</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.6.4.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.4.4.1"><span class="ltx_text" id="A2.T6.6.4.4.1.1" style="font-size:90%;">AttMask</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.4.4.2">
<span class="ltx_ERROR undefined" id="A2.T6.6.4.4.2.1">\ul</span><span class="ltx_text" id="A2.T6.6.4.4.2.2" style="font-size:90%;">50.4</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.4.4.3"><span class="ltx_text ltx_font_bold" id="A2.T6.6.4.4.3.1" style="font-size:90%;">59.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.4.4.4"><span class="ltx_text" id="A2.T6.6.4.4.4.1" style="font-size:90%;">3.2</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.6.4.4.5">
<span class="ltx_ERROR undefined" id="A2.T6.6.4.4.5.1">\ul</span><span class="ltx_text" id="A2.T6.6.4.4.5.2" style="font-size:90%;">37.6</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T6.6.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.5.5.1"><span class="ltx_text" id="A2.T6.6.5.5.1.1" style="font-size:90%;">MFM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.5.5.2"><span class="ltx_text" id="A2.T6.6.5.5.2.1" style="font-size:90%;">26.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.5.5.3"><span class="ltx_text" id="A2.T6.6.5.5.3.1" style="font-size:90%;">31.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.5.5.4"><span class="ltx_text" id="A2.T6.6.5.5.4.1" style="font-size:90%;">6.3</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.6.5.5.5"><span class="ltx_text" id="A2.T6.6.5.5.5.1" style="font-size:90%;">21.6</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.6.6.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.6.6.1"><span class="ltx_text" id="A2.T6.6.6.6.1.1" style="font-size:90%;">MFM + Com/RCom</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.6.6.2"><span class="ltx_text" id="A2.T6.6.6.6.2.1" style="font-size:90%;">42.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.6.6.3"><span class="ltx_text" id="A2.T6.6.6.6.3.1" style="font-size:90%;">44.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.6.6.6.4">
<span class="ltx_ERROR undefined" id="A2.T6.6.6.6.4.1">\ul</span><span class="ltx_text" id="A2.T6.6.6.6.4.2" style="font-size:90%;">10.7</span>
</td>
<td class="ltx_td ltx_align_center" id="A2.T6.6.6.6.5"><span class="ltx_text" id="A2.T6.6.6.6.5.1" style="font-size:90%;">32.6</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.6.7.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A2.T6.6.7.7.1"><span class="ltx_text ltx_font_bold" id="A2.T6.6.7.7.1.1" style="font-size:90%;">FOLK</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A2.T6.6.7.7.2"><span class="ltx_text ltx_font_bold" id="A2.T6.6.7.7.2.1" style="font-size:90%;">51.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A2.T6.6.7.7.3"><span class="ltx_text" id="A2.T6.6.7.7.3.1" style="font-size:90%;">56.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A2.T6.6.7.7.4"><span class="ltx_text ltx_font_bold" id="A2.T6.6.7.7.4.1" style="font-size:90%;">20.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T6.6.7.7.5"><span class="ltx_text ltx_font_bold" id="A2.T6.6.7.7.5.1" style="font-size:90%;">42.8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Results of few-shot learning by fine-tuning pre-trained models for <math alttext="1000" class="ltx_Math" display="inline" id="A2.T6.3.m1.1"><semantics id="A2.T6.3.m1.1b"><mn id="A2.T6.3.m1.1.1" xref="A2.T6.3.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A2.T6.3.m1.1c"><cn id="A2.T6.3.m1.1.1.cmml" type="integer" xref="A2.T6.3.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.3.m1.1d">1000</annotation><annotation encoding="application/x-llamapun" id="A2.T6.3.m1.1e">1000</annotation></semantics></math> epochs on <math alttext="1\%" class="ltx_Math" display="inline" id="A2.T6.4.m2.1"><semantics id="A2.T6.4.m2.1b"><mrow id="A2.T6.4.m2.1.1" xref="A2.T6.4.m2.1.1.cmml"><mn id="A2.T6.4.m2.1.1.2" xref="A2.T6.4.m2.1.1.2.cmml">1</mn><mo id="A2.T6.4.m2.1.1.1" xref="A2.T6.4.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T6.4.m2.1c"><apply id="A2.T6.4.m2.1.1.cmml" xref="A2.T6.4.m2.1.1"><csymbol cd="latexml" id="A2.T6.4.m2.1.1.1.cmml" xref="A2.T6.4.m2.1.1.1">percent</csymbol><cn id="A2.T6.4.m2.1.1.2.cmml" type="integer" xref="A2.T6.4.m2.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.4.m2.1d">1\%</annotation><annotation encoding="application/x-llamapun" id="A2.T6.4.m2.1e">1 %</annotation></semantics></math> of labeled ImageNet-1k. All models were sourced directly from their respective original repositories.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS2.p2">
<p class="ltx_p" id="A2.SS2.p2.1"><span class="ltx_text" id="A2.SS2.p2.1.1" style="font-size:90%;">The performance data presented in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.T6" style="font-size:90%;" title="Table 6 ‣ B.2 Few Shot Learning ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">6</span></a><span class="ltx_text" id="A2.SS2.p2.1.2" style="font-size:90%;"> underscores the robustness of the FOLK method across various learning rates and warm-up settings, evidenced by its superior average performance of </span><math alttext="42.8\%" class="ltx_Math" display="inline" id="A2.SS2.p2.1.m1.1"><semantics id="A2.SS2.p2.1.m1.1a"><mrow id="A2.SS2.p2.1.m1.1.1" xref="A2.SS2.p2.1.m1.1.1.cmml"><mn id="A2.SS2.p2.1.m1.1.1.2" mathsize="90%" xref="A2.SS2.p2.1.m1.1.1.2.cmml">42.8</mn><mo id="A2.SS2.p2.1.m1.1.1.1" mathsize="90%" xref="A2.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.1.m1.1b"><apply id="A2.SS2.p2.1.m1.1.1.cmml" xref="A2.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="A2.SS2.p2.1.m1.1.1.1.cmml" xref="A2.SS2.p2.1.m1.1.1.1">percent</csymbol><cn id="A2.SS2.p2.1.m1.1.1.2.cmml" type="float" xref="A2.SS2.p2.1.m1.1.1.2">42.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.1.m1.1c">42.8\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p2.1.m1.1d">42.8 %</annotation></semantics></math><span class="ltx_text" id="A2.SS2.p2.1.3" style="font-size:90%;">. This consistency indicates FOLK’s inherent stability and adaptability in few-shot learning scenarios, distinguishing it from other models. Unlike iBOT and MFM, which exhibit fluctuating accuracies with changes in learning rates and warm-up periods, FOLK maintains a high level of performance. This suggests that FOLK is less sensitive to hyperparameter adjustments, thus requiring less fine-tuning to achieve good results. This characteristic is particularly significant in practical applications where extensive parameter tuning is inapplicable. By effectively integrating dual inputs—filtered and original images—FOLK enhances feature extraction and generalization capabilities, resulting in more reliable performance across various settings. This robustness, combined with a reduced dependency on precise parameter tuning, positions FOLK as an attractive option for tasks demanding high accuracy with minimal labeled data and limited pre-processing.</span></p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Ablation Study - Different Filters</h3>
<div class="ltx_para" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.4"><span class="ltx_text" id="A2.SS3.p1.4.1" style="font-size:90%;">Another part of our ablation study demonstrates the advantages of selective masking over random masking when applied to the frequency spectrum during model pre-training. The </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p1.1.m1.1"><semantics id="A2.SS3.p1.1.m1.1a"><mrow id="A2.SS3.p1.1.m1.1.1" xref="A2.SS3.p1.1.m1.1.1.cmml"><mi id="A2.SS3.p1.1.m1.1.1.2" mathsize="90%" xref="A2.SS3.p1.1.m1.1.1.2.cmml">C</mi><mo id="A2.SS3.p1.1.m1.1.1.1" xref="A2.SS3.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.1.m1.1.1.3" mathsize="90%" xref="A2.SS3.p1.1.m1.1.1.3.cmml">o</mi><mo id="A2.SS3.p1.1.m1.1.1.1a" xref="A2.SS3.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.1.m1.1.1.4" mathsize="90%" xref="A2.SS3.p1.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.1.m1.1b"><apply id="A2.SS3.p1.1.m1.1.1.cmml" xref="A2.SS3.p1.1.m1.1.1"><times id="A2.SS3.p1.1.m1.1.1.1.cmml" xref="A2.SS3.p1.1.m1.1.1.1"></times><ci id="A2.SS3.p1.1.m1.1.1.2.cmml" xref="A2.SS3.p1.1.m1.1.1.2">𝐶</ci><ci id="A2.SS3.p1.1.m1.1.1.3.cmml" xref="A2.SS3.p1.1.m1.1.1.3">𝑜</ci><ci id="A2.SS3.p1.1.m1.1.1.4.cmml" xref="A2.SS3.p1.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p1.4.2" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p1.2.m2.1"><semantics id="A2.SS3.p1.2.m2.1a"><mrow id="A2.SS3.p1.2.m2.1.1" xref="A2.SS3.p1.2.m2.1.1.cmml"><mi id="A2.SS3.p1.2.m2.1.1.2" mathsize="90%" xref="A2.SS3.p1.2.m2.1.1.2.cmml">R</mi><mo id="A2.SS3.p1.2.m2.1.1.1" xref="A2.SS3.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.2.m2.1.1.3" mathsize="90%" xref="A2.SS3.p1.2.m2.1.1.3.cmml">C</mi><mo id="A2.SS3.p1.2.m2.1.1.1a" xref="A2.SS3.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.2.m2.1.1.4" mathsize="90%" xref="A2.SS3.p1.2.m2.1.1.4.cmml">o</mi><mo id="A2.SS3.p1.2.m2.1.1.1b" xref="A2.SS3.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.2.m2.1.1.5" mathsize="90%" xref="A2.SS3.p1.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.2.m2.1b"><apply id="A2.SS3.p1.2.m2.1.1.cmml" xref="A2.SS3.p1.2.m2.1.1"><times id="A2.SS3.p1.2.m2.1.1.1.cmml" xref="A2.SS3.p1.2.m2.1.1.1"></times><ci id="A2.SS3.p1.2.m2.1.1.2.cmml" xref="A2.SS3.p1.2.m2.1.1.2">𝑅</ci><ci id="A2.SS3.p1.2.m2.1.1.3.cmml" xref="A2.SS3.p1.2.m2.1.1.3">𝐶</ci><ci id="A2.SS3.p1.2.m2.1.1.4.cmml" xref="A2.SS3.p1.2.m2.1.1.4">𝑜</ci><ci id="A2.SS3.p1.2.m2.1.1.5.cmml" xref="A2.SS3.p1.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p1.4.3" style="font-size:90%;"> filters play a crucial role in optimizing self-supervised learning by leveraging the principles of image compression. The </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p1.3.m3.1"><semantics id="A2.SS3.p1.3.m3.1a"><mrow id="A2.SS3.p1.3.m3.1.1" xref="A2.SS3.p1.3.m3.1.1.cmml"><mi id="A2.SS3.p1.3.m3.1.1.2" mathsize="90%" xref="A2.SS3.p1.3.m3.1.1.2.cmml">C</mi><mo id="A2.SS3.p1.3.m3.1.1.1" xref="A2.SS3.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.3.m3.1.1.3" mathsize="90%" xref="A2.SS3.p1.3.m3.1.1.3.cmml">o</mi><mo id="A2.SS3.p1.3.m3.1.1.1a" xref="A2.SS3.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.3.m3.1.1.4" mathsize="90%" xref="A2.SS3.p1.3.m3.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.3.m3.1b"><apply id="A2.SS3.p1.3.m3.1.1.cmml" xref="A2.SS3.p1.3.m3.1.1"><times id="A2.SS3.p1.3.m3.1.1.1.cmml" xref="A2.SS3.p1.3.m3.1.1.1"></times><ci id="A2.SS3.p1.3.m3.1.1.2.cmml" xref="A2.SS3.p1.3.m3.1.1.2">𝐶</ci><ci id="A2.SS3.p1.3.m3.1.1.3.cmml" xref="A2.SS3.p1.3.m3.1.1.3">𝑜</ci><ci id="A2.SS3.p1.3.m3.1.1.4.cmml" xref="A2.SS3.p1.3.m3.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.3.m3.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.3.m3.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p1.4.4" style="font-size:90%;"> filter focuses on major visual elements by preserving significant frequencies, thus compressing the image and emphasizing crucial features. Conversely, the </span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p1.4.m4.1"><semantics id="A2.SS3.p1.4.m4.1a"><mrow id="A2.SS3.p1.4.m4.1.1" xref="A2.SS3.p1.4.m4.1.1.cmml"><mi id="A2.SS3.p1.4.m4.1.1.2" mathsize="90%" xref="A2.SS3.p1.4.m4.1.1.2.cmml">R</mi><mo id="A2.SS3.p1.4.m4.1.1.1" xref="A2.SS3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.4.m4.1.1.3" mathsize="90%" xref="A2.SS3.p1.4.m4.1.1.3.cmml">C</mi><mo id="A2.SS3.p1.4.m4.1.1.1a" xref="A2.SS3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.4.m4.1.1.4" mathsize="90%" xref="A2.SS3.p1.4.m4.1.1.4.cmml">o</mi><mo id="A2.SS3.p1.4.m4.1.1.1b" xref="A2.SS3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p1.4.m4.1.1.5" mathsize="90%" xref="A2.SS3.p1.4.m4.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.4.m4.1b"><apply id="A2.SS3.p1.4.m4.1.1.cmml" xref="A2.SS3.p1.4.m4.1.1"><times id="A2.SS3.p1.4.m4.1.1.1.cmml" xref="A2.SS3.p1.4.m4.1.1.1"></times><ci id="A2.SS3.p1.4.m4.1.1.2.cmml" xref="A2.SS3.p1.4.m4.1.1.2">𝑅</ci><ci id="A2.SS3.p1.4.m4.1.1.3.cmml" xref="A2.SS3.p1.4.m4.1.1.3">𝐶</ci><ci id="A2.SS3.p1.4.m4.1.1.4.cmml" xref="A2.SS3.p1.4.m4.1.1.4">𝑜</ci><ci id="A2.SS3.p1.4.m4.1.1.5.cmml" xref="A2.SS3.p1.4.m4.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.4.m4.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.4.m4.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p1.4.5" style="font-size:90%;"> filter retains less dominant frequencies to highlight finer details and textures, enhancing the model’s sensitivity to subtle visual cues. This approach ensures that models are trained on both comprehensive and detailed representations, fostering adaptability and improved performance across diverse applications.</span></p>
</div>
<div class="ltx_para" id="A2.SS3.p2">
<p class="ltx_p" id="A2.SS3.p2.1"><span class="ltx_text" id="A2.SS3.p2.1.1" style="font-size:90%;">Additionally, our masking approach generates unique masks according to each image’s frequency responses, thereby accounting for each image’s distinctive features and semantics (see examples in the Tables </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T9" style="font-size:90%;" title="Table 9 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">9</span></a><span class="ltx_text" id="A2.SS3.p2.1.2" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T10" style="font-size:90%;" title="Table 10 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">10</span></a><span class="ltx_text" id="A2.SS3.p2.1.3" style="font-size:90%;"> and </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T11" style="font-size:90%;" title="Table 11 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text" id="A2.SS3.p2.1.4" style="font-size:90%;">). This contrasts sharply with random masking. By targeting essential frequencies, selective masking ensures that the model adapts to recognize and prioritize these key signals, resulting in more robust and effective pre-training. Our findings indicate that this method significantly enhances the model’s generalization capabilities and overall accuracy, confirming the efficacy of selective masking in the frequency domain for developing advanced predictive models.</span></p>
</div>
<figure class="ltx_figure" id="A2.F4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.F4.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.F4.10.11.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.F4.10.11.1.1"><span class="ltx_text" id="A2.F4.10.11.1.1.1" style="font-size:90%;">Original</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.F4.10.11.1.2"><span class="ltx_text ltx_font_bold" id="A2.F4.10.11.1.2.1" style="font-size:90%;">Com</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.F4.10.11.1.3"><span class="ltx_text" id="A2.F4.10.11.1.3.1" style="font-size:90%;">Gabor</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.F4.10.11.1.4"><span class="ltx_text" id="A2.F4.10.11.1.4.1" style="font-size:90%;">Token Mask</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.F4.10.11.1.5"><span class="ltx_text" id="A2.F4.10.11.1.5.1" style="font-size:90%;">Circle Mask</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.F4.5.5">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.F4.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.1.1.1.g1" src="extracted/5858280/images_folder/ablation/image_512_7.jpg" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.F4.2.2.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.2.2.2.g1" src="extracted/5858280/images_folder/ablation/image_com.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.F4.3.3.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.3.3.3.g1" src="extracted/5858280/images_folder/ablation/image_gabor_7.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.F4.4.4.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.4.4.4.g1" src="extracted/5858280/images_folder/ablation/image_tok_mask.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.F4.5.5.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.5.5.5.g1" src="extracted/5858280/images_folder/ablation/image_cicle_mask.png" width="85"/></td>
</tr>
<tr class="ltx_tr" id="A2.F4.10.10">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A2.F4.6.6.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.6.6.1.g1" src="extracted/5858280/images_folder/ablation/magnitude_7.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.F4.7.7.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.7.7.2.g1" src="extracted/5858280/images_folder/ablation/mag_com_mask.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.F4.8.8.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.8.8.3.g1" src="extracted/5858280/images_folder/ablation/mag_gabor_7.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.F4.9.9.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.9.9.4.g1" src="extracted/5858280/images_folder/ablation/mag_tok_mask.png" width="85"/></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.F4.10.10.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="85" id="A2.F4.10.10.5.g1" src="extracted/5858280/images_folder/ablation/mag_cicle_mask.png" width="85"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Visual comparison between <math alttext="Com" class="ltx_Math" display="inline" id="A2.F4.13.m1.1"><semantics id="A2.F4.13.m1.1b"><mrow id="A2.F4.13.m1.1.1" xref="A2.F4.13.m1.1.1.cmml"><mi id="A2.F4.13.m1.1.1.2" xref="A2.F4.13.m1.1.1.2.cmml">C</mi><mo id="A2.F4.13.m1.1.1.1" xref="A2.F4.13.m1.1.1.1.cmml">⁢</mo><mi id="A2.F4.13.m1.1.1.3" xref="A2.F4.13.m1.1.1.3.cmml">o</mi><mo id="A2.F4.13.m1.1.1.1b" xref="A2.F4.13.m1.1.1.1.cmml">⁢</mo><mi id="A2.F4.13.m1.1.1.4" xref="A2.F4.13.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.F4.13.m1.1c"><apply id="A2.F4.13.m1.1.1.cmml" xref="A2.F4.13.m1.1.1"><times id="A2.F4.13.m1.1.1.1.cmml" xref="A2.F4.13.m1.1.1.1"></times><ci id="A2.F4.13.m1.1.1.2.cmml" xref="A2.F4.13.m1.1.1.2">𝐶</ci><ci id="A2.F4.13.m1.1.1.3.cmml" xref="A2.F4.13.m1.1.1.3">𝑜</ci><ci id="A2.F4.13.m1.1.1.4.cmml" xref="A2.F4.13.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F4.13.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="A2.F4.13.m1.1e">italic_C italic_o italic_m</annotation></semantics></math>/<math alttext="RCom" class="ltx_Math" display="inline" id="A2.F4.14.m2.1"><semantics id="A2.F4.14.m2.1b"><mrow id="A2.F4.14.m2.1.1" xref="A2.F4.14.m2.1.1.cmml"><mi id="A2.F4.14.m2.1.1.2" xref="A2.F4.14.m2.1.1.2.cmml">R</mi><mo id="A2.F4.14.m2.1.1.1" xref="A2.F4.14.m2.1.1.1.cmml">⁢</mo><mi id="A2.F4.14.m2.1.1.3" xref="A2.F4.14.m2.1.1.3.cmml">C</mi><mo id="A2.F4.14.m2.1.1.1b" xref="A2.F4.14.m2.1.1.1.cmml">⁢</mo><mi id="A2.F4.14.m2.1.1.4" xref="A2.F4.14.m2.1.1.4.cmml">o</mi><mo id="A2.F4.14.m2.1.1.1c" xref="A2.F4.14.m2.1.1.1.cmml">⁢</mo><mi id="A2.F4.14.m2.1.1.5" xref="A2.F4.14.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.F4.14.m2.1c"><apply id="A2.F4.14.m2.1.1.cmml" xref="A2.F4.14.m2.1.1"><times id="A2.F4.14.m2.1.1.1.cmml" xref="A2.F4.14.m2.1.1.1"></times><ci id="A2.F4.14.m2.1.1.2.cmml" xref="A2.F4.14.m2.1.1.2">𝑅</ci><ci id="A2.F4.14.m2.1.1.3.cmml" xref="A2.F4.14.m2.1.1.3">𝐶</ci><ci id="A2.F4.14.m2.1.1.4.cmml" xref="A2.F4.14.m2.1.1.4">𝑜</ci><ci id="A2.F4.14.m2.1.1.5.cmml" xref="A2.F4.14.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F4.14.m2.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.F4.14.m2.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> filters employed by FOLK and other random masking techniques.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS3.p3">
<p class="ltx_p" id="A2.SS3.p3.7"><span class="ltx_text" id="A2.SS3.p3.7.1" style="font-size:90%;">Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.F4" style="font-size:90%;" title="Figure 4 ‣ B.3 Ablation Study - Different Filters ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="A2.SS3.p3.7.2" style="font-size:90%;"> illustrates the implementation of three supplementary random filtering techniques on the input frequencies and the effect of those filters compared with our </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p3.1.m1.1"><semantics id="A2.SS3.p3.1.m1.1a"><mrow id="A2.SS3.p3.1.m1.1.1" xref="A2.SS3.p3.1.m1.1.1.cmml"><mi id="A2.SS3.p3.1.m1.1.1.2" mathsize="90%" xref="A2.SS3.p3.1.m1.1.1.2.cmml">C</mi><mo id="A2.SS3.p3.1.m1.1.1.1" xref="A2.SS3.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.1.m1.1.1.3" mathsize="90%" xref="A2.SS3.p3.1.m1.1.1.3.cmml">o</mi><mo id="A2.SS3.p3.1.m1.1.1.1a" xref="A2.SS3.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.1.m1.1.1.4" mathsize="90%" xref="A2.SS3.p3.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.1.m1.1b"><apply id="A2.SS3.p3.1.m1.1.1.cmml" xref="A2.SS3.p3.1.m1.1.1"><times id="A2.SS3.p3.1.m1.1.1.1.cmml" xref="A2.SS3.p3.1.m1.1.1.1"></times><ci id="A2.SS3.p3.1.m1.1.1.2.cmml" xref="A2.SS3.p3.1.m1.1.1.2">𝐶</ci><ci id="A2.SS3.p3.1.m1.1.1.3.cmml" xref="A2.SS3.p3.1.m1.1.1.3">𝑜</ci><ci id="A2.SS3.p3.1.m1.1.1.4.cmml" xref="A2.SS3.p3.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.3" style="font-size:90%;"> filter. The </span><math alttext="Gabor" class="ltx_Math" display="inline" id="A2.SS3.p3.2.m2.1"><semantics id="A2.SS3.p3.2.m2.1a"><mrow id="A2.SS3.p3.2.m2.1.1" xref="A2.SS3.p3.2.m2.1.1.cmml"><mi id="A2.SS3.p3.2.m2.1.1.2" mathsize="90%" xref="A2.SS3.p3.2.m2.1.1.2.cmml">G</mi><mo id="A2.SS3.p3.2.m2.1.1.1" xref="A2.SS3.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.2.m2.1.1.3" mathsize="90%" xref="A2.SS3.p3.2.m2.1.1.3.cmml">a</mi><mo id="A2.SS3.p3.2.m2.1.1.1a" xref="A2.SS3.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.2.m2.1.1.4" mathsize="90%" xref="A2.SS3.p3.2.m2.1.1.4.cmml">b</mi><mo id="A2.SS3.p3.2.m2.1.1.1b" xref="A2.SS3.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.2.m2.1.1.5" mathsize="90%" xref="A2.SS3.p3.2.m2.1.1.5.cmml">o</mi><mo id="A2.SS3.p3.2.m2.1.1.1c" xref="A2.SS3.p3.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.2.m2.1.1.6" mathsize="90%" xref="A2.SS3.p3.2.m2.1.1.6.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.2.m2.1b"><apply id="A2.SS3.p3.2.m2.1.1.cmml" xref="A2.SS3.p3.2.m2.1.1"><times id="A2.SS3.p3.2.m2.1.1.1.cmml" xref="A2.SS3.p3.2.m2.1.1.1"></times><ci id="A2.SS3.p3.2.m2.1.1.2.cmml" xref="A2.SS3.p3.2.m2.1.1.2">𝐺</ci><ci id="A2.SS3.p3.2.m2.1.1.3.cmml" xref="A2.SS3.p3.2.m2.1.1.3">𝑎</ci><ci id="A2.SS3.p3.2.m2.1.1.4.cmml" xref="A2.SS3.p3.2.m2.1.1.4">𝑏</ci><ci id="A2.SS3.p3.2.m2.1.1.5.cmml" xref="A2.SS3.p3.2.m2.1.1.5">𝑜</ci><ci id="A2.SS3.p3.2.m2.1.1.6.cmml" xref="A2.SS3.p3.2.m2.1.1.6">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.2.m2.1c">Gabor</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.2.m2.1d">italic_G italic_a italic_b italic_o italic_r</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.4" style="font-size:90%;"> filter that we directly applied in the frequency domain, </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.SS3.p3.7.5.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Kamarainen et al.</span><span class="ltx_text" id="A2.SS3.p3.7.6.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">2006</span></a><span class="ltx_text" id="A2.SS3.p3.7.7.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A2.SS3.p3.7.8" style="font-size:90%;">. In addition to this, </span><math alttext="Token\ Mask" class="ltx_Math" display="inline" id="A2.SS3.p3.3.m3.1"><semantics id="A2.SS3.p3.3.m3.1a"><mrow id="A2.SS3.p3.3.m3.1.1" xref="A2.SS3.p3.3.m3.1.1.cmml"><mi id="A2.SS3.p3.3.m3.1.1.2" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.2.cmml">T</mi><mo id="A2.SS3.p3.3.m3.1.1.1" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.3" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.3.cmml">o</mi><mo id="A2.SS3.p3.3.m3.1.1.1a" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.4" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.4.cmml">k</mi><mo id="A2.SS3.p3.3.m3.1.1.1b" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.5" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.5.cmml">e</mi><mo id="A2.SS3.p3.3.m3.1.1.1c" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.6" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.6.cmml">n</mi><mo id="A2.SS3.p3.3.m3.1.1.1d" lspace="0.450em" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.7" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.7.cmml">M</mi><mo id="A2.SS3.p3.3.m3.1.1.1e" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.8" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.8.cmml">a</mi><mo id="A2.SS3.p3.3.m3.1.1.1f" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.9" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.9.cmml">s</mi><mo id="A2.SS3.p3.3.m3.1.1.1g" xref="A2.SS3.p3.3.m3.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.3.m3.1.1.10" mathsize="90%" xref="A2.SS3.p3.3.m3.1.1.10.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.3.m3.1b"><apply id="A2.SS3.p3.3.m3.1.1.cmml" xref="A2.SS3.p3.3.m3.1.1"><times id="A2.SS3.p3.3.m3.1.1.1.cmml" xref="A2.SS3.p3.3.m3.1.1.1"></times><ci id="A2.SS3.p3.3.m3.1.1.2.cmml" xref="A2.SS3.p3.3.m3.1.1.2">𝑇</ci><ci id="A2.SS3.p3.3.m3.1.1.3.cmml" xref="A2.SS3.p3.3.m3.1.1.3">𝑜</ci><ci id="A2.SS3.p3.3.m3.1.1.4.cmml" xref="A2.SS3.p3.3.m3.1.1.4">𝑘</ci><ci id="A2.SS3.p3.3.m3.1.1.5.cmml" xref="A2.SS3.p3.3.m3.1.1.5">𝑒</ci><ci id="A2.SS3.p3.3.m3.1.1.6.cmml" xref="A2.SS3.p3.3.m3.1.1.6">𝑛</ci><ci id="A2.SS3.p3.3.m3.1.1.7.cmml" xref="A2.SS3.p3.3.m3.1.1.7">𝑀</ci><ci id="A2.SS3.p3.3.m3.1.1.8.cmml" xref="A2.SS3.p3.3.m3.1.1.8">𝑎</ci><ci id="A2.SS3.p3.3.m3.1.1.9.cmml" xref="A2.SS3.p3.3.m3.1.1.9">𝑠</ci><ci id="A2.SS3.p3.3.m3.1.1.10.cmml" xref="A2.SS3.p3.3.m3.1.1.10">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.3.m3.1c">Token\ Mask</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.3.m3.1d">italic_T italic_o italic_k italic_e italic_n italic_M italic_a italic_s italic_k</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.9" style="font-size:90%;"> is utilized, drawing inspiration from the </span><math alttext="SimMIM" class="ltx_Math" display="inline" id="A2.SS3.p3.4.m4.1"><semantics id="A2.SS3.p3.4.m4.1a"><mrow id="A2.SS3.p3.4.m4.1.1" xref="A2.SS3.p3.4.m4.1.1.cmml"><mi id="A2.SS3.p3.4.m4.1.1.2" mathsize="90%" xref="A2.SS3.p3.4.m4.1.1.2.cmml">S</mi><mo id="A2.SS3.p3.4.m4.1.1.1" xref="A2.SS3.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.4.m4.1.1.3" mathsize="90%" xref="A2.SS3.p3.4.m4.1.1.3.cmml">i</mi><mo id="A2.SS3.p3.4.m4.1.1.1a" xref="A2.SS3.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.4.m4.1.1.4" mathsize="90%" xref="A2.SS3.p3.4.m4.1.1.4.cmml">m</mi><mo id="A2.SS3.p3.4.m4.1.1.1b" xref="A2.SS3.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.4.m4.1.1.5" mathsize="90%" xref="A2.SS3.p3.4.m4.1.1.5.cmml">M</mi><mo id="A2.SS3.p3.4.m4.1.1.1c" xref="A2.SS3.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.4.m4.1.1.6" mathsize="90%" xref="A2.SS3.p3.4.m4.1.1.6.cmml">I</mi><mo id="A2.SS3.p3.4.m4.1.1.1d" xref="A2.SS3.p3.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.4.m4.1.1.7" mathsize="90%" xref="A2.SS3.p3.4.m4.1.1.7.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.4.m4.1b"><apply id="A2.SS3.p3.4.m4.1.1.cmml" xref="A2.SS3.p3.4.m4.1.1"><times id="A2.SS3.p3.4.m4.1.1.1.cmml" xref="A2.SS3.p3.4.m4.1.1.1"></times><ci id="A2.SS3.p3.4.m4.1.1.2.cmml" xref="A2.SS3.p3.4.m4.1.1.2">𝑆</ci><ci id="A2.SS3.p3.4.m4.1.1.3.cmml" xref="A2.SS3.p3.4.m4.1.1.3">𝑖</ci><ci id="A2.SS3.p3.4.m4.1.1.4.cmml" xref="A2.SS3.p3.4.m4.1.1.4">𝑚</ci><ci id="A2.SS3.p3.4.m4.1.1.5.cmml" xref="A2.SS3.p3.4.m4.1.1.5">𝑀</ci><ci id="A2.SS3.p3.4.m4.1.1.6.cmml" xref="A2.SS3.p3.4.m4.1.1.6">𝐼</ci><ci id="A2.SS3.p3.4.m4.1.1.7.cmml" xref="A2.SS3.p3.4.m4.1.1.7">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.4.m4.1c">SimMIM</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.4.m4.1d">italic_S italic_i italic_m italic_M italic_I italic_M</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.10" style="font-size:90%;"> approach </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="A2.SS3.p3.7.11.1" style="font-size:90%;">[</span><span class="ltx_text" style="font-size:90%;">Xie et al.</span><span class="ltx_text" id="A2.SS3.p3.7.12.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#bib.bib63" title=""><span class="ltx_text" style="font-size:90%;">2022</span></a><span class="ltx_text" id="A2.SS3.p3.7.13.3" style="font-size:90%;">]</span></cite><span class="ltx_text" id="A2.SS3.p3.7.14" style="font-size:90%;">, where random square regions are masked in the frequency domain to mimic missing information. Furthermore, we introduce the </span><math alttext="Circle\ Mask" class="ltx_Math" display="inline" id="A2.SS3.p3.5.m5.1"><semantics id="A2.SS3.p3.5.m5.1a"><mrow id="A2.SS3.p3.5.m5.1.1" xref="A2.SS3.p3.5.m5.1.1.cmml"><mi id="A2.SS3.p3.5.m5.1.1.2" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.2.cmml">C</mi><mo id="A2.SS3.p3.5.m5.1.1.1" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.3" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.3.cmml">i</mi><mo id="A2.SS3.p3.5.m5.1.1.1a" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.4" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.4.cmml">r</mi><mo id="A2.SS3.p3.5.m5.1.1.1b" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.5" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.5.cmml">c</mi><mo id="A2.SS3.p3.5.m5.1.1.1c" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.6" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.6.cmml">l</mi><mo id="A2.SS3.p3.5.m5.1.1.1d" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.7" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.7.cmml">e</mi><mo id="A2.SS3.p3.5.m5.1.1.1e" lspace="0.450em" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.8" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.8.cmml">M</mi><mo id="A2.SS3.p3.5.m5.1.1.1f" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.9" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.9.cmml">a</mi><mo id="A2.SS3.p3.5.m5.1.1.1g" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.10" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.10.cmml">s</mi><mo id="A2.SS3.p3.5.m5.1.1.1h" xref="A2.SS3.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.5.m5.1.1.11" mathsize="90%" xref="A2.SS3.p3.5.m5.1.1.11.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.5.m5.1b"><apply id="A2.SS3.p3.5.m5.1.1.cmml" xref="A2.SS3.p3.5.m5.1.1"><times id="A2.SS3.p3.5.m5.1.1.1.cmml" xref="A2.SS3.p3.5.m5.1.1.1"></times><ci id="A2.SS3.p3.5.m5.1.1.2.cmml" xref="A2.SS3.p3.5.m5.1.1.2">𝐶</ci><ci id="A2.SS3.p3.5.m5.1.1.3.cmml" xref="A2.SS3.p3.5.m5.1.1.3">𝑖</ci><ci id="A2.SS3.p3.5.m5.1.1.4.cmml" xref="A2.SS3.p3.5.m5.1.1.4">𝑟</ci><ci id="A2.SS3.p3.5.m5.1.1.5.cmml" xref="A2.SS3.p3.5.m5.1.1.5">𝑐</ci><ci id="A2.SS3.p3.5.m5.1.1.6.cmml" xref="A2.SS3.p3.5.m5.1.1.6">𝑙</ci><ci id="A2.SS3.p3.5.m5.1.1.7.cmml" xref="A2.SS3.p3.5.m5.1.1.7">𝑒</ci><ci id="A2.SS3.p3.5.m5.1.1.8.cmml" xref="A2.SS3.p3.5.m5.1.1.8">𝑀</ci><ci id="A2.SS3.p3.5.m5.1.1.9.cmml" xref="A2.SS3.p3.5.m5.1.1.9">𝑎</ci><ci id="A2.SS3.p3.5.m5.1.1.10.cmml" xref="A2.SS3.p3.5.m5.1.1.10">𝑠</ci><ci id="A2.SS3.p3.5.m5.1.1.11.cmml" xref="A2.SS3.p3.5.m5.1.1.11">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.5.m5.1c">Circle\ Mask</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.5.m5.1d">italic_C italic_i italic_r italic_c italic_l italic_e italic_M italic_a italic_s italic_k</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.15" style="font-size:90%;"> strategy, which involves randomly masking circular areas at various distances from the center of the frequency spectrum. One of the significant advantages of our introduced filter (</span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p3.6.m6.1"><semantics id="A2.SS3.p3.6.m6.1a"><mrow id="A2.SS3.p3.6.m6.1.1" xref="A2.SS3.p3.6.m6.1.1.cmml"><mi id="A2.SS3.p3.6.m6.1.1.2" mathsize="90%" xref="A2.SS3.p3.6.m6.1.1.2.cmml">C</mi><mo id="A2.SS3.p3.6.m6.1.1.1" xref="A2.SS3.p3.6.m6.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.6.m6.1.1.3" mathsize="90%" xref="A2.SS3.p3.6.m6.1.1.3.cmml">o</mi><mo id="A2.SS3.p3.6.m6.1.1.1a" xref="A2.SS3.p3.6.m6.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.6.m6.1.1.4" mathsize="90%" xref="A2.SS3.p3.6.m6.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.6.m6.1b"><apply id="A2.SS3.p3.6.m6.1.1.cmml" xref="A2.SS3.p3.6.m6.1.1"><times id="A2.SS3.p3.6.m6.1.1.1.cmml" xref="A2.SS3.p3.6.m6.1.1.1"></times><ci id="A2.SS3.p3.6.m6.1.1.2.cmml" xref="A2.SS3.p3.6.m6.1.1.2">𝐶</ci><ci id="A2.SS3.p3.6.m6.1.1.3.cmml" xref="A2.SS3.p3.6.m6.1.1.3">𝑜</ci><ci id="A2.SS3.p3.6.m6.1.1.4.cmml" xref="A2.SS3.p3.6.m6.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.6.m6.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.6.m6.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.16" style="font-size:90%;">/</span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p3.7.m7.1"><semantics id="A2.SS3.p3.7.m7.1a"><mrow id="A2.SS3.p3.7.m7.1.1" xref="A2.SS3.p3.7.m7.1.1.cmml"><mi id="A2.SS3.p3.7.m7.1.1.2" mathsize="90%" xref="A2.SS3.p3.7.m7.1.1.2.cmml">R</mi><mo id="A2.SS3.p3.7.m7.1.1.1" xref="A2.SS3.p3.7.m7.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.7.m7.1.1.3" mathsize="90%" xref="A2.SS3.p3.7.m7.1.1.3.cmml">C</mi><mo id="A2.SS3.p3.7.m7.1.1.1a" xref="A2.SS3.p3.7.m7.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.7.m7.1.1.4" mathsize="90%" xref="A2.SS3.p3.7.m7.1.1.4.cmml">o</mi><mo id="A2.SS3.p3.7.m7.1.1.1b" xref="A2.SS3.p3.7.m7.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p3.7.m7.1.1.5" mathsize="90%" xref="A2.SS3.p3.7.m7.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.7.m7.1b"><apply id="A2.SS3.p3.7.m7.1.1.cmml" xref="A2.SS3.p3.7.m7.1.1"><times id="A2.SS3.p3.7.m7.1.1.1.cmml" xref="A2.SS3.p3.7.m7.1.1.1"></times><ci id="A2.SS3.p3.7.m7.1.1.2.cmml" xref="A2.SS3.p3.7.m7.1.1.2">𝑅</ci><ci id="A2.SS3.p3.7.m7.1.1.3.cmml" xref="A2.SS3.p3.7.m7.1.1.3">𝐶</ci><ci id="A2.SS3.p3.7.m7.1.1.4.cmml" xref="A2.SS3.p3.7.m7.1.1.4">𝑜</ci><ci id="A2.SS3.p3.7.m7.1.1.5.cmml" xref="A2.SS3.p3.7.m7.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.7.m7.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.7.m7.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p3.7.17" style="font-size:90%;">) is that it uses actual image information for masking, while other filters just randomly or constantly mask (like MFM) a portion of the frequency area without considering the structure and information of the image.</span></p>
</div>
<figure class="ltx_table" id="A2.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T7.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T7.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.2.2.3"><span class="ltx_text ltx_font_bold" id="A2.T7.2.2.3.1" style="font-size:90%;">Filters</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.2.2.4"><span class="ltx_text" id="A2.T7.2.2.4.1" style="font-size:90%;">Gabor</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.2.2.5"><span class="ltx_text" id="A2.T7.2.2.5.1" style="font-size:90%;">Token Mask</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.2.2.6"><span class="ltx_text" id="A2.T7.2.2.6.1" style="font-size:90%;">Circle Mask</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.2.2.2">
<math alttext="Com" class="ltx_Math" display="inline" id="A2.T7.1.1.1.m1.1"><semantics id="A2.T7.1.1.1.m1.1a"><mrow id="A2.T7.1.1.1.m1.1.1" xref="A2.T7.1.1.1.m1.1.1.cmml"><mi id="A2.T7.1.1.1.m1.1.1.2" mathsize="90%" xref="A2.T7.1.1.1.m1.1.1.2.cmml">C</mi><mo id="A2.T7.1.1.1.m1.1.1.1" xref="A2.T7.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.T7.1.1.1.m1.1.1.3" mathsize="90%" xref="A2.T7.1.1.1.m1.1.1.3.cmml">o</mi><mo id="A2.T7.1.1.1.m1.1.1.1a" xref="A2.T7.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.T7.1.1.1.m1.1.1.4" mathsize="90%" xref="A2.T7.1.1.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T7.1.1.1.m1.1b"><apply id="A2.T7.1.1.1.m1.1.1.cmml" xref="A2.T7.1.1.1.m1.1.1"><times id="A2.T7.1.1.1.m1.1.1.1.cmml" xref="A2.T7.1.1.1.m1.1.1.1"></times><ci id="A2.T7.1.1.1.m1.1.1.2.cmml" xref="A2.T7.1.1.1.m1.1.1.2">𝐶</ci><ci id="A2.T7.1.1.1.m1.1.1.3.cmml" xref="A2.T7.1.1.1.m1.1.1.3">𝑜</ci><ci id="A2.T7.1.1.1.m1.1.1.4.cmml" xref="A2.T7.1.1.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.1.1.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.T7.1.1.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.T7.2.2.2.1" style="font-size:90%;">/</span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.T7.2.2.2.m2.1"><semantics id="A2.T7.2.2.2.m2.1a"><mrow id="A2.T7.2.2.2.m2.1.1" xref="A2.T7.2.2.2.m2.1.1.cmml"><mi id="A2.T7.2.2.2.m2.1.1.2" mathsize="90%" xref="A2.T7.2.2.2.m2.1.1.2.cmml">R</mi><mo id="A2.T7.2.2.2.m2.1.1.1" xref="A2.T7.2.2.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.T7.2.2.2.m2.1.1.3" mathsize="90%" xref="A2.T7.2.2.2.m2.1.1.3.cmml">C</mi><mo id="A2.T7.2.2.2.m2.1.1.1a" xref="A2.T7.2.2.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.T7.2.2.2.m2.1.1.4" mathsize="90%" xref="A2.T7.2.2.2.m2.1.1.4.cmml">o</mi><mo id="A2.T7.2.2.2.m2.1.1.1b" xref="A2.T7.2.2.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.T7.2.2.2.m2.1.1.5" mathsize="90%" xref="A2.T7.2.2.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.T7.2.2.2.m2.1b"><apply id="A2.T7.2.2.2.m2.1.1.cmml" xref="A2.T7.2.2.2.m2.1.1"><times id="A2.T7.2.2.2.m2.1.1.1.cmml" xref="A2.T7.2.2.2.m2.1.1.1"></times><ci id="A2.T7.2.2.2.m2.1.1.2.cmml" xref="A2.T7.2.2.2.m2.1.1.2">𝑅</ci><ci id="A2.T7.2.2.2.m2.1.1.3.cmml" xref="A2.T7.2.2.2.m2.1.1.3">𝐶</ci><ci id="A2.T7.2.2.2.m2.1.1.4.cmml" xref="A2.T7.2.2.2.m2.1.1.4">𝑜</ci><ci id="A2.T7.2.2.2.m2.1.1.5.cmml" xref="A2.T7.2.2.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.2.2.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.T7.2.2.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A2.T7.2.3.1">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A2.T7.2.3.1.1"><span class="ltx_text ltx_font_bold" id="A2.T7.2.3.1.1.1" style="font-size:90%;">Acc</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A2.T7.2.3.1.2"><span class="ltx_text" id="A2.T7.2.3.1.2.1" style="font-size:90%;">80.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A2.T7.2.3.1.3"><span class="ltx_text" id="A2.T7.2.3.1.3.1" style="font-size:90%;">80.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A2.T7.2.3.1.4"><span class="ltx_text" id="A2.T7.2.3.1.4.1" style="font-size:90%;">80.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A2.T7.2.3.1.5"><span class="ltx_text ltx_font_bold" id="A2.T7.2.3.1.5.1" style="font-size:90%;">81.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Image classification results of utilizing different filters for masking in the FOLK framework.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS3.p4">
<p class="ltx_p" id="A2.SS3.p4.10"><span class="ltx_text" id="A2.SS3.p4.10.1" style="font-size:90%;">Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.T7" style="font-size:90%;" title="Table 7 ‣ B.3 Ablation Study - Different Filters ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">7</span></a><span class="ltx_text" id="A2.SS3.p4.10.2" style="font-size:90%;"> illustrates the impact of various filtering techniques used for masking within the FOLK framework on model accuracy. The methods compared include Gabor filters, Token Mask, and Circle Mask filters. A clear pattern emerges from the data, with the </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p4.1.m1.1"><semantics id="A2.SS3.p4.1.m1.1a"><mrow id="A2.SS3.p4.1.m1.1.1" xref="A2.SS3.p4.1.m1.1.1.cmml"><mi id="A2.SS3.p4.1.m1.1.1.2" mathsize="90%" xref="A2.SS3.p4.1.m1.1.1.2.cmml">C</mi><mo id="A2.SS3.p4.1.m1.1.1.1" xref="A2.SS3.p4.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.1.m1.1.1.3" mathsize="90%" xref="A2.SS3.p4.1.m1.1.1.3.cmml">o</mi><mo id="A2.SS3.p4.1.m1.1.1.1a" xref="A2.SS3.p4.1.m1.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.1.m1.1.1.4" mathsize="90%" xref="A2.SS3.p4.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.1.m1.1b"><apply id="A2.SS3.p4.1.m1.1.1.cmml" xref="A2.SS3.p4.1.m1.1.1"><times id="A2.SS3.p4.1.m1.1.1.1.cmml" xref="A2.SS3.p4.1.m1.1.1.1"></times><ci id="A2.SS3.p4.1.m1.1.1.2.cmml" xref="A2.SS3.p4.1.m1.1.1.2">𝐶</ci><ci id="A2.SS3.p4.1.m1.1.1.3.cmml" xref="A2.SS3.p4.1.m1.1.1.3">𝑜</ci><ci id="A2.SS3.p4.1.m1.1.1.4.cmml" xref="A2.SS3.p4.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.3" style="font-size:90%;">/</span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p4.2.m2.1"><semantics id="A2.SS3.p4.2.m2.1a"><mrow id="A2.SS3.p4.2.m2.1.1" xref="A2.SS3.p4.2.m2.1.1.cmml"><mi id="A2.SS3.p4.2.m2.1.1.2" mathsize="90%" xref="A2.SS3.p4.2.m2.1.1.2.cmml">R</mi><mo id="A2.SS3.p4.2.m2.1.1.1" xref="A2.SS3.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.2.m2.1.1.3" mathsize="90%" xref="A2.SS3.p4.2.m2.1.1.3.cmml">C</mi><mo id="A2.SS3.p4.2.m2.1.1.1a" xref="A2.SS3.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.2.m2.1.1.4" mathsize="90%" xref="A2.SS3.p4.2.m2.1.1.4.cmml">o</mi><mo id="A2.SS3.p4.2.m2.1.1.1b" xref="A2.SS3.p4.2.m2.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.2.m2.1.1.5" mathsize="90%" xref="A2.SS3.p4.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.2.m2.1b"><apply id="A2.SS3.p4.2.m2.1.1.cmml" xref="A2.SS3.p4.2.m2.1.1"><times id="A2.SS3.p4.2.m2.1.1.1.cmml" xref="A2.SS3.p4.2.m2.1.1.1"></times><ci id="A2.SS3.p4.2.m2.1.1.2.cmml" xref="A2.SS3.p4.2.m2.1.1.2">𝑅</ci><ci id="A2.SS3.p4.2.m2.1.1.3.cmml" xref="A2.SS3.p4.2.m2.1.1.3">𝐶</ci><ci id="A2.SS3.p4.2.m2.1.1.4.cmml" xref="A2.SS3.p4.2.m2.1.1.4">𝑜</ci><ci id="A2.SS3.p4.2.m2.1.1.5.cmml" xref="A2.SS3.p4.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.4" style="font-size:90%;"> filters significantly outperforming the other techniques, achieving the highest accuracy at </span><math alttext="81.6\%" class="ltx_Math" display="inline" id="A2.SS3.p4.3.m3.1"><semantics id="A2.SS3.p4.3.m3.1a"><mrow id="A2.SS3.p4.3.m3.1.1" xref="A2.SS3.p4.3.m3.1.1.cmml"><mn id="A2.SS3.p4.3.m3.1.1.2" mathsize="90%" xref="A2.SS3.p4.3.m3.1.1.2.cmml">81.6</mn><mo id="A2.SS3.p4.3.m3.1.1.1" mathsize="90%" xref="A2.SS3.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.3.m3.1b"><apply id="A2.SS3.p4.3.m3.1.1.cmml" xref="A2.SS3.p4.3.m3.1.1"><csymbol cd="latexml" id="A2.SS3.p4.3.m3.1.1.1.cmml" xref="A2.SS3.p4.3.m3.1.1.1">percent</csymbol><cn id="A2.SS3.p4.3.m3.1.1.2.cmml" type="float" xref="A2.SS3.p4.3.m3.1.1.2">81.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.3.m3.1c">81.6\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.3.m3.1d">81.6 %</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.5" style="font-size:90%;">. This indicates a superior efficacy of </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p4.4.m4.1"><semantics id="A2.SS3.p4.4.m4.1a"><mrow id="A2.SS3.p4.4.m4.1.1" xref="A2.SS3.p4.4.m4.1.1.cmml"><mi id="A2.SS3.p4.4.m4.1.1.2" mathsize="90%" xref="A2.SS3.p4.4.m4.1.1.2.cmml">C</mi><mo id="A2.SS3.p4.4.m4.1.1.1" xref="A2.SS3.p4.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.4.m4.1.1.3" mathsize="90%" xref="A2.SS3.p4.4.m4.1.1.3.cmml">o</mi><mo id="A2.SS3.p4.4.m4.1.1.1a" xref="A2.SS3.p4.4.m4.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.4.m4.1.1.4" mathsize="90%" xref="A2.SS3.p4.4.m4.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.4.m4.1b"><apply id="A2.SS3.p4.4.m4.1.1.cmml" xref="A2.SS3.p4.4.m4.1.1"><times id="A2.SS3.p4.4.m4.1.1.1.cmml" xref="A2.SS3.p4.4.m4.1.1.1"></times><ci id="A2.SS3.p4.4.m4.1.1.2.cmml" xref="A2.SS3.p4.4.m4.1.1.2">𝐶</ci><ci id="A2.SS3.p4.4.m4.1.1.3.cmml" xref="A2.SS3.p4.4.m4.1.1.3">𝑜</ci><ci id="A2.SS3.p4.4.m4.1.1.4.cmml" xref="A2.SS3.p4.4.m4.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.4.m4.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.4.m4.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.6" style="font-size:90%;">/</span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p4.5.m5.1"><semantics id="A2.SS3.p4.5.m5.1a"><mrow id="A2.SS3.p4.5.m5.1.1" xref="A2.SS3.p4.5.m5.1.1.cmml"><mi id="A2.SS3.p4.5.m5.1.1.2" mathsize="90%" xref="A2.SS3.p4.5.m5.1.1.2.cmml">R</mi><mo id="A2.SS3.p4.5.m5.1.1.1" xref="A2.SS3.p4.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.5.m5.1.1.3" mathsize="90%" xref="A2.SS3.p4.5.m5.1.1.3.cmml">C</mi><mo id="A2.SS3.p4.5.m5.1.1.1a" xref="A2.SS3.p4.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.5.m5.1.1.4" mathsize="90%" xref="A2.SS3.p4.5.m5.1.1.4.cmml">o</mi><mo id="A2.SS3.p4.5.m5.1.1.1b" xref="A2.SS3.p4.5.m5.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.5.m5.1.1.5" mathsize="90%" xref="A2.SS3.p4.5.m5.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.5.m5.1b"><apply id="A2.SS3.p4.5.m5.1.1.cmml" xref="A2.SS3.p4.5.m5.1.1"><times id="A2.SS3.p4.5.m5.1.1.1.cmml" xref="A2.SS3.p4.5.m5.1.1.1"></times><ci id="A2.SS3.p4.5.m5.1.1.2.cmml" xref="A2.SS3.p4.5.m5.1.1.2">𝑅</ci><ci id="A2.SS3.p4.5.m5.1.1.3.cmml" xref="A2.SS3.p4.5.m5.1.1.3">𝐶</ci><ci id="A2.SS3.p4.5.m5.1.1.4.cmml" xref="A2.SS3.p4.5.m5.1.1.4">𝑜</ci><ci id="A2.SS3.p4.5.m5.1.1.5.cmml" xref="A2.SS3.p4.5.m5.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.5.m5.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.5.m5.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.7" style="font-size:90%;"> filters in capturing and utilizing relevant image features for model training. The other filters—Gabor, Token, and Circle—also show competitive accuracies, but they are notably less effective than </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p4.6.m6.1"><semantics id="A2.SS3.p4.6.m6.1a"><mrow id="A2.SS3.p4.6.m6.1.1" xref="A2.SS3.p4.6.m6.1.1.cmml"><mi id="A2.SS3.p4.6.m6.1.1.2" mathsize="90%" xref="A2.SS3.p4.6.m6.1.1.2.cmml">C</mi><mo id="A2.SS3.p4.6.m6.1.1.1" xref="A2.SS3.p4.6.m6.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.6.m6.1.1.3" mathsize="90%" xref="A2.SS3.p4.6.m6.1.1.3.cmml">o</mi><mo id="A2.SS3.p4.6.m6.1.1.1a" xref="A2.SS3.p4.6.m6.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.6.m6.1.1.4" mathsize="90%" xref="A2.SS3.p4.6.m6.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.6.m6.1b"><apply id="A2.SS3.p4.6.m6.1.1.cmml" xref="A2.SS3.p4.6.m6.1.1"><times id="A2.SS3.p4.6.m6.1.1.1.cmml" xref="A2.SS3.p4.6.m6.1.1.1"></times><ci id="A2.SS3.p4.6.m6.1.1.2.cmml" xref="A2.SS3.p4.6.m6.1.1.2">𝐶</ci><ci id="A2.SS3.p4.6.m6.1.1.3.cmml" xref="A2.SS3.p4.6.m6.1.1.3">𝑜</ci><ci id="A2.SS3.p4.6.m6.1.1.4.cmml" xref="A2.SS3.p4.6.m6.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.6.m6.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.6.m6.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.8" style="font-size:90%;">/</span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p4.7.m7.1"><semantics id="A2.SS3.p4.7.m7.1a"><mrow id="A2.SS3.p4.7.m7.1.1" xref="A2.SS3.p4.7.m7.1.1.cmml"><mi id="A2.SS3.p4.7.m7.1.1.2" mathsize="90%" xref="A2.SS3.p4.7.m7.1.1.2.cmml">R</mi><mo id="A2.SS3.p4.7.m7.1.1.1" xref="A2.SS3.p4.7.m7.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.7.m7.1.1.3" mathsize="90%" xref="A2.SS3.p4.7.m7.1.1.3.cmml">C</mi><mo id="A2.SS3.p4.7.m7.1.1.1a" xref="A2.SS3.p4.7.m7.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.7.m7.1.1.4" mathsize="90%" xref="A2.SS3.p4.7.m7.1.1.4.cmml">o</mi><mo id="A2.SS3.p4.7.m7.1.1.1b" xref="A2.SS3.p4.7.m7.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.7.m7.1.1.5" mathsize="90%" xref="A2.SS3.p4.7.m7.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.7.m7.1b"><apply id="A2.SS3.p4.7.m7.1.1.cmml" xref="A2.SS3.p4.7.m7.1.1"><times id="A2.SS3.p4.7.m7.1.1.1.cmml" xref="A2.SS3.p4.7.m7.1.1.1"></times><ci id="A2.SS3.p4.7.m7.1.1.2.cmml" xref="A2.SS3.p4.7.m7.1.1.2">𝑅</ci><ci id="A2.SS3.p4.7.m7.1.1.3.cmml" xref="A2.SS3.p4.7.m7.1.1.3">𝐶</ci><ci id="A2.SS3.p4.7.m7.1.1.4.cmml" xref="A2.SS3.p4.7.m7.1.1.4">𝑜</ci><ci id="A2.SS3.p4.7.m7.1.1.5.cmml" xref="A2.SS3.p4.7.m7.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.7.m7.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.7.m7.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.9" style="font-size:90%;">, with accuracies hovering around the </span><math alttext="80\%" class="ltx_Math" display="inline" id="A2.SS3.p4.8.m8.1"><semantics id="A2.SS3.p4.8.m8.1a"><mrow id="A2.SS3.p4.8.m8.1.1" xref="A2.SS3.p4.8.m8.1.1.cmml"><mn id="A2.SS3.p4.8.m8.1.1.2" mathsize="90%" xref="A2.SS3.p4.8.m8.1.1.2.cmml">80</mn><mo id="A2.SS3.p4.8.m8.1.1.1" mathsize="90%" xref="A2.SS3.p4.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.8.m8.1b"><apply id="A2.SS3.p4.8.m8.1.1.cmml" xref="A2.SS3.p4.8.m8.1.1"><csymbol cd="latexml" id="A2.SS3.p4.8.m8.1.1.1.cmml" xref="A2.SS3.p4.8.m8.1.1.1">percent</csymbol><cn id="A2.SS3.p4.8.m8.1.1.2.cmml" type="integer" xref="A2.SS3.p4.8.m8.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.8.m8.1c">80\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.8.m8.1d">80 %</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.10" style="font-size:90%;"> mark. This suggests that the design and application of the </span><math alttext="Com" class="ltx_Math" display="inline" id="A2.SS3.p4.9.m9.1"><semantics id="A2.SS3.p4.9.m9.1a"><mrow id="A2.SS3.p4.9.m9.1.1" xref="A2.SS3.p4.9.m9.1.1.cmml"><mi id="A2.SS3.p4.9.m9.1.1.2" mathsize="90%" xref="A2.SS3.p4.9.m9.1.1.2.cmml">C</mi><mo id="A2.SS3.p4.9.m9.1.1.1" xref="A2.SS3.p4.9.m9.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.9.m9.1.1.3" mathsize="90%" xref="A2.SS3.p4.9.m9.1.1.3.cmml">o</mi><mo id="A2.SS3.p4.9.m9.1.1.1a" xref="A2.SS3.p4.9.m9.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.9.m9.1.1.4" mathsize="90%" xref="A2.SS3.p4.9.m9.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.9.m9.1b"><apply id="A2.SS3.p4.9.m9.1.1.cmml" xref="A2.SS3.p4.9.m9.1.1"><times id="A2.SS3.p4.9.m9.1.1.1.cmml" xref="A2.SS3.p4.9.m9.1.1.1"></times><ci id="A2.SS3.p4.9.m9.1.1.2.cmml" xref="A2.SS3.p4.9.m9.1.1.2">𝐶</ci><ci id="A2.SS3.p4.9.m9.1.1.3.cmml" xref="A2.SS3.p4.9.m9.1.1.3">𝑜</ci><ci id="A2.SS3.p4.9.m9.1.1.4.cmml" xref="A2.SS3.p4.9.m9.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.9.m9.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.9.m9.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.11" style="font-size:90%;">/</span><math alttext="RCom" class="ltx_Math" display="inline" id="A2.SS3.p4.10.m10.1"><semantics id="A2.SS3.p4.10.m10.1a"><mrow id="A2.SS3.p4.10.m10.1.1" xref="A2.SS3.p4.10.m10.1.1.cmml"><mi id="A2.SS3.p4.10.m10.1.1.2" mathsize="90%" xref="A2.SS3.p4.10.m10.1.1.2.cmml">R</mi><mo id="A2.SS3.p4.10.m10.1.1.1" xref="A2.SS3.p4.10.m10.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.10.m10.1.1.3" mathsize="90%" xref="A2.SS3.p4.10.m10.1.1.3.cmml">C</mi><mo id="A2.SS3.p4.10.m10.1.1.1a" xref="A2.SS3.p4.10.m10.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.10.m10.1.1.4" mathsize="90%" xref="A2.SS3.p4.10.m10.1.1.4.cmml">o</mi><mo id="A2.SS3.p4.10.m10.1.1.1b" xref="A2.SS3.p4.10.m10.1.1.1.cmml">⁢</mo><mi id="A2.SS3.p4.10.m10.1.1.5" mathsize="90%" xref="A2.SS3.p4.10.m10.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS3.p4.10.m10.1b"><apply id="A2.SS3.p4.10.m10.1.1.cmml" xref="A2.SS3.p4.10.m10.1.1"><times id="A2.SS3.p4.10.m10.1.1.1.cmml" xref="A2.SS3.p4.10.m10.1.1.1"></times><ci id="A2.SS3.p4.10.m10.1.1.2.cmml" xref="A2.SS3.p4.10.m10.1.1.2">𝑅</ci><ci id="A2.SS3.p4.10.m10.1.1.3.cmml" xref="A2.SS3.p4.10.m10.1.1.3">𝐶</ci><ci id="A2.SS3.p4.10.m10.1.1.4.cmml" xref="A2.SS3.p4.10.m10.1.1.4">𝑜</ci><ci id="A2.SS3.p4.10.m10.1.1.5.cmml" xref="A2.SS3.p4.10.m10.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p4.10.m10.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p4.10.m10.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A2.SS3.p4.10.12" style="font-size:90%;"> filters are better aligned with image intrinsic information, enhancing the model’s ability to generalize from the training effectively.</span></p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS4">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>Efficiency Analysis</h3>
<div class="ltx_para" id="A2.SS4.p1">
<p class="ltx_p" id="A2.SS4.p1.1"><span class="ltx_text" id="A2.SS4.p1.1.1" style="font-size:90%;">Our proposed enhancement involves augmenting the MFM model framework to accommodate dual inputs: both the original and the filtered images. By processing both types of inputs, the model gains a more comprehensive understanding of the data, which is particularly advantageous in scenarios requiring robust feature recognition, such as few-shot learning tasks. This approach aims to optimize the model’s performance by leveraging the distinct characteristics captured in the filtered versus original images.</span></p>
</div>
<div class="ltx_para" id="A2.SS4.p2">
<p class="ltx_p" id="A2.SS4.p2.1"><span class="ltx_text" id="A2.SS4.p2.1.1" style="font-size:90%;">To assess the effectiveness of our enhanced model, we provide memory usage on the GPU, and overall accuracy. The results of these evaluations are summarized in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.T8" style="font-size:90%;" title="Table 8 ‣ B.4 Efficiency Analysis ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">8</span></a><span class="ltx_text" id="A2.SS4.p2.1.2" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="A2.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T8.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T8.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="A2.T8.1.1.2"><span class="ltx_text" id="A2.T8.1.1.2.1" style="font-size:90%;">Methods</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T8.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.3.1" style="font-size:90%;">FOLK</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T8.1.1.4"><span class="ltx_text" id="A2.T8.1.1.4.1" style="font-size:90%;">MFM</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T8.1.1.5"><span class="ltx_text" id="A2.T8.1.1.5.1" style="font-size:90%;">iBOT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T8.1.1.1">
<span class="ltx_text" id="A2.T8.1.1.1.1" style="font-size:90%;">AttMask</span><sup class="ltx_sup" id="A2.T8.1.1.1.2"><span class="ltx_text" id="A2.T8.1.1.1.2.1" style="font-size:90%;">∗</span></sup>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T8.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T8.2.2.2"><span class="ltx_text" id="A2.T8.2.2.2.1" style="font-size:90%;">MemGPU (GB)</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.2.2.3">
<span class="ltx_ERROR undefined" id="A2.T8.2.2.3.1">\ul</span><span class="ltx_text" id="A2.T8.2.2.3.2" style="font-size:90%;">19.82</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.2.2.4"><span class="ltx_text ltx_font_bold" id="A2.T8.2.2.4.1" style="font-size:90%;">10.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.2.2.5"><span class="ltx_text" id="A2.T8.2.2.5.1" style="font-size:90%;">21.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T8.2.2.1">
<span class="ltx_text" id="A2.T8.2.2.1.1" style="font-size:90%;">39.38</span><sup class="ltx_sup" id="A2.T8.2.2.1.2"><span class="ltx_text" id="A2.T8.2.2.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
</tr>
<tr class="ltx_tr" id="A2.T8.2.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T8.2.3.1.1"><span class="ltx_text" id="A2.T8.2.3.1.1.1" style="font-size:90%;">Few-Shot Accuracy (%)</span></th>
<td class="ltx_td ltx_align_center" id="A2.T8.2.3.1.2"><span class="ltx_text ltx_font_bold" id="A2.T8.2.3.1.2.1" style="font-size:90%;">67.2</span></td>
<td class="ltx_td ltx_align_center" id="A2.T8.2.3.1.3"><span class="ltx_text" id="A2.T8.2.3.1.3.1" style="font-size:90%;">52.7</span></td>
<td class="ltx_td ltx_align_center" id="A2.T8.2.3.1.4"><span class="ltx_text" id="A2.T8.2.3.1.4.1" style="font-size:90%;">45.7</span></td>
<td class="ltx_td ltx_align_center" id="A2.T8.2.3.1.5">
<span class="ltx_ERROR undefined" id="A2.T8.2.3.1.5.1">\ul</span><span class="ltx_text" id="A2.T8.2.3.1.5.2" style="font-size:90%;">57.4</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T8.2.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A2.T8.2.4.2.1"><span class="ltx_text" id="A2.T8.2.4.2.1.1" style="font-size:90%;">Classification Accuracy (%)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.2.4.2.2"><span class="ltx_text ltx_font_bold" id="A2.T8.2.4.2.2.1" style="font-size:90%;">81.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.2.4.2.3">
<span class="ltx_ERROR undefined" id="A2.T8.2.4.2.3.1">\ul</span><span class="ltx_text" id="A2.T8.2.4.2.3.2" style="font-size:90%;">81.4</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.2.4.2.4"><span class="ltx_text" id="A2.T8.2.4.2.4.1" style="font-size:90%;">81.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T8.2.4.2.5"><span class="ltx_text" id="A2.T8.2.4.2.5.1" style="font-size:90%;">81.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 8: </span>Comparison of GPU memory usage and model accuracy between FOLK and other methods. All methods are based on a ViT-S backbone. MemGPU is GPU memory with a batch size of 128. Few-Shot Accuracy is averaged from Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.T2" title="Table 2 ‣ 4.2.2 Few Shot Learning ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">2</span></a>. Classification Accuracy comes from Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#S4.T1" title="Table 1 ‣ 4.2.1 Image Classification ‣ 4.2 Experimental Analysis ‣ 4 Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">1</span></a> in the main manuscript. <sup class="ltx_sup" id="A2.T8.12.1">∗</sup>We could not run AttMask’s official code with batch 128 with A100 80G and received a memory error. Hence, we ran it with batch 64.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS4.p3">
<p class="ltx_p" id="A2.SS4.p3.2"><span class="ltx_text" id="A2.SS4.p3.2.1" style="font-size:90%;">Table </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A2.T8" style="font-size:90%;" title="Table 8 ‣ B.4 Efficiency Analysis ‣ Appendix B Extra Experiments ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">8</span></a><span class="ltx_text" id="A2.SS4.p3.2.2" style="font-size:90%;"> summarizes the performance metrics of various self-supervised learning methods, highlighting the impact of integrating dual inputs—original and filtered images—on model efficacy, particularly within the FOLK framework. Memory usage is a crucial consideration, as only GPUs with high capacity can run the model. This is noteworthy when compared to iBOT and AttMask which consume more memory</span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>AttMask cannot run with a batch size of 128 on an A100 80GB GPU, so we run it with a batch size of 64.</span></span></span><span class="ltx_text" id="A2.SS4.p3.2.3" style="font-size:90%;">, while our model requires less than 20GB of memory for the same batch size. The increased memory usage in models like FOLK and iBOT correlates with the advanced processing capabilities necessary for handling dual inputs. However, the evident gains in learning accuracy justify the resource allocation, making it a worthwhile trade-off for applications where high precision and robust feature recognition are critical, such as few-shot learning scenarios. FOLK achieves the highest few-shot learning accuracy at </span><math alttext="67.2\%" class="ltx_Math" display="inline" id="A2.SS4.p3.1.m1.1"><semantics id="A2.SS4.p3.1.m1.1a"><mrow id="A2.SS4.p3.1.m1.1.1" xref="A2.SS4.p3.1.m1.1.1.cmml"><mn id="A2.SS4.p3.1.m1.1.1.2" mathsize="90%" xref="A2.SS4.p3.1.m1.1.1.2.cmml">67.2</mn><mo id="A2.SS4.p3.1.m1.1.1.1" mathsize="90%" xref="A2.SS4.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS4.p3.1.m1.1b"><apply id="A2.SS4.p3.1.m1.1.1.cmml" xref="A2.SS4.p3.1.m1.1.1"><csymbol cd="latexml" id="A2.SS4.p3.1.m1.1.1.1.cmml" xref="A2.SS4.p3.1.m1.1.1.1">percent</csymbol><cn id="A2.SS4.p3.1.m1.1.1.2.cmml" type="float" xref="A2.SS4.p3.1.m1.1.1.2">67.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p3.1.m1.1c">67.2\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS4.p3.1.m1.1d">67.2 %</annotation></semantics></math><span class="ltx_text" id="A2.SS4.p3.2.4" style="font-size:90%;"> and tops classification accuracy at </span><math alttext="81.6\%" class="ltx_Math" display="inline" id="A2.SS4.p3.2.m2.1"><semantics id="A2.SS4.p3.2.m2.1a"><mrow id="A2.SS4.p3.2.m2.1.1" xref="A2.SS4.p3.2.m2.1.1.cmml"><mn id="A2.SS4.p3.2.m2.1.1.2" mathsize="90%" xref="A2.SS4.p3.2.m2.1.1.2.cmml">81.6</mn><mo id="A2.SS4.p3.2.m2.1.1.1" mathsize="90%" xref="A2.SS4.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS4.p3.2.m2.1b"><apply id="A2.SS4.p3.2.m2.1.1.cmml" xref="A2.SS4.p3.2.m2.1.1"><csymbol cd="latexml" id="A2.SS4.p3.2.m2.1.1.1.cmml" xref="A2.SS4.p3.2.m2.1.1.1">percent</csymbol><cn id="A2.SS4.p3.2.m2.1.1.2.cmml" type="float" xref="A2.SS4.p3.2.m2.1.1.2">81.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS4.p3.2.m2.1c">81.6\%</annotation><annotation encoding="application/x-llamapun" id="A2.SS4.p3.2.m2.1d">81.6 %</annotation></semantics></math><span class="ltx_text" id="A2.SS4.p3.2.5" style="font-size:90%;">. This performance indicates that the model’s ability to effectively utilize both filtered and original images significantly enhances its learning capabilities, particularly in tasks requiring robust feature recognition.</span></p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3" lang="en">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prediction Visualization</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.4"><span class="ltx_text" id="A3.p1.4.1" style="font-size:90%;">This section presents visualizations of a series of images from the ImageNet-1K dataset, processed by our newly proposed techniques, namely the </span><math alttext="Com" class="ltx_Math" display="inline" id="A3.p1.1.m1.1"><semantics id="A3.p1.1.m1.1a"><mrow id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mi id="A3.p1.1.m1.1.1.2" mathsize="90%" xref="A3.p1.1.m1.1.1.2.cmml">C</mi><mo id="A3.p1.1.m1.1.1.1" xref="A3.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A3.p1.1.m1.1.1.3" mathsize="90%" xref="A3.p1.1.m1.1.1.3.cmml">o</mi><mo id="A3.p1.1.m1.1.1.1a" xref="A3.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="A3.p1.1.m1.1.1.4" mathsize="90%" xref="A3.p1.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><times id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1.1"></times><ci id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">𝐶</ci><ci id="A3.p1.1.m1.1.1.3.cmml" xref="A3.p1.1.m1.1.1.3">𝑜</ci><ci id="A3.p1.1.m1.1.1.4.cmml" xref="A3.p1.1.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A3.p1.1.m1.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A3.p1.4.2" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="A3.p1.2.m2.1"><semantics id="A3.p1.2.m2.1a"><mrow id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml"><mi id="A3.p1.2.m2.1.1.2" mathsize="90%" xref="A3.p1.2.m2.1.1.2.cmml">R</mi><mo id="A3.p1.2.m2.1.1.1" xref="A3.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A3.p1.2.m2.1.1.3" mathsize="90%" xref="A3.p1.2.m2.1.1.3.cmml">C</mi><mo id="A3.p1.2.m2.1.1.1a" xref="A3.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A3.p1.2.m2.1.1.4" mathsize="90%" xref="A3.p1.2.m2.1.1.4.cmml">o</mi><mo id="A3.p1.2.m2.1.1.1b" xref="A3.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="A3.p1.2.m2.1.1.5" mathsize="90%" xref="A3.p1.2.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><apply id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1"><times id="A3.p1.2.m2.1.1.1.cmml" xref="A3.p1.2.m2.1.1.1"></times><ci id="A3.p1.2.m2.1.1.2.cmml" xref="A3.p1.2.m2.1.1.2">𝑅</ci><ci id="A3.p1.2.m2.1.1.3.cmml" xref="A3.p1.2.m2.1.1.3">𝐶</ci><ci id="A3.p1.2.m2.1.1.4.cmml" xref="A3.p1.2.m2.1.1.4">𝑜</ci><ci id="A3.p1.2.m2.1.1.5.cmml" xref="A3.p1.2.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A3.p1.2.m2.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A3.p1.4.3" style="font-size:90%;"> filters. Tables </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T9" style="font-size:90%;" title="Table 9 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">9</span></a><span class="ltx_text" id="A3.p1.4.4" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T10" style="font-size:90%;" title="Table 10 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">10</span></a><span class="ltx_text" id="A3.p1.4.5" style="font-size:90%;">, and </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T11" style="font-size:90%;" title="Table 11 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text" id="A3.p1.4.6" style="font-size:90%;"> collectively demonstrate the impact of our proposed approach. Distinct from the MFM method, which employs static and conventional low/high-pass filters, </span><math alttext="Com" class="ltx_Math" display="inline" id="A3.p1.3.m3.1"><semantics id="A3.p1.3.m3.1a"><mrow id="A3.p1.3.m3.1.1" xref="A3.p1.3.m3.1.1.cmml"><mi id="A3.p1.3.m3.1.1.2" mathsize="90%" xref="A3.p1.3.m3.1.1.2.cmml">C</mi><mo id="A3.p1.3.m3.1.1.1" xref="A3.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="A3.p1.3.m3.1.1.3" mathsize="90%" xref="A3.p1.3.m3.1.1.3.cmml">o</mi><mo id="A3.p1.3.m3.1.1.1a" xref="A3.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="A3.p1.3.m3.1.1.4" mathsize="90%" xref="A3.p1.3.m3.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.3.m3.1b"><apply id="A3.p1.3.m3.1.1.cmml" xref="A3.p1.3.m3.1.1"><times id="A3.p1.3.m3.1.1.1.cmml" xref="A3.p1.3.m3.1.1.1"></times><ci id="A3.p1.3.m3.1.1.2.cmml" xref="A3.p1.3.m3.1.1.2">𝐶</ci><ci id="A3.p1.3.m3.1.1.3.cmml" xref="A3.p1.3.m3.1.1.3">𝑜</ci><ci id="A3.p1.3.m3.1.1.4.cmml" xref="A3.p1.3.m3.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.3.m3.1c">Com</annotation><annotation encoding="application/x-llamapun" id="A3.p1.3.m3.1d">italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A3.p1.4.7" style="font-size:90%;"> and </span><math alttext="RCom" class="ltx_Math" display="inline" id="A3.p1.4.m4.1"><semantics id="A3.p1.4.m4.1a"><mrow id="A3.p1.4.m4.1.1" xref="A3.p1.4.m4.1.1.cmml"><mi id="A3.p1.4.m4.1.1.2" mathsize="90%" xref="A3.p1.4.m4.1.1.2.cmml">R</mi><mo id="A3.p1.4.m4.1.1.1" xref="A3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="A3.p1.4.m4.1.1.3" mathsize="90%" xref="A3.p1.4.m4.1.1.3.cmml">C</mi><mo id="A3.p1.4.m4.1.1.1a" xref="A3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="A3.p1.4.m4.1.1.4" mathsize="90%" xref="A3.p1.4.m4.1.1.4.cmml">o</mi><mo id="A3.p1.4.m4.1.1.1b" xref="A3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="A3.p1.4.m4.1.1.5" mathsize="90%" xref="A3.p1.4.m4.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.4.m4.1b"><apply id="A3.p1.4.m4.1.1.cmml" xref="A3.p1.4.m4.1.1"><times id="A3.p1.4.m4.1.1.1.cmml" xref="A3.p1.4.m4.1.1.1"></times><ci id="A3.p1.4.m4.1.1.2.cmml" xref="A3.p1.4.m4.1.1.2">𝑅</ci><ci id="A3.p1.4.m4.1.1.3.cmml" xref="A3.p1.4.m4.1.1.3">𝐶</ci><ci id="A3.p1.4.m4.1.1.4.cmml" xref="A3.p1.4.m4.1.1.4">𝑜</ci><ci id="A3.p1.4.m4.1.1.5.cmml" xref="A3.p1.4.m4.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.4.m4.1c">RCom</annotation><annotation encoding="application/x-llamapun" id="A3.p1.4.m4.1d">italic_R italic_C italic_o italic_m</annotation></semantics></math><span class="ltx_text" id="A3.p1.4.8" style="font-size:90%;"> filters are dynamic and tailored to each image. This adaptability allows the filters to change in response to an image’s unique concept and structural characteristics, offering a more nuanced and effective processing method. In addition, Tables </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T9" style="font-size:90%;" title="Table 9 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">9</span></a><span class="ltx_text" id="A3.p1.4.9" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T10" style="font-size:90%;" title="Table 10 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">10</span></a><span class="ltx_text" id="A3.p1.4.10" style="font-size:90%;">, and </span><a class="ltx_ref" href="https://arxiv.org/html/2409.10362v1#A3.T11" style="font-size:90%;" title="Table 11 ‣ Appendix C Prediction Visualization ‣ Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning"><span class="ltx_text ltx_ref_tag">11</span></a><span class="ltx_text" id="A3.p1.4.11" style="font-size:90%;"> also show the reconstructed missing frequencies for each image, generated by the FOLK pre-trained model. The clear alignments between the model predicted and the ground-truth masked frequencies provide further evidence for the successful pre-training of FOLK and, therefore the improved model efficacy.</span></p>
</div>
<figure class="ltx_table" id="A3.T9">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T9.40">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T9.40.41.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A3.T9.40.41.1.1"><span class="ltx_text ltx_font_bold" id="A3.T9.40.41.1.1.1" style="font-size:90%;">Original Image</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T9.40.41.1.2"><span class="ltx_text ltx_font_bold" id="A3.T9.40.41.1.2.1" style="font-size:90%;">Frequency</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A3.T9.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T9.1.1.1.g1" src="extracted/5858280/images/1/org.png" width="167"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T9.2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T9.2.2.2.g1" src="extracted/5858280/images/1/freq.png" width="167"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.40.42.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.42.2.1"><span class="ltx_text" id="A3.T9.40.42.2.1.1" style="font-size:90%;">Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.42.2.2"><span class="ltx_text" id="A3.T9.40.42.2.2.1" style="font-size:90%;">Com Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.42.2.3"><span class="ltx_text" id="A3.T9.40.42.2.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.42.2.4"><span class="ltx_text" id="A3.T9.40.42.2.4.1" style="font-size:90%;">Predicted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.42.2.5"><span class="ltx_text" id="A3.T9.40.42.2.5.1" style="font-size:90%;">RCom Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.42.2.6"><span class="ltx_text" id="A3.T9.40.42.2.6.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.40.42.2.7"><span class="ltx_text" id="A3.T9.40.42.2.7.1" style="font-size:90%;">Predicted</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.8.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.8.8.7"><span class="ltx_text" id="A3.T9.8.8.7.1" style="font-size:90%;">.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.3.3.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.3.3.1.g1" src="extracted/5858280/images/1/freq_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.4.4.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.4.4.2.g1" src="extracted/5858280/images/1/org_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.5.5.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.5.5.3.g1" src="extracted/5858280/images/1/_out_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.6.6.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.6.6.4.g1" src="extracted/5858280/images/1/freq_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.7.7.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.7.7.5.g1" src="extracted/5858280/images/1/org_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.8.8.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.8.8.6.g1" src="extracted/5858280/images/1/_out_50_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.14.14">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.14.14.7"><span class="ltx_text" id="A3.T9.14.14.7.1" style="font-size:90%;">.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.9.9.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.9.9.1.g1" src="extracted/5858280/images/1/freq_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.10.10.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.10.10.2.g1" src="extracted/5858280/images/1/org_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.11.11.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.11.11.3.g1" src="extracted/5858280/images/1/_out_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.12.12.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.12.12.4.g1" src="extracted/5858280/images/1/freq_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.13.13.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.13.13.5.g1" src="extracted/5858280/images/1/org_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.14.14.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.14.14.6.g1" src="extracted/5858280/images/1/_out_10_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.20.20">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.20.20.7"><span class="ltx_text" id="A3.T9.20.20.7.1" style="font-size:90%;">.005</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.15.15.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.15.15.1.g1" src="extracted/5858280/images/1/freq_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.16.16.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.16.16.2.g1" src="extracted/5858280/images/1/org_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.17.17.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.17.17.3.g1" src="extracted/5858280/images/1/_out_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.18.18.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.18.18.4.g1" src="extracted/5858280/images/1/freq_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.19.19.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.19.19.5.g1" src="extracted/5858280/images/1/org_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.20.20.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.20.20.6.g1" src="extracted/5858280/images/1/_out_5_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.22.22">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" id="A3.T9.21.21.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T9.21.21.1.g1" src="extracted/5858280/images/2/org.png" width="167"/></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A3.T9.22.22.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T9.22.22.2.g1" src="extracted/5858280/images/2/freq.png" width="167"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.40.43.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.43.3.1"><span class="ltx_text" id="A3.T9.40.43.3.1.1" style="font-size:90%;">Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.43.3.2"><span class="ltx_text" id="A3.T9.40.43.3.2.1" style="font-size:90%;">Com Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.43.3.3"><span class="ltx_text" id="A3.T9.40.43.3.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.43.3.4"><span class="ltx_text" id="A3.T9.40.43.3.4.1" style="font-size:90%;">Predicted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.43.3.5"><span class="ltx_text" id="A3.T9.40.43.3.5.1" style="font-size:90%;">RCom Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.40.43.3.6"><span class="ltx_text" id="A3.T9.40.43.3.6.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.40.43.3.7"><span class="ltx_text" id="A3.T9.40.43.3.7.1" style="font-size:90%;">Predicted</span></td>
</tr>
<tr class="ltx_tr" id="A3.T9.28.28">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.28.28.7"><span class="ltx_text" id="A3.T9.28.28.7.1" style="font-size:90%;">.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.23.23.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.23.23.1.g1" src="extracted/5858280/images/2/freq_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.24.24.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.24.24.2.g1" src="extracted/5858280/images/2/org_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.25.25.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.25.25.3.g1" src="extracted/5858280/images/2/_out_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.26.26.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.26.26.4.g1" src="extracted/5858280/images/2/freq_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.27.27.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.27.27.5.g1" src="extracted/5858280/images/2/org_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.28.28.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.28.28.6.g1" src="extracted/5858280/images/2/_out_50_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.34.34">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.34.34.7"><span class="ltx_text" id="A3.T9.34.34.7.1" style="font-size:90%;">.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.29.29.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.29.29.1.g1" src="extracted/5858280/images/2/freq_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.30.30.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.30.30.2.g1" src="extracted/5858280/images/2/org_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.31.31.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.31.31.3.g1" src="extracted/5858280/images/2/_out_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.32.32.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.32.32.4.g1" src="extracted/5858280/images/2/freq_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T9.33.33.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.33.33.5.g1" src="extracted/5858280/images/2/org_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.34.34.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.34.34.6.g1" src="extracted/5858280/images/2/_out_10_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T9.40.40">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T9.40.40.7"><span class="ltx_text" id="A3.T9.40.40.7.1" style="font-size:90%;">.005</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T9.35.35.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.35.35.1.g1" src="extracted/5858280/images/2/freq_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T9.36.36.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.36.36.2.g1" src="extracted/5858280/images/2/org_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T9.37.37.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.37.37.3.g1" src="extracted/5858280/images/2/_out_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T9.38.38.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.38.38.4.g1" src="extracted/5858280/images/2/freq_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T9.39.39.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.39.39.5.g1" src="extracted/5858280/images/2/org_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T9.40.40.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T9.40.40.6.g1" src="extracted/5858280/images/2/_out_5_m.png" width="50"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 9: </span>The effect of applying <math alttext="Com" class="ltx_Math" display="inline" id="A3.T9.43.m1.1"><semantics id="A3.T9.43.m1.1b"><mrow id="A3.T9.43.m1.1.1" xref="A3.T9.43.m1.1.1.cmml"><mi id="A3.T9.43.m1.1.1.2" xref="A3.T9.43.m1.1.1.2.cmml">C</mi><mo id="A3.T9.43.m1.1.1.1" xref="A3.T9.43.m1.1.1.1.cmml">⁢</mo><mi id="A3.T9.43.m1.1.1.3" xref="A3.T9.43.m1.1.1.3.cmml">o</mi><mo id="A3.T9.43.m1.1.1.1b" xref="A3.T9.43.m1.1.1.1.cmml">⁢</mo><mi id="A3.T9.43.m1.1.1.4" xref="A3.T9.43.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T9.43.m1.1c"><apply id="A3.T9.43.m1.1.1.cmml" xref="A3.T9.43.m1.1.1"><times id="A3.T9.43.m1.1.1.1.cmml" xref="A3.T9.43.m1.1.1.1"></times><ci id="A3.T9.43.m1.1.1.2.cmml" xref="A3.T9.43.m1.1.1.2">𝐶</ci><ci id="A3.T9.43.m1.1.1.3.cmml" xref="A3.T9.43.m1.1.1.3">𝑜</ci><ci id="A3.T9.43.m1.1.1.4.cmml" xref="A3.T9.43.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.43.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="A3.T9.43.m1.1e">italic_C italic_o italic_m</annotation></semantics></math> and <math alttext="RCom" class="ltx_Math" display="inline" id="A3.T9.44.m2.1"><semantics id="A3.T9.44.m2.1b"><mrow id="A3.T9.44.m2.1.1" xref="A3.T9.44.m2.1.1.cmml"><mi id="A3.T9.44.m2.1.1.2" xref="A3.T9.44.m2.1.1.2.cmml">R</mi><mo id="A3.T9.44.m2.1.1.1" xref="A3.T9.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T9.44.m2.1.1.3" xref="A3.T9.44.m2.1.1.3.cmml">C</mi><mo id="A3.T9.44.m2.1.1.1b" xref="A3.T9.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T9.44.m2.1.1.4" xref="A3.T9.44.m2.1.1.4.cmml">o</mi><mo id="A3.T9.44.m2.1.1.1c" xref="A3.T9.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T9.44.m2.1.1.5" xref="A3.T9.44.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T9.44.m2.1c"><apply id="A3.T9.44.m2.1.1.cmml" xref="A3.T9.44.m2.1.1"><times id="A3.T9.44.m2.1.1.1.cmml" xref="A3.T9.44.m2.1.1.1"></times><ci id="A3.T9.44.m2.1.1.2.cmml" xref="A3.T9.44.m2.1.1.2">𝑅</ci><ci id="A3.T9.44.m2.1.1.3.cmml" xref="A3.T9.44.m2.1.1.3">𝐶</ci><ci id="A3.T9.44.m2.1.1.4.cmml" xref="A3.T9.44.m2.1.1.4">𝑜</ci><ci id="A3.T9.44.m2.1.1.5.cmml" xref="A3.T9.44.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T9.44.m2.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="A3.T9.44.m2.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> filters to different images, and the predicted missing frequencies by the FOLK pre-trained model. Rate means the rate of compression (between 0 and 1).</figcaption>
</figure>
<figure class="ltx_table" id="A3.T10">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T10.40">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T10.40.41.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A3.T10.40.41.1.1"><span class="ltx_text ltx_font_bold" id="A3.T10.40.41.1.1.1" style="font-size:90%;">Original Image</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T10.40.41.1.2"><span class="ltx_text ltx_font_bold" id="A3.T10.40.41.1.2.1" style="font-size:90%;">Frequency</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A3.T10.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T10.1.1.1.g1" src="extracted/5858280/images/3/org.png" width="167"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T10.2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T10.2.2.2.g1" src="extracted/5858280/images/3/freq.png" width="167"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.40.42.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.42.2.1"><span class="ltx_text" id="A3.T10.40.42.2.1.1" style="font-size:90%;">Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.42.2.2"><span class="ltx_text" id="A3.T10.40.42.2.2.1" style="font-size:90%;">Com Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.42.2.3"><span class="ltx_text" id="A3.T10.40.42.2.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.42.2.4"><span class="ltx_text" id="A3.T10.40.42.2.4.1" style="font-size:90%;">Predicted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.42.2.5"><span class="ltx_text" id="A3.T10.40.42.2.5.1" style="font-size:90%;">RCom Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.42.2.6"><span class="ltx_text" id="A3.T10.40.42.2.6.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.40.42.2.7"><span class="ltx_text" id="A3.T10.40.42.2.7.1" style="font-size:90%;">Predicted</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.8.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.8.8.7"><span class="ltx_text" id="A3.T10.8.8.7.1" style="font-size:90%;">.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.3.3.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.3.3.1.g1" src="extracted/5858280/images/3/freq_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.4.4.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.4.4.2.g1" src="extracted/5858280/images/3/org_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.5.5.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.5.5.3.g1" src="extracted/5858280/images/3/_out_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.6.6.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.6.6.4.g1" src="extracted/5858280/images/3/freq_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.7.7.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.7.7.5.g1" src="extracted/5858280/images/3/org_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.8.8.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.8.8.6.g1" src="extracted/5858280/images/3/_out_50_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.14.14">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.14.14.7"><span class="ltx_text" id="A3.T10.14.14.7.1" style="font-size:90%;">.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.9.9.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.9.9.1.g1" src="extracted/5858280/images/3/freq_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.10.10.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.10.10.2.g1" src="extracted/5858280/images/3/org_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.11.11.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.11.11.3.g1" src="extracted/5858280/images/3/_out_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.12.12.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.12.12.4.g1" src="extracted/5858280/images/3/freq_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.13.13.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.13.13.5.g1" src="extracted/5858280/images/3/org_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.14.14.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.14.14.6.g1" src="extracted/5858280/images/3/_out_10_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.20.20">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.20.20.7"><span class="ltx_text" id="A3.T10.20.20.7.1" style="font-size:90%;">.005</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.15.15.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.15.15.1.g1" src="extracted/5858280/images/3/freq_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.16.16.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.16.16.2.g1" src="extracted/5858280/images/3/org_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.17.17.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.17.17.3.g1" src="extracted/5858280/images/3/_out_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.18.18.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.18.18.4.g1" src="extracted/5858280/images/3/freq_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.19.19.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.19.19.5.g1" src="extracted/5858280/images/3/org_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.20.20.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.20.20.6.g1" src="extracted/5858280/images/3/_out_5_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.22.22">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" id="A3.T10.21.21.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T10.21.21.1.g1" src="extracted/5858280/images/4/org.png" width="167"/></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A3.T10.22.22.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T10.22.22.2.g1" src="extracted/5858280/images/4/freq.png" width="167"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.40.43.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.43.3.1"><span class="ltx_text" id="A3.T10.40.43.3.1.1" style="font-size:90%;">Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.43.3.2"><span class="ltx_text" id="A3.T10.40.43.3.2.1" style="font-size:90%;">Com Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.43.3.3"><span class="ltx_text" id="A3.T10.40.43.3.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.43.3.4"><span class="ltx_text" id="A3.T10.40.43.3.4.1" style="font-size:90%;">Predicted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.43.3.5"><span class="ltx_text" id="A3.T10.40.43.3.5.1" style="font-size:90%;">RCom Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.40.43.3.6"><span class="ltx_text" id="A3.T10.40.43.3.6.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.40.43.3.7"><span class="ltx_text" id="A3.T10.40.43.3.7.1" style="font-size:90%;">Predicted</span></td>
</tr>
<tr class="ltx_tr" id="A3.T10.28.28">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.28.28.7"><span class="ltx_text" id="A3.T10.28.28.7.1" style="font-size:90%;">.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.23.23.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.23.23.1.g1" src="extracted/5858280/images/4/freq_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.24.24.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.24.24.2.g1" src="extracted/5858280/images/4/org_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.25.25.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.25.25.3.g1" src="extracted/5858280/images/4/_out_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.26.26.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.26.26.4.g1" src="extracted/5858280/images/4/freq_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.27.27.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.27.27.5.g1" src="extracted/5858280/images/4/org_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.28.28.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.28.28.6.g1" src="extracted/5858280/images/4/_out_50_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.34.34">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.34.34.7"><span class="ltx_text" id="A3.T10.34.34.7.1" style="font-size:90%;">.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.29.29.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.29.29.1.g1" src="extracted/5858280/images/4/freq_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.30.30.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.30.30.2.g1" src="extracted/5858280/images/4/org_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.31.31.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.31.31.3.g1" src="extracted/5858280/images/4/_out_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.32.32.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.32.32.4.g1" src="extracted/5858280/images/4/freq_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T10.33.33.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.33.33.5.g1" src="extracted/5858280/images/4/org_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.34.34.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.34.34.6.g1" src="extracted/5858280/images/4/_out_10_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T10.40.40">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T10.40.40.7"><span class="ltx_text" id="A3.T10.40.40.7.1" style="font-size:90%;">.005</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T10.35.35.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.35.35.1.g1" src="extracted/5858280/images/4/freq_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T10.36.36.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.36.36.2.g1" src="extracted/5858280/images/4/org_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T10.37.37.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.37.37.3.g1" src="extracted/5858280/images/4/_out_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T10.38.38.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.38.38.4.g1" src="extracted/5858280/images/4/freq_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T10.39.39.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.39.39.5.g1" src="extracted/5858280/images/4/org_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T10.40.40.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T10.40.40.6.g1" src="extracted/5858280/images/4/_out_5_m.png" width="50"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 10: </span>The effect of applying <math alttext="Com" class="ltx_Math" display="inline" id="A3.T10.43.m1.1"><semantics id="A3.T10.43.m1.1b"><mrow id="A3.T10.43.m1.1.1" xref="A3.T10.43.m1.1.1.cmml"><mi id="A3.T10.43.m1.1.1.2" xref="A3.T10.43.m1.1.1.2.cmml">C</mi><mo id="A3.T10.43.m1.1.1.1" xref="A3.T10.43.m1.1.1.1.cmml">⁢</mo><mi id="A3.T10.43.m1.1.1.3" xref="A3.T10.43.m1.1.1.3.cmml">o</mi><mo id="A3.T10.43.m1.1.1.1b" xref="A3.T10.43.m1.1.1.1.cmml">⁢</mo><mi id="A3.T10.43.m1.1.1.4" xref="A3.T10.43.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T10.43.m1.1c"><apply id="A3.T10.43.m1.1.1.cmml" xref="A3.T10.43.m1.1.1"><times id="A3.T10.43.m1.1.1.1.cmml" xref="A3.T10.43.m1.1.1.1"></times><ci id="A3.T10.43.m1.1.1.2.cmml" xref="A3.T10.43.m1.1.1.2">𝐶</ci><ci id="A3.T10.43.m1.1.1.3.cmml" xref="A3.T10.43.m1.1.1.3">𝑜</ci><ci id="A3.T10.43.m1.1.1.4.cmml" xref="A3.T10.43.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.43.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="A3.T10.43.m1.1e">italic_C italic_o italic_m</annotation></semantics></math> and <math alttext="RCom" class="ltx_Math" display="inline" id="A3.T10.44.m2.1"><semantics id="A3.T10.44.m2.1b"><mrow id="A3.T10.44.m2.1.1" xref="A3.T10.44.m2.1.1.cmml"><mi id="A3.T10.44.m2.1.1.2" xref="A3.T10.44.m2.1.1.2.cmml">R</mi><mo id="A3.T10.44.m2.1.1.1" xref="A3.T10.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T10.44.m2.1.1.3" xref="A3.T10.44.m2.1.1.3.cmml">C</mi><mo id="A3.T10.44.m2.1.1.1b" xref="A3.T10.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T10.44.m2.1.1.4" xref="A3.T10.44.m2.1.1.4.cmml">o</mi><mo id="A3.T10.44.m2.1.1.1c" xref="A3.T10.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T10.44.m2.1.1.5" xref="A3.T10.44.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T10.44.m2.1c"><apply id="A3.T10.44.m2.1.1.cmml" xref="A3.T10.44.m2.1.1"><times id="A3.T10.44.m2.1.1.1.cmml" xref="A3.T10.44.m2.1.1.1"></times><ci id="A3.T10.44.m2.1.1.2.cmml" xref="A3.T10.44.m2.1.1.2">𝑅</ci><ci id="A3.T10.44.m2.1.1.3.cmml" xref="A3.T10.44.m2.1.1.3">𝐶</ci><ci id="A3.T10.44.m2.1.1.4.cmml" xref="A3.T10.44.m2.1.1.4">𝑜</ci><ci id="A3.T10.44.m2.1.1.5.cmml" xref="A3.T10.44.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T10.44.m2.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="A3.T10.44.m2.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> filters to different images, and the predicted missing frequencies by the FOLK pre-trained model. Rate means the rate of compression (between 0 and 1).</figcaption>
</figure>
<figure class="ltx_table" id="A3.T11">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T11.40">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T11.40.41.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A3.T11.40.41.1.1"><span class="ltx_text ltx_font_bold" id="A3.T11.40.41.1.1.1" style="font-size:90%;">Original Image</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T11.40.41.1.2"><span class="ltx_text ltx_font_bold" id="A3.T11.40.41.1.2.1" style="font-size:90%;">Frequency</span></td>
</tr>
<tr class="ltx_tr" id="A3.T11.2.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A3.T11.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T11.1.1.1.g1" src="extracted/5858280/images/5/org.png" width="167"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T11.2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T11.2.2.2.g1" src="extracted/5858280/images/5/freq.png" width="167"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.40.42.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.42.2.1"><span class="ltx_text" id="A3.T11.40.42.2.1.1" style="font-size:90%;">Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.42.2.2"><span class="ltx_text" id="A3.T11.40.42.2.2.1" style="font-size:90%;">Com Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.42.2.3"><span class="ltx_text" id="A3.T11.40.42.2.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.42.2.4"><span class="ltx_text" id="A3.T11.40.42.2.4.1" style="font-size:90%;">Predicted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.42.2.5"><span class="ltx_text" id="A3.T11.40.42.2.5.1" style="font-size:90%;">RCom Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.42.2.6"><span class="ltx_text" id="A3.T11.40.42.2.6.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.40.42.2.7"><span class="ltx_text" id="A3.T11.40.42.2.7.1" style="font-size:90%;">Predicted</span></td>
</tr>
<tr class="ltx_tr" id="A3.T11.8.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.8.8.7"><span class="ltx_text" id="A3.T11.8.8.7.1" style="font-size:90%;">.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.3.3.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.3.3.1.g1" src="extracted/5858280/images/5/freq_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.4.4.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.4.4.2.g1" src="extracted/5858280/images/5/org_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.5.5.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.5.5.3.g1" src="extracted/5858280/images/5/_out_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.6.6.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.6.6.4.g1" src="extracted/5858280/images/5/freq_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.7.7.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.7.7.5.g1" src="extracted/5858280/images/5/org_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.8.8.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.8.8.6.g1" src="extracted/5858280/images/5/_out_50_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.14.14">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.14.14.7"><span class="ltx_text" id="A3.T11.14.14.7.1" style="font-size:90%;">.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.9.9.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.9.9.1.g1" src="extracted/5858280/images/5/freq_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.10.10.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.10.10.2.g1" src="extracted/5858280/images/5/org_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.11.11.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.11.11.3.g1" src="extracted/5858280/images/5/_out_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.12.12.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.12.12.4.g1" src="extracted/5858280/images/5/freq_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.13.13.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.13.13.5.g1" src="extracted/5858280/images/5/org_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.14.14.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.14.14.6.g1" src="extracted/5858280/images/5/_out_10_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.20.20">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.20.20.7"><span class="ltx_text" id="A3.T11.20.20.7.1" style="font-size:90%;">.005</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.15.15.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.15.15.1.g1" src="extracted/5858280/images/5/freq_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.16.16.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.16.16.2.g1" src="extracted/5858280/images/5/org_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.17.17.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.17.17.3.g1" src="extracted/5858280/images/5/_out_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.18.18.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.18.18.4.g1" src="extracted/5858280/images/5/freq_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.19.19.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.19.19.5.g1" src="extracted/5858280/images/5/org_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.20.20.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.20.20.6.g1" src="extracted/5858280/images/5/_out_5_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.22.22">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" id="A3.T11.21.21.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T11.21.21.1.g1" src="extracted/5858280/images/6/org.png" width="167"/></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A3.T11.22.22.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="167" id="A3.T11.22.22.2.g1" src="extracted/5858280/images/6/freq.png" width="167"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.40.43.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.43.3.1"><span class="ltx_text" id="A3.T11.40.43.3.1.1" style="font-size:90%;">Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.43.3.2"><span class="ltx_text" id="A3.T11.40.43.3.2.1" style="font-size:90%;">Com Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.43.3.3"><span class="ltx_text" id="A3.T11.40.43.3.3.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.43.3.4"><span class="ltx_text" id="A3.T11.40.43.3.4.1" style="font-size:90%;">Predicted</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.43.3.5"><span class="ltx_text" id="A3.T11.40.43.3.5.1" style="font-size:90%;">RCom Masked</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.40.43.3.6"><span class="ltx_text" id="A3.T11.40.43.3.6.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.40.43.3.7"><span class="ltx_text" id="A3.T11.40.43.3.7.1" style="font-size:90%;">Predicted</span></td>
</tr>
<tr class="ltx_tr" id="A3.T11.28.28">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.28.28.7"><span class="ltx_text" id="A3.T11.28.28.7.1" style="font-size:90%;">.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.23.23.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.23.23.1.g1" src="extracted/5858280/images/6/freq_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.24.24.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.24.24.2.g1" src="extracted/5858280/images/6/org_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.25.25.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.25.25.3.g1" src="extracted/5858280/images/6/_out_50.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.26.26.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.26.26.4.g1" src="extracted/5858280/images/6/freq_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.27.27.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.27.27.5.g1" src="extracted/5858280/images/6/org_50_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.28.28.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.28.28.6.g1" src="extracted/5858280/images/6/_out_50_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.34.34">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.34.34.7"><span class="ltx_text" id="A3.T11.34.34.7.1" style="font-size:90%;">.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.29.29.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.29.29.1.g1" src="extracted/5858280/images/6/freq_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.30.30.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.30.30.2.g1" src="extracted/5858280/images/6/org_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.31.31.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.31.31.3.g1" src="extracted/5858280/images/6/_out_10.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.32.32.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.32.32.4.g1" src="extracted/5858280/images/6/freq_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T11.33.33.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.33.33.5.g1" src="extracted/5858280/images/6/org_10_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.34.34.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.34.34.6.g1" src="extracted/5858280/images/6/_out_10_m.png" width="50"/></td>
</tr>
<tr class="ltx_tr" id="A3.T11.40.40">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T11.40.40.7"><span class="ltx_text" id="A3.T11.40.40.7.1" style="font-size:90%;">.005</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T11.35.35.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.35.35.1.g1" src="extracted/5858280/images/6/freq_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T11.36.36.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.36.36.2.g1" src="extracted/5858280/images/6/org_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T11.37.37.3"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.37.37.3.g1" src="extracted/5858280/images/6/_out_5.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T11.38.38.4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.38.38.4.g1" src="extracted/5858280/images/6/freq_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A3.T11.39.39.5"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.39.39.5.g1" src="extracted/5858280/images/6/org_5_m.png" width="50"/></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A3.T11.40.40.6"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="50" id="A3.T11.40.40.6.g1" src="extracted/5858280/images/6/_out_5_m.png" width="50"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 11: </span>The effect of applying <math alttext="Com" class="ltx_Math" display="inline" id="A3.T11.43.m1.1"><semantics id="A3.T11.43.m1.1b"><mrow id="A3.T11.43.m1.1.1" xref="A3.T11.43.m1.1.1.cmml"><mi id="A3.T11.43.m1.1.1.2" xref="A3.T11.43.m1.1.1.2.cmml">C</mi><mo id="A3.T11.43.m1.1.1.1" xref="A3.T11.43.m1.1.1.1.cmml">⁢</mo><mi id="A3.T11.43.m1.1.1.3" xref="A3.T11.43.m1.1.1.3.cmml">o</mi><mo id="A3.T11.43.m1.1.1.1b" xref="A3.T11.43.m1.1.1.1.cmml">⁢</mo><mi id="A3.T11.43.m1.1.1.4" xref="A3.T11.43.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.43.m1.1c"><apply id="A3.T11.43.m1.1.1.cmml" xref="A3.T11.43.m1.1.1"><times id="A3.T11.43.m1.1.1.1.cmml" xref="A3.T11.43.m1.1.1.1"></times><ci id="A3.T11.43.m1.1.1.2.cmml" xref="A3.T11.43.m1.1.1.2">𝐶</ci><ci id="A3.T11.43.m1.1.1.3.cmml" xref="A3.T11.43.m1.1.1.3">𝑜</ci><ci id="A3.T11.43.m1.1.1.4.cmml" xref="A3.T11.43.m1.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.43.m1.1d">Com</annotation><annotation encoding="application/x-llamapun" id="A3.T11.43.m1.1e">italic_C italic_o italic_m</annotation></semantics></math> and <math alttext="RCom" class="ltx_Math" display="inline" id="A3.T11.44.m2.1"><semantics id="A3.T11.44.m2.1b"><mrow id="A3.T11.44.m2.1.1" xref="A3.T11.44.m2.1.1.cmml"><mi id="A3.T11.44.m2.1.1.2" xref="A3.T11.44.m2.1.1.2.cmml">R</mi><mo id="A3.T11.44.m2.1.1.1" xref="A3.T11.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T11.44.m2.1.1.3" xref="A3.T11.44.m2.1.1.3.cmml">C</mi><mo id="A3.T11.44.m2.1.1.1b" xref="A3.T11.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T11.44.m2.1.1.4" xref="A3.T11.44.m2.1.1.4.cmml">o</mi><mo id="A3.T11.44.m2.1.1.1c" xref="A3.T11.44.m2.1.1.1.cmml">⁢</mo><mi id="A3.T11.44.m2.1.1.5" xref="A3.T11.44.m2.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.44.m2.1c"><apply id="A3.T11.44.m2.1.1.cmml" xref="A3.T11.44.m2.1.1"><times id="A3.T11.44.m2.1.1.1.cmml" xref="A3.T11.44.m2.1.1.1"></times><ci id="A3.T11.44.m2.1.1.2.cmml" xref="A3.T11.44.m2.1.1.2">𝑅</ci><ci id="A3.T11.44.m2.1.1.3.cmml" xref="A3.T11.44.m2.1.1.3">𝐶</ci><ci id="A3.T11.44.m2.1.1.4.cmml" xref="A3.T11.44.m2.1.1.4">𝑜</ci><ci id="A3.T11.44.m2.1.1.5.cmml" xref="A3.T11.44.m2.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.44.m2.1d">RCom</annotation><annotation encoding="application/x-llamapun" id="A3.T11.44.m2.1e">italic_R italic_C italic_o italic_m</annotation></semantics></math> filters to different images, and the predicted missing frequencies by the FOLK pre-trained model. Rate means the rate of compression (between 0 and 1).</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Sep 16 15:05:24 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
